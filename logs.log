2024-04-23 20:01:49,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:01:49,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:01:49,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:01:49,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:04:30,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:04:30,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:04:30,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:04:30,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:09:08,643:INFO:PyCaret ClassificationExperiment
2024-04-23 20:09:08,643:INFO:Logging name: clf-default-name
2024-04-23 20:09:08,643:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-23 20:09:08,643:INFO:version 3.1.0
2024-04-23 20:09:08,643:INFO:Initializing setup()
2024-04-23 20:09:08,643:INFO:self.USI: 4fd9
2024-04-23 20:09:08,643:INFO:self._variable_keys: {'_ml_usecase', 'logging_param', 'is_multiclass', 'fold_groups_param', 'X_test', 'y', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'exp_name_log', 'fix_imbalance', 'X', 'pipeline', 'X_train', 'y_test', 'fold_generator', 'memory', 'target_param', 'gpu_n_jobs_param', 'exp_id', 'gpu_param', 'log_plots_param', 'idx', 'n_jobs_param', 'USI', 'y_train', 'html_param'}
2024-04-23 20:09:08,643:INFO:Checking environment
2024-04-23 20:09:08,643:INFO:python_version: 3.10.0
2024-04-23 20:09:08,643:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-23 20:09:08,643:INFO:machine: AMD64
2024-04-23 20:09:08,651:INFO:platform: Windows-10-10.0.19045-SP0
2024-04-23 20:09:08,654:INFO:Memory: svmem(total=17041117184, available=7162732544, percent=58.0, used=9878384640, free=7162732544)
2024-04-23 20:09:08,654:INFO:Physical Core: 6
2024-04-23 20:09:08,654:INFO:Logical Core: 12
2024-04-23 20:09:08,654:INFO:Checking libraries
2024-04-23 20:09:08,655:INFO:System:
2024-04-23 20:09:08,655:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-23 20:09:08,655:INFO:executable: C:\Users\User\AppData\Local\Programs\Python\Python310\python.exe
2024-04-23 20:09:08,655:INFO:   machine: Windows-10-10.0.19045-SP0
2024-04-23 20:09:08,655:INFO:PyCaret required dependencies:
2024-04-23 20:09:08,741:INFO:                 pip: 21.2.3
2024-04-23 20:09:08,742:INFO:          setuptools: 57.4.0
2024-04-23 20:09:08,742:INFO:             pycaret: 3.1.0
2024-04-23 20:09:08,742:INFO:             IPython: 8.17.2
2024-04-23 20:09:08,742:INFO:          ipywidgets: 8.1.1
2024-04-23 20:09:08,742:INFO:                tqdm: 4.66.1
2024-04-23 20:09:08,742:INFO:               numpy: 1.25.2
2024-04-23 20:09:08,742:INFO:              pandas: 2.0.3
2024-04-23 20:09:08,742:INFO:              jinja2: 3.1.2
2024-04-23 20:09:08,742:INFO:               scipy: 1.10.1
2024-04-23 20:09:08,742:INFO:              joblib: 1.3.2
2024-04-23 20:09:08,742:INFO:             sklearn: 1.2.2
2024-04-23 20:09:08,742:INFO:                pyod: 1.1.1
2024-04-23 20:09:08,742:INFO:            imblearn: 0.11.0
2024-04-23 20:09:08,742:INFO:   category_encoders: 2.6.3
2024-04-23 20:09:08,742:INFO:            lightgbm: 4.1.0
2024-04-23 20:09:08,742:INFO:               numba: 0.58.1
2024-04-23 20:09:08,742:INFO:            requests: 2.31.0
2024-04-23 20:09:08,742:INFO:          matplotlib: 3.7.3
2024-04-23 20:09:08,742:INFO:          scikitplot: 0.3.7
2024-04-23 20:09:08,742:INFO:         yellowbrick: 1.5
2024-04-23 20:09:08,742:INFO:              plotly: 5.18.0
2024-04-23 20:09:08,742:INFO:    plotly-resampler: Not installed
2024-04-23 20:09:08,742:INFO:             kaleido: 0.2.1
2024-04-23 20:09:08,742:INFO:           schemdraw: 0.15
2024-04-23 20:09:08,742:INFO:         statsmodels: 0.14.0
2024-04-23 20:09:08,743:INFO:              sktime: 0.21.1
2024-04-23 20:09:08,743:INFO:               tbats: 1.1.3
2024-04-23 20:09:08,743:INFO:            pmdarima: 2.0.4
2024-04-23 20:09:08,743:INFO:              psutil: 5.9.6
2024-04-23 20:09:08,743:INFO:          markupsafe: 2.1.3
2024-04-23 20:09:08,743:INFO:             pickle5: Not installed
2024-04-23 20:09:08,743:INFO:         cloudpickle: 3.0.0
2024-04-23 20:09:08,743:INFO:         deprecation: 2.1.0
2024-04-23 20:09:08,743:INFO:              xxhash: 3.4.1
2024-04-23 20:09:08,743:INFO:           wurlitzer: Not installed
2024-04-23 20:09:08,743:INFO:PyCaret optional dependencies:
2024-04-23 20:09:08,756:INFO:                shap: Not installed
2024-04-23 20:09:08,756:INFO:           interpret: Not installed
2024-04-23 20:09:08,756:INFO:                umap: Not installed
2024-04-23 20:09:08,756:INFO:     ydata_profiling: 4.6.1
2024-04-23 20:09:08,756:INFO:  explainerdashboard: Not installed
2024-04-23 20:09:08,756:INFO:             autoviz: Not installed
2024-04-23 20:09:08,756:INFO:           fairlearn: Not installed
2024-04-23 20:09:08,757:INFO:          deepchecks: Not installed
2024-04-23 20:09:08,757:INFO:             xgboost: Not installed
2024-04-23 20:09:08,757:INFO:            catboost: Not installed
2024-04-23 20:09:08,757:INFO:              kmodes: Not installed
2024-04-23 20:09:08,757:INFO:             mlxtend: Not installed
2024-04-23 20:09:08,757:INFO:       statsforecast: Not installed
2024-04-23 20:09:08,757:INFO:        tune_sklearn: Not installed
2024-04-23 20:09:08,757:INFO:                 ray: Not installed
2024-04-23 20:09:08,757:INFO:            hyperopt: Not installed
2024-04-23 20:09:08,757:INFO:              optuna: Not installed
2024-04-23 20:09:08,757:INFO:               skopt: Not installed
2024-04-23 20:09:08,757:INFO:              mlflow: Not installed
2024-04-23 20:09:08,757:INFO:              gradio: Not installed
2024-04-23 20:09:08,757:INFO:             fastapi: Not installed
2024-04-23 20:09:08,757:INFO:             uvicorn: Not installed
2024-04-23 20:09:08,757:INFO:              m2cgen: Not installed
2024-04-23 20:09:08,757:INFO:           evidently: Not installed
2024-04-23 20:09:08,757:INFO:               fugue: Not installed
2024-04-23 20:09:08,757:INFO:           streamlit: 1.28.0
2024-04-23 20:09:08,757:INFO:             prophet: Not installed
2024-04-23 20:09:08,757:INFO:None
2024-04-23 20:09:08,757:INFO:Set up data.
2024-04-23 20:09:08,768:INFO:Set up folding strategy.
2024-04-23 20:09:08,768:INFO:Set up train/test split.
2024-04-23 20:09:08,776:INFO:Set up index.
2024-04-23 20:09:08,776:INFO:Assigning column types.
2024-04-23 20:09:08,779:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-23 20:09:08,826:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:09:08,829:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:09:08,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:08,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:08,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:09:08,913:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:09:08,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:08,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:08,942:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-23 20:09:08,987:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:09:09,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:09:09,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,099:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-23 20:09:09,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,253:INFO:Preparing preprocessing pipeline...
2024-04-23 20:09:09,254:INFO:Set up simple imputation.
2024-04-23 20:09:09,258:INFO:Set up encoding of ordinal features.
2024-04-23 20:09:09,259:INFO:Set up encoding of categorical features.
2024-04-23 20:09:09,416:INFO:Finished creating preprocessing pipeline.
2024-04-23 20:09:09,436:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecate...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-04-23 20:09:09,437:INFO:Creating final display dataframe.
2024-04-23 20:09:09,868:INFO:Setup _display_container:                     Description             Value
0                    Session id               208
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 5
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              4fd9
2024-04-23 20:09:09,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:10,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:10,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:10,023:INFO:setup() successfully completed in 1.39s...............
2024-04-23 20:09:10,026:INFO:Initializing compare_models()
2024-04-23 20:09:10,026:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-23 20:09:10,026:INFO:Checking exceptions
2024-04-23 20:09:10,029:INFO:Preparing display monitor
2024-04-23 20:09:10,037:INFO:Initializing Logistic Regression
2024-04-23 20:09:10,037:INFO:Total runtime is 0.0 minutes
2024-04-23 20:09:10,037:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:10,038:INFO:Initializing create_model()
2024-04-23 20:09:10,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:10,038:INFO:Checking exceptions
2024-04-23 20:09:10,038:INFO:Importing libraries
2024-04-23 20:09:10,038:INFO:Copying training dataset
2024-04-23 20:09:10,042:INFO:Defining folds
2024-04-23 20:09:10,042:INFO:Declaring metric variables
2024-04-23 20:09:10,042:INFO:Importing untrained model
2024-04-23 20:09:10,042:INFO:Logistic Regression Imported successfully
2024-04-23 20:09:10,043:INFO:Starting cross validation
2024-04-23 20:09:10,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:16,316:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,368:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,373:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,436:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,454:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,480:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,513:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,548:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,906:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,951:INFO:Calculating mean and std
2024-04-23 20:09:16,952:INFO:Creating metrics dataframe
2024-04-23 20:09:16,955:INFO:Uploading results into container
2024-04-23 20:09:16,956:INFO:Uploading model into container now
2024-04-23 20:09:16,956:INFO:_master_model_container: 1
2024-04-23 20:09:16,956:INFO:_display_container: 2
2024-04-23 20:09:16,956:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:09:16,956:INFO:create_model() successfully completed......................................
2024-04-23 20:09:17,096:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:17,097:INFO:Creating metrics dataframe
2024-04-23 20:09:17,101:INFO:Initializing K Neighbors Classifier
2024-04-23 20:09:17,102:INFO:Total runtime is 0.11774900356928507 minutes
2024-04-23 20:09:17,102:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:17,102:INFO:Initializing create_model()
2024-04-23 20:09:17,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:17,102:INFO:Checking exceptions
2024-04-23 20:09:17,103:INFO:Importing libraries
2024-04-23 20:09:17,103:INFO:Copying training dataset
2024-04-23 20:09:17,107:INFO:Defining folds
2024-04-23 20:09:17,107:INFO:Declaring metric variables
2024-04-23 20:09:17,107:INFO:Importing untrained model
2024-04-23 20:09:17,107:INFO:K Neighbors Classifier Imported successfully
2024-04-23 20:09:17,108:INFO:Starting cross validation
2024-04-23 20:09:17,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:19,557:INFO:Calculating mean and std
2024-04-23 20:09:19,559:INFO:Creating metrics dataframe
2024-04-23 20:09:19,566:INFO:Uploading results into container
2024-04-23 20:09:19,568:INFO:Uploading model into container now
2024-04-23 20:09:19,568:INFO:_master_model_container: 2
2024-04-23 20:09:19,569:INFO:_display_container: 2
2024-04-23 20:09:19,569:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-23 20:09:19,569:INFO:create_model() successfully completed......................................
2024-04-23 20:09:19,701:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:19,701:INFO:Creating metrics dataframe
2024-04-23 20:09:19,705:INFO:Initializing Naive Bayes
2024-04-23 20:09:19,705:INFO:Total runtime is 0.16112928390502929 minutes
2024-04-23 20:09:19,706:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:19,706:INFO:Initializing create_model()
2024-04-23 20:09:19,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:19,706:INFO:Checking exceptions
2024-04-23 20:09:19,706:INFO:Importing libraries
2024-04-23 20:09:19,706:INFO:Copying training dataset
2024-04-23 20:09:19,709:INFO:Defining folds
2024-04-23 20:09:19,709:INFO:Declaring metric variables
2024-04-23 20:09:19,710:INFO:Importing untrained model
2024-04-23 20:09:19,710:INFO:Naive Bayes Imported successfully
2024-04-23 20:09:19,710:INFO:Starting cross validation
2024-04-23 20:09:19,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:19,994:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,069:INFO:Calculating mean and std
2024-04-23 20:09:20,070:INFO:Creating metrics dataframe
2024-04-23 20:09:20,073:INFO:Uploading results into container
2024-04-23 20:09:20,074:INFO:Uploading model into container now
2024-04-23 20:09:20,075:INFO:_master_model_container: 3
2024-04-23 20:09:20,075:INFO:_display_container: 2
2024-04-23 20:09:20,075:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-23 20:09:20,075:INFO:create_model() successfully completed......................................
2024-04-23 20:09:20,198:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:20,198:INFO:Creating metrics dataframe
2024-04-23 20:09:20,203:INFO:Initializing Decision Tree Classifier
2024-04-23 20:09:20,203:INFO:Total runtime is 0.16942691405614216 minutes
2024-04-23 20:09:20,203:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:20,203:INFO:Initializing create_model()
2024-04-23 20:09:20,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:20,203:INFO:Checking exceptions
2024-04-23 20:09:20,204:INFO:Importing libraries
2024-04-23 20:09:20,204:INFO:Copying training dataset
2024-04-23 20:09:20,208:INFO:Defining folds
2024-04-23 20:09:20,209:INFO:Declaring metric variables
2024-04-23 20:09:20,209:INFO:Importing untrained model
2024-04-23 20:09:20,209:INFO:Decision Tree Classifier Imported successfully
2024-04-23 20:09:20,209:INFO:Starting cross validation
2024-04-23 20:09:20,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:20,462:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,477:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,487:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,502:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,511:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,515:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,539:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,540:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,575:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,603:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,612:INFO:Calculating mean and std
2024-04-23 20:09:20,613:INFO:Creating metrics dataframe
2024-04-23 20:09:20,615:INFO:Uploading results into container
2024-04-23 20:09:20,616:INFO:Uploading model into container now
2024-04-23 20:09:20,616:INFO:_master_model_container: 4
2024-04-23 20:09:20,616:INFO:_display_container: 2
2024-04-23 20:09:20,617:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=208, splitter='best')
2024-04-23 20:09:20,617:INFO:create_model() successfully completed......................................
2024-04-23 20:09:20,740:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:20,740:INFO:Creating metrics dataframe
2024-04-23 20:09:20,744:INFO:Initializing SVM - Linear Kernel
2024-04-23 20:09:20,744:INFO:Total runtime is 0.17843695481618244 minutes
2024-04-23 20:09:20,745:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:20,745:INFO:Initializing create_model()
2024-04-23 20:09:20,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:20,745:INFO:Checking exceptions
2024-04-23 20:09:20,745:INFO:Importing libraries
2024-04-23 20:09:20,745:INFO:Copying training dataset
2024-04-23 20:09:20,749:INFO:Defining folds
2024-04-23 20:09:20,749:INFO:Declaring metric variables
2024-04-23 20:09:20,749:INFO:Importing untrained model
2024-04-23 20:09:20,749:INFO:SVM - Linear Kernel Imported successfully
2024-04-23 20:09:20,749:INFO:Starting cross validation
2024-04-23 20:09:20,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:21,116:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,116:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,116:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,117:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,116:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,117:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,117:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,119:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,144:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,150:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:21,160:INFO:Calculating mean and std
2024-04-23 20:09:21,161:INFO:Creating metrics dataframe
2024-04-23 20:09:21,164:INFO:Uploading results into container
2024-04-23 20:09:21,165:INFO:Uploading model into container now
2024-04-23 20:09:21,165:INFO:_master_model_container: 5
2024-04-23 20:09:21,165:INFO:_display_container: 2
2024-04-23 20:09:21,166:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=208, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-23 20:09:21,166:INFO:create_model() successfully completed......................................
2024-04-23 20:09:21,293:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:21,294:INFO:Creating metrics dataframe
2024-04-23 20:09:21,298:INFO:Initializing Ridge Classifier
2024-04-23 20:09:21,298:INFO:Total runtime is 0.18767929871877032 minutes
2024-04-23 20:09:21,298:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:21,299:INFO:Initializing create_model()
2024-04-23 20:09:21,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:21,299:INFO:Checking exceptions
2024-04-23 20:09:21,299:INFO:Importing libraries
2024-04-23 20:09:21,299:INFO:Copying training dataset
2024-04-23 20:09:21,304:INFO:Defining folds
2024-04-23 20:09:21,304:INFO:Declaring metric variables
2024-04-23 20:09:21,305:INFO:Importing untrained model
2024-04-23 20:09:21,305:INFO:Ridge Classifier Imported successfully
2024-04-23 20:09:21,305:INFO:Starting cross validation
2024-04-23 20:09:21,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:21,573:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,585:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,590:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,597:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,607:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,639:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,640:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,650:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,654:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,702:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,711:INFO:Calculating mean and std
2024-04-23 20:09:21,712:INFO:Creating metrics dataframe
2024-04-23 20:09:21,716:INFO:Uploading results into container
2024-04-23 20:09:21,717:INFO:Uploading model into container now
2024-04-23 20:09:21,717:INFO:_master_model_container: 6
2024-04-23 20:09:21,717:INFO:_display_container: 2
2024-04-23 20:09:21,718:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=208, solver='auto',
                tol=0.0001)
2024-04-23 20:09:21,718:INFO:create_model() successfully completed......................................
2024-04-23 20:09:21,841:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:21,841:INFO:Creating metrics dataframe
2024-04-23 20:09:21,847:INFO:Initializing Random Forest Classifier
2024-04-23 20:09:21,847:INFO:Total runtime is 0.19682150284449257 minutes
2024-04-23 20:09:21,848:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:21,848:INFO:Initializing create_model()
2024-04-23 20:09:21,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:21,848:INFO:Checking exceptions
2024-04-23 20:09:21,848:INFO:Importing libraries
2024-04-23 20:09:21,848:INFO:Copying training dataset
2024-04-23 20:09:21,852:INFO:Defining folds
2024-04-23 20:09:21,853:INFO:Declaring metric variables
2024-04-23 20:09:21,853:INFO:Importing untrained model
2024-04-23 20:09:21,854:INFO:Random Forest Classifier Imported successfully
2024-04-23 20:09:21,854:INFO:Starting cross validation
2024-04-23 20:09:21,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:22,531:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,531:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,532:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,535:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,585:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,587:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,599:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,678:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,709:INFO:Calculating mean and std
2024-04-23 20:09:22,710:INFO:Creating metrics dataframe
2024-04-23 20:09:22,713:INFO:Uploading results into container
2024-04-23 20:09:22,714:INFO:Uploading model into container now
2024-04-23 20:09:22,714:INFO:_master_model_container: 7
2024-04-23 20:09:22,714:INFO:_display_container: 2
2024-04-23 20:09:22,715:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=208, verbose=0, warm_start=False)
2024-04-23 20:09:22,715:INFO:create_model() successfully completed......................................
2024-04-23 20:09:22,833:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:22,833:INFO:Creating metrics dataframe
2024-04-23 20:09:22,837:INFO:Initializing Quadratic Discriminant Analysis
2024-04-23 20:09:22,837:INFO:Total runtime is 0.21333289941151934 minutes
2024-04-23 20:09:22,837:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:22,838:INFO:Initializing create_model()
2024-04-23 20:09:22,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:22,838:INFO:Checking exceptions
2024-04-23 20:09:22,838:INFO:Importing libraries
2024-04-23 20:09:22,838:INFO:Copying training dataset
2024-04-23 20:09:22,841:INFO:Defining folds
2024-04-23 20:09:22,841:INFO:Declaring metric variables
2024-04-23 20:09:22,841:INFO:Importing untrained model
2024-04-23 20:09:22,842:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-23 20:09:22,842:INFO:Starting cross validation
2024-04-23 20:09:22,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:23,017:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,020:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,023:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,023:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,032:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,036:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,041:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,051:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,101:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,114:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,117:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,119:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,128:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,131:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,132:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,134:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,135:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,176:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,188:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,221:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,226:INFO:Calculating mean and std
2024-04-23 20:09:23,227:INFO:Creating metrics dataframe
2024-04-23 20:09:23,231:INFO:Uploading results into container
2024-04-23 20:09:23,231:INFO:Uploading model into container now
2024-04-23 20:09:23,231:INFO:_master_model_container: 8
2024-04-23 20:09:23,232:INFO:_display_container: 2
2024-04-23 20:09:23,232:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-23 20:09:23,232:INFO:create_model() successfully completed......................................
2024-04-23 20:09:23,354:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:23,354:INFO:Creating metrics dataframe
2024-04-23 20:09:23,359:INFO:Initializing Ada Boost Classifier
2024-04-23 20:09:23,359:INFO:Total runtime is 0.22201821009318032 minutes
2024-04-23 20:09:23,359:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:23,359:INFO:Initializing create_model()
2024-04-23 20:09:23,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:23,359:INFO:Checking exceptions
2024-04-23 20:09:23,359:INFO:Importing libraries
2024-04-23 20:09:23,359:INFO:Copying training dataset
2024-04-23 20:09:23,363:INFO:Defining folds
2024-04-23 20:09:23,363:INFO:Declaring metric variables
2024-04-23 20:09:23,363:INFO:Importing untrained model
2024-04-23 20:09:23,363:INFO:Ada Boost Classifier Imported successfully
2024-04-23 20:09:23,363:INFO:Starting cross validation
2024-04-23 20:09:23,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:23,619:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,623:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,629:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,641:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,647:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,653:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,653:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,662:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,665:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,670:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,683:INFO:Calculating mean and std
2024-04-23 20:09:23,684:INFO:Creating metrics dataframe
2024-04-23 20:09:23,687:INFO:Uploading results into container
2024-04-23 20:09:23,688:INFO:Uploading model into container now
2024-04-23 20:09:23,688:INFO:_master_model_container: 9
2024-04-23 20:09:23,688:INFO:_display_container: 2
2024-04-23 20:09:23,688:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=208)
2024-04-23 20:09:23,688:INFO:create_model() successfully completed......................................
2024-04-23 20:09:23,805:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:23,805:INFO:Creating metrics dataframe
2024-04-23 20:09:23,811:INFO:Initializing Gradient Boosting Classifier
2024-04-23 20:09:23,811:INFO:Total runtime is 0.22955313126246132 minutes
2024-04-23 20:09:23,811:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:23,812:INFO:Initializing create_model()
2024-04-23 20:09:23,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:23,812:INFO:Checking exceptions
2024-04-23 20:09:23,812:INFO:Importing libraries
2024-04-23 20:09:23,812:INFO:Copying training dataset
2024-04-23 20:09:23,817:INFO:Defining folds
2024-04-23 20:09:23,817:INFO:Declaring metric variables
2024-04-23 20:09:23,817:INFO:Importing untrained model
2024-04-23 20:09:23,817:INFO:Gradient Boosting Classifier Imported successfully
2024-04-23 20:09:23,817:INFO:Starting cross validation
2024-04-23 20:09:23,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:24,205:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,220:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,223:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,232:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,239:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,244:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,245:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,246:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,265:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,374:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,388:INFO:Calculating mean and std
2024-04-23 20:09:24,389:INFO:Creating metrics dataframe
2024-04-23 20:09:24,392:INFO:Uploading results into container
2024-04-23 20:09:24,392:INFO:Uploading model into container now
2024-04-23 20:09:24,393:INFO:_master_model_container: 10
2024-04-23 20:09:24,393:INFO:_display_container: 2
2024-04-23 20:09:24,393:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=208, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-23 20:09:24,393:INFO:create_model() successfully completed......................................
2024-04-23 20:09:24,513:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:24,513:INFO:Creating metrics dataframe
2024-04-23 20:09:24,518:INFO:Initializing Linear Discriminant Analysis
2024-04-23 20:09:24,518:INFO:Total runtime is 0.241348926226298 minutes
2024-04-23 20:09:24,518:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:24,518:INFO:Initializing create_model()
2024-04-23 20:09:24,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:24,519:INFO:Checking exceptions
2024-04-23 20:09:24,519:INFO:Importing libraries
2024-04-23 20:09:24,519:INFO:Copying training dataset
2024-04-23 20:09:24,522:INFO:Defining folds
2024-04-23 20:09:24,523:INFO:Declaring metric variables
2024-04-23 20:09:24,523:INFO:Importing untrained model
2024-04-23 20:09:24,523:INFO:Linear Discriminant Analysis Imported successfully
2024-04-23 20:09:24,523:INFO:Starting cross validation
2024-04-23 20:09:24,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:24,773:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,787:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,793:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,796:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,803:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,818:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,830:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,839:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,847:INFO:Calculating mean and std
2024-04-23 20:09:24,848:INFO:Creating metrics dataframe
2024-04-23 20:09:24,851:INFO:Uploading results into container
2024-04-23 20:09:24,851:INFO:Uploading model into container now
2024-04-23 20:09:24,851:INFO:_master_model_container: 11
2024-04-23 20:09:24,851:INFO:_display_container: 2
2024-04-23 20:09:24,852:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-23 20:09:24,852:INFO:create_model() successfully completed......................................
2024-04-23 20:09:24,977:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:24,977:INFO:Creating metrics dataframe
2024-04-23 20:09:24,983:INFO:Initializing Extra Trees Classifier
2024-04-23 20:09:24,983:INFO:Total runtime is 0.2490948716799418 minutes
2024-04-23 20:09:24,983:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:24,984:INFO:Initializing create_model()
2024-04-23 20:09:24,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:24,984:INFO:Checking exceptions
2024-04-23 20:09:24,984:INFO:Importing libraries
2024-04-23 20:09:24,984:INFO:Copying training dataset
2024-04-23 20:09:24,987:INFO:Defining folds
2024-04-23 20:09:24,988:INFO:Declaring metric variables
2024-04-23 20:09:24,988:INFO:Importing untrained model
2024-04-23 20:09:24,988:INFO:Extra Trees Classifier Imported successfully
2024-04-23 20:09:24,988:INFO:Starting cross validation
2024-04-23 20:09:24,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:25,662:INFO:Calculating mean and std
2024-04-23 20:09:25,663:INFO:Creating metrics dataframe
2024-04-23 20:09:25,667:INFO:Uploading results into container
2024-04-23 20:09:25,668:INFO:Uploading model into container now
2024-04-23 20:09:25,669:INFO:_master_model_container: 12
2024-04-23 20:09:25,669:INFO:_display_container: 2
2024-04-23 20:09:25,669:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=208, verbose=0, warm_start=False)
2024-04-23 20:09:25,669:INFO:create_model() successfully completed......................................
2024-04-23 20:09:25,788:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:25,788:INFO:Creating metrics dataframe
2024-04-23 20:09:25,792:INFO:Initializing Light Gradient Boosting Machine
2024-04-23 20:09:25,792:INFO:Total runtime is 0.2625685175259908 minutes
2024-04-23 20:09:25,792:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:25,792:INFO:Initializing create_model()
2024-04-23 20:09:25,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:25,793:INFO:Checking exceptions
2024-04-23 20:09:25,793:INFO:Importing libraries
2024-04-23 20:09:25,793:INFO:Copying training dataset
2024-04-23 20:09:25,796:INFO:Defining folds
2024-04-23 20:09:25,796:INFO:Declaring metric variables
2024-04-23 20:09:25,797:INFO:Importing untrained model
2024-04-23 20:09:25,797:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-23 20:09:25,797:INFO:Starting cross validation
2024-04-23 20:09:25,798:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:26,403:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,404:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,421:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,440:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,553:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,578:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,585:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,677:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,734:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,749:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,764:INFO:Calculating mean and std
2024-04-23 20:09:26,765:INFO:Creating metrics dataframe
2024-04-23 20:09:26,769:INFO:Uploading results into container
2024-04-23 20:09:26,770:INFO:Uploading model into container now
2024-04-23 20:09:26,771:INFO:_master_model_container: 13
2024-04-23 20:09:26,771:INFO:_display_container: 2
2024-04-23 20:09:26,772:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=208, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-23 20:09:26,772:INFO:create_model() successfully completed......................................
2024-04-23 20:09:26,920:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:26,921:INFO:Creating metrics dataframe
2024-04-23 20:09:26,925:INFO:Initializing Dummy Classifier
2024-04-23 20:09:26,925:INFO:Total runtime is 0.28145132859547933 minutes
2024-04-23 20:09:26,925:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:26,925:INFO:Initializing create_model()
2024-04-23 20:09:26,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:26,925:INFO:Checking exceptions
2024-04-23 20:09:26,926:INFO:Importing libraries
2024-04-23 20:09:26,926:INFO:Copying training dataset
2024-04-23 20:09:26,929:INFO:Defining folds
2024-04-23 20:09:26,929:INFO:Declaring metric variables
2024-04-23 20:09:26,929:INFO:Importing untrained model
2024-04-23 20:09:26,930:INFO:Dummy Classifier Imported successfully
2024-04-23 20:09:26,930:INFO:Starting cross validation
2024-04-23 20:09:26,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:27,214:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,224:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,239:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,274:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,275:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,290:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,309:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,311:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,313:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,329:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,334:INFO:Calculating mean and std
2024-04-23 20:09:27,334:INFO:Creating metrics dataframe
2024-04-23 20:09:27,337:INFO:Uploading results into container
2024-04-23 20:09:27,338:INFO:Uploading model into container now
2024-04-23 20:09:27,338:INFO:_master_model_container: 14
2024-04-23 20:09:27,338:INFO:_display_container: 2
2024-04-23 20:09:27,338:INFO:DummyClassifier(constant=None, random_state=208, strategy='prior')
2024-04-23 20:09:27,338:INFO:create_model() successfully completed......................................
2024-04-23 20:09:27,488:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:27,488:INFO:Creating metrics dataframe
2024-04-23 20:09:27,500:INFO:Initializing create_model()
2024-04-23 20:09:27,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:27,501:INFO:Checking exceptions
2024-04-23 20:09:27,502:INFO:Importing libraries
2024-04-23 20:09:27,502:INFO:Copying training dataset
2024-04-23 20:09:27,506:INFO:Defining folds
2024-04-23 20:09:27,506:INFO:Declaring metric variables
2024-04-23 20:09:27,506:INFO:Importing untrained model
2024-04-23 20:09:27,506:INFO:Declaring custom model
2024-04-23 20:09:27,506:INFO:Logistic Regression Imported successfully
2024-04-23 20:09:27,508:INFO:Cross validation set to False
2024-04-23 20:09:27,508:INFO:Fitting Model
2024-04-23 20:09:27,729:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:27,729:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:09:27,729:INFO:create_model() successfully completed......................................
2024-04-23 20:09:27,896:INFO:_master_model_container: 14
2024-04-23 20:09:27,896:INFO:_display_container: 2
2024-04-23 20:09:27,896:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:09:27,896:INFO:compare_models() successfully completed......................................
2024-04-23 20:09:27,921:INFO:Initializing save_model()
2024-04-23 20:09:27,921:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecate...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-23 20:09:27,921:INFO:Adding model into prep_pipe
2024-04-23 20:09:27,931:INFO:best_classifier.pkl saved in current working directory
2024-04-23 20:09:27,957:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Transforme...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=208,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-04-23 20:09:27,957:INFO:save_model() successfully completed......................................
2024-04-23 20:13:44,753:INFO:Initializing load_model()
2024-04-23 20:13:44,753:INFO:load_model(model_name=trained_classifier, platform=None, authentication=None, verbose=True)
2024-04-23 20:14:08,154:INFO:PyCaret ClassificationExperiment
2024-04-23 20:14:08,154:INFO:Logging name: clf-default-name
2024-04-23 20:14:08,154:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-23 20:14:08,154:INFO:version 3.1.0
2024-04-23 20:14:08,154:INFO:Initializing setup()
2024-04-23 20:14:08,154:INFO:self.USI: 15d3
2024-04-23 20:14:08,154:INFO:self._variable_keys: {'_ml_usecase', 'logging_param', 'is_multiclass', 'fold_groups_param', 'X_test', 'y', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'exp_name_log', 'fix_imbalance', 'X', 'pipeline', 'X_train', 'y_test', 'fold_generator', 'memory', 'target_param', 'gpu_n_jobs_param', 'exp_id', 'gpu_param', 'log_plots_param', 'idx', 'n_jobs_param', 'USI', 'y_train', 'html_param'}
2024-04-23 20:14:08,154:INFO:Checking environment
2024-04-23 20:14:08,154:INFO:python_version: 3.10.0
2024-04-23 20:14:08,154:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-23 20:14:08,154:INFO:machine: AMD64
2024-04-23 20:14:08,154:INFO:platform: Windows-10-10.0.19045-SP0
2024-04-23 20:14:08,159:INFO:Memory: svmem(total=17041117184, available=5699416064, percent=66.6, used=11341701120, free=5699416064)
2024-04-23 20:14:08,159:INFO:Physical Core: 6
2024-04-23 20:14:08,159:INFO:Logical Core: 12
2024-04-23 20:14:08,159:INFO:Checking libraries
2024-04-23 20:14:08,160:INFO:System:
2024-04-23 20:14:08,160:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-23 20:14:08,160:INFO:executable: C:\Users\User\AppData\Local\Programs\Python\Python310\python.exe
2024-04-23 20:14:08,160:INFO:   machine: Windows-10-10.0.19045-SP0
2024-04-23 20:14:08,160:INFO:PyCaret required dependencies:
2024-04-23 20:14:08,160:INFO:                 pip: 21.2.3
2024-04-23 20:14:08,160:INFO:          setuptools: 57.4.0
2024-04-23 20:14:08,160:INFO:             pycaret: 3.1.0
2024-04-23 20:14:08,160:INFO:             IPython: 8.17.2
2024-04-23 20:14:08,160:INFO:          ipywidgets: 8.1.1
2024-04-23 20:14:08,160:INFO:                tqdm: 4.66.1
2024-04-23 20:14:08,160:INFO:               numpy: 1.25.2
2024-04-23 20:14:08,160:INFO:              pandas: 2.0.3
2024-04-23 20:14:08,160:INFO:              jinja2: 3.1.2
2024-04-23 20:14:08,160:INFO:               scipy: 1.10.1
2024-04-23 20:14:08,160:INFO:              joblib: 1.3.2
2024-04-23 20:14:08,160:INFO:             sklearn: 1.2.2
2024-04-23 20:14:08,160:INFO:                pyod: 1.1.1
2024-04-23 20:14:08,160:INFO:            imblearn: 0.11.0
2024-04-23 20:14:08,160:INFO:   category_encoders: 2.6.3
2024-04-23 20:14:08,160:INFO:            lightgbm: 4.1.0
2024-04-23 20:14:08,160:INFO:               numba: 0.58.1
2024-04-23 20:14:08,160:INFO:            requests: 2.31.0
2024-04-23 20:14:08,160:INFO:          matplotlib: 3.7.3
2024-04-23 20:14:08,160:INFO:          scikitplot: 0.3.7
2024-04-23 20:14:08,161:INFO:         yellowbrick: 1.5
2024-04-23 20:14:08,161:INFO:              plotly: 5.18.0
2024-04-23 20:14:08,161:INFO:    plotly-resampler: Not installed
2024-04-23 20:14:08,161:INFO:             kaleido: 0.2.1
2024-04-23 20:14:08,161:INFO:           schemdraw: 0.15
2024-04-23 20:14:08,161:INFO:         statsmodels: 0.14.0
2024-04-23 20:14:08,161:INFO:              sktime: 0.21.1
2024-04-23 20:14:08,161:INFO:               tbats: 1.1.3
2024-04-23 20:14:08,161:INFO:            pmdarima: 2.0.4
2024-04-23 20:14:08,161:INFO:              psutil: 5.9.6
2024-04-23 20:14:08,161:INFO:          markupsafe: 2.1.3
2024-04-23 20:14:08,161:INFO:             pickle5: Not installed
2024-04-23 20:14:08,161:INFO:         cloudpickle: 3.0.0
2024-04-23 20:14:08,161:INFO:         deprecation: 2.1.0
2024-04-23 20:14:08,161:INFO:              xxhash: 3.4.1
2024-04-23 20:14:08,161:INFO:           wurlitzer: Not installed
2024-04-23 20:14:08,162:INFO:PyCaret optional dependencies:
2024-04-23 20:14:08,162:INFO:                shap: Not installed
2024-04-23 20:14:08,162:INFO:           interpret: Not installed
2024-04-23 20:14:08,162:INFO:                umap: Not installed
2024-04-23 20:14:08,162:INFO:     ydata_profiling: 4.6.1
2024-04-23 20:14:08,162:INFO:  explainerdashboard: Not installed
2024-04-23 20:14:08,162:INFO:             autoviz: Not installed
2024-04-23 20:14:08,162:INFO:           fairlearn: Not installed
2024-04-23 20:14:08,162:INFO:          deepchecks: Not installed
2024-04-23 20:14:08,162:INFO:             xgboost: Not installed
2024-04-23 20:14:08,162:INFO:            catboost: Not installed
2024-04-23 20:14:08,162:INFO:              kmodes: Not installed
2024-04-23 20:14:08,162:INFO:             mlxtend: Not installed
2024-04-23 20:14:08,162:INFO:       statsforecast: Not installed
2024-04-23 20:14:08,162:INFO:        tune_sklearn: Not installed
2024-04-23 20:14:08,162:INFO:                 ray: Not installed
2024-04-23 20:14:08,162:INFO:            hyperopt: Not installed
2024-04-23 20:14:08,163:INFO:              optuna: Not installed
2024-04-23 20:14:08,163:INFO:               skopt: Not installed
2024-04-23 20:14:08,163:INFO:              mlflow: Not installed
2024-04-23 20:14:08,163:INFO:              gradio: Not installed
2024-04-23 20:14:08,163:INFO:             fastapi: Not installed
2024-04-23 20:14:08,163:INFO:             uvicorn: Not installed
2024-04-23 20:14:08,163:INFO:              m2cgen: Not installed
2024-04-23 20:14:08,163:INFO:           evidently: Not installed
2024-04-23 20:14:08,163:INFO:               fugue: Not installed
2024-04-23 20:14:08,163:INFO:           streamlit: 1.28.0
2024-04-23 20:14:08,163:INFO:             prophet: Not installed
2024-04-23 20:14:08,163:INFO:None
2024-04-23 20:14:08,163:INFO:Set up data.
2024-04-23 20:14:08,171:INFO:Set up folding strategy.
2024-04-23 20:14:08,171:INFO:Set up train/test split.
2024-04-23 20:14:08,178:INFO:Set up index.
2024-04-23 20:14:08,179:INFO:Assigning column types.
2024-04-23 20:14:08,184:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-23 20:14:08,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,330:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,331:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,361:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-23 20:14:08,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,489:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,521:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-23 20:14:08,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,676:INFO:Preparing preprocessing pipeline...
2024-04-23 20:14:08,678:INFO:Set up simple imputation.
2024-04-23 20:14:08,682:INFO:Set up encoding of ordinal features.
2024-04-23 20:14:08,685:INFO:Set up encoding of categorical features.
2024-04-23 20:14:08,815:INFO:Finished creating preprocessing pipeline.
2024-04-23 20:14:08,837:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecate...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-04-23 20:14:08,837:INFO:Creating final display dataframe.
2024-04-23 20:14:09,271:INFO:Setup _display_container:                     Description             Value
0                    Session id              3685
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 5
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              15d3
2024-04-23 20:14:09,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:09,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:09,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:09,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:09,423:INFO:setup() successfully completed in 1.27s...............
2024-04-23 20:14:09,426:INFO:Initializing compare_models()
2024-04-23 20:14:09,426:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-23 20:14:09,426:INFO:Checking exceptions
2024-04-23 20:14:09,429:INFO:Preparing display monitor
2024-04-23 20:14:09,432:INFO:Initializing Logistic Regression
2024-04-23 20:14:09,432:INFO:Total runtime is 0.0 minutes
2024-04-23 20:14:09,432:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:09,432:INFO:Initializing create_model()
2024-04-23 20:14:09,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:09,433:INFO:Checking exceptions
2024-04-23 20:14:09,433:INFO:Importing libraries
2024-04-23 20:14:09,433:INFO:Copying training dataset
2024-04-23 20:14:09,439:INFO:Defining folds
2024-04-23 20:14:09,439:INFO:Declaring metric variables
2024-04-23 20:14:09,439:INFO:Importing untrained model
2024-04-23 20:14:09,440:INFO:Logistic Regression Imported successfully
2024-04-23 20:14:09,440:INFO:Starting cross validation
2024-04-23 20:14:09,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:09,968:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:09,972:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,020:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,051:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,058:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,098:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,151:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,160:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,161:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,239:INFO:Calculating mean and std
2024-04-23 20:14:10,240:INFO:Creating metrics dataframe
2024-04-23 20:14:10,248:INFO:Uploading results into container
2024-04-23 20:14:10,249:INFO:Uploading model into container now
2024-04-23 20:14:10,250:INFO:_master_model_container: 1
2024-04-23 20:14:10,250:INFO:_display_container: 2
2024-04-23 20:14:10,250:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:14:10,250:INFO:create_model() successfully completed......................................
2024-04-23 20:14:10,389:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:10,389:INFO:Creating metrics dataframe
2024-04-23 20:14:10,393:INFO:Initializing K Neighbors Classifier
2024-04-23 20:14:10,393:INFO:Total runtime is 0.016020663579305015 minutes
2024-04-23 20:14:10,393:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:10,394:INFO:Initializing create_model()
2024-04-23 20:14:10,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:10,394:INFO:Checking exceptions
2024-04-23 20:14:10,394:INFO:Importing libraries
2024-04-23 20:14:10,394:INFO:Copying training dataset
2024-04-23 20:14:10,398:INFO:Defining folds
2024-04-23 20:14:10,398:INFO:Declaring metric variables
2024-04-23 20:14:10,398:INFO:Importing untrained model
2024-04-23 20:14:10,398:INFO:K Neighbors Classifier Imported successfully
2024-04-23 20:14:10,398:INFO:Starting cross validation
2024-04-23 20:14:10,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:10,897:INFO:Calculating mean and std
2024-04-23 20:14:10,898:INFO:Creating metrics dataframe
2024-04-23 20:14:10,901:INFO:Uploading results into container
2024-04-23 20:14:10,901:INFO:Uploading model into container now
2024-04-23 20:14:10,901:INFO:_master_model_container: 2
2024-04-23 20:14:10,901:INFO:_display_container: 2
2024-04-23 20:14:10,902:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-23 20:14:10,902:INFO:create_model() successfully completed......................................
2024-04-23 20:14:11,042:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:11,042:INFO:Creating metrics dataframe
2024-04-23 20:14:11,048:INFO:Initializing Naive Bayes
2024-04-23 20:14:11,048:INFO:Total runtime is 0.026941430568695073 minutes
2024-04-23 20:14:11,049:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:11,049:INFO:Initializing create_model()
2024-04-23 20:14:11,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:11,049:INFO:Checking exceptions
2024-04-23 20:14:11,049:INFO:Importing libraries
2024-04-23 20:14:11,049:INFO:Copying training dataset
2024-04-23 20:14:11,053:INFO:Defining folds
2024-04-23 20:14:11,053:INFO:Declaring metric variables
2024-04-23 20:14:11,053:INFO:Importing untrained model
2024-04-23 20:14:11,054:INFO:Naive Bayes Imported successfully
2024-04-23 20:14:11,054:INFO:Starting cross validation
2024-04-23 20:14:11,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:11,463:INFO:Calculating mean and std
2024-04-23 20:14:11,464:INFO:Creating metrics dataframe
2024-04-23 20:14:11,467:INFO:Uploading results into container
2024-04-23 20:14:11,467:INFO:Uploading model into container now
2024-04-23 20:14:11,468:INFO:_master_model_container: 3
2024-04-23 20:14:11,468:INFO:_display_container: 2
2024-04-23 20:14:11,468:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-23 20:14:11,468:INFO:create_model() successfully completed......................................
2024-04-23 20:14:11,608:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:11,608:INFO:Creating metrics dataframe
2024-04-23 20:14:11,613:INFO:Initializing Decision Tree Classifier
2024-04-23 20:14:11,613:INFO:Total runtime is 0.036349594593048096 minutes
2024-04-23 20:14:11,613:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:11,614:INFO:Initializing create_model()
2024-04-23 20:14:11,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:11,614:INFO:Checking exceptions
2024-04-23 20:14:11,614:INFO:Importing libraries
2024-04-23 20:14:11,614:INFO:Copying training dataset
2024-04-23 20:14:11,619:INFO:Defining folds
2024-04-23 20:14:11,619:INFO:Declaring metric variables
2024-04-23 20:14:11,620:INFO:Importing untrained model
2024-04-23 20:14:11,620:INFO:Decision Tree Classifier Imported successfully
2024-04-23 20:14:11,621:INFO:Starting cross validation
2024-04-23 20:14:11,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:11,953:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:11,966:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:11,991:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,019:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,026:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,027:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,027:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,066:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,099:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,103:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,108:INFO:Calculating mean and std
2024-04-23 20:14:12,109:INFO:Creating metrics dataframe
2024-04-23 20:14:12,112:INFO:Uploading results into container
2024-04-23 20:14:12,112:INFO:Uploading model into container now
2024-04-23 20:14:12,113:INFO:_master_model_container: 4
2024-04-23 20:14:12,113:INFO:_display_container: 2
2024-04-23 20:14:12,114:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3685, splitter='best')
2024-04-23 20:14:12,114:INFO:create_model() successfully completed......................................
2024-04-23 20:14:12,264:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:12,264:INFO:Creating metrics dataframe
2024-04-23 20:14:12,269:INFO:Initializing SVM - Linear Kernel
2024-04-23 20:14:12,269:INFO:Total runtime is 0.04728872776031494 minutes
2024-04-23 20:14:12,269:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:12,269:INFO:Initializing create_model()
2024-04-23 20:14:12,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:12,269:INFO:Checking exceptions
2024-04-23 20:14:12,269:INFO:Importing libraries
2024-04-23 20:14:12,269:INFO:Copying training dataset
2024-04-23 20:14:12,273:INFO:Defining folds
2024-04-23 20:14:12,273:INFO:Declaring metric variables
2024-04-23 20:14:12,273:INFO:Importing untrained model
2024-04-23 20:14:12,274:INFO:SVM - Linear Kernel Imported successfully
2024-04-23 20:14:12,274:INFO:Starting cross validation
2024-04-23 20:14:12,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:12,585:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,621:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,626:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,637:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,659:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,665:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,690:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,702:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,704:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,710:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,724:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,742:INFO:Calculating mean and std
2024-04-23 20:14:12,743:INFO:Creating metrics dataframe
2024-04-23 20:14:12,747:INFO:Uploading results into container
2024-04-23 20:14:12,747:INFO:Uploading model into container now
2024-04-23 20:14:12,748:INFO:_master_model_container: 5
2024-04-23 20:14:12,748:INFO:_display_container: 2
2024-04-23 20:14:12,748:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3685, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-23 20:14:12,748:INFO:create_model() successfully completed......................................
2024-04-23 20:14:12,882:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:12,882:INFO:Creating metrics dataframe
2024-04-23 20:14:12,887:INFO:Initializing Ridge Classifier
2024-04-23 20:14:12,887:INFO:Total runtime is 0.057596131165822344 minutes
2024-04-23 20:14:12,887:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:12,887:INFO:Initializing create_model()
2024-04-23 20:14:12,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:12,888:INFO:Checking exceptions
2024-04-23 20:14:12,888:INFO:Importing libraries
2024-04-23 20:14:12,888:INFO:Copying training dataset
2024-04-23 20:14:12,891:INFO:Defining folds
2024-04-23 20:14:12,891:INFO:Declaring metric variables
2024-04-23 20:14:12,892:INFO:Importing untrained model
2024-04-23 20:14:12,892:INFO:Ridge Classifier Imported successfully
2024-04-23 20:14:12,892:INFO:Starting cross validation
2024-04-23 20:14:12,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:13,174:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,180:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,180:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,213:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,225:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,227:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,229:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,235:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,243:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,252:INFO:Calculating mean and std
2024-04-23 20:14:13,252:INFO:Creating metrics dataframe
2024-04-23 20:14:13,256:INFO:Uploading results into container
2024-04-23 20:14:13,256:INFO:Uploading model into container now
2024-04-23 20:14:13,257:INFO:_master_model_container: 6
2024-04-23 20:14:13,257:INFO:_display_container: 2
2024-04-23 20:14:13,257:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3685, solver='auto',
                tol=0.0001)
2024-04-23 20:14:13,257:INFO:create_model() successfully completed......................................
2024-04-23 20:14:13,390:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:13,390:INFO:Creating metrics dataframe
2024-04-23 20:14:13,395:INFO:Initializing Random Forest Classifier
2024-04-23 20:14:13,395:INFO:Total runtime is 0.0660632570584615 minutes
2024-04-23 20:14:13,395:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:13,395:INFO:Initializing create_model()
2024-04-23 20:14:13,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:13,395:INFO:Checking exceptions
2024-04-23 20:14:13,395:INFO:Importing libraries
2024-04-23 20:14:13,395:INFO:Copying training dataset
2024-04-23 20:14:13,399:INFO:Defining folds
2024-04-23 20:14:13,399:INFO:Declaring metric variables
2024-04-23 20:14:13,399:INFO:Importing untrained model
2024-04-23 20:14:13,400:INFO:Random Forest Classifier Imported successfully
2024-04-23 20:14:13,400:INFO:Starting cross validation
2024-04-23 20:14:13,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:14,227:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,229:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,238:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,241:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,242:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,250:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,294:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,303:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,366:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,414:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,422:INFO:Calculating mean and std
2024-04-23 20:14:14,423:INFO:Creating metrics dataframe
2024-04-23 20:14:14,427:INFO:Uploading results into container
2024-04-23 20:14:14,429:INFO:Uploading model into container now
2024-04-23 20:14:14,430:INFO:_master_model_container: 7
2024-04-23 20:14:14,430:INFO:_display_container: 2
2024-04-23 20:14:14,431:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3685, verbose=0, warm_start=False)
2024-04-23 20:14:14,431:INFO:create_model() successfully completed......................................
2024-04-23 20:14:14,634:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:14,635:INFO:Creating metrics dataframe
2024-04-23 20:14:14,648:INFO:Initializing Quadratic Discriminant Analysis
2024-04-23 20:14:14,648:INFO:Total runtime is 0.08693687915802001 minutes
2024-04-23 20:14:14,649:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:14,649:INFO:Initializing create_model()
2024-04-23 20:14:14,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:14,649:INFO:Checking exceptions
2024-04-23 20:14:14,649:INFO:Importing libraries
2024-04-23 20:14:14,649:INFO:Copying training dataset
2024-04-23 20:14:14,657:INFO:Defining folds
2024-04-23 20:14:14,657:INFO:Declaring metric variables
2024-04-23 20:14:14,658:INFO:Importing untrained model
2024-04-23 20:14:14,658:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-23 20:14:14,658:INFO:Starting cross validation
2024-04-23 20:14:14,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:14,873:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,875:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,899:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,904:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,941:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,941:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,958:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,962:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,976:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,976:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,009:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:15,012:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,016:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,032:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,039:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:15,051:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,064:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:15,072:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,095:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,111:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,122:INFO:Calculating mean and std
2024-04-23 20:14:15,123:INFO:Creating metrics dataframe
2024-04-23 20:14:15,126:INFO:Uploading results into container
2024-04-23 20:14:15,126:INFO:Uploading model into container now
2024-04-23 20:14:15,126:INFO:_master_model_container: 8
2024-04-23 20:14:15,126:INFO:_display_container: 2
2024-04-23 20:14:15,127:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-23 20:14:15,127:INFO:create_model() successfully completed......................................
2024-04-23 20:14:15,264:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:15,264:INFO:Creating metrics dataframe
2024-04-23 20:14:15,271:INFO:Initializing Ada Boost Classifier
2024-04-23 20:14:15,271:INFO:Total runtime is 0.09731918176015217 minutes
2024-04-23 20:14:15,271:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:15,271:INFO:Initializing create_model()
2024-04-23 20:14:15,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:15,271:INFO:Checking exceptions
2024-04-23 20:14:15,271:INFO:Importing libraries
2024-04-23 20:14:15,271:INFO:Copying training dataset
2024-04-23 20:14:15,275:INFO:Defining folds
2024-04-23 20:14:15,275:INFO:Declaring metric variables
2024-04-23 20:14:15,275:INFO:Importing untrained model
2024-04-23 20:14:15,276:INFO:Ada Boost Classifier Imported successfully
2024-04-23 20:14:15,276:INFO:Starting cross validation
2024-04-23 20:14:15,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:15,484:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,488:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,493:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,499:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,500:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,649:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,649:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,667:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,675:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,679:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,689:INFO:Calculating mean and std
2024-04-23 20:14:15,691:INFO:Creating metrics dataframe
2024-04-23 20:14:15,698:INFO:Uploading results into container
2024-04-23 20:14:15,700:INFO:Uploading model into container now
2024-04-23 20:14:15,700:INFO:_master_model_container: 9
2024-04-23 20:14:15,700:INFO:_display_container: 2
2024-04-23 20:14:15,701:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3685)
2024-04-23 20:14:15,701:INFO:create_model() successfully completed......................................
2024-04-23 20:14:15,851:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:15,851:INFO:Creating metrics dataframe
2024-04-23 20:14:15,856:INFO:Initializing Gradient Boosting Classifier
2024-04-23 20:14:15,856:INFO:Total runtime is 0.10707320769627887 minutes
2024-04-23 20:14:15,856:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:15,857:INFO:Initializing create_model()
2024-04-23 20:14:15,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:15,857:INFO:Checking exceptions
2024-04-23 20:14:15,857:INFO:Importing libraries
2024-04-23 20:14:15,857:INFO:Copying training dataset
2024-04-23 20:14:15,861:INFO:Defining folds
2024-04-23 20:14:15,861:INFO:Declaring metric variables
2024-04-23 20:14:15,861:INFO:Importing untrained model
2024-04-23 20:14:15,861:INFO:Gradient Boosting Classifier Imported successfully
2024-04-23 20:14:15,862:INFO:Starting cross validation
2024-04-23 20:14:15,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:16,305:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,315:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,316:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,330:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,333:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,348:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,510:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,521:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,527:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,533:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,548:INFO:Calculating mean and std
2024-04-23 20:14:16,549:INFO:Creating metrics dataframe
2024-04-23 20:14:16,552:INFO:Uploading results into container
2024-04-23 20:14:16,553:INFO:Uploading model into container now
2024-04-23 20:14:16,553:INFO:_master_model_container: 10
2024-04-23 20:14:16,553:INFO:_display_container: 2
2024-04-23 20:14:16,553:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3685, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-23 20:14:16,553:INFO:create_model() successfully completed......................................
2024-04-23 20:14:16,729:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:16,729:INFO:Creating metrics dataframe
2024-04-23 20:14:16,739:INFO:Initializing Linear Discriminant Analysis
2024-04-23 20:14:16,739:INFO:Total runtime is 0.12179587284723915 minutes
2024-04-23 20:14:16,740:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:16,740:INFO:Initializing create_model()
2024-04-23 20:14:16,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:16,741:INFO:Checking exceptions
2024-04-23 20:14:16,741:INFO:Importing libraries
2024-04-23 20:14:16,741:INFO:Copying training dataset
2024-04-23 20:14:16,748:INFO:Defining folds
2024-04-23 20:14:16,748:INFO:Declaring metric variables
2024-04-23 20:14:16,749:INFO:Importing untrained model
2024-04-23 20:14:16,749:INFO:Linear Discriminant Analysis Imported successfully
2024-04-23 20:14:16,750:INFO:Starting cross validation
2024-04-23 20:14:16,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:16,960:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,969:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,971:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,141:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,156:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,159:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,194:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,206:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,229:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,239:INFO:Calculating mean and std
2024-04-23 20:14:17,240:INFO:Creating metrics dataframe
2024-04-23 20:14:17,243:INFO:Uploading results into container
2024-04-23 20:14:17,244:INFO:Uploading model into container now
2024-04-23 20:14:17,244:INFO:_master_model_container: 11
2024-04-23 20:14:17,244:INFO:_display_container: 2
2024-04-23 20:14:17,245:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-23 20:14:17,245:INFO:create_model() successfully completed......................................
2024-04-23 20:14:17,400:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:17,400:INFO:Creating metrics dataframe
2024-04-23 20:14:17,404:INFO:Initializing Extra Trees Classifier
2024-04-23 20:14:17,404:INFO:Total runtime is 0.13287239869435627 minutes
2024-04-23 20:14:17,405:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:17,405:INFO:Initializing create_model()
2024-04-23 20:14:17,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:17,405:INFO:Checking exceptions
2024-04-23 20:14:17,405:INFO:Importing libraries
2024-04-23 20:14:17,405:INFO:Copying training dataset
2024-04-23 20:14:17,409:INFO:Defining folds
2024-04-23 20:14:17,409:INFO:Declaring metric variables
2024-04-23 20:14:17,409:INFO:Importing untrained model
2024-04-23 20:14:17,409:INFO:Extra Trees Classifier Imported successfully
2024-04-23 20:14:17,410:INFO:Starting cross validation
2024-04-23 20:14:17,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:18,319:INFO:Calculating mean and std
2024-04-23 20:14:18,320:INFO:Creating metrics dataframe
2024-04-23 20:14:18,324:INFO:Uploading results into container
2024-04-23 20:14:18,327:INFO:Uploading model into container now
2024-04-23 20:14:18,327:INFO:_master_model_container: 12
2024-04-23 20:14:18,328:INFO:_display_container: 2
2024-04-23 20:14:18,329:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3685, verbose=0, warm_start=False)
2024-04-23 20:14:18,329:INFO:create_model() successfully completed......................................
2024-04-23 20:14:18,529:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:18,529:INFO:Creating metrics dataframe
2024-04-23 20:14:18,539:INFO:Initializing Light Gradient Boosting Machine
2024-04-23 20:14:18,540:INFO:Total runtime is 0.1518085956573486 minutes
2024-04-23 20:14:18,540:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:18,540:INFO:Initializing create_model()
2024-04-23 20:14:18,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:18,541:INFO:Checking exceptions
2024-04-23 20:14:18,541:INFO:Importing libraries
2024-04-23 20:14:18,541:INFO:Copying training dataset
2024-04-23 20:14:18,547:INFO:Defining folds
2024-04-23 20:14:18,548:INFO:Declaring metric variables
2024-04-23 20:14:18,548:INFO:Importing untrained model
2024-04-23 20:14:18,548:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-23 20:14:18,548:INFO:Starting cross validation
2024-04-23 20:14:18,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:19,143:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,143:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,154:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,159:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,220:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,351:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,363:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,372:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,414:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,444:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,450:INFO:Calculating mean and std
2024-04-23 20:14:19,451:INFO:Creating metrics dataframe
2024-04-23 20:14:19,455:INFO:Uploading results into container
2024-04-23 20:14:19,456:INFO:Uploading model into container now
2024-04-23 20:14:19,456:INFO:_master_model_container: 13
2024-04-23 20:14:19,456:INFO:_display_container: 2
2024-04-23 20:14:19,457:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3685, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-23 20:14:19,457:INFO:create_model() successfully completed......................................
2024-04-23 20:14:19,643:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:19,643:INFO:Creating metrics dataframe
2024-04-23 20:14:19,650:INFO:Initializing Dummy Classifier
2024-04-23 20:14:19,650:INFO:Total runtime is 0.17030945221583046 minutes
2024-04-23 20:14:19,650:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:19,651:INFO:Initializing create_model()
2024-04-23 20:14:19,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:19,651:INFO:Checking exceptions
2024-04-23 20:14:19,651:INFO:Importing libraries
2024-04-23 20:14:19,651:INFO:Copying training dataset
2024-04-23 20:14:19,659:INFO:Defining folds
2024-04-23 20:14:19,659:INFO:Declaring metric variables
2024-04-23 20:14:19,660:INFO:Importing untrained model
2024-04-23 20:14:19,660:INFO:Dummy Classifier Imported successfully
2024-04-23 20:14:19,661:INFO:Starting cross validation
2024-04-23 20:14:19,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:20,052:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,058:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,086:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,088:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,122:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,130:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,131:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,138:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,152:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,164:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,179:INFO:Calculating mean and std
2024-04-23 20:14:20,180:INFO:Creating metrics dataframe
2024-04-23 20:14:20,187:INFO:Uploading results into container
2024-04-23 20:14:20,188:INFO:Uploading model into container now
2024-04-23 20:14:20,189:INFO:_master_model_container: 14
2024-04-23 20:14:20,189:INFO:_display_container: 2
2024-04-23 20:14:20,189:INFO:DummyClassifier(constant=None, random_state=3685, strategy='prior')
2024-04-23 20:14:20,189:INFO:create_model() successfully completed......................................
2024-04-23 20:14:20,354:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:20,355:INFO:Creating metrics dataframe
2024-04-23 20:14:20,362:INFO:Initializing create_model()
2024-04-23 20:14:20,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:20,362:INFO:Checking exceptions
2024-04-23 20:14:20,363:INFO:Importing libraries
2024-04-23 20:14:20,363:INFO:Copying training dataset
2024-04-23 20:14:20,368:INFO:Defining folds
2024-04-23 20:14:20,368:INFO:Declaring metric variables
2024-04-23 20:14:20,369:INFO:Importing untrained model
2024-04-23 20:14:20,369:INFO:Declaring custom model
2024-04-23 20:14:20,370:INFO:Logistic Regression Imported successfully
2024-04-23 20:14:20,372:INFO:Cross validation set to False
2024-04-23 20:14:20,372:INFO:Fitting Model
2024-04-23 20:14:20,663:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:20,664:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:14:20,664:INFO:create_model() successfully completed......................................
2024-04-23 20:14:20,837:INFO:_master_model_container: 14
2024-04-23 20:14:20,837:INFO:_display_container: 2
2024-04-23 20:14:20,838:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:14:20,838:INFO:compare_models() successfully completed......................................
2024-04-23 20:14:20,861:INFO:Initializing save_model()
2024-04-23 20:14:20,861:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecate...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-23 20:14:20,862:INFO:Adding model into prep_pipe
2024-04-23 20:14:20,873:INFO:best_classifier.pkl saved in current working directory
2024-04-23 20:14:20,895:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Transforme...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=3685,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-04-23 20:14:20,895:INFO:save_model() successfully completed......................................
2024-04-23 20:15:01,593:INFO:Initializing load_model()
2024-04-23 20:15:01,593:INFO:load_model(model_name=trained_classifier, platform=None, authentication=None, verbose=True)
2024-04-23 20:15:01,655:INFO:Initializing predict_model()
2024-04-23 20:15:01,655:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most_...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=3685))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002B32ABDB7F0>)
2024-04-23 20:15:01,655:INFO:Checking exceptions
2024-04-23 20:15:01,655:INFO:Preloading libraries
2024-04-23 20:15:01,655:INFO:Set up data.
2024-04-23 20:15:01,662:INFO:Set up index.
2024-04-23 20:20:05,118:INFO:PyCaret RegressionExperiment
2024-04-23 20:20:05,124:INFO:Logging name: reg-default-name
2024-04-23 20:20:05,130:INFO:ML Usecase: MLUsecase.REGRESSION
2024-04-23 20:20:05,136:INFO:version 3.1.0
2024-04-23 20:20:05,142:INFO:Initializing setup()
2024-04-23 20:20:05,148:INFO:self.USI: 0905
2024-04-23 20:20:05,154:INFO:self._variable_keys: {'_ml_usecase', 'logging_param', 'fold_groups_param', 'X_test', 'y', 'fold_shuffle_param', 'transform_target_param', 'seed', 'data', '_available_plots', 'exp_name_log', 'X', 'pipeline', 'X_train', 'y_test', 'fold_generator', 'memory', 'target_param', 'gpu_n_jobs_param', 'exp_id', 'gpu_param', 'log_plots_param', 'idx', 'n_jobs_param', 'USI', 'y_train', 'html_param'}
2024-04-23 20:20:05,160:INFO:Checking environment
2024-04-23 20:20:05,160:INFO:python_version: 3.10.0
2024-04-23 20:20:05,165:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-23 20:20:05,171:INFO:machine: AMD64
2024-04-23 20:20:05,177:INFO:platform: Windows-10-10.0.19045-SP0
2024-04-23 20:20:05,187:INFO:Memory: svmem(total=17041117184, available=7126892544, percent=58.2, used=9914224640, free=7126892544)
2024-04-23 20:20:05,194:INFO:Physical Core: 6
2024-04-23 20:20:05,200:INFO:Logical Core: 12
2024-04-23 20:20:05,206:INFO:Checking libraries
2024-04-23 20:20:05,206:INFO:System:
2024-04-23 20:20:05,206:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-23 20:20:05,206:INFO:executable: C:\Users\User\AppData\Local\Programs\Python\Python310\python.exe
2024-04-23 20:20:05,206:INFO:   machine: Windows-10-10.0.19045-SP0
2024-04-23 20:20:05,206:INFO:PyCaret required dependencies:
2024-04-23 20:20:05,212:INFO:                 pip: 21.2.3
2024-04-23 20:20:05,218:INFO:          setuptools: 57.4.0
2024-04-23 20:20:05,224:INFO:             pycaret: 3.1.0
2024-04-23 20:20:05,230:INFO:             IPython: 8.17.2
2024-04-23 20:20:05,230:INFO:          ipywidgets: 8.1.1
2024-04-23 20:20:05,230:INFO:                tqdm: 4.66.1
2024-04-23 20:20:05,236:INFO:               numpy: 1.25.2
2024-04-23 20:20:05,241:INFO:              pandas: 2.0.3
2024-04-23 20:20:05,247:INFO:              jinja2: 3.1.2
2024-04-23 20:20:05,253:INFO:               scipy: 1.10.1
2024-04-23 20:20:05,259:INFO:              joblib: 1.3.2
2024-04-23 20:20:05,265:INFO:             sklearn: 1.2.2
2024-04-23 20:20:05,271:INFO:                pyod: 1.1.1
2024-04-23 20:20:05,277:INFO:            imblearn: 0.11.0
2024-04-23 20:20:05,277:INFO:   category_encoders: 2.6.3
2024-04-23 20:20:05,277:INFO:            lightgbm: 4.1.0
2024-04-23 20:20:05,277:INFO:               numba: 0.58.1
2024-04-23 20:20:05,277:INFO:            requests: 2.31.0
2024-04-23 20:20:05,277:INFO:          matplotlib: 3.7.3
2024-04-23 20:20:05,283:INFO:          scikitplot: 0.3.7
2024-04-23 20:20:05,288:INFO:         yellowbrick: 1.5
2024-04-23 20:20:05,294:INFO:              plotly: 5.18.0
2024-04-23 20:20:05,300:INFO:    plotly-resampler: Not installed
2024-04-23 20:20:05,306:INFO:             kaleido: 0.2.1
2024-04-23 20:20:05,312:INFO:           schemdraw: 0.15
2024-04-23 20:20:05,318:INFO:         statsmodels: 0.14.0
2024-04-23 20:20:05,324:INFO:              sktime: 0.21.1
2024-04-23 20:20:05,330:INFO:               tbats: 1.1.3
2024-04-23 20:20:05,336:INFO:            pmdarima: 2.0.4
2024-04-23 20:20:05,342:INFO:              psutil: 5.9.6
2024-04-23 20:20:05,348:INFO:          markupsafe: 2.1.3
2024-04-23 20:20:05,354:INFO:             pickle5: Not installed
2024-04-23 20:20:05,360:INFO:         cloudpickle: 3.0.0
2024-04-23 20:20:05,366:INFO:         deprecation: 2.1.0
2024-04-23 20:20:05,372:INFO:              xxhash: 3.4.1
2024-04-23 20:20:05,378:INFO:           wurlitzer: Not installed
2024-04-23 20:20:05,384:INFO:PyCaret optional dependencies:
2024-04-23 20:20:05,390:INFO:                shap: Not installed
2024-04-23 20:20:05,396:INFO:           interpret: Not installed
2024-04-23 20:20:05,402:INFO:                umap: Not installed
2024-04-23 20:20:05,408:INFO:     ydata_profiling: 4.6.1
2024-04-23 20:20:05,414:INFO:  explainerdashboard: Not installed
2024-04-23 20:20:05,420:INFO:             autoviz: Not installed
2024-04-23 20:20:05,432:INFO:           fairlearn: Not installed
2024-04-23 20:20:05,438:INFO:          deepchecks: Not installed
2024-04-23 20:20:05,444:INFO:             xgboost: Not installed
2024-04-23 20:20:05,450:INFO:            catboost: Not installed
2024-04-23 20:20:05,456:INFO:              kmodes: Not installed
2024-04-23 20:20:05,462:INFO:             mlxtend: Not installed
2024-04-23 20:20:05,467:INFO:       statsforecast: Not installed
2024-04-23 20:20:05,473:INFO:        tune_sklearn: Not installed
2024-04-23 20:20:05,479:INFO:                 ray: Not installed
2024-04-23 20:20:05,485:INFO:            hyperopt: Not installed
2024-04-23 20:20:05,497:INFO:              optuna: Not installed
2024-04-23 20:20:05,497:INFO:               skopt: Not installed
2024-04-23 20:20:05,503:INFO:              mlflow: Not installed
2024-04-23 20:20:05,509:INFO:              gradio: Not installed
2024-04-23 20:20:05,515:INFO:             fastapi: Not installed
2024-04-23 20:20:05,521:INFO:             uvicorn: Not installed
2024-04-23 20:20:05,527:INFO:              m2cgen: Not installed
2024-04-23 20:20:05,533:INFO:           evidently: Not installed
2024-04-23 20:20:05,539:INFO:               fugue: Not installed
2024-04-23 20:20:05,545:INFO:           streamlit: 1.28.0
2024-04-23 20:20:05,551:INFO:             prophet: Not installed
2024-04-23 20:20:05,557:INFO:None
2024-04-23 20:20:05,563:INFO:Set up data.
2024-04-23 20:20:06,410:INFO:Set up folding strategy.
2024-04-23 20:20:06,416:INFO:Set up train/test split.
2024-04-23 20:20:06,590:INFO:Set up index.
2024-04-23 20:20:06,603:INFO:Assigning column types.
2024-04-23 20:20:06,709:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-23 20:20:06,715:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-04-23 20:20:06,725:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:20:06,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:06,996:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,117:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,121:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,131:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,438:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-04-23 20:20:07,448:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,452:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,714:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,724:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,915:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,021:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-04-23 20:20:08,035:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,307:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,512:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,612:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-04-23 20:20:08,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:09,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:09,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,213:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-23 20:20:09,384:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:09,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:09,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,766:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-04-23 20:20:10,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:10,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:10,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:10,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:10,379:INFO:Preparing preprocessing pipeline...
2024-04-23 20:20:10,385:INFO:Set up simple imputation.
2024-04-23 20:20:10,712:INFO:Set up encoding of ordinal features.
2024-04-23 20:20:10,739:INFO:Set up encoding of categorical features.
2024-04-23 20:20:25,441:INFO:Finished creating preprocessing pipeline.
2024-04-23 20:20:25,494:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtF...
                                                                    'Condition1',
                                                                    'Condition2',
                                                                    'BldgType',
                                                                    'HouseStyle',
                                                                    'RoofStyle',
                                                                    'RoofMatl',
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2024-04-23 20:20:25,495:INFO:Creating final display dataframe.
2024-04-23 20:20:27,291:INFO:Setup _display_container:                     Description             Value
0                    Session id              6210
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape        (1460, 81)
4        Transformed data shape       (1460, 277)
5   Transformed train set shape       (1021, 277)
6    Transformed test set shape        (439, 277)
7              Ordinal features                 3
8              Numeric features                37
9          Categorical features                43
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              0905
2024-04-23 20:20:27,421:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:27,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:27,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:27,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:27,545:INFO:setup() successfully completed in 22.97s...............
2024-04-23 20:20:51,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:20:51,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:20:51,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:20:51,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:25:31,225:INFO:PyCaret RegressionExperiment
2024-04-23 20:25:31,225:INFO:Logging name: reg-default-name
2024-04-23 20:25:31,225:INFO:ML Usecase: MLUsecase.REGRESSION
2024-04-23 20:25:31,225:INFO:version 3.1.0
2024-04-23 20:25:31,225:INFO:Initializing setup()
2024-04-23 20:25:31,225:INFO:self.USI: ade5
2024-04-23 20:25:31,225:INFO:self._variable_keys: {'fold_shuffle_param', '_available_plots', 'html_param', 'gpu_param', 'exp_id', 'USI', 'n_jobs_param', 'seed', 'idx', 'y_train', 'y', 'X', 'memory', 'logging_param', 'fold_generator', 'transform_target_param', 'target_param', '_ml_usecase', 'y_test', 'X_test', 'pipeline', 'log_plots_param', 'X_train', 'data', 'exp_name_log', 'gpu_n_jobs_param', 'fold_groups_param'}
2024-04-23 20:25:31,225:INFO:Checking environment
2024-04-23 20:25:31,226:INFO:python_version: 3.10.0
2024-04-23 20:25:31,226:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-23 20:25:31,226:INFO:machine: AMD64
2024-04-23 20:25:31,238:INFO:platform: Windows-10-10.0.19045-SP0
2024-04-23 20:25:31,243:INFO:Memory: svmem(total=17041117184, available=6372716544, percent=62.6, used=10668400640, free=6372716544)
2024-04-23 20:25:31,243:INFO:Physical Core: 6
2024-04-23 20:25:31,243:INFO:Logical Core: 12
2024-04-23 20:25:31,243:INFO:Checking libraries
2024-04-23 20:25:31,243:INFO:System:
2024-04-23 20:25:31,243:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-23 20:25:31,243:INFO:executable: C:\Users\User\AppData\Local\Programs\Python\Python310\python.exe
2024-04-23 20:25:31,243:INFO:   machine: Windows-10-10.0.19045-SP0
2024-04-23 20:25:31,243:INFO:PyCaret required dependencies:
2024-04-23 20:25:31,277:INFO:                 pip: 21.2.3
2024-04-23 20:25:31,278:INFO:          setuptools: 57.4.0
2024-04-23 20:25:31,278:INFO:             pycaret: 3.1.0
2024-04-23 20:25:31,278:INFO:             IPython: 8.17.2
2024-04-23 20:25:31,278:INFO:          ipywidgets: 8.1.1
2024-04-23 20:25:31,278:INFO:                tqdm: 4.66.1
2024-04-23 20:25:31,278:INFO:               numpy: 1.25.2
2024-04-23 20:25:31,278:INFO:              pandas: 2.0.3
2024-04-23 20:25:31,278:INFO:              jinja2: 3.1.2
2024-04-23 20:25:31,278:INFO:               scipy: 1.10.1
2024-04-23 20:25:31,278:INFO:              joblib: 1.3.2
2024-04-23 20:25:31,278:INFO:             sklearn: 1.2.2
2024-04-23 20:25:31,279:INFO:                pyod: 1.1.1
2024-04-23 20:25:31,279:INFO:            imblearn: 0.11.0
2024-04-23 20:25:31,279:INFO:   category_encoders: 2.6.3
2024-04-23 20:25:31,279:INFO:            lightgbm: 4.1.0
2024-04-23 20:25:31,279:INFO:               numba: 0.58.1
2024-04-23 20:25:31,279:INFO:            requests: 2.31.0
2024-04-23 20:25:31,279:INFO:          matplotlib: 3.7.3
2024-04-23 20:25:31,279:INFO:          scikitplot: 0.3.7
2024-04-23 20:25:31,279:INFO:         yellowbrick: 1.5
2024-04-23 20:25:31,279:INFO:              plotly: 5.18.0
2024-04-23 20:25:31,279:INFO:    plotly-resampler: Not installed
2024-04-23 20:25:31,279:INFO:             kaleido: 0.2.1
2024-04-23 20:25:31,279:INFO:           schemdraw: 0.15
2024-04-23 20:25:31,279:INFO:         statsmodels: 0.14.0
2024-04-23 20:25:31,279:INFO:              sktime: 0.21.1
2024-04-23 20:25:31,279:INFO:               tbats: 1.1.3
2024-04-23 20:25:31,280:INFO:            pmdarima: 2.0.4
2024-04-23 20:25:31,280:INFO:              psutil: 5.9.6
2024-04-23 20:25:31,280:INFO:          markupsafe: 2.1.3
2024-04-23 20:25:31,280:INFO:             pickle5: Not installed
2024-04-23 20:25:31,280:INFO:         cloudpickle: 3.0.0
2024-04-23 20:25:31,280:INFO:         deprecation: 2.1.0
2024-04-23 20:25:31,280:INFO:              xxhash: 3.4.1
2024-04-23 20:25:31,280:INFO:           wurlitzer: Not installed
2024-04-23 20:25:31,280:INFO:PyCaret optional dependencies:
2024-04-23 20:25:31,295:INFO:                shap: Not installed
2024-04-23 20:25:31,295:INFO:           interpret: Not installed
2024-04-23 20:25:31,296:INFO:                umap: Not installed
2024-04-23 20:25:31,296:INFO:     ydata_profiling: 4.6.1
2024-04-23 20:25:31,296:INFO:  explainerdashboard: Not installed
2024-04-23 20:25:31,296:INFO:             autoviz: Not installed
2024-04-23 20:25:31,296:INFO:           fairlearn: Not installed
2024-04-23 20:25:31,296:INFO:          deepchecks: Not installed
2024-04-23 20:25:31,296:INFO:             xgboost: Not installed
2024-04-23 20:25:31,296:INFO:            catboost: Not installed
2024-04-23 20:25:31,296:INFO:              kmodes: Not installed
2024-04-23 20:25:31,296:INFO:             mlxtend: Not installed
2024-04-23 20:25:31,296:INFO:       statsforecast: Not installed
2024-04-23 20:25:31,296:INFO:        tune_sklearn: Not installed
2024-04-23 20:25:31,296:INFO:                 ray: Not installed
2024-04-23 20:25:31,296:INFO:            hyperopt: Not installed
2024-04-23 20:25:31,296:INFO:              optuna: Not installed
2024-04-23 20:25:31,296:INFO:               skopt: Not installed
2024-04-23 20:25:31,296:INFO:              mlflow: Not installed
2024-04-23 20:25:31,296:INFO:              gradio: Not installed
2024-04-23 20:25:31,296:INFO:             fastapi: Not installed
2024-04-23 20:25:31,296:INFO:             uvicorn: Not installed
2024-04-23 20:25:31,296:INFO:              m2cgen: Not installed
2024-04-23 20:25:31,296:INFO:           evidently: Not installed
2024-04-23 20:25:31,296:INFO:               fugue: Not installed
2024-04-23 20:25:31,297:INFO:           streamlit: 1.28.0
2024-04-23 20:25:31,297:INFO:             prophet: Not installed
2024-04-23 20:25:31,297:INFO:None
2024-04-23 20:25:31,297:INFO:Set up data.
2024-04-23 20:25:31,307:INFO:Set up folding strategy.
2024-04-23 20:25:31,308:INFO:Set up train/test split.
2024-04-23 20:25:31,316:INFO:Set up index.
2024-04-23 20:25:31,317:INFO:Assigning column types.
2024-04-23 20:25:31,320:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-23 20:25:31,320:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,325:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,330:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,448:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,453:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,583:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-04-23 20:25:31,587:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,592:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,661:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,718:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,723:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,848:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,849:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-04-23 20:25:31,859:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,098:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-04-23 20:25:32,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,297:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,361:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-23 20:25:32,432:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,618:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-04-23 20:25:32,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,854:INFO:Preparing preprocessing pipeline...
2024-04-23 20:25:32,854:INFO:Set up simple imputation.
2024-04-23 20:25:32,858:INFO:Set up encoding of ordinal features.
2024-04-23 20:25:32,865:INFO:Set up encoding of categorical features.
2024-04-23 20:25:32,982:INFO:Finished creating preprocessing pipeline.
2024-04-23 20:25:33,066:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fur...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2024-04-23 20:25:33,066:INFO:Creating final display dataframe.
2024-04-23 20:25:33,364:INFO:Setup _display_container:                     Description             Value
0                    Session id               571
1                        Target             price
2                   Target type        Regression
3           Original data shape         (545, 13)
4        Transformed data shape         (545, 15)
5   Transformed train set shape         (381, 15)
6    Transformed test set shape         (164, 15)
7              Ordinal features                 6
8              Numeric features                 5
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              ade5
2024-04-23 20:25:33,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:33,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:33,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:33,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:33,599:INFO:setup() successfully completed in 2.38s...............
2024-04-23 20:25:33,605:INFO:Initializing compare_models()
2024-04-23 20:25:33,606:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-04-23 20:25:33,606:INFO:Checking exceptions
2024-04-23 20:25:33,607:INFO:Preparing display monitor
2024-04-23 20:25:33,611:INFO:Initializing Linear Regression
2024-04-23 20:25:33,611:INFO:Total runtime is 0.0 minutes
2024-04-23 20:25:33,612:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:33,612:INFO:Initializing create_model()
2024-04-23 20:25:33,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:33,612:INFO:Checking exceptions
2024-04-23 20:25:33,612:INFO:Importing libraries
2024-04-23 20:25:33,612:INFO:Copying training dataset
2024-04-23 20:25:33,620:INFO:Defining folds
2024-04-23 20:25:33,620:INFO:Declaring metric variables
2024-04-23 20:25:33,620:INFO:Importing untrained model
2024-04-23 20:25:33,621:INFO:Linear Regression Imported successfully
2024-04-23 20:25:33,621:INFO:Starting cross validation
2024-04-23 20:25:33,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:40,717:INFO:Calculating mean and std
2024-04-23 20:25:40,718:INFO:Creating metrics dataframe
2024-04-23 20:25:40,724:INFO:Uploading results into container
2024-04-23 20:25:40,725:INFO:Uploading model into container now
2024-04-23 20:25:40,726:INFO:_master_model_container: 1
2024-04-23 20:25:40,726:INFO:_display_container: 2
2024-04-23 20:25:40,727:INFO:LinearRegression(n_jobs=-1)
2024-04-23 20:25:40,727:INFO:create_model() successfully completed......................................
2024-04-23 20:25:40,900:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:40,900:INFO:Creating metrics dataframe
2024-04-23 20:25:40,904:INFO:Initializing Lasso Regression
2024-04-23 20:25:40,904:INFO:Total runtime is 0.12154926856358846 minutes
2024-04-23 20:25:40,904:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:40,905:INFO:Initializing create_model()
2024-04-23 20:25:40,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:40,905:INFO:Checking exceptions
2024-04-23 20:25:40,905:INFO:Importing libraries
2024-04-23 20:25:40,905:INFO:Copying training dataset
2024-04-23 20:25:40,909:INFO:Defining folds
2024-04-23 20:25:40,909:INFO:Declaring metric variables
2024-04-23 20:25:40,909:INFO:Importing untrained model
2024-04-23 20:25:40,910:INFO:Lasso Regression Imported successfully
2024-04-23 20:25:40,910:INFO:Starting cross validation
2024-04-23 20:25:40,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:43,268:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+13, tolerance: 1.249e+11
  model = cd_fast.enet_coordinate_descent(

2024-04-23 20:25:43,308:INFO:Calculating mean and std
2024-04-23 20:25:43,309:INFO:Creating metrics dataframe
2024-04-23 20:25:43,312:INFO:Uploading results into container
2024-04-23 20:25:43,313:INFO:Uploading model into container now
2024-04-23 20:25:43,313:INFO:_master_model_container: 2
2024-04-23 20:25:43,313:INFO:_display_container: 2
2024-04-23 20:25:43,313:INFO:Lasso(random_state=571)
2024-04-23 20:25:43,313:INFO:create_model() successfully completed......................................
2024-04-23 20:25:43,464:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:43,464:INFO:Creating metrics dataframe
2024-04-23 20:25:43,469:INFO:Initializing Ridge Regression
2024-04-23 20:25:43,469:INFO:Total runtime is 0.16429104010264078 minutes
2024-04-23 20:25:43,469:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:43,469:INFO:Initializing create_model()
2024-04-23 20:25:43,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:43,469:INFO:Checking exceptions
2024-04-23 20:25:43,469:INFO:Importing libraries
2024-04-23 20:25:43,469:INFO:Copying training dataset
2024-04-23 20:25:43,473:INFO:Defining folds
2024-04-23 20:25:43,473:INFO:Declaring metric variables
2024-04-23 20:25:43,473:INFO:Importing untrained model
2024-04-23 20:25:43,473:INFO:Ridge Regression Imported successfully
2024-04-23 20:25:43,473:INFO:Starting cross validation
2024-04-23 20:25:43,475:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:43,801:INFO:Calculating mean and std
2024-04-23 20:25:43,802:INFO:Creating metrics dataframe
2024-04-23 20:25:43,805:INFO:Uploading results into container
2024-04-23 20:25:43,805:INFO:Uploading model into container now
2024-04-23 20:25:43,806:INFO:_master_model_container: 3
2024-04-23 20:25:43,806:INFO:_display_container: 2
2024-04-23 20:25:43,806:INFO:Ridge(random_state=571)
2024-04-23 20:25:43,806:INFO:create_model() successfully completed......................................
2024-04-23 20:25:43,940:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:43,940:INFO:Creating metrics dataframe
2024-04-23 20:25:43,945:INFO:Initializing Elastic Net
2024-04-23 20:25:43,945:INFO:Total runtime is 0.17223515510559081 minutes
2024-04-23 20:25:43,945:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:43,946:INFO:Initializing create_model()
2024-04-23 20:25:43,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:43,946:INFO:Checking exceptions
2024-04-23 20:25:43,946:INFO:Importing libraries
2024-04-23 20:25:43,946:INFO:Copying training dataset
2024-04-23 20:25:43,949:INFO:Defining folds
2024-04-23 20:25:43,949:INFO:Declaring metric variables
2024-04-23 20:25:43,950:INFO:Importing untrained model
2024-04-23 20:25:43,950:INFO:Elastic Net Imported successfully
2024-04-23 20:25:43,950:INFO:Starting cross validation
2024-04-23 20:25:43,952:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:44,306:INFO:Calculating mean and std
2024-04-23 20:25:44,307:INFO:Creating metrics dataframe
2024-04-23 20:25:44,310:INFO:Uploading results into container
2024-04-23 20:25:44,311:INFO:Uploading model into container now
2024-04-23 20:25:44,311:INFO:_master_model_container: 4
2024-04-23 20:25:44,311:INFO:_display_container: 2
2024-04-23 20:25:44,312:INFO:ElasticNet(random_state=571)
2024-04-23 20:25:44,312:INFO:create_model() successfully completed......................................
2024-04-23 20:25:44,469:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:44,469:INFO:Creating metrics dataframe
2024-04-23 20:25:44,473:INFO:Initializing Least Angle Regression
2024-04-23 20:25:44,473:INFO:Total runtime is 0.18103678623835245 minutes
2024-04-23 20:25:44,473:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:44,474:INFO:Initializing create_model()
2024-04-23 20:25:44,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:44,474:INFO:Checking exceptions
2024-04-23 20:25:44,474:INFO:Importing libraries
2024-04-23 20:25:44,474:INFO:Copying training dataset
2024-04-23 20:25:44,477:INFO:Defining folds
2024-04-23 20:25:44,478:INFO:Declaring metric variables
2024-04-23 20:25:44,478:INFO:Importing untrained model
2024-04-23 20:25:44,478:INFO:Least Angle Regression Imported successfully
2024-04-23 20:25:44,479:INFO:Starting cross validation
2024-04-23 20:25:44,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:44,840:INFO:Calculating mean and std
2024-04-23 20:25:44,841:INFO:Creating metrics dataframe
2024-04-23 20:25:44,844:INFO:Uploading results into container
2024-04-23 20:25:44,845:INFO:Uploading model into container now
2024-04-23 20:25:44,845:INFO:_master_model_container: 5
2024-04-23 20:25:44,845:INFO:_display_container: 2
2024-04-23 20:25:44,845:INFO:Lars(random_state=571)
2024-04-23 20:25:44,845:INFO:create_model() successfully completed......................................
2024-04-23 20:25:44,994:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:44,995:INFO:Creating metrics dataframe
2024-04-23 20:25:44,999:INFO:Initializing Lasso Least Angle Regression
2024-04-23 20:25:45,000:INFO:Total runtime is 0.18981643120447794 minutes
2024-04-23 20:25:45,000:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:45,000:INFO:Initializing create_model()
2024-04-23 20:25:45,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:45,000:INFO:Checking exceptions
2024-04-23 20:25:45,000:INFO:Importing libraries
2024-04-23 20:25:45,000:INFO:Copying training dataset
2024-04-23 20:25:45,004:INFO:Defining folds
2024-04-23 20:25:45,005:INFO:Declaring metric variables
2024-04-23 20:25:45,005:INFO:Importing untrained model
2024-04-23 20:25:45,005:INFO:Lasso Least Angle Regression Imported successfully
2024-04-23 20:25:45,005:INFO:Starting cross validation
2024-04-23 20:25:45,006:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:45,349:INFO:Calculating mean and std
2024-04-23 20:25:45,351:INFO:Creating metrics dataframe
2024-04-23 20:25:45,354:INFO:Uploading results into container
2024-04-23 20:25:45,355:INFO:Uploading model into container now
2024-04-23 20:25:45,355:INFO:_master_model_container: 6
2024-04-23 20:25:45,355:INFO:_display_container: 2
2024-04-23 20:25:45,356:INFO:LassoLars(random_state=571)
2024-04-23 20:25:45,356:INFO:create_model() successfully completed......................................
2024-04-23 20:25:45,492:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:45,492:INFO:Creating metrics dataframe
2024-04-23 20:25:45,496:INFO:Initializing Orthogonal Matching Pursuit
2024-04-23 20:25:45,496:INFO:Total runtime is 0.19807765086491902 minutes
2024-04-23 20:25:45,496:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:45,497:INFO:Initializing create_model()
2024-04-23 20:25:45,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:45,497:INFO:Checking exceptions
2024-04-23 20:25:45,497:INFO:Importing libraries
2024-04-23 20:25:45,497:INFO:Copying training dataset
2024-04-23 20:25:45,500:INFO:Defining folds
2024-04-23 20:25:45,501:INFO:Declaring metric variables
2024-04-23 20:25:45,501:INFO:Importing untrained model
2024-04-23 20:25:45,501:INFO:Orthogonal Matching Pursuit Imported successfully
2024-04-23 20:25:45,501:INFO:Starting cross validation
2024-04-23 20:25:45,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:45,872:INFO:Calculating mean and std
2024-04-23 20:25:45,872:INFO:Creating metrics dataframe
2024-04-23 20:25:45,875:INFO:Uploading results into container
2024-04-23 20:25:45,876:INFO:Uploading model into container now
2024-04-23 20:25:45,876:INFO:_master_model_container: 7
2024-04-23 20:25:45,876:INFO:_display_container: 2
2024-04-23 20:25:45,876:INFO:OrthogonalMatchingPursuit()
2024-04-23 20:25:45,876:INFO:create_model() successfully completed......................................
2024-04-23 20:25:46,009:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:46,009:INFO:Creating metrics dataframe
2024-04-23 20:25:46,013:INFO:Initializing Bayesian Ridge
2024-04-23 20:25:46,013:INFO:Total runtime is 0.2067064881324768 minutes
2024-04-23 20:25:46,014:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:46,014:INFO:Initializing create_model()
2024-04-23 20:25:46,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:46,014:INFO:Checking exceptions
2024-04-23 20:25:46,014:INFO:Importing libraries
2024-04-23 20:25:46,014:INFO:Copying training dataset
2024-04-23 20:25:46,018:INFO:Defining folds
2024-04-23 20:25:46,018:INFO:Declaring metric variables
2024-04-23 20:25:46,019:INFO:Importing untrained model
2024-04-23 20:25:46,019:INFO:Bayesian Ridge Imported successfully
2024-04-23 20:25:46,019:INFO:Starting cross validation
2024-04-23 20:25:46,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:46,356:INFO:Calculating mean and std
2024-04-23 20:25:46,357:INFO:Creating metrics dataframe
2024-04-23 20:25:46,360:INFO:Uploading results into container
2024-04-23 20:25:46,360:INFO:Uploading model into container now
2024-04-23 20:25:46,360:INFO:_master_model_container: 8
2024-04-23 20:25:46,360:INFO:_display_container: 2
2024-04-23 20:25:46,361:INFO:BayesianRidge()
2024-04-23 20:25:46,361:INFO:create_model() successfully completed......................................
2024-04-23 20:25:46,490:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:46,490:INFO:Creating metrics dataframe
2024-04-23 20:25:46,494:INFO:Initializing Passive Aggressive Regressor
2024-04-23 20:25:46,494:INFO:Total runtime is 0.2147192319234212 minutes
2024-04-23 20:25:46,495:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:46,495:INFO:Initializing create_model()
2024-04-23 20:25:46,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:46,495:INFO:Checking exceptions
2024-04-23 20:25:46,495:INFO:Importing libraries
2024-04-23 20:25:46,495:INFO:Copying training dataset
2024-04-23 20:25:46,499:INFO:Defining folds
2024-04-23 20:25:46,499:INFO:Declaring metric variables
2024-04-23 20:25:46,499:INFO:Importing untrained model
2024-04-23 20:25:46,499:INFO:Passive Aggressive Regressor Imported successfully
2024-04-23 20:25:46,500:INFO:Starting cross validation
2024-04-23 20:25:46,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:46,831:INFO:Calculating mean and std
2024-04-23 20:25:46,831:INFO:Creating metrics dataframe
2024-04-23 20:25:46,834:INFO:Uploading results into container
2024-04-23 20:25:46,835:INFO:Uploading model into container now
2024-04-23 20:25:46,835:INFO:_master_model_container: 9
2024-04-23 20:25:46,835:INFO:_display_container: 2
2024-04-23 20:25:46,835:INFO:PassiveAggressiveRegressor(random_state=571)
2024-04-23 20:25:46,835:INFO:create_model() successfully completed......................................
2024-04-23 20:25:46,975:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:46,975:INFO:Creating metrics dataframe
2024-04-23 20:25:46,980:INFO:Initializing Huber Regressor
2024-04-23 20:25:46,981:INFO:Total runtime is 0.2228252053260803 minutes
2024-04-23 20:25:46,981:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:46,982:INFO:Initializing create_model()
2024-04-23 20:25:46,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:46,982:INFO:Checking exceptions
2024-04-23 20:25:46,982:INFO:Importing libraries
2024-04-23 20:25:46,983:INFO:Copying training dataset
2024-04-23 20:25:46,987:INFO:Defining folds
2024-04-23 20:25:46,987:INFO:Declaring metric variables
2024-04-23 20:25:46,987:INFO:Importing untrained model
2024-04-23 20:25:46,987:INFO:Huber Regressor Imported successfully
2024-04-23 20:25:46,987:INFO:Starting cross validation
2024-04-23 20:25:46,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:47,268:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-04-23 20:25:47,282:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-04-23 20:25:47,304:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-04-23 20:25:47,367:INFO:Calculating mean and std
2024-04-23 20:25:47,368:INFO:Creating metrics dataframe
2024-04-23 20:25:47,370:INFO:Uploading results into container
2024-04-23 20:25:47,371:INFO:Uploading model into container now
2024-04-23 20:25:47,371:INFO:_master_model_container: 10
2024-04-23 20:25:47,371:INFO:_display_container: 2
2024-04-23 20:25:47,371:INFO:HuberRegressor()
2024-04-23 20:25:47,371:INFO:create_model() successfully completed......................................
2024-04-23 20:25:47,503:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:47,503:INFO:Creating metrics dataframe
2024-04-23 20:25:47,507:INFO:Initializing K Neighbors Regressor
2024-04-23 20:25:47,507:INFO:Total runtime is 0.2316017150878906 minutes
2024-04-23 20:25:47,508:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:47,508:INFO:Initializing create_model()
2024-04-23 20:25:47,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:47,508:INFO:Checking exceptions
2024-04-23 20:25:47,508:INFO:Importing libraries
2024-04-23 20:25:47,508:INFO:Copying training dataset
2024-04-23 20:25:47,512:INFO:Defining folds
2024-04-23 20:25:47,512:INFO:Declaring metric variables
2024-04-23 20:25:47,512:INFO:Importing untrained model
2024-04-23 20:25:47,512:INFO:K Neighbors Regressor Imported successfully
2024-04-23 20:25:47,512:INFO:Starting cross validation
2024-04-23 20:25:47,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:47,891:INFO:Calculating mean and std
2024-04-23 20:25:47,891:INFO:Creating metrics dataframe
2024-04-23 20:25:47,894:INFO:Uploading results into container
2024-04-23 20:25:47,895:INFO:Uploading model into container now
2024-04-23 20:25:47,895:INFO:_master_model_container: 11
2024-04-23 20:25:47,895:INFO:_display_container: 2
2024-04-23 20:25:47,896:INFO:KNeighborsRegressor(n_jobs=-1)
2024-04-23 20:25:47,896:INFO:create_model() successfully completed......................................
2024-04-23 20:25:48,027:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:48,027:INFO:Creating metrics dataframe
2024-04-23 20:25:48,031:INFO:Initializing Decision Tree Regressor
2024-04-23 20:25:48,031:INFO:Total runtime is 0.24032702048619586 minutes
2024-04-23 20:25:48,032:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:48,032:INFO:Initializing create_model()
2024-04-23 20:25:48,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:48,032:INFO:Checking exceptions
2024-04-23 20:25:48,032:INFO:Importing libraries
2024-04-23 20:25:48,032:INFO:Copying training dataset
2024-04-23 20:25:48,036:INFO:Defining folds
2024-04-23 20:25:48,036:INFO:Declaring metric variables
2024-04-23 20:25:48,036:INFO:Importing untrained model
2024-04-23 20:25:48,036:INFO:Decision Tree Regressor Imported successfully
2024-04-23 20:25:48,036:INFO:Starting cross validation
2024-04-23 20:25:48,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:48,349:INFO:Calculating mean and std
2024-04-23 20:25:48,350:INFO:Creating metrics dataframe
2024-04-23 20:25:48,353:INFO:Uploading results into container
2024-04-23 20:25:48,354:INFO:Uploading model into container now
2024-04-23 20:25:48,354:INFO:_master_model_container: 12
2024-04-23 20:25:48,354:INFO:_display_container: 2
2024-04-23 20:25:48,355:INFO:DecisionTreeRegressor(random_state=571)
2024-04-23 20:25:48,355:INFO:create_model() successfully completed......................................
2024-04-23 20:25:48,484:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:48,484:INFO:Creating metrics dataframe
2024-04-23 20:25:48,489:INFO:Initializing Random Forest Regressor
2024-04-23 20:25:48,489:INFO:Total runtime is 0.24795717795689898 minutes
2024-04-23 20:25:48,489:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:48,489:INFO:Initializing create_model()
2024-04-23 20:25:48,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:48,490:INFO:Checking exceptions
2024-04-23 20:25:48,490:INFO:Importing libraries
2024-04-23 20:25:48,490:INFO:Copying training dataset
2024-04-23 20:25:48,492:INFO:Defining folds
2024-04-23 20:25:48,492:INFO:Declaring metric variables
2024-04-23 20:25:48,493:INFO:Importing untrained model
2024-04-23 20:25:48,493:INFO:Random Forest Regressor Imported successfully
2024-04-23 20:25:48,493:INFO:Starting cross validation
2024-04-23 20:25:48,494:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:49,231:INFO:Calculating mean and std
2024-04-23 20:25:49,231:INFO:Creating metrics dataframe
2024-04-23 20:25:49,235:INFO:Uploading results into container
2024-04-23 20:25:49,235:INFO:Uploading model into container now
2024-04-23 20:25:49,236:INFO:_master_model_container: 13
2024-04-23 20:25:49,236:INFO:_display_container: 2
2024-04-23 20:25:49,236:INFO:RandomForestRegressor(n_jobs=-1, random_state=571)
2024-04-23 20:25:49,236:INFO:create_model() successfully completed......................................
2024-04-23 20:25:49,367:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:49,367:INFO:Creating metrics dataframe
2024-04-23 20:25:49,372:INFO:Initializing Extra Trees Regressor
2024-04-23 20:25:49,372:INFO:Total runtime is 0.2626766403516133 minutes
2024-04-23 20:25:49,372:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:49,373:INFO:Initializing create_model()
2024-04-23 20:25:49,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:49,373:INFO:Checking exceptions
2024-04-23 20:25:49,373:INFO:Importing libraries
2024-04-23 20:25:49,373:INFO:Copying training dataset
2024-04-23 20:25:49,379:INFO:Defining folds
2024-04-23 20:25:49,379:INFO:Declaring metric variables
2024-04-23 20:25:49,379:INFO:Importing untrained model
2024-04-23 20:25:49,380:INFO:Extra Trees Regressor Imported successfully
2024-04-23 20:25:49,380:INFO:Starting cross validation
2024-04-23 20:25:49,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:50,026:INFO:Calculating mean and std
2024-04-23 20:25:50,027:INFO:Creating metrics dataframe
2024-04-23 20:25:50,030:INFO:Uploading results into container
2024-04-23 20:25:50,030:INFO:Uploading model into container now
2024-04-23 20:25:50,031:INFO:_master_model_container: 14
2024-04-23 20:25:50,031:INFO:_display_container: 2
2024-04-23 20:25:50,031:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=571)
2024-04-23 20:25:50,031:INFO:create_model() successfully completed......................................
2024-04-23 20:25:50,164:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:50,164:INFO:Creating metrics dataframe
2024-04-23 20:25:50,169:INFO:Initializing AdaBoost Regressor
2024-04-23 20:25:50,169:INFO:Total runtime is 0.2759583473205566 minutes
2024-04-23 20:25:50,169:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:50,170:INFO:Initializing create_model()
2024-04-23 20:25:50,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:50,170:INFO:Checking exceptions
2024-04-23 20:25:50,170:INFO:Importing libraries
2024-04-23 20:25:50,170:INFO:Copying training dataset
2024-04-23 20:25:50,174:INFO:Defining folds
2024-04-23 20:25:50,174:INFO:Declaring metric variables
2024-04-23 20:25:50,174:INFO:Importing untrained model
2024-04-23 20:25:50,175:INFO:AdaBoost Regressor Imported successfully
2024-04-23 20:25:50,175:INFO:Starting cross validation
2024-04-23 20:25:50,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:50,659:INFO:Calculating mean and std
2024-04-23 20:25:50,661:INFO:Creating metrics dataframe
2024-04-23 20:25:50,664:INFO:Uploading results into container
2024-04-23 20:25:50,664:INFO:Uploading model into container now
2024-04-23 20:25:50,664:INFO:_master_model_container: 15
2024-04-23 20:25:50,664:INFO:_display_container: 2
2024-04-23 20:25:50,665:INFO:AdaBoostRegressor(random_state=571)
2024-04-23 20:25:50,665:INFO:create_model() successfully completed......................................
2024-04-23 20:25:50,798:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:50,798:INFO:Creating metrics dataframe
2024-04-23 20:25:50,802:INFO:Initializing Gradient Boosting Regressor
2024-04-23 20:25:50,803:INFO:Total runtime is 0.2865343769391377 minutes
2024-04-23 20:25:50,803:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:50,803:INFO:Initializing create_model()
2024-04-23 20:25:50,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:50,803:INFO:Checking exceptions
2024-04-23 20:25:50,803:INFO:Importing libraries
2024-04-23 20:25:50,803:INFO:Copying training dataset
2024-04-23 20:25:50,807:INFO:Defining folds
2024-04-23 20:25:50,807:INFO:Declaring metric variables
2024-04-23 20:25:50,807:INFO:Importing untrained model
2024-04-23 20:25:50,808:INFO:Gradient Boosting Regressor Imported successfully
2024-04-23 20:25:50,808:INFO:Starting cross validation
2024-04-23 20:25:50,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:51,377:INFO:Calculating mean and std
2024-04-23 20:25:51,379:INFO:Creating metrics dataframe
2024-04-23 20:25:51,383:INFO:Uploading results into container
2024-04-23 20:25:51,384:INFO:Uploading model into container now
2024-04-23 20:25:51,384:INFO:_master_model_container: 16
2024-04-23 20:25:51,384:INFO:_display_container: 2
2024-04-23 20:25:51,384:INFO:GradientBoostingRegressor(random_state=571)
2024-04-23 20:25:51,385:INFO:create_model() successfully completed......................................
2024-04-23 20:25:51,535:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:51,535:INFO:Creating metrics dataframe
2024-04-23 20:25:51,539:INFO:Initializing Light Gradient Boosting Machine
2024-04-23 20:25:51,540:INFO:Total runtime is 0.2988181749979654 minutes
2024-04-23 20:25:51,540:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:51,540:INFO:Initializing create_model()
2024-04-23 20:25:51,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:51,540:INFO:Checking exceptions
2024-04-23 20:25:51,540:INFO:Importing libraries
2024-04-23 20:25:51,540:INFO:Copying training dataset
2024-04-23 20:25:51,544:INFO:Defining folds
2024-04-23 20:25:51,545:INFO:Declaring metric variables
2024-04-23 20:25:51,545:INFO:Importing untrained model
2024-04-23 20:25:51,545:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-23 20:25:51,546:INFO:Starting cross validation
2024-04-23 20:25:51,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:52,950:INFO:Calculating mean and std
2024-04-23 20:25:52,951:INFO:Creating metrics dataframe
2024-04-23 20:25:52,955:INFO:Uploading results into container
2024-04-23 20:25:52,955:INFO:Uploading model into container now
2024-04-23 20:25:52,956:INFO:_master_model_container: 17
2024-04-23 20:25:52,956:INFO:_display_container: 2
2024-04-23 20:25:52,956:INFO:LGBMRegressor(n_jobs=-1, random_state=571)
2024-04-23 20:25:52,956:INFO:create_model() successfully completed......................................
2024-04-23 20:25:53,163:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:53,163:INFO:Creating metrics dataframe
2024-04-23 20:25:53,171:INFO:Initializing Dummy Regressor
2024-04-23 20:25:53,171:INFO:Total runtime is 0.32599687178929637 minutes
2024-04-23 20:25:53,171:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:53,172:INFO:Initializing create_model()
2024-04-23 20:25:53,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:53,172:INFO:Checking exceptions
2024-04-23 20:25:53,172:INFO:Importing libraries
2024-04-23 20:25:53,172:INFO:Copying training dataset
2024-04-23 20:25:53,195:INFO:Defining folds
2024-04-23 20:25:53,197:INFO:Declaring metric variables
2024-04-23 20:25:53,197:INFO:Importing untrained model
2024-04-23 20:25:53,203:INFO:Dummy Regressor Imported successfully
2024-04-23 20:25:53,206:INFO:Starting cross validation
2024-04-23 20:25:53,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:53,865:INFO:Calculating mean and std
2024-04-23 20:25:53,866:INFO:Creating metrics dataframe
2024-04-23 20:25:53,870:INFO:Uploading results into container
2024-04-23 20:25:53,870:INFO:Uploading model into container now
2024-04-23 20:25:53,871:INFO:_master_model_container: 18
2024-04-23 20:25:53,871:INFO:_display_container: 2
2024-04-23 20:25:53,871:INFO:DummyRegressor()
2024-04-23 20:25:53,871:INFO:create_model() successfully completed......................................
2024-04-23 20:25:54,048:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:54,048:INFO:Creating metrics dataframe
2024-04-23 20:25:54,055:INFO:Initializing create_model()
2024-04-23 20:25:54,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=Ridge(random_state=571), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:54,055:INFO:Checking exceptions
2024-04-23 20:25:54,056:INFO:Importing libraries
2024-04-23 20:25:54,056:INFO:Copying training dataset
2024-04-23 20:25:54,059:INFO:Defining folds
2024-04-23 20:25:54,059:INFO:Declaring metric variables
2024-04-23 20:25:54,059:INFO:Importing untrained model
2024-04-23 20:25:54,059:INFO:Declaring custom model
2024-04-23 20:25:54,060:INFO:Ridge Regression Imported successfully
2024-04-23 20:25:54,061:INFO:Cross validation set to False
2024-04-23 20:25:54,061:INFO:Fitting Model
2024-04-23 20:25:54,138:INFO:Ridge(random_state=571)
2024-04-23 20:25:54,138:INFO:create_model() successfully completed......................................
2024-04-23 20:25:54,304:INFO:_master_model_container: 18
2024-04-23 20:25:54,304:INFO:_display_container: 2
2024-04-23 20:25:54,305:INFO:Ridge(random_state=571)
2024-04-23 20:25:54,305:INFO:compare_models() successfully completed......................................
2024-04-23 20:25:54,399:INFO:Initializing save_model()
2024-04-23 20:25:54,400:INFO:save_model(model=Ridge(random_state=571), model_name=best_regressor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fur...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2024-04-23 20:25:54,400:INFO:Adding model into prep_pipe
2024-04-23 20:25:54,409:INFO:best_regressor.pkl saved in current working directory
2024-04-23 20:25:54,504:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'furnishingstatus'],
                                    transformer=SimpleImput...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model', Ridge(random_state=571))])
2024-04-23 20:25:54,504:INFO:save_model() successfully completed......................................
2024-04-23 20:26:55,320:INFO:Initializing load_model()
2024-04-23 20:26:55,320:INFO:load_model(model_name=trained_regressor, platform=None, authentication=None, verbose=True)
2024-04-23 20:26:55,471:INFO:Initializing predict_model()
2024-04-23 20:26:55,471:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fur...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model', Ridge(random_state=571))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CC31F94310>)
2024-04-23 20:26:55,471:INFO:Checking exceptions
2024-04-23 20:26:55,471:INFO:Preloading libraries
2024-04-23 20:26:55,472:INFO:Set up data.
2024-04-23 20:26:55,479:INFO:Set up index.
2024-11-10 11:28:52,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-10 11:28:52,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-10 11:28:52,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-10 11:28:52,542:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-10 12:02:28,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-10 12:02:28,910:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-10 12:02:28,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-10 12:02:28,912:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-11-10 12:03:41,221:INFO:PyCaret RegressionExperiment
2024-11-10 12:03:41,223:INFO:Logging name: reg-default-name
2024-11-10 12:03:41,223:INFO:ML Usecase: MLUsecase.REGRESSION
2024-11-10 12:03:41,223:INFO:version 3.3.2
2024-11-10 12:03:41,223:INFO:Initializing setup()
2024-11-10 12:03:41,223:INFO:self.USI: 25ff
2024-11-10 12:03:41,223:INFO:self._variable_keys: {'idx', 'y', 'data', '_ml_usecase', 'log_plots_param', 'y_test', 'fold_generator', 'transform_target_param', 'target_param', 'fold_groups_param', 'X', 'html_param', 'X_test', 'exp_id', 'memory', 'y_train', 'pipeline', 'USI', '_available_plots', 'X_train', 'gpu_n_jobs_param', 'fold_shuffle_param', 'seed', 'n_jobs_param', 'logging_param', 'exp_name_log', 'gpu_param'}
2024-11-10 12:03:41,223:INFO:Checking environment
2024-11-10 12:03:41,223:INFO:python_version: 3.10.0
2024-11-10 12:03:41,223:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-11-10 12:03:41,223:INFO:machine: AMD64
2024-11-10 12:03:41,251:INFO:platform: Windows-10-10.0.22631-SP0
2024-11-10 12:03:41,257:INFO:Memory: svmem(total=17037209600, available=5109579776, percent=70.0, used=11927629824, free=5109579776)
2024-11-10 12:03:41,257:INFO:Physical Core: 6
2024-11-10 12:03:41,257:INFO:Logical Core: 12
2024-11-10 12:03:41,257:INFO:Checking libraries
2024-11-10 12:03:41,257:INFO:System:
2024-11-10 12:03:41,257:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-11-10 12:03:41,257:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2024-11-10 12:03:41,257:INFO:   machine: Windows-10-10.0.22631-SP0
2024-11-10 12:03:41,257:INFO:PyCaret required dependencies:
2024-11-10 12:03:41,325:INFO:                 pip: 21.2.3
2024-11-10 12:03:41,325:INFO:          setuptools: 57.4.0
2024-11-10 12:03:41,325:INFO:             pycaret: 3.3.2
2024-11-10 12:03:41,325:INFO:             IPython: 8.29.0
2024-11-10 12:03:41,325:INFO:          ipywidgets: 8.1.5
2024-11-10 12:03:41,325:INFO:                tqdm: 4.67.0
2024-11-10 12:03:41,325:INFO:               numpy: 1.26.4
2024-11-10 12:03:41,325:INFO:              pandas: 2.1.4
2024-11-10 12:03:41,325:INFO:              jinja2: 3.1.4
2024-11-10 12:03:41,325:INFO:               scipy: 1.11.4
2024-11-10 12:03:41,325:INFO:              joblib: 1.3.2
2024-11-10 12:03:41,325:INFO:             sklearn: 1.4.2
2024-11-10 12:03:41,326:INFO:                pyod: 2.0.2
2024-11-10 12:03:41,326:INFO:            imblearn: 0.12.4
2024-11-10 12:03:41,326:INFO:   category_encoders: 2.6.4
2024-11-10 12:03:41,326:INFO:            lightgbm: 4.5.0
2024-11-10 12:03:41,326:INFO:               numba: 0.60.0
2024-11-10 12:03:41,326:INFO:            requests: 2.32.3
2024-11-10 12:03:41,326:INFO:          matplotlib: 3.7.5
2024-11-10 12:03:41,326:INFO:          scikitplot: 0.3.7
2024-11-10 12:03:41,326:INFO:         yellowbrick: 1.5
2024-11-10 12:03:41,326:INFO:              plotly: 5.24.1
2024-11-10 12:03:41,326:INFO:    plotly-resampler: Not installed
2024-11-10 12:03:41,326:INFO:             kaleido: 0.2.1
2024-11-10 12:03:41,326:INFO:           schemdraw: 0.15
2024-11-10 12:03:41,326:INFO:         statsmodels: 0.14.4
2024-11-10 12:03:41,326:INFO:              sktime: 0.26.0
2024-11-10 12:03:41,326:INFO:               tbats: 1.1.3
2024-11-10 12:03:41,326:INFO:            pmdarima: 2.0.4
2024-11-10 12:03:41,326:INFO:              psutil: 6.1.0
2024-11-10 12:03:41,326:INFO:          markupsafe: 3.0.2
2024-11-10 12:03:41,326:INFO:             pickle5: Not installed
2024-11-10 12:03:41,326:INFO:         cloudpickle: 3.1.0
2024-11-10 12:03:41,326:INFO:         deprecation: 2.1.0
2024-11-10 12:03:41,326:INFO:              xxhash: 3.5.0
2024-11-10 12:03:41,326:INFO:           wurlitzer: Not installed
2024-11-10 12:03:41,326:INFO:PyCaret optional dependencies:
2024-11-10 12:03:41,338:INFO:                shap: Not installed
2024-11-10 12:03:41,338:INFO:           interpret: Not installed
2024-11-10 12:03:41,338:INFO:                umap: Not installed
2024-11-10 12:03:41,338:INFO:     ydata_profiling: 4.12.0
2024-11-10 12:03:41,338:INFO:  explainerdashboard: Not installed
2024-11-10 12:03:41,338:INFO:             autoviz: Not installed
2024-11-10 12:03:41,338:INFO:           fairlearn: Not installed
2024-11-10 12:03:41,338:INFO:          deepchecks: Not installed
2024-11-10 12:03:41,338:INFO:             xgboost: Not installed
2024-11-10 12:03:41,338:INFO:            catboost: Not installed
2024-11-10 12:03:41,338:INFO:              kmodes: Not installed
2024-11-10 12:03:41,338:INFO:             mlxtend: Not installed
2024-11-10 12:03:41,338:INFO:       statsforecast: Not installed
2024-11-10 12:03:41,339:INFO:        tune_sklearn: Not installed
2024-11-10 12:03:41,339:INFO:                 ray: Not installed
2024-11-10 12:03:41,339:INFO:            hyperopt: Not installed
2024-11-10 12:03:41,339:INFO:              optuna: Not installed
2024-11-10 12:03:41,339:INFO:               skopt: Not installed
2024-11-10 12:03:41,339:INFO:              mlflow: Not installed
2024-11-10 12:03:41,339:INFO:              gradio: Not installed
2024-11-10 12:03:41,339:INFO:             fastapi: Not installed
2024-11-10 12:03:41,339:INFO:             uvicorn: Not installed
2024-11-10 12:03:41,339:INFO:              m2cgen: Not installed
2024-11-10 12:03:41,339:INFO:           evidently: Not installed
2024-11-10 12:03:41,339:INFO:               fugue: Not installed
2024-11-10 12:03:41,339:INFO:           streamlit: 1.40.0
2024-11-10 12:03:41,339:INFO:             prophet: Not installed
2024-11-10 12:03:41,339:INFO:None
2024-11-10 12:03:41,339:INFO:Set up data.
2024-11-10 12:03:41,347:INFO:Set up folding strategy.
2024-11-10 12:03:41,347:INFO:Set up train/test split.
2024-11-10 12:03:41,352:INFO:Set up index.
2024-11-10 12:03:41,353:INFO:Assigning column types.
2024-11-10 12:03:41,356:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-10 12:03:41,356:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,360:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,365:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,417:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,457:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,458:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,458:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,459:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,463:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,467:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,565:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-11-10 12:03:41,569:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,574:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,626:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,665:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,670:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,674:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,725:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,767:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,768:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-11-10 12:03:41,778:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,869:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,869:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,870:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,878:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,930:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,968:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:03:41,969:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,969:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:41,969:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-11-10 12:03:42,033:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:42,072:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:03:42,073:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,073:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:42,174:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:03:42,174:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,175:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-10 12:03:42,237:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:42,278:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-11-10 12:03:42,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,380:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-11-10 12:03:42,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,581:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:42,583:INFO:Preparing preprocessing pipeline...
2024-11-10 12:03:42,583:INFO:Set up simple imputation.
2024-11-10 12:03:42,587:INFO:Set up encoding of ordinal features.
2024-11-10 12:03:42,594:INFO:Set up encoding of categorical features.
2024-11-10 12:03:42,691:INFO:Finished creating preprocessing pipeline.
2024-11-10 12:03:42,764:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2024-11-10 12:03:42,764:INFO:Creating final display dataframe.
2024-11-10 12:03:43,020:INFO:Setup _display_container:                     Description             Value
0                    Session id              7960
1                        Target             price
2                   Target type        Regression
3           Original data shape         (545, 13)
4        Transformed data shape         (545, 15)
5   Transformed train set shape         (381, 15)
6    Transformed test set shape         (164, 15)
7              Numeric features                 5
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              25ff
2024-11-10 12:03:43,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:43,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:43,233:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:43,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:03:43,233:INFO:setup() successfully completed in 2.01s...............
2024-11-10 12:03:43,238:INFO:Initializing compare_models()
2024-11-10 12:03:43,238:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-11-10 12:03:43,239:INFO:Checking exceptions
2024-11-10 12:03:43,241:INFO:Preparing display monitor
2024-11-10 12:03:43,243:INFO:Initializing Linear Regression
2024-11-10 12:03:43,244:INFO:Total runtime is 1.9792715708414713e-05 minutes
2024-11-10 12:03:43,244:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:43,244:INFO:Initializing create_model()
2024-11-10 12:03:43,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:43,244:INFO:Checking exceptions
2024-11-10 12:03:43,244:INFO:Importing libraries
2024-11-10 12:03:43,244:INFO:Copying training dataset
2024-11-10 12:03:43,249:INFO:Defining folds
2024-11-10 12:03:43,249:INFO:Declaring metric variables
2024-11-10 12:03:43,249:INFO:Importing untrained model
2024-11-10 12:03:43,249:INFO:Linear Regression Imported successfully
2024-11-10 12:03:43,250:INFO:Starting cross validation
2024-11-10 12:03:43,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:48,325:INFO:Calculating mean and std
2024-11-10 12:03:48,326:INFO:Creating metrics dataframe
2024-11-10 12:03:48,329:INFO:Uploading results into container
2024-11-10 12:03:48,329:INFO:Uploading model into container now
2024-11-10 12:03:48,330:INFO:_master_model_container: 1
2024-11-10 12:03:48,330:INFO:_display_container: 2
2024-11-10 12:03:48,330:INFO:LinearRegression(n_jobs=-1)
2024-11-10 12:03:48,330:INFO:create_model() successfully completed......................................
2024-11-10 12:03:48,527:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:48,527:INFO:Creating metrics dataframe
2024-11-10 12:03:48,529:INFO:Initializing Lasso Regression
2024-11-10 12:03:48,529:INFO:Total runtime is 0.0880990743637085 minutes
2024-11-10 12:03:48,529:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:48,529:INFO:Initializing create_model()
2024-11-10 12:03:48,529:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:48,529:INFO:Checking exceptions
2024-11-10 12:03:48,529:INFO:Importing libraries
2024-11-10 12:03:48,529:INFO:Copying training dataset
2024-11-10 12:03:48,533:INFO:Defining folds
2024-11-10 12:03:48,533:INFO:Declaring metric variables
2024-11-10 12:03:48,533:INFO:Importing untrained model
2024-11-10 12:03:48,533:INFO:Lasso Regression Imported successfully
2024-11-10 12:03:48,534:INFO:Starting cross validation
2024-11-10 12:03:48,535:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:48,691:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.164e+13, tolerance: 1.326e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:48,705:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.166e+13, tolerance: 1.265e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:48,710:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.193e+13, tolerance: 1.253e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:48,710:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.245e+13, tolerance: 1.271e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:48,721:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.154e+13, tolerance: 1.267e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:48,728:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.027e+13, tolerance: 1.256e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:48,736:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.111e+13, tolerance: 1.296e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:48,747:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.031e+13, tolerance: 1.234e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:50,410:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.212e+13, tolerance: 1.273e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:50,415:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.616e+13, tolerance: 1.301e+11
  model = cd_fast.enet_coordinate_descent(

2024-11-10 12:03:50,456:INFO:Calculating mean and std
2024-11-10 12:03:50,457:INFO:Creating metrics dataframe
2024-11-10 12:03:50,459:INFO:Uploading results into container
2024-11-10 12:03:50,459:INFO:Uploading model into container now
2024-11-10 12:03:50,460:INFO:_master_model_container: 2
2024-11-10 12:03:50,460:INFO:_display_container: 2
2024-11-10 12:03:50,460:INFO:Lasso(random_state=7960)
2024-11-10 12:03:50,460:INFO:create_model() successfully completed......................................
2024-11-10 12:03:50,560:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:50,560:INFO:Creating metrics dataframe
2024-11-10 12:03:50,562:INFO:Initializing Ridge Regression
2024-11-10 12:03:50,562:INFO:Total runtime is 0.12197839419047038 minutes
2024-11-10 12:03:50,562:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:50,562:INFO:Initializing create_model()
2024-11-10 12:03:50,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:50,562:INFO:Checking exceptions
2024-11-10 12:03:50,562:INFO:Importing libraries
2024-11-10 12:03:50,562:INFO:Copying training dataset
2024-11-10 12:03:50,566:INFO:Defining folds
2024-11-10 12:03:50,566:INFO:Declaring metric variables
2024-11-10 12:03:50,566:INFO:Importing untrained model
2024-11-10 12:03:50,567:INFO:Ridge Regression Imported successfully
2024-11-10 12:03:50,567:INFO:Starting cross validation
2024-11-10 12:03:50,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:50,804:INFO:Calculating mean and std
2024-11-10 12:03:50,804:INFO:Creating metrics dataframe
2024-11-10 12:03:50,807:INFO:Uploading results into container
2024-11-10 12:03:50,807:INFO:Uploading model into container now
2024-11-10 12:03:50,807:INFO:_master_model_container: 3
2024-11-10 12:03:50,807:INFO:_display_container: 2
2024-11-10 12:03:50,807:INFO:Ridge(random_state=7960)
2024-11-10 12:03:50,808:INFO:create_model() successfully completed......................................
2024-11-10 12:03:50,900:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:50,900:INFO:Creating metrics dataframe
2024-11-10 12:03:50,902:INFO:Initializing Elastic Net
2024-11-10 12:03:50,902:INFO:Total runtime is 0.12764469782511392 minutes
2024-11-10 12:03:50,902:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:50,903:INFO:Initializing create_model()
2024-11-10 12:03:50,903:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:50,903:INFO:Checking exceptions
2024-11-10 12:03:50,903:INFO:Importing libraries
2024-11-10 12:03:50,903:INFO:Copying training dataset
2024-11-10 12:03:50,907:INFO:Defining folds
2024-11-10 12:03:50,907:INFO:Declaring metric variables
2024-11-10 12:03:50,908:INFO:Importing untrained model
2024-11-10 12:03:50,908:INFO:Elastic Net Imported successfully
2024-11-10 12:03:50,908:INFO:Starting cross validation
2024-11-10 12:03:50,909:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:51,135:INFO:Calculating mean and std
2024-11-10 12:03:51,135:INFO:Creating metrics dataframe
2024-11-10 12:03:51,137:INFO:Uploading results into container
2024-11-10 12:03:51,137:INFO:Uploading model into container now
2024-11-10 12:03:51,137:INFO:_master_model_container: 4
2024-11-10 12:03:51,137:INFO:_display_container: 2
2024-11-10 12:03:51,137:INFO:ElasticNet(random_state=7960)
2024-11-10 12:03:51,137:INFO:create_model() successfully completed......................................
2024-11-10 12:03:51,226:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:51,227:INFO:Creating metrics dataframe
2024-11-10 12:03:51,229:INFO:Initializing Least Angle Regression
2024-11-10 12:03:51,229:INFO:Total runtime is 0.13309885263442991 minutes
2024-11-10 12:03:51,229:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:51,229:INFO:Initializing create_model()
2024-11-10 12:03:51,229:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:51,229:INFO:Checking exceptions
2024-11-10 12:03:51,229:INFO:Importing libraries
2024-11-10 12:03:51,229:INFO:Copying training dataset
2024-11-10 12:03:51,233:INFO:Defining folds
2024-11-10 12:03:51,233:INFO:Declaring metric variables
2024-11-10 12:03:51,233:INFO:Importing untrained model
2024-11-10 12:03:51,233:INFO:Least Angle Regression Imported successfully
2024-11-10 12:03:51,233:INFO:Starting cross validation
2024-11-10 12:03:51,235:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:51,468:INFO:Calculating mean and std
2024-11-10 12:03:51,468:INFO:Creating metrics dataframe
2024-11-10 12:03:51,470:INFO:Uploading results into container
2024-11-10 12:03:51,470:INFO:Uploading model into container now
2024-11-10 12:03:51,471:INFO:_master_model_container: 5
2024-11-10 12:03:51,471:INFO:_display_container: 2
2024-11-10 12:03:51,471:INFO:Lars(random_state=7960)
2024-11-10 12:03:51,471:INFO:create_model() successfully completed......................................
2024-11-10 12:03:51,562:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:51,562:INFO:Creating metrics dataframe
2024-11-10 12:03:51,564:INFO:Initializing Lasso Least Angle Regression
2024-11-10 12:03:51,564:INFO:Total runtime is 0.1386918306350708 minutes
2024-11-10 12:03:51,564:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:51,564:INFO:Initializing create_model()
2024-11-10 12:03:51,564:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:51,564:INFO:Checking exceptions
2024-11-10 12:03:51,565:INFO:Importing libraries
2024-11-10 12:03:51,565:INFO:Copying training dataset
2024-11-10 12:03:51,568:INFO:Defining folds
2024-11-10 12:03:51,568:INFO:Declaring metric variables
2024-11-10 12:03:51,569:INFO:Importing untrained model
2024-11-10 12:03:51,569:INFO:Lasso Least Angle Regression Imported successfully
2024-11-10 12:03:51,569:INFO:Starting cross validation
2024-11-10 12:03:51,570:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:51,810:INFO:Calculating mean and std
2024-11-10 12:03:51,810:INFO:Creating metrics dataframe
2024-11-10 12:03:51,812:INFO:Uploading results into container
2024-11-10 12:03:51,812:INFO:Uploading model into container now
2024-11-10 12:03:51,813:INFO:_master_model_container: 6
2024-11-10 12:03:51,813:INFO:_display_container: 2
2024-11-10 12:03:51,813:INFO:LassoLars(random_state=7960)
2024-11-10 12:03:51,813:INFO:create_model() successfully completed......................................
2024-11-10 12:03:51,904:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:51,904:INFO:Creating metrics dataframe
2024-11-10 12:03:51,907:INFO:Initializing Orthogonal Matching Pursuit
2024-11-10 12:03:51,907:INFO:Total runtime is 0.14440029859542847 minutes
2024-11-10 12:03:51,907:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:51,907:INFO:Initializing create_model()
2024-11-10 12:03:51,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:51,908:INFO:Checking exceptions
2024-11-10 12:03:51,908:INFO:Importing libraries
2024-11-10 12:03:51,908:INFO:Copying training dataset
2024-11-10 12:03:51,911:INFO:Defining folds
2024-11-10 12:03:51,912:INFO:Declaring metric variables
2024-11-10 12:03:51,912:INFO:Importing untrained model
2024-11-10 12:03:51,912:INFO:Orthogonal Matching Pursuit Imported successfully
2024-11-10 12:03:51,912:INFO:Starting cross validation
2024-11-10 12:03:51,913:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:52,167:INFO:Calculating mean and std
2024-11-10 12:03:52,167:INFO:Creating metrics dataframe
2024-11-10 12:03:52,169:INFO:Uploading results into container
2024-11-10 12:03:52,169:INFO:Uploading model into container now
2024-11-10 12:03:52,170:INFO:_master_model_container: 7
2024-11-10 12:03:52,170:INFO:_display_container: 2
2024-11-10 12:03:52,170:INFO:OrthogonalMatchingPursuit()
2024-11-10 12:03:52,170:INFO:create_model() successfully completed......................................
2024-11-10 12:03:52,267:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:52,267:INFO:Creating metrics dataframe
2024-11-10 12:03:52,269:INFO:Initializing Bayesian Ridge
2024-11-10 12:03:52,269:INFO:Total runtime is 0.1504295825958252 minutes
2024-11-10 12:03:52,270:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:52,270:INFO:Initializing create_model()
2024-11-10 12:03:52,270:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:52,270:INFO:Checking exceptions
2024-11-10 12:03:52,270:INFO:Importing libraries
2024-11-10 12:03:52,270:INFO:Copying training dataset
2024-11-10 12:03:52,275:INFO:Defining folds
2024-11-10 12:03:52,275:INFO:Declaring metric variables
2024-11-10 12:03:52,275:INFO:Importing untrained model
2024-11-10 12:03:52,275:INFO:Bayesian Ridge Imported successfully
2024-11-10 12:03:52,276:INFO:Starting cross validation
2024-11-10 12:03:52,277:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:52,513:INFO:Calculating mean and std
2024-11-10 12:03:52,513:INFO:Creating metrics dataframe
2024-11-10 12:03:52,515:INFO:Uploading results into container
2024-11-10 12:03:52,515:INFO:Uploading model into container now
2024-11-10 12:03:52,516:INFO:_master_model_container: 8
2024-11-10 12:03:52,516:INFO:_display_container: 2
2024-11-10 12:03:52,516:INFO:BayesianRidge()
2024-11-10 12:03:52,516:INFO:create_model() successfully completed......................................
2024-11-10 12:03:52,608:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:52,608:INFO:Creating metrics dataframe
2024-11-10 12:03:52,610:INFO:Initializing Passive Aggressive Regressor
2024-11-10 12:03:52,610:INFO:Total runtime is 0.15612760384877522 minutes
2024-11-10 12:03:52,610:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:52,610:INFO:Initializing create_model()
2024-11-10 12:03:52,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:52,611:INFO:Checking exceptions
2024-11-10 12:03:52,611:INFO:Importing libraries
2024-11-10 12:03:52,611:INFO:Copying training dataset
2024-11-10 12:03:52,615:INFO:Defining folds
2024-11-10 12:03:52,615:INFO:Declaring metric variables
2024-11-10 12:03:52,615:INFO:Importing untrained model
2024-11-10 12:03:52,615:INFO:Passive Aggressive Regressor Imported successfully
2024-11-10 12:03:52,615:INFO:Starting cross validation
2024-11-10 12:03:52,617:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:52,852:INFO:Calculating mean and std
2024-11-10 12:03:52,853:INFO:Creating metrics dataframe
2024-11-10 12:03:52,854:INFO:Uploading results into container
2024-11-10 12:03:52,854:INFO:Uploading model into container now
2024-11-10 12:03:52,855:INFO:_master_model_container: 9
2024-11-10 12:03:52,855:INFO:_display_container: 2
2024-11-10 12:03:52,855:INFO:PassiveAggressiveRegressor(random_state=7960)
2024-11-10 12:03:52,855:INFO:create_model() successfully completed......................................
2024-11-10 12:03:52,943:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:52,943:INFO:Creating metrics dataframe
2024-11-10 12:03:52,945:INFO:Initializing Huber Regressor
2024-11-10 12:03:52,945:INFO:Total runtime is 0.16169858376185098 minutes
2024-11-10 12:03:52,945:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:52,945:INFO:Initializing create_model()
2024-11-10 12:03:52,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:52,946:INFO:Checking exceptions
2024-11-10 12:03:52,946:INFO:Importing libraries
2024-11-10 12:03:52,946:INFO:Copying training dataset
2024-11-10 12:03:52,949:INFO:Defining folds
2024-11-10 12:03:52,949:INFO:Declaring metric variables
2024-11-10 12:03:52,949:INFO:Importing untrained model
2024-11-10 12:03:52,950:INFO:Huber Regressor Imported successfully
2024-11-10 12:03:52,950:INFO:Starting cross validation
2024-11-10 12:03:52,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:53,151:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-11-10 12:03:53,203:INFO:Calculating mean and std
2024-11-10 12:03:53,203:INFO:Creating metrics dataframe
2024-11-10 12:03:53,204:INFO:Uploading results into container
2024-11-10 12:03:53,205:INFO:Uploading model into container now
2024-11-10 12:03:53,205:INFO:_master_model_container: 10
2024-11-10 12:03:53,205:INFO:_display_container: 2
2024-11-10 12:03:53,205:INFO:HuberRegressor()
2024-11-10 12:03:53,205:INFO:create_model() successfully completed......................................
2024-11-10 12:03:53,301:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:53,301:INFO:Creating metrics dataframe
2024-11-10 12:03:53,303:INFO:Initializing K Neighbors Regressor
2024-11-10 12:03:53,303:INFO:Total runtime is 0.16767451763153074 minutes
2024-11-10 12:03:53,303:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:53,303:INFO:Initializing create_model()
2024-11-10 12:03:53,303:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:53,303:INFO:Checking exceptions
2024-11-10 12:03:53,303:INFO:Importing libraries
2024-11-10 12:03:53,303:INFO:Copying training dataset
2024-11-10 12:03:53,308:INFO:Defining folds
2024-11-10 12:03:53,308:INFO:Declaring metric variables
2024-11-10 12:03:53,308:INFO:Importing untrained model
2024-11-10 12:03:53,308:INFO:K Neighbors Regressor Imported successfully
2024-11-10 12:03:53,308:INFO:Starting cross validation
2024-11-10 12:03:53,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:53,569:INFO:Calculating mean and std
2024-11-10 12:03:53,569:INFO:Creating metrics dataframe
2024-11-10 12:03:53,571:INFO:Uploading results into container
2024-11-10 12:03:53,571:INFO:Uploading model into container now
2024-11-10 12:03:53,572:INFO:_master_model_container: 11
2024-11-10 12:03:53,572:INFO:_display_container: 2
2024-11-10 12:03:53,572:INFO:KNeighborsRegressor(n_jobs=-1)
2024-11-10 12:03:53,572:INFO:create_model() successfully completed......................................
2024-11-10 12:03:53,664:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:53,664:INFO:Creating metrics dataframe
2024-11-10 12:03:53,666:INFO:Initializing Decision Tree Regressor
2024-11-10 12:03:53,666:INFO:Total runtime is 0.17371863524119058 minutes
2024-11-10 12:03:53,667:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:53,667:INFO:Initializing create_model()
2024-11-10 12:03:53,667:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:53,667:INFO:Checking exceptions
2024-11-10 12:03:53,667:INFO:Importing libraries
2024-11-10 12:03:53,667:INFO:Copying training dataset
2024-11-10 12:03:53,671:INFO:Defining folds
2024-11-10 12:03:53,671:INFO:Declaring metric variables
2024-11-10 12:03:53,671:INFO:Importing untrained model
2024-11-10 12:03:53,672:INFO:Decision Tree Regressor Imported successfully
2024-11-10 12:03:53,672:INFO:Starting cross validation
2024-11-10 12:03:53,673:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:53,900:INFO:Calculating mean and std
2024-11-10 12:03:53,900:INFO:Creating metrics dataframe
2024-11-10 12:03:53,902:INFO:Uploading results into container
2024-11-10 12:03:53,902:INFO:Uploading model into container now
2024-11-10 12:03:53,902:INFO:_master_model_container: 12
2024-11-10 12:03:53,903:INFO:_display_container: 2
2024-11-10 12:03:53,903:INFO:DecisionTreeRegressor(random_state=7960)
2024-11-10 12:03:53,903:INFO:create_model() successfully completed......................................
2024-11-10 12:03:53,995:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:53,995:INFO:Creating metrics dataframe
2024-11-10 12:03:53,997:INFO:Initializing Random Forest Regressor
2024-11-10 12:03:53,997:INFO:Total runtime is 0.17923529942830402 minutes
2024-11-10 12:03:53,997:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:53,998:INFO:Initializing create_model()
2024-11-10 12:03:53,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:53,998:INFO:Checking exceptions
2024-11-10 12:03:53,998:INFO:Importing libraries
2024-11-10 12:03:53,998:INFO:Copying training dataset
2024-11-10 12:03:54,002:INFO:Defining folds
2024-11-10 12:03:54,002:INFO:Declaring metric variables
2024-11-10 12:03:54,002:INFO:Importing untrained model
2024-11-10 12:03:54,002:INFO:Random Forest Regressor Imported successfully
2024-11-10 12:03:54,002:INFO:Starting cross validation
2024-11-10 12:03:54,003:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:54,549:INFO:Calculating mean and std
2024-11-10 12:03:54,550:INFO:Creating metrics dataframe
2024-11-10 12:03:54,551:INFO:Uploading results into container
2024-11-10 12:03:54,551:INFO:Uploading model into container now
2024-11-10 12:03:54,551:INFO:_master_model_container: 13
2024-11-10 12:03:54,551:INFO:_display_container: 2
2024-11-10 12:03:54,553:INFO:RandomForestRegressor(n_jobs=-1, random_state=7960)
2024-11-10 12:03:54,553:INFO:create_model() successfully completed......................................
2024-11-10 12:03:54,641:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:54,641:INFO:Creating metrics dataframe
2024-11-10 12:03:54,643:INFO:Initializing Extra Trees Regressor
2024-11-10 12:03:54,643:INFO:Total runtime is 0.1900046149889628 minutes
2024-11-10 12:03:54,643:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:54,644:INFO:Initializing create_model()
2024-11-10 12:03:54,644:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:54,644:INFO:Checking exceptions
2024-11-10 12:03:54,644:INFO:Importing libraries
2024-11-10 12:03:54,644:INFO:Copying training dataset
2024-11-10 12:03:54,647:INFO:Defining folds
2024-11-10 12:03:54,647:INFO:Declaring metric variables
2024-11-10 12:03:54,648:INFO:Importing untrained model
2024-11-10 12:03:54,648:INFO:Extra Trees Regressor Imported successfully
2024-11-10 12:03:54,648:INFO:Starting cross validation
2024-11-10 12:03:54,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:55,135:INFO:Calculating mean and std
2024-11-10 12:03:55,136:INFO:Creating metrics dataframe
2024-11-10 12:03:55,137:INFO:Uploading results into container
2024-11-10 12:03:55,137:INFO:Uploading model into container now
2024-11-10 12:03:55,138:INFO:_master_model_container: 14
2024-11-10 12:03:55,138:INFO:_display_container: 2
2024-11-10 12:03:55,138:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7960)
2024-11-10 12:03:55,138:INFO:create_model() successfully completed......................................
2024-11-10 12:03:55,241:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:55,241:INFO:Creating metrics dataframe
2024-11-10 12:03:55,243:INFO:Initializing AdaBoost Regressor
2024-11-10 12:03:55,243:INFO:Total runtime is 0.19999656279881795 minutes
2024-11-10 12:03:55,243:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:55,244:INFO:Initializing create_model()
2024-11-10 12:03:55,244:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:55,244:INFO:Checking exceptions
2024-11-10 12:03:55,244:INFO:Importing libraries
2024-11-10 12:03:55,244:INFO:Copying training dataset
2024-11-10 12:03:55,248:INFO:Defining folds
2024-11-10 12:03:55,248:INFO:Declaring metric variables
2024-11-10 12:03:55,248:INFO:Importing untrained model
2024-11-10 12:03:55,248:INFO:AdaBoost Regressor Imported successfully
2024-11-10 12:03:55,248:INFO:Starting cross validation
2024-11-10 12:03:55,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:55,610:INFO:Calculating mean and std
2024-11-10 12:03:55,611:INFO:Creating metrics dataframe
2024-11-10 12:03:55,613:INFO:Uploading results into container
2024-11-10 12:03:55,613:INFO:Uploading model into container now
2024-11-10 12:03:55,613:INFO:_master_model_container: 15
2024-11-10 12:03:55,613:INFO:_display_container: 2
2024-11-10 12:03:55,614:INFO:AdaBoostRegressor(random_state=7960)
2024-11-10 12:03:55,614:INFO:create_model() successfully completed......................................
2024-11-10 12:03:55,705:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:55,705:INFO:Creating metrics dataframe
2024-11-10 12:03:55,708:INFO:Initializing Gradient Boosting Regressor
2024-11-10 12:03:55,708:INFO:Total runtime is 0.20775020917256673 minutes
2024-11-10 12:03:55,708:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:55,708:INFO:Initializing create_model()
2024-11-10 12:03:55,708:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:55,708:INFO:Checking exceptions
2024-11-10 12:03:55,708:INFO:Importing libraries
2024-11-10 12:03:55,708:INFO:Copying training dataset
2024-11-10 12:03:55,712:INFO:Defining folds
2024-11-10 12:03:55,712:INFO:Declaring metric variables
2024-11-10 12:03:55,712:INFO:Importing untrained model
2024-11-10 12:03:55,712:INFO:Gradient Boosting Regressor Imported successfully
2024-11-10 12:03:55,713:INFO:Starting cross validation
2024-11-10 12:03:55,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:56,057:INFO:Calculating mean and std
2024-11-10 12:03:56,057:INFO:Creating metrics dataframe
2024-11-10 12:03:56,059:INFO:Uploading results into container
2024-11-10 12:03:56,059:INFO:Uploading model into container now
2024-11-10 12:03:56,060:INFO:_master_model_container: 16
2024-11-10 12:03:56,060:INFO:_display_container: 2
2024-11-10 12:03:56,060:INFO:GradientBoostingRegressor(random_state=7960)
2024-11-10 12:03:56,060:INFO:create_model() successfully completed......................................
2024-11-10 12:03:56,153:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:56,153:INFO:Creating metrics dataframe
2024-11-10 12:03:56,157:INFO:Initializing Light Gradient Boosting Machine
2024-11-10 12:03:56,157:INFO:Total runtime is 0.2152338663736979 minutes
2024-11-10 12:03:56,157:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:56,157:INFO:Initializing create_model()
2024-11-10 12:03:56,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:56,157:INFO:Checking exceptions
2024-11-10 12:03:56,157:INFO:Importing libraries
2024-11-10 12:03:56,158:INFO:Copying training dataset
2024-11-10 12:03:56,161:INFO:Defining folds
2024-11-10 12:03:56,161:INFO:Declaring metric variables
2024-11-10 12:03:56,161:INFO:Importing untrained model
2024-11-10 12:03:56,161:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-10 12:03:56,161:INFO:Starting cross validation
2024-11-10 12:03:56,163:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:57,000:INFO:Calculating mean and std
2024-11-10 12:03:57,001:INFO:Creating metrics dataframe
2024-11-10 12:03:57,003:INFO:Uploading results into container
2024-11-10 12:03:57,003:INFO:Uploading model into container now
2024-11-10 12:03:57,003:INFO:_master_model_container: 17
2024-11-10 12:03:57,003:INFO:_display_container: 2
2024-11-10 12:03:57,004:INFO:LGBMRegressor(n_jobs=-1, random_state=7960)
2024-11-10 12:03:57,004:INFO:create_model() successfully completed......................................
2024-11-10 12:03:57,116:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:57,116:INFO:Creating metrics dataframe
2024-11-10 12:03:57,118:INFO:Initializing Dummy Regressor
2024-11-10 12:03:57,119:INFO:Total runtime is 0.23127712408701578 minutes
2024-11-10 12:03:57,119:INFO:SubProcess create_model() called ==================================
2024-11-10 12:03:57,119:INFO:Initializing create_model()
2024-11-10 12:03:57,119:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024804581480>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:57,119:INFO:Checking exceptions
2024-11-10 12:03:57,119:INFO:Importing libraries
2024-11-10 12:03:57,119:INFO:Copying training dataset
2024-11-10 12:03:57,124:INFO:Defining folds
2024-11-10 12:03:57,124:INFO:Declaring metric variables
2024-11-10 12:03:57,124:INFO:Importing untrained model
2024-11-10 12:03:57,124:INFO:Dummy Regressor Imported successfully
2024-11-10 12:03:57,124:INFO:Starting cross validation
2024-11-10 12:03:57,125:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:03:57,380:INFO:Calculating mean and std
2024-11-10 12:03:57,381:INFO:Creating metrics dataframe
2024-11-10 12:03:57,383:INFO:Uploading results into container
2024-11-10 12:03:57,383:INFO:Uploading model into container now
2024-11-10 12:03:57,384:INFO:_master_model_container: 18
2024-11-10 12:03:57,384:INFO:_display_container: 2
2024-11-10 12:03:57,384:INFO:DummyRegressor()
2024-11-10 12:03:57,384:INFO:create_model() successfully completed......................................
2024-11-10 12:03:57,486:INFO:SubProcess create_model() end ==================================
2024-11-10 12:03:57,486:INFO:Creating metrics dataframe
2024-11-10 12:03:57,490:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-10 12:03:57,493:INFO:Initializing create_model()
2024-11-10 12:03:57,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=Ridge(random_state=7960), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:03:57,493:INFO:Checking exceptions
2024-11-10 12:03:57,494:INFO:Importing libraries
2024-11-10 12:03:57,494:INFO:Copying training dataset
2024-11-10 12:03:57,497:INFO:Defining folds
2024-11-10 12:03:57,497:INFO:Declaring metric variables
2024-11-10 12:03:57,498:INFO:Importing untrained model
2024-11-10 12:03:57,498:INFO:Declaring custom model
2024-11-10 12:03:57,498:INFO:Ridge Regression Imported successfully
2024-11-10 12:03:57,500:INFO:Cross validation set to False
2024-11-10 12:03:57,500:INFO:Fitting Model
2024-11-10 12:03:57,566:INFO:Ridge(random_state=7960)
2024-11-10 12:03:57,566:INFO:create_model() successfully completed......................................
2024-11-10 12:03:57,679:INFO:_master_model_container: 18
2024-11-10 12:03:57,679:INFO:_display_container: 2
2024-11-10 12:03:57,679:INFO:Ridge(random_state=7960)
2024-11-10 12:03:57,679:INFO:compare_models() successfully completed......................................
2024-11-10 12:03:57,768:INFO:Initializing save_model()
2024-11-10 12:03:57,768:INFO:save_model(model=Ridge(random_state=7960), model_name=best_regressor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2024-11-10 12:03:57,768:INFO:Adding model into prep_pipe
2024-11-10 12:03:57,779:INFO:best_regressor.pkl saved in current working directory
2024-11-10 12:03:57,861:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'furnishingstatus'],
                                    transformer=SimpleImput...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model', Ridge(random_state=7960))])
2024-11-10 12:03:57,861:INFO:save_model() successfully completed......................................
2024-11-10 12:04:51,352:INFO:Initializing load_model()
2024-11-10 12:04:51,353:INFO:load_model(model_name=trained_regressor, platform=None, authentication=None, verbose=True)
2024-11-10 12:05:23,379:INFO:Initializing load_model()
2024-11-10 12:05:23,380:INFO:load_model(model_name=trained_regressor, platform=None, authentication=None, verbose=True)
2024-11-10 12:05:23,497:INFO:Initializing predict_model()
2024-11-10 12:05:23,497:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000024804764EE0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model', Ridge(random_state=7960))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000248045091B0>)
2024-11-10 12:05:23,497:INFO:Checking exceptions
2024-11-10 12:05:23,497:INFO:Preloading libraries
2024-11-10 12:05:23,497:INFO:Set up data.
2024-11-10 12:05:23,502:INFO:Set up index.
2024-11-10 12:08:56,993:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x00000248620C4DF0, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2024-11-10 12:09:19,029:INFO:PyCaret ClassificationExperiment
2024-11-10 12:09:19,029:INFO:Logging name: clf-default-name
2024-11-10 12:09:19,029:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-11-10 12:09:19,029:INFO:version 3.3.2
2024-11-10 12:09:19,029:INFO:Initializing setup()
2024-11-10 12:09:19,029:INFO:self.USI: b4d1
2024-11-10 12:09:19,029:INFO:self._variable_keys: {'fix_imbalance', 'idx', 'y', 'data', '_ml_usecase', 'log_plots_param', 'y_test', 'fold_generator', 'target_param', 'is_multiclass', 'fold_groups_param', 'X', 'html_param', 'X_test', 'exp_id', 'memory', 'y_train', 'pipeline', 'USI', '_available_plots', 'X_train', 'gpu_n_jobs_param', 'fold_shuffle_param', 'seed', 'n_jobs_param', 'logging_param', 'exp_name_log', 'gpu_param'}
2024-11-10 12:09:19,029:INFO:Checking environment
2024-11-10 12:09:19,029:INFO:python_version: 3.10.0
2024-11-10 12:09:19,029:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-11-10 12:09:19,029:INFO:machine: AMD64
2024-11-10 12:09:19,029:INFO:platform: Windows-10-10.0.22631-SP0
2024-11-10 12:09:19,033:INFO:Memory: svmem(total=17037209600, available=4986417152, percent=70.7, used=12050792448, free=4986417152)
2024-11-10 12:09:19,034:INFO:Physical Core: 6
2024-11-10 12:09:19,034:INFO:Logical Core: 12
2024-11-10 12:09:19,034:INFO:Checking libraries
2024-11-10 12:09:19,034:INFO:System:
2024-11-10 12:09:19,034:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-11-10 12:09:19,034:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2024-11-10 12:09:19,034:INFO:   machine: Windows-10-10.0.22631-SP0
2024-11-10 12:09:19,034:INFO:PyCaret required dependencies:
2024-11-10 12:09:19,034:INFO:                 pip: 21.2.3
2024-11-10 12:09:19,034:INFO:          setuptools: 57.4.0
2024-11-10 12:09:19,034:INFO:             pycaret: 3.3.2
2024-11-10 12:09:19,034:INFO:             IPython: 8.29.0
2024-11-10 12:09:19,034:INFO:          ipywidgets: 8.1.5
2024-11-10 12:09:19,034:INFO:                tqdm: 4.67.0
2024-11-10 12:09:19,034:INFO:               numpy: 1.26.4
2024-11-10 12:09:19,034:INFO:              pandas: 2.1.4
2024-11-10 12:09:19,034:INFO:              jinja2: 3.1.4
2024-11-10 12:09:19,034:INFO:               scipy: 1.11.4
2024-11-10 12:09:19,034:INFO:              joblib: 1.3.2
2024-11-10 12:09:19,034:INFO:             sklearn: 1.4.2
2024-11-10 12:09:19,034:INFO:                pyod: 2.0.2
2024-11-10 12:09:19,034:INFO:            imblearn: 0.12.4
2024-11-10 12:09:19,034:INFO:   category_encoders: 2.6.4
2024-11-10 12:09:19,035:INFO:            lightgbm: 4.5.0
2024-11-10 12:09:19,035:INFO:               numba: 0.60.0
2024-11-10 12:09:19,035:INFO:            requests: 2.32.3
2024-11-10 12:09:19,035:INFO:          matplotlib: 3.7.5
2024-11-10 12:09:19,035:INFO:          scikitplot: 0.3.7
2024-11-10 12:09:19,035:INFO:         yellowbrick: 1.5
2024-11-10 12:09:19,035:INFO:              plotly: 5.24.1
2024-11-10 12:09:19,035:INFO:    plotly-resampler: Not installed
2024-11-10 12:09:19,035:INFO:             kaleido: 0.2.1
2024-11-10 12:09:19,035:INFO:           schemdraw: 0.15
2024-11-10 12:09:19,035:INFO:         statsmodels: 0.14.4
2024-11-10 12:09:19,035:INFO:              sktime: 0.26.0
2024-11-10 12:09:19,035:INFO:               tbats: 1.1.3
2024-11-10 12:09:19,035:INFO:            pmdarima: 2.0.4
2024-11-10 12:09:19,035:INFO:              psutil: 6.1.0
2024-11-10 12:09:19,035:INFO:          markupsafe: 3.0.2
2024-11-10 12:09:19,035:INFO:             pickle5: Not installed
2024-11-10 12:09:19,035:INFO:         cloudpickle: 3.1.0
2024-11-10 12:09:19,035:INFO:         deprecation: 2.1.0
2024-11-10 12:09:19,035:INFO:              xxhash: 3.5.0
2024-11-10 12:09:19,035:INFO:           wurlitzer: Not installed
2024-11-10 12:09:19,035:INFO:PyCaret optional dependencies:
2024-11-10 12:09:19,035:INFO:                shap: Not installed
2024-11-10 12:09:19,035:INFO:           interpret: Not installed
2024-11-10 12:09:19,035:INFO:                umap: Not installed
2024-11-10 12:09:19,036:INFO:     ydata_profiling: 4.12.0
2024-11-10 12:09:19,036:INFO:  explainerdashboard: Not installed
2024-11-10 12:09:19,036:INFO:             autoviz: Not installed
2024-11-10 12:09:19,036:INFO:           fairlearn: Not installed
2024-11-10 12:09:19,036:INFO:          deepchecks: Not installed
2024-11-10 12:09:19,036:INFO:             xgboost: Not installed
2024-11-10 12:09:19,036:INFO:            catboost: Not installed
2024-11-10 12:09:19,036:INFO:              kmodes: Not installed
2024-11-10 12:09:19,036:INFO:             mlxtend: Not installed
2024-11-10 12:09:19,036:INFO:       statsforecast: Not installed
2024-11-10 12:09:19,036:INFO:        tune_sklearn: Not installed
2024-11-10 12:09:19,036:INFO:                 ray: Not installed
2024-11-10 12:09:19,036:INFO:            hyperopt: Not installed
2024-11-10 12:09:19,036:INFO:              optuna: Not installed
2024-11-10 12:09:19,036:INFO:               skopt: Not installed
2024-11-10 12:09:19,036:INFO:              mlflow: Not installed
2024-11-10 12:09:19,036:INFO:              gradio: Not installed
2024-11-10 12:09:19,036:INFO:             fastapi: Not installed
2024-11-10 12:09:19,036:INFO:             uvicorn: Not installed
2024-11-10 12:09:19,036:INFO:              m2cgen: Not installed
2024-11-10 12:09:19,036:INFO:           evidently: Not installed
2024-11-10 12:09:19,036:INFO:               fugue: Not installed
2024-11-10 12:09:19,036:INFO:           streamlit: 1.40.0
2024-11-10 12:09:19,036:INFO:             prophet: Not installed
2024-11-10 12:09:19,036:INFO:None
2024-11-10 12:09:19,036:INFO:Set up data.
2024-11-10 12:09:19,044:INFO:Set up folding strategy.
2024-11-10 12:09:19,044:INFO:Set up train/test split.
2024-11-10 12:09:19,051:INFO:Set up index.
2024-11-10 12:09:19,051:INFO:Assigning column types.
2024-11-10 12:09:19,055:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-11-10 12:09:19,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:09:19,101:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-10 12:09:19,131:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,131:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,176:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-11-10 12:09:19,177:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-10 12:09:19,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,220:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-11-10 12:09:19,267:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-10 12:09:19,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,293:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,337:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-11-10 12:09:19,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,364:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,364:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-11-10 12:09:19,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,500:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:19,501:INFO:Preparing preprocessing pipeline...
2024-11-10 12:09:19,501:INFO:Set up simple imputation.
2024-11-10 12:09:19,504:INFO:Set up encoding of ordinal features.
2024-11-10 12:09:19,506:INFO:Set up encoding of categorical features.
2024-11-10 12:09:19,613:INFO:Finished creating preprocessing pipeline.
2024-11-10 12:09:19,630:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-11-10 12:09:19,630:INFO:Creating final display dataframe.
2024-11-10 12:09:20,011:INFO:Setup _display_container:                     Description             Value
0                    Session id              6576
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              b4d1
2024-11-10 12:09:20,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:20,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:20,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:20,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-11-10 12:09:20,155:INFO:setup() successfully completed in 1.13s...............
2024-11-10 12:09:20,161:INFO:Initializing compare_models()
2024-11-10 12:09:20,161:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-11-10 12:09:20,162:INFO:Checking exceptions
2024-11-10 12:09:20,166:INFO:Preparing display monitor
2024-11-10 12:09:20,168:INFO:Initializing Logistic Regression
2024-11-10 12:09:20,168:INFO:Total runtime is 0.0 minutes
2024-11-10 12:09:20,168:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:20,168:INFO:Initializing create_model()
2024-11-10 12:09:20,168:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:20,168:INFO:Checking exceptions
2024-11-10 12:09:20,168:INFO:Importing libraries
2024-11-10 12:09:20,168:INFO:Copying training dataset
2024-11-10 12:09:20,174:INFO:Defining folds
2024-11-10 12:09:20,174:INFO:Declaring metric variables
2024-11-10 12:09:20,174:INFO:Importing untrained model
2024-11-10 12:09:20,175:INFO:Logistic Regression Imported successfully
2024-11-10 12:09:20,175:INFO:Starting cross validation
2024-11-10 12:09:20,177:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:25,098:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,145:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,176:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,204:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,215:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,279:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,328:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,380:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,399:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,434:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:25,492:INFO:Calculating mean and std
2024-11-10 12:09:25,493:INFO:Creating metrics dataframe
2024-11-10 12:09:25,495:INFO:Uploading results into container
2024-11-10 12:09:25,495:INFO:Uploading model into container now
2024-11-10 12:09:25,496:INFO:_master_model_container: 1
2024-11-10 12:09:25,496:INFO:_display_container: 2
2024-11-10 12:09:25,496:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6576, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-10 12:09:25,497:INFO:create_model() successfully completed......................................
2024-11-10 12:09:25,633:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:25,633:INFO:Creating metrics dataframe
2024-11-10 12:09:25,635:INFO:Initializing K Neighbors Classifier
2024-11-10 12:09:25,635:INFO:Total runtime is 0.09111356337865194 minutes
2024-11-10 12:09:25,635:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:25,635:INFO:Initializing create_model()
2024-11-10 12:09:25,635:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:25,635:INFO:Checking exceptions
2024-11-10 12:09:25,635:INFO:Importing libraries
2024-11-10 12:09:25,635:INFO:Copying training dataset
2024-11-10 12:09:25,640:INFO:Defining folds
2024-11-10 12:09:25,640:INFO:Declaring metric variables
2024-11-10 12:09:25,640:INFO:Importing untrained model
2024-11-10 12:09:25,640:INFO:K Neighbors Classifier Imported successfully
2024-11-10 12:09:25,641:INFO:Starting cross validation
2024-11-10 12:09:25,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:27,801:INFO:Calculating mean and std
2024-11-10 12:09:27,802:INFO:Creating metrics dataframe
2024-11-10 12:09:27,803:INFO:Uploading results into container
2024-11-10 12:09:27,804:INFO:Uploading model into container now
2024-11-10 12:09:27,804:INFO:_master_model_container: 2
2024-11-10 12:09:27,804:INFO:_display_container: 2
2024-11-10 12:09:27,804:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-11-10 12:09:27,804:INFO:create_model() successfully completed......................................
2024-11-10 12:09:27,908:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:27,908:INFO:Creating metrics dataframe
2024-11-10 12:09:27,910:INFO:Initializing Naive Bayes
2024-11-10 12:09:27,910:INFO:Total runtime is 0.12903607686360677 minutes
2024-11-10 12:09:27,910:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:27,910:INFO:Initializing create_model()
2024-11-10 12:09:27,910:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:27,910:INFO:Checking exceptions
2024-11-10 12:09:27,910:INFO:Importing libraries
2024-11-10 12:09:27,910:INFO:Copying training dataset
2024-11-10 12:09:27,914:INFO:Defining folds
2024-11-10 12:09:27,914:INFO:Declaring metric variables
2024-11-10 12:09:27,915:INFO:Importing untrained model
2024-11-10 12:09:27,915:INFO:Naive Bayes Imported successfully
2024-11-10 12:09:27,915:INFO:Starting cross validation
2024-11-10 12:09:27,916:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:28,158:INFO:Calculating mean and std
2024-11-10 12:09:28,159:INFO:Creating metrics dataframe
2024-11-10 12:09:28,160:INFO:Uploading results into container
2024-11-10 12:09:28,161:INFO:Uploading model into container now
2024-11-10 12:09:28,161:INFO:_master_model_container: 3
2024-11-10 12:09:28,161:INFO:_display_container: 2
2024-11-10 12:09:28,161:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-11-10 12:09:28,161:INFO:create_model() successfully completed......................................
2024-11-10 12:09:28,260:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:28,260:INFO:Creating metrics dataframe
2024-11-10 12:09:28,262:INFO:Initializing Decision Tree Classifier
2024-11-10 12:09:28,262:INFO:Total runtime is 0.1348897377649943 minutes
2024-11-10 12:09:28,262:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:28,262:INFO:Initializing create_model()
2024-11-10 12:09:28,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:28,262:INFO:Checking exceptions
2024-11-10 12:09:28,262:INFO:Importing libraries
2024-11-10 12:09:28,262:INFO:Copying training dataset
2024-11-10 12:09:28,267:INFO:Defining folds
2024-11-10 12:09:28,267:INFO:Declaring metric variables
2024-11-10 12:09:28,267:INFO:Importing untrained model
2024-11-10 12:09:28,267:INFO:Decision Tree Classifier Imported successfully
2024-11-10 12:09:28,267:INFO:Starting cross validation
2024-11-10 12:09:28,269:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:28,475:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,478:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,478:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,478:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,483:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,488:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,489:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,490:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,491:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,495:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:28,505:INFO:Calculating mean and std
2024-11-10 12:09:28,506:INFO:Creating metrics dataframe
2024-11-10 12:09:28,508:INFO:Uploading results into container
2024-11-10 12:09:28,508:INFO:Uploading model into container now
2024-11-10 12:09:28,508:INFO:_master_model_container: 4
2024-11-10 12:09:28,508:INFO:_display_container: 2
2024-11-10 12:09:28,509:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6576, splitter='best')
2024-11-10 12:09:28,509:INFO:create_model() successfully completed......................................
2024-11-10 12:09:28,606:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:28,606:INFO:Creating metrics dataframe
2024-11-10 12:09:28,608:INFO:Initializing SVM - Linear Kernel
2024-11-10 12:09:28,608:INFO:Total runtime is 0.1406576077143351 minutes
2024-11-10 12:09:28,608:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:28,609:INFO:Initializing create_model()
2024-11-10 12:09:28,609:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:28,609:INFO:Checking exceptions
2024-11-10 12:09:28,609:INFO:Importing libraries
2024-11-10 12:09:28,609:INFO:Copying training dataset
2024-11-10 12:09:28,612:INFO:Defining folds
2024-11-10 12:09:28,612:INFO:Declaring metric variables
2024-11-10 12:09:28,612:INFO:Importing untrained model
2024-11-10 12:09:28,612:INFO:SVM - Linear Kernel Imported successfully
2024-11-10 12:09:28,613:INFO:Starting cross validation
2024-11-10 12:09:28,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:28,861:INFO:Calculating mean and std
2024-11-10 12:09:28,862:INFO:Creating metrics dataframe
2024-11-10 12:09:28,864:INFO:Uploading results into container
2024-11-10 12:09:28,864:INFO:Uploading model into container now
2024-11-10 12:09:28,864:INFO:_master_model_container: 5
2024-11-10 12:09:28,864:INFO:_display_container: 2
2024-11-10 12:09:28,864:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6576, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-11-10 12:09:28,864:INFO:create_model() successfully completed......................................
2024-11-10 12:09:28,961:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:28,962:INFO:Creating metrics dataframe
2024-11-10 12:09:28,964:INFO:Initializing Ridge Classifier
2024-11-10 12:09:28,964:INFO:Total runtime is 0.14659969409306842 minutes
2024-11-10 12:09:28,964:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:28,964:INFO:Initializing create_model()
2024-11-10 12:09:28,964:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:28,964:INFO:Checking exceptions
2024-11-10 12:09:28,964:INFO:Importing libraries
2024-11-10 12:09:28,964:INFO:Copying training dataset
2024-11-10 12:09:28,968:INFO:Defining folds
2024-11-10 12:09:28,968:INFO:Declaring metric variables
2024-11-10 12:09:28,969:INFO:Importing untrained model
2024-11-10 12:09:28,969:INFO:Ridge Classifier Imported successfully
2024-11-10 12:09:28,969:INFO:Starting cross validation
2024-11-10 12:09:28,970:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:29,218:INFO:Calculating mean and std
2024-11-10 12:09:29,219:INFO:Creating metrics dataframe
2024-11-10 12:09:29,220:INFO:Uploading results into container
2024-11-10 12:09:29,220:INFO:Uploading model into container now
2024-11-10 12:09:29,221:INFO:_master_model_container: 6
2024-11-10 12:09:29,221:INFO:_display_container: 2
2024-11-10 12:09:29,221:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6576, solver='auto',
                tol=0.0001)
2024-11-10 12:09:29,221:INFO:create_model() successfully completed......................................
2024-11-10 12:09:29,315:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:29,315:INFO:Creating metrics dataframe
2024-11-10 12:09:29,318:INFO:Initializing Random Forest Classifier
2024-11-10 12:09:29,318:INFO:Total runtime is 0.15250347057978308 minutes
2024-11-10 12:09:29,318:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:29,318:INFO:Initializing create_model()
2024-11-10 12:09:29,318:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:29,318:INFO:Checking exceptions
2024-11-10 12:09:29,318:INFO:Importing libraries
2024-11-10 12:09:29,318:INFO:Copying training dataset
2024-11-10 12:09:29,321:INFO:Defining folds
2024-11-10 12:09:29,323:INFO:Declaring metric variables
2024-11-10 12:09:29,323:INFO:Importing untrained model
2024-11-10 12:09:29,323:INFO:Random Forest Classifier Imported successfully
2024-11-10 12:09:29,323:INFO:Starting cross validation
2024-11-10 12:09:29,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:29,812:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:29,821:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:29,829:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:29,830:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:29,831:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:29,834:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:29,843:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:29,853:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:29,867:INFO:Calculating mean and std
2024-11-10 12:09:29,868:INFO:Creating metrics dataframe
2024-11-10 12:09:29,869:INFO:Uploading results into container
2024-11-10 12:09:29,869:INFO:Uploading model into container now
2024-11-10 12:09:29,870:INFO:_master_model_container: 7
2024-11-10 12:09:29,870:INFO:_display_container: 2
2024-11-10 12:09:29,870:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6576, verbose=0,
                       warm_start=False)
2024-11-10 12:09:29,870:INFO:create_model() successfully completed......................................
2024-11-10 12:09:29,970:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:29,970:INFO:Creating metrics dataframe
2024-11-10 12:09:29,972:INFO:Initializing Quadratic Discriminant Analysis
2024-11-10 12:09:29,972:INFO:Total runtime is 0.16340030034383135 minutes
2024-11-10 12:09:29,972:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:29,973:INFO:Initializing create_model()
2024-11-10 12:09:29,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:29,973:INFO:Checking exceptions
2024-11-10 12:09:29,973:INFO:Importing libraries
2024-11-10 12:09:29,973:INFO:Copying training dataset
2024-11-10 12:09:29,978:INFO:Defining folds
2024-11-10 12:09:29,978:INFO:Declaring metric variables
2024-11-10 12:09:29,978:INFO:Importing untrained model
2024-11-10 12:09:29,978:INFO:Quadratic Discriminant Analysis Imported successfully
2024-11-10 12:09:29,978:INFO:Starting cross validation
2024-11-10 12:09:29,980:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:30,128:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-10 12:09:30,135:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-10 12:09:30,136:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-10 12:09:30,138:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-10 12:09:30,138:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-10 12:09:30,146:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-10 12:09:30,146:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-10 12:09:30,159:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-10 12:09:30,160:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-11-10 12:09:30,201:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,204:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,204:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,208:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,209:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,212:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,221:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,223:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,238:INFO:Calculating mean and std
2024-11-10 12:09:30,238:INFO:Creating metrics dataframe
2024-11-10 12:09:30,240:INFO:Uploading results into container
2024-11-10 12:09:30,240:INFO:Uploading model into container now
2024-11-10 12:09:30,241:INFO:_master_model_container: 8
2024-11-10 12:09:30,241:INFO:_display_container: 2
2024-11-10 12:09:30,241:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-11-10 12:09:30,241:INFO:create_model() successfully completed......................................
2024-11-10 12:09:30,340:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:30,341:INFO:Creating metrics dataframe
2024-11-10 12:09:30,342:INFO:Initializing Ada Boost Classifier
2024-11-10 12:09:30,343:INFO:Total runtime is 0.16958250602086383 minutes
2024-11-10 12:09:30,343:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:30,343:INFO:Initializing create_model()
2024-11-10 12:09:30,343:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:30,343:INFO:Checking exceptions
2024-11-10 12:09:30,343:INFO:Importing libraries
2024-11-10 12:09:30,343:INFO:Copying training dataset
2024-11-10 12:09:30,347:INFO:Defining folds
2024-11-10 12:09:30,347:INFO:Declaring metric variables
2024-11-10 12:09:30,347:INFO:Importing untrained model
2024-11-10 12:09:30,348:INFO:Ada Boost Classifier Imported successfully
2024-11-10 12:09:30,348:INFO:Starting cross validation
2024-11-10 12:09:30,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:30,492:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,494:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,494:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,500:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,501:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,505:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,508:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,511:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,516:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,523:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-11-10 12:09:30,560:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,561:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,561:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,570:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,572:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,573:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,573:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,583:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,584:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,591:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:30,603:INFO:Calculating mean and std
2024-11-10 12:09:30,604:INFO:Creating metrics dataframe
2024-11-10 12:09:30,605:INFO:Uploading results into container
2024-11-10 12:09:30,605:INFO:Uploading model into container now
2024-11-10 12:09:30,605:INFO:_master_model_container: 9
2024-11-10 12:09:30,605:INFO:_display_container: 2
2024-11-10 12:09:30,606:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6576)
2024-11-10 12:09:30,606:INFO:create_model() successfully completed......................................
2024-11-10 12:09:30,702:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:30,703:INFO:Creating metrics dataframe
2024-11-10 12:09:30,704:INFO:Initializing Gradient Boosting Classifier
2024-11-10 12:09:30,704:INFO:Total runtime is 0.17560412883758544 minutes
2024-11-10 12:09:30,705:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:30,705:INFO:Initializing create_model()
2024-11-10 12:09:30,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:30,705:INFO:Checking exceptions
2024-11-10 12:09:30,705:INFO:Importing libraries
2024-11-10 12:09:30,706:INFO:Copying training dataset
2024-11-10 12:09:30,709:INFO:Defining folds
2024-11-10 12:09:30,709:INFO:Declaring metric variables
2024-11-10 12:09:30,710:INFO:Importing untrained model
2024-11-10 12:09:30,710:INFO:Gradient Boosting Classifier Imported successfully
2024-11-10 12:09:30,710:INFO:Starting cross validation
2024-11-10 12:09:30,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:31,048:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,057:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,058:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,060:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,060:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,061:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,063:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,064:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,072:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,078:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,093:INFO:Calculating mean and std
2024-11-10 12:09:31,094:INFO:Creating metrics dataframe
2024-11-10 12:09:31,095:INFO:Uploading results into container
2024-11-10 12:09:31,095:INFO:Uploading model into container now
2024-11-10 12:09:31,096:INFO:_master_model_container: 10
2024-11-10 12:09:31,096:INFO:_display_container: 2
2024-11-10 12:09:31,096:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6576, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-11-10 12:09:31,096:INFO:create_model() successfully completed......................................
2024-11-10 12:09:31,196:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:31,196:INFO:Creating metrics dataframe
2024-11-10 12:09:31,198:INFO:Initializing Linear Discriminant Analysis
2024-11-10 12:09:31,199:INFO:Total runtime is 0.18385008573532105 minutes
2024-11-10 12:09:31,199:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:31,199:INFO:Initializing create_model()
2024-11-10 12:09:31,199:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:31,199:INFO:Checking exceptions
2024-11-10 12:09:31,199:INFO:Importing libraries
2024-11-10 12:09:31,199:INFO:Copying training dataset
2024-11-10 12:09:31,203:INFO:Defining folds
2024-11-10 12:09:31,203:INFO:Declaring metric variables
2024-11-10 12:09:31,203:INFO:Importing untrained model
2024-11-10 12:09:31,203:INFO:Linear Discriminant Analysis Imported successfully
2024-11-10 12:09:31,203:INFO:Starting cross validation
2024-11-10 12:09:31,205:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:31,418:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,418:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,419:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,425:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,426:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,428:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,430:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,437:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,442:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:31,449:INFO:Calculating mean and std
2024-11-10 12:09:31,450:INFO:Creating metrics dataframe
2024-11-10 12:09:31,451:INFO:Uploading results into container
2024-11-10 12:09:31,451:INFO:Uploading model into container now
2024-11-10 12:09:31,452:INFO:_master_model_container: 11
2024-11-10 12:09:31,452:INFO:_display_container: 2
2024-11-10 12:09:31,452:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-11-10 12:09:31,452:INFO:create_model() successfully completed......................................
2024-11-10 12:09:31,549:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:31,549:INFO:Creating metrics dataframe
2024-11-10 12:09:31,551:INFO:Initializing Extra Trees Classifier
2024-11-10 12:09:31,551:INFO:Total runtime is 0.18971719741821289 minutes
2024-11-10 12:09:31,552:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:31,552:INFO:Initializing create_model()
2024-11-10 12:09:31,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:31,552:INFO:Checking exceptions
2024-11-10 12:09:31,552:INFO:Importing libraries
2024-11-10 12:09:31,552:INFO:Copying training dataset
2024-11-10 12:09:31,556:INFO:Defining folds
2024-11-10 12:09:31,556:INFO:Declaring metric variables
2024-11-10 12:09:31,557:INFO:Importing untrained model
2024-11-10 12:09:31,557:INFO:Extra Trees Classifier Imported successfully
2024-11-10 12:09:31,557:INFO:Starting cross validation
2024-11-10 12:09:31,559:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:32,110:INFO:Calculating mean and std
2024-11-10 12:09:32,111:INFO:Creating metrics dataframe
2024-11-10 12:09:32,112:INFO:Uploading results into container
2024-11-10 12:09:32,113:INFO:Uploading model into container now
2024-11-10 12:09:32,114:INFO:_master_model_container: 12
2024-11-10 12:09:32,114:INFO:_display_container: 2
2024-11-10 12:09:32,114:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6576, verbose=0,
                     warm_start=False)
2024-11-10 12:09:32,114:INFO:create_model() successfully completed......................................
2024-11-10 12:09:32,217:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:32,218:INFO:Creating metrics dataframe
2024-11-10 12:09:32,220:INFO:Initializing Light Gradient Boosting Machine
2024-11-10 12:09:32,220:INFO:Total runtime is 0.20085586309432982 minutes
2024-11-10 12:09:32,220:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:32,221:INFO:Initializing create_model()
2024-11-10 12:09:32,221:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:32,221:INFO:Checking exceptions
2024-11-10 12:09:32,221:INFO:Importing libraries
2024-11-10 12:09:32,221:INFO:Copying training dataset
2024-11-10 12:09:32,225:INFO:Defining folds
2024-11-10 12:09:32,225:INFO:Declaring metric variables
2024-11-10 12:09:32,225:INFO:Importing untrained model
2024-11-10 12:09:32,225:INFO:Light Gradient Boosting Machine Imported successfully
2024-11-10 12:09:32,225:INFO:Starting cross validation
2024-11-10 12:09:32,227:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:32,744:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:32,745:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:32,768:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:32,827:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:32,899:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:32,966:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,060:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,140:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,179:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,194:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,204:INFO:Calculating mean and std
2024-11-10 12:09:33,205:INFO:Creating metrics dataframe
2024-11-10 12:09:33,208:INFO:Uploading results into container
2024-11-10 12:09:33,208:INFO:Uploading model into container now
2024-11-10 12:09:33,209:INFO:_master_model_container: 13
2024-11-10 12:09:33,209:INFO:_display_container: 2
2024-11-10 12:09:33,209:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6576, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-11-10 12:09:33,209:INFO:create_model() successfully completed......................................
2024-11-10 12:09:33,339:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:33,340:INFO:Creating metrics dataframe
2024-11-10 12:09:33,342:INFO:Initializing Dummy Classifier
2024-11-10 12:09:33,342:INFO:Total runtime is 0.21955678860346475 minutes
2024-11-10 12:09:33,342:INFO:SubProcess create_model() called ==================================
2024-11-10 12:09:33,342:INFO:Initializing create_model()
2024-11-10 12:09:33,342:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000248028BBB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:33,342:INFO:Checking exceptions
2024-11-10 12:09:33,342:INFO:Importing libraries
2024-11-10 12:09:33,342:INFO:Copying training dataset
2024-11-10 12:09:33,347:INFO:Defining folds
2024-11-10 12:09:33,347:INFO:Declaring metric variables
2024-11-10 12:09:33,347:INFO:Importing untrained model
2024-11-10 12:09:33,347:INFO:Dummy Classifier Imported successfully
2024-11-10 12:09:33,347:INFO:Starting cross validation
2024-11-10 12:09:33,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-11-10 12:09:33,591:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,608:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,609:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,610:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,613:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,615:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,617:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,621:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,625:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,628:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-11-10 12:09:33,635:INFO:Calculating mean and std
2024-11-10 12:09:33,636:INFO:Creating metrics dataframe
2024-11-10 12:09:33,637:INFO:Uploading results into container
2024-11-10 12:09:33,638:INFO:Uploading model into container now
2024-11-10 12:09:33,638:INFO:_master_model_container: 14
2024-11-10 12:09:33,638:INFO:_display_container: 2
2024-11-10 12:09:33,638:INFO:DummyClassifier(constant=None, random_state=6576, strategy='prior')
2024-11-10 12:09:33,638:INFO:create_model() successfully completed......................................
2024-11-10 12:09:33,744:INFO:SubProcess create_model() end ==================================
2024-11-10 12:09:33,745:INFO:Creating metrics dataframe
2024-11-10 12:09:33,748:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-11-10 12:09:33,749:INFO:Initializing create_model()
2024-11-10 12:09:33,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6576, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-11-10 12:09:33,749:INFO:Checking exceptions
2024-11-10 12:09:33,750:INFO:Importing libraries
2024-11-10 12:09:33,750:INFO:Copying training dataset
2024-11-10 12:09:33,754:INFO:Defining folds
2024-11-10 12:09:33,755:INFO:Declaring metric variables
2024-11-10 12:09:33,755:INFO:Importing untrained model
2024-11-10 12:09:33,755:INFO:Declaring custom model
2024-11-10 12:09:33,755:INFO:Logistic Regression Imported successfully
2024-11-10 12:09:33,757:INFO:Cross validation set to False
2024-11-10 12:09:33,757:INFO:Fitting Model
2024-11-10 12:09:33,945:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-11-10 12:09:33,946:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6576, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-10 12:09:33,946:INFO:create_model() successfully completed......................................
2024-11-10 12:09:34,058:INFO:_master_model_container: 14
2024-11-10 12:09:34,059:INFO:_display_container: 2
2024-11-10 12:09:34,059:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6576, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-11-10 12:09:34,059:INFO:compare_models() successfully completed......................................
2024-11-10 12:09:34,084:INFO:Initializing save_model()
2024-11-10 12:09:34,084:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6576, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-11-10 12:09:34,085:INFO:Adding model into prep_pipe
2024-11-10 12:09:34,094:INFO:best_classifier.pkl saved in current working directory
2024-11-10 12:09:34,120:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=6576,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-11-10 12:09:34,120:INFO:save_model() successfully completed......................................
2024-11-10 12:09:59,917:INFO:Initializing load_model()
2024-11-10 12:09:59,918:INFO:load_model(model_name=trained_classifier, platform=None, authentication=None, verbose=True)
2024-11-10 12:09:59,971:INFO:Initializing predict_model()
2024-11-10 12:09:59,971:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000248031D9930>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=6576))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000024802786290>)
2024-11-10 12:09:59,971:INFO:Checking exceptions
2024-11-10 12:09:59,971:INFO:Preloading libraries
2024-11-10 12:09:59,972:INFO:Set up data.
2024-11-10 12:09:59,978:INFO:Set up index.
2025-03-15 22:55:49,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 22:55:49,637:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 22:55:49,637:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 22:55:49,637:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 22:56:14,816:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000002284ABF5DC0, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-03-15 22:56:40,313:INFO:PyCaret RegressionExperiment
2025-03-15 22:56:40,314:INFO:Logging name: reg-default-name
2025-03-15 22:56:40,314:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-15 22:56:40,314:INFO:version 3.3.2
2025-03-15 22:56:40,314:INFO:Initializing setup()
2025-03-15 22:56:40,314:INFO:self.USI: 8ce8
2025-03-15 22:56:40,314:INFO:self._variable_keys: {'target_param', 'y', 'USI', 'y_test', 'gpu_param', 'X_train', 'X_test', 'n_jobs_param', 'pipeline', 'X', '_available_plots', 'log_plots_param', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'html_param', 'y_train', 'logging_param', 'fold_generator', 'fold_groups_param', 'exp_id', 'seed', 'fold_shuffle_param', '_ml_usecase', 'idx', 'memory', 'transform_target_param'}
2025-03-15 22:56:40,314:INFO:Checking environment
2025-03-15 22:56:40,314:INFO:python_version: 3.10.0
2025-03-15 22:56:40,314:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-15 22:56:40,314:INFO:machine: AMD64
2025-03-15 22:56:40,333:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-15 22:56:40,340:INFO:Memory: svmem(total=17037209600, available=5910540288, percent=65.3, used=11126669312, free=5910540288)
2025-03-15 22:56:40,340:INFO:Physical Core: 6
2025-03-15 22:56:40,340:INFO:Logical Core: 12
2025-03-15 22:56:40,340:INFO:Checking libraries
2025-03-15 22:56:40,340:INFO:System:
2025-03-15 22:56:40,340:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-15 22:56:40,340:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-15 22:56:40,341:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-15 22:56:40,341:INFO:PyCaret required dependencies:
2025-03-15 22:56:40,421:INFO:                 pip: 21.2.3
2025-03-15 22:56:40,421:INFO:          setuptools: 57.4.0
2025-03-15 22:56:40,421:INFO:             pycaret: 3.3.2
2025-03-15 22:56:40,421:INFO:             IPython: 8.29.0
2025-03-15 22:56:40,421:INFO:          ipywidgets: 8.1.5
2025-03-15 22:56:40,422:INFO:                tqdm: 4.67.0
2025-03-15 22:56:40,422:INFO:               numpy: 1.26.4
2025-03-15 22:56:40,422:INFO:              pandas: 2.1.4
2025-03-15 22:56:40,422:INFO:              jinja2: 3.1.4
2025-03-15 22:56:40,422:INFO:               scipy: 1.11.4
2025-03-15 22:56:40,422:INFO:              joblib: 1.3.2
2025-03-15 22:56:40,422:INFO:             sklearn: 1.4.2
2025-03-15 22:56:40,422:INFO:                pyod: 2.0.2
2025-03-15 22:56:40,422:INFO:            imblearn: 0.12.4
2025-03-15 22:56:40,422:INFO:   category_encoders: 2.6.4
2025-03-15 22:56:40,422:INFO:            lightgbm: 4.5.0
2025-03-15 22:56:40,422:INFO:               numba: 0.60.0
2025-03-15 22:56:40,422:INFO:            requests: 2.32.3
2025-03-15 22:56:40,422:INFO:          matplotlib: 3.7.5
2025-03-15 22:56:40,422:INFO:          scikitplot: 0.3.7
2025-03-15 22:56:40,422:INFO:         yellowbrick: 1.5
2025-03-15 22:56:40,422:INFO:              plotly: 5.24.1
2025-03-15 22:56:40,422:INFO:    plotly-resampler: Not installed
2025-03-15 22:56:40,422:INFO:             kaleido: 0.2.1
2025-03-15 22:56:40,422:INFO:           schemdraw: 0.15
2025-03-15 22:56:40,422:INFO:         statsmodels: 0.14.4
2025-03-15 22:56:40,422:INFO:              sktime: 0.26.0
2025-03-15 22:56:40,422:INFO:               tbats: 1.1.3
2025-03-15 22:56:40,422:INFO:            pmdarima: 2.0.4
2025-03-15 22:56:40,423:INFO:              psutil: 6.1.0
2025-03-15 22:56:40,423:INFO:          markupsafe: 3.0.2
2025-03-15 22:56:40,423:INFO:             pickle5: Not installed
2025-03-15 22:56:40,423:INFO:         cloudpickle: 3.1.0
2025-03-15 22:56:40,423:INFO:         deprecation: 2.1.0
2025-03-15 22:56:40,423:INFO:              xxhash: 3.5.0
2025-03-15 22:56:40,423:INFO:           wurlitzer: Not installed
2025-03-15 22:56:40,423:INFO:PyCaret optional dependencies:
2025-03-15 22:56:40,436:INFO:                shap: Not installed
2025-03-15 22:56:40,436:INFO:           interpret: Not installed
2025-03-15 22:56:40,436:INFO:                umap: Not installed
2025-03-15 22:56:40,437:INFO:     ydata_profiling: 4.12.0
2025-03-15 22:56:40,437:INFO:  explainerdashboard: Not installed
2025-03-15 22:56:40,437:INFO:             autoviz: Not installed
2025-03-15 22:56:40,437:INFO:           fairlearn: Not installed
2025-03-15 22:56:40,437:INFO:          deepchecks: Not installed
2025-03-15 22:56:40,437:INFO:             xgboost: Not installed
2025-03-15 22:56:40,437:INFO:            catboost: Not installed
2025-03-15 22:56:40,437:INFO:              kmodes: Not installed
2025-03-15 22:56:40,437:INFO:             mlxtend: Not installed
2025-03-15 22:56:40,437:INFO:       statsforecast: Not installed
2025-03-15 22:56:40,437:INFO:        tune_sklearn: Not installed
2025-03-15 22:56:40,437:INFO:                 ray: Not installed
2025-03-15 22:56:40,437:INFO:            hyperopt: Not installed
2025-03-15 22:56:40,437:INFO:              optuna: Not installed
2025-03-15 22:56:40,437:INFO:               skopt: Not installed
2025-03-15 22:56:40,437:INFO:              mlflow: Not installed
2025-03-15 22:56:40,437:INFO:              gradio: Not installed
2025-03-15 22:56:40,437:INFO:             fastapi: Not installed
2025-03-15 22:56:40,437:INFO:             uvicorn: Not installed
2025-03-15 22:56:40,437:INFO:              m2cgen: Not installed
2025-03-15 22:56:40,437:INFO:           evidently: Not installed
2025-03-15 22:56:40,437:INFO:               fugue: Not installed
2025-03-15 22:56:40,437:INFO:           streamlit: 1.40.0
2025-03-15 22:56:40,437:INFO:             prophet: Not installed
2025-03-15 22:56:40,437:INFO:None
2025-03-15 22:56:40,437:INFO:Set up data.
2025-03-15 22:56:40,446:INFO:Set up folding strategy.
2025-03-15 22:56:40,446:INFO:Set up train/test split.
2025-03-15 22:56:40,458:INFO:Set up index.
2025-03-15 22:56:40,458:INFO:Assigning column types.
2025-03-15 22:56:40,462:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-15 22:56:40,462:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,467:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,471:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,530:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,574:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:40,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:40,575:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,579:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,584:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,639:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,681:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:40,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:40,683:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-15 22:56:40,688:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,692:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,747:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,790:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:40,790:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:40,795:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,799:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,855:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,901:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:40,902:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:40,902:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-15 22:56:40,911:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 22:56:40,968:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,012:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,020:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,077:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,120:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,120:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,120:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,121:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-15 22:56:41,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,231:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,231:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,294:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,336:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,338:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-15 22:56:41,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,509:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 22:56:41,552:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,552:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,553:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-15 22:56:41,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:41,775:INFO:Preparing preprocessing pipeline...
2025-03-15 22:56:41,775:INFO:Set up simple imputation.
2025-03-15 22:56:41,780:INFO:Set up encoding of ordinal features.
2025-03-15 22:56:41,782:INFO:Set up encoding of categorical features.
2025-03-15 22:56:41,907:INFO:Finished creating preprocessing pipeline.
2025-03-15 22:56:41,935:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan')))])
2025-03-15 22:56:41,936:INFO:Creating final display dataframe.
2025-03-15 22:56:42,318:INFO:Setup _display_container:                     Description             Value
0                    Session id              7298
1                        Target          Survived
2                   Target type        Regression
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              8ce8
2025-03-15 22:56:42,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:42,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:42,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:42,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:56:42,548:INFO:setup() successfully completed in 2.24s...............
2025-03-15 22:56:42,555:INFO:Initializing compare_models()
2025-03-15 22:56:42,555:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-15 22:56:42,555:INFO:Checking exceptions
2025-03-15 22:56:42,558:INFO:Preparing display monitor
2025-03-15 22:56:42,561:INFO:Initializing Linear Regression
2025-03-15 22:56:42,561:INFO:Total runtime is 0.0 minutes
2025-03-15 22:56:42,561:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:42,562:INFO:Initializing create_model()
2025-03-15 22:56:42,562:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:42,562:INFO:Checking exceptions
2025-03-15 22:56:42,562:INFO:Importing libraries
2025-03-15 22:56:42,562:INFO:Copying training dataset
2025-03-15 22:56:42,566:INFO:Defining folds
2025-03-15 22:56:42,567:INFO:Declaring metric variables
2025-03-15 22:56:42,567:INFO:Importing untrained model
2025-03-15 22:56:42,567:INFO:Linear Regression Imported successfully
2025-03-15 22:56:42,567:INFO:Starting cross validation
2025-03-15 22:56:42,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:48,468:INFO:Calculating mean and std
2025-03-15 22:56:48,469:INFO:Creating metrics dataframe
2025-03-15 22:56:48,471:INFO:Uploading results into container
2025-03-15 22:56:48,472:INFO:Uploading model into container now
2025-03-15 22:56:48,472:INFO:_master_model_container: 1
2025-03-15 22:56:48,472:INFO:_display_container: 2
2025-03-15 22:56:48,472:INFO:LinearRegression(n_jobs=-1)
2025-03-15 22:56:48,472:INFO:create_model() successfully completed......................................
2025-03-15 22:56:48,576:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:48,576:INFO:Creating metrics dataframe
2025-03-15 22:56:48,578:INFO:Initializing Lasso Regression
2025-03-15 22:56:48,578:INFO:Total runtime is 0.10028720299402873 minutes
2025-03-15 22:56:48,578:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:48,579:INFO:Initializing create_model()
2025-03-15 22:56:48,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:48,579:INFO:Checking exceptions
2025-03-15 22:56:48,579:INFO:Importing libraries
2025-03-15 22:56:48,579:INFO:Copying training dataset
2025-03-15 22:56:48,583:INFO:Defining folds
2025-03-15 22:56:48,583:INFO:Declaring metric variables
2025-03-15 22:56:48,583:INFO:Importing untrained model
2025-03-15 22:56:48,584:INFO:Lasso Regression Imported successfully
2025-03-15 22:56:48,584:INFO:Starting cross validation
2025-03-15 22:56:48,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:50,964:INFO:Calculating mean and std
2025-03-15 22:56:50,965:INFO:Creating metrics dataframe
2025-03-15 22:56:50,967:INFO:Uploading results into container
2025-03-15 22:56:50,968:INFO:Uploading model into container now
2025-03-15 22:56:50,968:INFO:_master_model_container: 2
2025-03-15 22:56:50,968:INFO:_display_container: 2
2025-03-15 22:56:50,969:INFO:Lasso(random_state=7298)
2025-03-15 22:56:50,969:INFO:create_model() successfully completed......................................
2025-03-15 22:56:51,077:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:51,077:INFO:Creating metrics dataframe
2025-03-15 22:56:51,079:INFO:Initializing Ridge Regression
2025-03-15 22:56:51,079:INFO:Total runtime is 0.14196753104527793 minutes
2025-03-15 22:56:51,079:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:51,080:INFO:Initializing create_model()
2025-03-15 22:56:51,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:51,080:INFO:Checking exceptions
2025-03-15 22:56:51,080:INFO:Importing libraries
2025-03-15 22:56:51,080:INFO:Copying training dataset
2025-03-15 22:56:51,084:INFO:Defining folds
2025-03-15 22:56:51,084:INFO:Declaring metric variables
2025-03-15 22:56:51,084:INFO:Importing untrained model
2025-03-15 22:56:51,084:INFO:Ridge Regression Imported successfully
2025-03-15 22:56:51,085:INFO:Starting cross validation
2025-03-15 22:56:51,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:51,336:INFO:Calculating mean and std
2025-03-15 22:56:51,337:INFO:Creating metrics dataframe
2025-03-15 22:56:51,338:INFO:Uploading results into container
2025-03-15 22:56:51,339:INFO:Uploading model into container now
2025-03-15 22:56:51,339:INFO:_master_model_container: 3
2025-03-15 22:56:51,339:INFO:_display_container: 2
2025-03-15 22:56:51,339:INFO:Ridge(random_state=7298)
2025-03-15 22:56:51,339:INFO:create_model() successfully completed......................................
2025-03-15 22:56:51,436:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:51,436:INFO:Creating metrics dataframe
2025-03-15 22:56:51,439:INFO:Initializing Elastic Net
2025-03-15 22:56:51,439:INFO:Total runtime is 0.14796047608057658 minutes
2025-03-15 22:56:51,439:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:51,439:INFO:Initializing create_model()
2025-03-15 22:56:51,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:51,439:INFO:Checking exceptions
2025-03-15 22:56:51,440:INFO:Importing libraries
2025-03-15 22:56:51,440:INFO:Copying training dataset
2025-03-15 22:56:51,444:INFO:Defining folds
2025-03-15 22:56:51,444:INFO:Declaring metric variables
2025-03-15 22:56:51,444:INFO:Importing untrained model
2025-03-15 22:56:51,445:INFO:Elastic Net Imported successfully
2025-03-15 22:56:51,445:INFO:Starting cross validation
2025-03-15 22:56:51,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:51,711:INFO:Calculating mean and std
2025-03-15 22:56:51,712:INFO:Creating metrics dataframe
2025-03-15 22:56:51,714:INFO:Uploading results into container
2025-03-15 22:56:51,714:INFO:Uploading model into container now
2025-03-15 22:56:51,714:INFO:_master_model_container: 4
2025-03-15 22:56:51,714:INFO:_display_container: 2
2025-03-15 22:56:51,715:INFO:ElasticNet(random_state=7298)
2025-03-15 22:56:51,715:INFO:create_model() successfully completed......................................
2025-03-15 22:56:51,808:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:51,808:INFO:Creating metrics dataframe
2025-03-15 22:56:51,810:INFO:Initializing Least Angle Regression
2025-03-15 22:56:51,810:INFO:Total runtime is 0.15414910713831584 minutes
2025-03-15 22:56:51,811:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:51,811:INFO:Initializing create_model()
2025-03-15 22:56:51,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:51,811:INFO:Checking exceptions
2025-03-15 22:56:51,811:INFO:Importing libraries
2025-03-15 22:56:51,811:INFO:Copying training dataset
2025-03-15 22:56:51,815:INFO:Defining folds
2025-03-15 22:56:51,815:INFO:Declaring metric variables
2025-03-15 22:56:51,815:INFO:Importing untrained model
2025-03-15 22:56:51,815:INFO:Least Angle Regression Imported successfully
2025-03-15 22:56:51,816:INFO:Starting cross validation
2025-03-15 22:56:51,817:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:52,102:INFO:Calculating mean and std
2025-03-15 22:56:52,103:INFO:Creating metrics dataframe
2025-03-15 22:56:52,104:INFO:Uploading results into container
2025-03-15 22:56:52,104:INFO:Uploading model into container now
2025-03-15 22:56:52,105:INFO:_master_model_container: 5
2025-03-15 22:56:52,105:INFO:_display_container: 2
2025-03-15 22:56:52,105:INFO:Lars(random_state=7298)
2025-03-15 22:56:52,105:INFO:create_model() successfully completed......................................
2025-03-15 22:56:52,199:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:52,200:INFO:Creating metrics dataframe
2025-03-15 22:56:52,202:INFO:Initializing Lasso Least Angle Regression
2025-03-15 22:56:52,203:INFO:Total runtime is 0.1607056220372518 minutes
2025-03-15 22:56:52,203:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:52,203:INFO:Initializing create_model()
2025-03-15 22:56:52,204:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:52,204:INFO:Checking exceptions
2025-03-15 22:56:52,204:INFO:Importing libraries
2025-03-15 22:56:52,204:INFO:Copying training dataset
2025-03-15 22:56:52,208:INFO:Defining folds
2025-03-15 22:56:52,208:INFO:Declaring metric variables
2025-03-15 22:56:52,208:INFO:Importing untrained model
2025-03-15 22:56:52,208:INFO:Lasso Least Angle Regression Imported successfully
2025-03-15 22:56:52,208:INFO:Starting cross validation
2025-03-15 22:56:52,210:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:52,472:INFO:Calculating mean and std
2025-03-15 22:56:52,474:INFO:Creating metrics dataframe
2025-03-15 22:56:52,480:INFO:Uploading results into container
2025-03-15 22:56:52,482:INFO:Uploading model into container now
2025-03-15 22:56:52,483:INFO:_master_model_container: 6
2025-03-15 22:56:52,483:INFO:_display_container: 2
2025-03-15 22:56:52,484:INFO:LassoLars(random_state=7298)
2025-03-15 22:56:52,484:INFO:create_model() successfully completed......................................
2025-03-15 22:56:52,583:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:52,583:INFO:Creating metrics dataframe
2025-03-15 22:56:52,585:INFO:Initializing Orthogonal Matching Pursuit
2025-03-15 22:56:52,585:INFO:Total runtime is 0.16707268953323365 minutes
2025-03-15 22:56:52,585:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:52,585:INFO:Initializing create_model()
2025-03-15 22:56:52,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:52,585:INFO:Checking exceptions
2025-03-15 22:56:52,585:INFO:Importing libraries
2025-03-15 22:56:52,585:INFO:Copying training dataset
2025-03-15 22:56:52,591:INFO:Defining folds
2025-03-15 22:56:52,591:INFO:Declaring metric variables
2025-03-15 22:56:52,591:INFO:Importing untrained model
2025-03-15 22:56:52,591:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-15 22:56:52,592:INFO:Starting cross validation
2025-03-15 22:56:52,593:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:52,847:INFO:Calculating mean and std
2025-03-15 22:56:52,847:INFO:Creating metrics dataframe
2025-03-15 22:56:52,849:INFO:Uploading results into container
2025-03-15 22:56:52,849:INFO:Uploading model into container now
2025-03-15 22:56:52,849:INFO:_master_model_container: 7
2025-03-15 22:56:52,850:INFO:_display_container: 2
2025-03-15 22:56:52,850:INFO:OrthogonalMatchingPursuit()
2025-03-15 22:56:52,850:INFO:create_model() successfully completed......................................
2025-03-15 22:56:52,947:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:52,947:INFO:Creating metrics dataframe
2025-03-15 22:56:52,950:INFO:Initializing Bayesian Ridge
2025-03-15 22:56:52,950:INFO:Total runtime is 0.17314483722050986 minutes
2025-03-15 22:56:52,951:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:52,951:INFO:Initializing create_model()
2025-03-15 22:56:52,951:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:52,951:INFO:Checking exceptions
2025-03-15 22:56:52,951:INFO:Importing libraries
2025-03-15 22:56:52,951:INFO:Copying training dataset
2025-03-15 22:56:52,956:INFO:Defining folds
2025-03-15 22:56:52,956:INFO:Declaring metric variables
2025-03-15 22:56:52,956:INFO:Importing untrained model
2025-03-15 22:56:52,956:INFO:Bayesian Ridge Imported successfully
2025-03-15 22:56:52,956:INFO:Starting cross validation
2025-03-15 22:56:52,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:53,222:INFO:Calculating mean and std
2025-03-15 22:56:53,223:INFO:Creating metrics dataframe
2025-03-15 22:56:53,225:INFO:Uploading results into container
2025-03-15 22:56:53,225:INFO:Uploading model into container now
2025-03-15 22:56:53,225:INFO:_master_model_container: 8
2025-03-15 22:56:53,225:INFO:_display_container: 2
2025-03-15 22:56:53,226:INFO:BayesianRidge()
2025-03-15 22:56:53,226:INFO:create_model() successfully completed......................................
2025-03-15 22:56:53,321:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:53,321:INFO:Creating metrics dataframe
2025-03-15 22:56:53,324:INFO:Initializing Passive Aggressive Regressor
2025-03-15 22:56:53,324:INFO:Total runtime is 0.1793847719828288 minutes
2025-03-15 22:56:53,324:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:53,324:INFO:Initializing create_model()
2025-03-15 22:56:53,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:53,324:INFO:Checking exceptions
2025-03-15 22:56:53,324:INFO:Importing libraries
2025-03-15 22:56:53,324:INFO:Copying training dataset
2025-03-15 22:56:53,329:INFO:Defining folds
2025-03-15 22:56:53,329:INFO:Declaring metric variables
2025-03-15 22:56:53,329:INFO:Importing untrained model
2025-03-15 22:56:53,330:INFO:Passive Aggressive Regressor Imported successfully
2025-03-15 22:56:53,330:INFO:Starting cross validation
2025-03-15 22:56:53,332:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:53,600:INFO:Calculating mean and std
2025-03-15 22:56:53,601:INFO:Creating metrics dataframe
2025-03-15 22:56:53,602:INFO:Uploading results into container
2025-03-15 22:56:53,602:INFO:Uploading model into container now
2025-03-15 22:56:53,603:INFO:_master_model_container: 9
2025-03-15 22:56:53,603:INFO:_display_container: 2
2025-03-15 22:56:53,603:INFO:PassiveAggressiveRegressor(random_state=7298)
2025-03-15 22:56:53,603:INFO:create_model() successfully completed......................................
2025-03-15 22:56:53,696:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:53,697:INFO:Creating metrics dataframe
2025-03-15 22:56:53,699:INFO:Initializing Huber Regressor
2025-03-15 22:56:53,699:INFO:Total runtime is 0.18562670548756918 minutes
2025-03-15 22:56:53,699:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:53,700:INFO:Initializing create_model()
2025-03-15 22:56:53,700:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:53,700:INFO:Checking exceptions
2025-03-15 22:56:53,700:INFO:Importing libraries
2025-03-15 22:56:53,700:INFO:Copying training dataset
2025-03-15 22:56:53,705:INFO:Defining folds
2025-03-15 22:56:53,706:INFO:Declaring metric variables
2025-03-15 22:56:53,706:INFO:Importing untrained model
2025-03-15 22:56:53,706:INFO:Huber Regressor Imported successfully
2025-03-15 22:56:53,706:INFO:Starting cross validation
2025-03-15 22:56:53,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:53,923:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 22:56:53,923:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 22:56:53,923:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 22:56:53,927:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 22:56:53,930:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 22:56:53,945:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 22:56:53,997:INFO:Calculating mean and std
2025-03-15 22:56:53,997:INFO:Creating metrics dataframe
2025-03-15 22:56:53,999:INFO:Uploading results into container
2025-03-15 22:56:54,000:INFO:Uploading model into container now
2025-03-15 22:56:54,000:INFO:_master_model_container: 10
2025-03-15 22:56:54,000:INFO:_display_container: 2
2025-03-15 22:56:54,000:INFO:HuberRegressor()
2025-03-15 22:56:54,000:INFO:create_model() successfully completed......................................
2025-03-15 22:56:54,097:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:54,097:INFO:Creating metrics dataframe
2025-03-15 22:56:54,100:INFO:Initializing K Neighbors Regressor
2025-03-15 22:56:54,100:INFO:Total runtime is 0.19230804443359376 minutes
2025-03-15 22:56:54,100:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:54,100:INFO:Initializing create_model()
2025-03-15 22:56:54,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:54,100:INFO:Checking exceptions
2025-03-15 22:56:54,100:INFO:Importing libraries
2025-03-15 22:56:54,100:INFO:Copying training dataset
2025-03-15 22:56:54,105:INFO:Defining folds
2025-03-15 22:56:54,105:INFO:Declaring metric variables
2025-03-15 22:56:54,105:INFO:Importing untrained model
2025-03-15 22:56:54,105:INFO:K Neighbors Regressor Imported successfully
2025-03-15 22:56:54,105:INFO:Starting cross validation
2025-03-15 22:56:54,106:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:54,395:INFO:Calculating mean and std
2025-03-15 22:56:54,396:INFO:Creating metrics dataframe
2025-03-15 22:56:54,397:INFO:Uploading results into container
2025-03-15 22:56:54,398:INFO:Uploading model into container now
2025-03-15 22:56:54,398:INFO:_master_model_container: 11
2025-03-15 22:56:54,398:INFO:_display_container: 2
2025-03-15 22:56:54,398:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-15 22:56:54,398:INFO:create_model() successfully completed......................................
2025-03-15 22:56:54,493:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:54,493:INFO:Creating metrics dataframe
2025-03-15 22:56:54,496:INFO:Initializing Decision Tree Regressor
2025-03-15 22:56:54,496:INFO:Total runtime is 0.19891622463862102 minutes
2025-03-15 22:56:54,496:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:54,497:INFO:Initializing create_model()
2025-03-15 22:56:54,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:54,497:INFO:Checking exceptions
2025-03-15 22:56:54,497:INFO:Importing libraries
2025-03-15 22:56:54,497:INFO:Copying training dataset
2025-03-15 22:56:54,501:INFO:Defining folds
2025-03-15 22:56:54,502:INFO:Declaring metric variables
2025-03-15 22:56:54,502:INFO:Importing untrained model
2025-03-15 22:56:54,502:INFO:Decision Tree Regressor Imported successfully
2025-03-15 22:56:54,502:INFO:Starting cross validation
2025-03-15 22:56:54,504:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:54,834:INFO:Calculating mean and std
2025-03-15 22:56:54,835:INFO:Creating metrics dataframe
2025-03-15 22:56:54,837:INFO:Uploading results into container
2025-03-15 22:56:54,837:INFO:Uploading model into container now
2025-03-15 22:56:54,837:INFO:_master_model_container: 12
2025-03-15 22:56:54,838:INFO:_display_container: 2
2025-03-15 22:56:54,838:INFO:DecisionTreeRegressor(random_state=7298)
2025-03-15 22:56:54,838:INFO:create_model() successfully completed......................................
2025-03-15 22:56:54,947:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:54,947:INFO:Creating metrics dataframe
2025-03-15 22:56:54,950:INFO:Initializing Random Forest Regressor
2025-03-15 22:56:54,950:INFO:Total runtime is 0.20648359457651774 minutes
2025-03-15 22:56:54,950:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:54,950:INFO:Initializing create_model()
2025-03-15 22:56:54,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:54,950:INFO:Checking exceptions
2025-03-15 22:56:54,950:INFO:Importing libraries
2025-03-15 22:56:54,950:INFO:Copying training dataset
2025-03-15 22:56:54,955:INFO:Defining folds
2025-03-15 22:56:54,955:INFO:Declaring metric variables
2025-03-15 22:56:54,955:INFO:Importing untrained model
2025-03-15 22:56:54,956:INFO:Random Forest Regressor Imported successfully
2025-03-15 22:56:54,956:INFO:Starting cross validation
2025-03-15 22:56:54,957:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:55,531:INFO:Calculating mean and std
2025-03-15 22:56:55,532:INFO:Creating metrics dataframe
2025-03-15 22:56:55,534:INFO:Uploading results into container
2025-03-15 22:56:55,534:INFO:Uploading model into container now
2025-03-15 22:56:55,534:INFO:_master_model_container: 13
2025-03-15 22:56:55,534:INFO:_display_container: 2
2025-03-15 22:56:55,535:INFO:RandomForestRegressor(n_jobs=-1, random_state=7298)
2025-03-15 22:56:55,535:INFO:create_model() successfully completed......................................
2025-03-15 22:56:55,644:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:55,644:INFO:Creating metrics dataframe
2025-03-15 22:56:55,646:INFO:Initializing Extra Trees Regressor
2025-03-15 22:56:55,646:INFO:Total runtime is 0.21807868480682374 minutes
2025-03-15 22:56:55,647:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:55,647:INFO:Initializing create_model()
2025-03-15 22:56:55,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:55,647:INFO:Checking exceptions
2025-03-15 22:56:55,647:INFO:Importing libraries
2025-03-15 22:56:55,647:INFO:Copying training dataset
2025-03-15 22:56:55,651:INFO:Defining folds
2025-03-15 22:56:55,652:INFO:Declaring metric variables
2025-03-15 22:56:55,652:INFO:Importing untrained model
2025-03-15 22:56:55,652:INFO:Extra Trees Regressor Imported successfully
2025-03-15 22:56:55,652:INFO:Starting cross validation
2025-03-15 22:56:55,654:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:56,113:INFO:Calculating mean and std
2025-03-15 22:56:56,114:INFO:Creating metrics dataframe
2025-03-15 22:56:56,116:INFO:Uploading results into container
2025-03-15 22:56:56,116:INFO:Uploading model into container now
2025-03-15 22:56:56,116:INFO:_master_model_container: 14
2025-03-15 22:56:56,116:INFO:_display_container: 2
2025-03-15 22:56:56,117:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=7298)
2025-03-15 22:56:56,117:INFO:create_model() successfully completed......................................
2025-03-15 22:56:56,214:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:56,214:INFO:Creating metrics dataframe
2025-03-15 22:56:56,217:INFO:Initializing AdaBoost Regressor
2025-03-15 22:56:56,217:INFO:Total runtime is 0.22759777704874676 minutes
2025-03-15 22:56:56,218:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:56,218:INFO:Initializing create_model()
2025-03-15 22:56:56,218:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:56,218:INFO:Checking exceptions
2025-03-15 22:56:56,218:INFO:Importing libraries
2025-03-15 22:56:56,218:INFO:Copying training dataset
2025-03-15 22:56:56,223:INFO:Defining folds
2025-03-15 22:56:56,223:INFO:Declaring metric variables
2025-03-15 22:56:56,223:INFO:Importing untrained model
2025-03-15 22:56:56,223:INFO:AdaBoost Regressor Imported successfully
2025-03-15 22:56:56,223:INFO:Starting cross validation
2025-03-15 22:56:56,225:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:56,487:INFO:Calculating mean and std
2025-03-15 22:56:56,487:INFO:Creating metrics dataframe
2025-03-15 22:56:56,489:INFO:Uploading results into container
2025-03-15 22:56:56,489:INFO:Uploading model into container now
2025-03-15 22:56:56,490:INFO:_master_model_container: 15
2025-03-15 22:56:56,490:INFO:_display_container: 2
2025-03-15 22:56:56,490:INFO:AdaBoostRegressor(random_state=7298)
2025-03-15 22:56:56,490:INFO:create_model() successfully completed......................................
2025-03-15 22:56:56,585:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:56,586:INFO:Creating metrics dataframe
2025-03-15 22:56:56,588:INFO:Initializing Gradient Boosting Regressor
2025-03-15 22:56:56,588:INFO:Total runtime is 0.23378415505091352 minutes
2025-03-15 22:56:56,588:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:56,589:INFO:Initializing create_model()
2025-03-15 22:56:56,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:56,589:INFO:Checking exceptions
2025-03-15 22:56:56,589:INFO:Importing libraries
2025-03-15 22:56:56,589:INFO:Copying training dataset
2025-03-15 22:56:56,593:INFO:Defining folds
2025-03-15 22:56:56,593:INFO:Declaring metric variables
2025-03-15 22:56:56,593:INFO:Importing untrained model
2025-03-15 22:56:56,594:INFO:Gradient Boosting Regressor Imported successfully
2025-03-15 22:56:56,594:INFO:Starting cross validation
2025-03-15 22:56:56,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:56,953:INFO:Calculating mean and std
2025-03-15 22:56:56,956:INFO:Creating metrics dataframe
2025-03-15 22:56:56,961:INFO:Uploading results into container
2025-03-15 22:56:56,963:INFO:Uploading model into container now
2025-03-15 22:56:56,964:INFO:_master_model_container: 16
2025-03-15 22:56:56,965:INFO:_display_container: 2
2025-03-15 22:56:56,966:INFO:GradientBoostingRegressor(random_state=7298)
2025-03-15 22:56:56,966:INFO:create_model() successfully completed......................................
2025-03-15 22:56:57,095:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:57,095:INFO:Creating metrics dataframe
2025-03-15 22:56:57,098:INFO:Initializing Light Gradient Boosting Machine
2025-03-15 22:56:57,099:INFO:Total runtime is 0.24229809443155928 minutes
2025-03-15 22:56:57,099:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:57,099:INFO:Initializing create_model()
2025-03-15 22:56:57,099:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:57,099:INFO:Checking exceptions
2025-03-15 22:56:57,099:INFO:Importing libraries
2025-03-15 22:56:57,099:INFO:Copying training dataset
2025-03-15 22:56:57,103:INFO:Defining folds
2025-03-15 22:56:57,103:INFO:Declaring metric variables
2025-03-15 22:56:57,103:INFO:Importing untrained model
2025-03-15 22:56:57,104:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 22:56:57,104:INFO:Starting cross validation
2025-03-15 22:56:57,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:58,094:INFO:Calculating mean and std
2025-03-15 22:56:58,095:INFO:Creating metrics dataframe
2025-03-15 22:56:58,097:INFO:Uploading results into container
2025-03-15 22:56:58,098:INFO:Uploading model into container now
2025-03-15 22:56:58,098:INFO:_master_model_container: 17
2025-03-15 22:56:58,099:INFO:_display_container: 2
2025-03-15 22:56:58,099:INFO:LGBMRegressor(n_jobs=-1, random_state=7298)
2025-03-15 22:56:58,099:INFO:create_model() successfully completed......................................
2025-03-15 22:56:58,209:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:58,209:INFO:Creating metrics dataframe
2025-03-15 22:56:58,212:INFO:Initializing Dummy Regressor
2025-03-15 22:56:58,213:INFO:Total runtime is 0.2608702898025513 minutes
2025-03-15 22:56:58,213:INFO:SubProcess create_model() called ==================================
2025-03-15 22:56:58,213:INFO:Initializing create_model()
2025-03-15 22:56:58,213:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000022868CC11B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:58,213:INFO:Checking exceptions
2025-03-15 22:56:58,213:INFO:Importing libraries
2025-03-15 22:56:58,213:INFO:Copying training dataset
2025-03-15 22:56:58,217:INFO:Defining folds
2025-03-15 22:56:58,217:INFO:Declaring metric variables
2025-03-15 22:56:58,217:INFO:Importing untrained model
2025-03-15 22:56:58,218:INFO:Dummy Regressor Imported successfully
2025-03-15 22:56:58,218:INFO:Starting cross validation
2025-03-15 22:56:58,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:56:58,482:INFO:Calculating mean and std
2025-03-15 22:56:58,483:INFO:Creating metrics dataframe
2025-03-15 22:56:58,484:INFO:Uploading results into container
2025-03-15 22:56:58,485:INFO:Uploading model into container now
2025-03-15 22:56:58,485:INFO:_master_model_container: 18
2025-03-15 22:56:58,485:INFO:_display_container: 2
2025-03-15 22:56:58,485:INFO:DummyRegressor()
2025-03-15 22:56:58,485:INFO:create_model() successfully completed......................................
2025-03-15 22:56:58,583:INFO:SubProcess create_model() end ==================================
2025-03-15 22:56:58,583:INFO:Creating metrics dataframe
2025-03-15 22:56:58,587:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-15 22:56:58,589:INFO:Initializing create_model()
2025-03-15 22:56:58,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000022868D83B50>, estimator=Ridge(random_state=7298), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:56:58,589:INFO:Checking exceptions
2025-03-15 22:56:58,590:INFO:Importing libraries
2025-03-15 22:56:58,590:INFO:Copying training dataset
2025-03-15 22:56:58,594:INFO:Defining folds
2025-03-15 22:56:58,594:INFO:Declaring metric variables
2025-03-15 22:56:58,594:INFO:Importing untrained model
2025-03-15 22:56:58,594:INFO:Declaring custom model
2025-03-15 22:56:58,595:INFO:Ridge Regression Imported successfully
2025-03-15 22:56:58,595:INFO:Cross validation set to False
2025-03-15 22:56:58,595:INFO:Fitting Model
2025-03-15 22:56:58,665:INFO:Ridge(random_state=7298)
2025-03-15 22:56:58,665:INFO:create_model() successfully completed......................................
2025-03-15 22:56:58,775:INFO:_master_model_container: 18
2025-03-15 22:56:58,775:INFO:_display_container: 2
2025-03-15 22:56:58,775:INFO:Ridge(random_state=7298)
2025-03-15 22:56:58,775:INFO:compare_models() successfully completed......................................
2025-03-15 22:56:58,804:INFO:Initializing save_model()
2025-03-15 22:56:58,804:INFO:save_model(model=Ridge(random_state=7298), model_name=best_regressor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                                                                         'mapping': female    0
male      1
NaN      -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan')))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-15 22:56:58,804:INFO:Adding model into prep_pipe
2025-03-15 22:56:58,814:INFO:best_regressor.pkl saved in current working directory
2025-03-15 22:56:58,845:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('ordinal_encoding',
                 Transf...
                ('onehot_encoding',
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model', Ridge(random_state=7298))])
2025-03-15 22:56:58,845:INFO:save_model() successfully completed......................................
2025-03-15 22:57:07,187:INFO:PyCaret ClassificationExperiment
2025-03-15 22:57:07,187:INFO:Logging name: clf-default-name
2025-03-15 22:57:07,187:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-15 22:57:07,187:INFO:version 3.3.2
2025-03-15 22:57:07,187:INFO:Initializing setup()
2025-03-15 22:57:07,188:INFO:self.USI: 4a46
2025-03-15 22:57:07,188:INFO:self._variable_keys: {'target_param', 'y', 'USI', 'y_test', 'gpu_param', 'X_train', 'X_test', 'n_jobs_param', 'pipeline', 'X', '_available_plots', 'fix_imbalance', 'log_plots_param', 'is_multiclass', 'exp_name_log', 'gpu_n_jobs_param', 'data', 'html_param', 'y_train', 'logging_param', 'fold_generator', 'fold_groups_param', 'exp_id', 'seed', 'fold_shuffle_param', '_ml_usecase', 'idx', 'memory'}
2025-03-15 22:57:07,188:INFO:Checking environment
2025-03-15 22:57:07,188:INFO:python_version: 3.10.0
2025-03-15 22:57:07,188:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-15 22:57:07,188:INFO:machine: AMD64
2025-03-15 22:57:07,188:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-15 22:57:07,193:INFO:Memory: svmem(total=17037209600, available=4604833792, percent=73.0, used=12432375808, free=4604833792)
2025-03-15 22:57:07,193:INFO:Physical Core: 6
2025-03-15 22:57:07,193:INFO:Logical Core: 12
2025-03-15 22:57:07,193:INFO:Checking libraries
2025-03-15 22:57:07,193:INFO:System:
2025-03-15 22:57:07,193:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-15 22:57:07,193:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-15 22:57:07,193:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-15 22:57:07,194:INFO:PyCaret required dependencies:
2025-03-15 22:57:07,194:INFO:                 pip: 21.2.3
2025-03-15 22:57:07,194:INFO:          setuptools: 57.4.0
2025-03-15 22:57:07,194:INFO:             pycaret: 3.3.2
2025-03-15 22:57:07,194:INFO:             IPython: 8.29.0
2025-03-15 22:57:07,194:INFO:          ipywidgets: 8.1.5
2025-03-15 22:57:07,194:INFO:                tqdm: 4.67.0
2025-03-15 22:57:07,194:INFO:               numpy: 1.26.4
2025-03-15 22:57:07,194:INFO:              pandas: 2.1.4
2025-03-15 22:57:07,194:INFO:              jinja2: 3.1.4
2025-03-15 22:57:07,194:INFO:               scipy: 1.11.4
2025-03-15 22:57:07,194:INFO:              joblib: 1.3.2
2025-03-15 22:57:07,194:INFO:             sklearn: 1.4.2
2025-03-15 22:57:07,194:INFO:                pyod: 2.0.2
2025-03-15 22:57:07,194:INFO:            imblearn: 0.12.4
2025-03-15 22:57:07,194:INFO:   category_encoders: 2.6.4
2025-03-15 22:57:07,194:INFO:            lightgbm: 4.5.0
2025-03-15 22:57:07,194:INFO:               numba: 0.60.0
2025-03-15 22:57:07,194:INFO:            requests: 2.32.3
2025-03-15 22:57:07,194:INFO:          matplotlib: 3.7.5
2025-03-15 22:57:07,194:INFO:          scikitplot: 0.3.7
2025-03-15 22:57:07,194:INFO:         yellowbrick: 1.5
2025-03-15 22:57:07,194:INFO:              plotly: 5.24.1
2025-03-15 22:57:07,194:INFO:    plotly-resampler: Not installed
2025-03-15 22:57:07,194:INFO:             kaleido: 0.2.1
2025-03-15 22:57:07,195:INFO:           schemdraw: 0.15
2025-03-15 22:57:07,195:INFO:         statsmodels: 0.14.4
2025-03-15 22:57:07,195:INFO:              sktime: 0.26.0
2025-03-15 22:57:07,195:INFO:               tbats: 1.1.3
2025-03-15 22:57:07,195:INFO:            pmdarima: 2.0.4
2025-03-15 22:57:07,195:INFO:              psutil: 6.1.0
2025-03-15 22:57:07,195:INFO:          markupsafe: 3.0.2
2025-03-15 22:57:07,195:INFO:             pickle5: Not installed
2025-03-15 22:57:07,195:INFO:         cloudpickle: 3.1.0
2025-03-15 22:57:07,195:INFO:         deprecation: 2.1.0
2025-03-15 22:57:07,195:INFO:              xxhash: 3.5.0
2025-03-15 22:57:07,195:INFO:           wurlitzer: Not installed
2025-03-15 22:57:07,195:INFO:PyCaret optional dependencies:
2025-03-15 22:57:07,195:INFO:                shap: Not installed
2025-03-15 22:57:07,195:INFO:           interpret: Not installed
2025-03-15 22:57:07,195:INFO:                umap: Not installed
2025-03-15 22:57:07,195:INFO:     ydata_profiling: 4.12.0
2025-03-15 22:57:07,195:INFO:  explainerdashboard: Not installed
2025-03-15 22:57:07,195:INFO:             autoviz: Not installed
2025-03-15 22:57:07,195:INFO:           fairlearn: Not installed
2025-03-15 22:57:07,196:INFO:          deepchecks: Not installed
2025-03-15 22:57:07,196:INFO:             xgboost: Not installed
2025-03-15 22:57:07,196:INFO:            catboost: Not installed
2025-03-15 22:57:07,196:INFO:              kmodes: Not installed
2025-03-15 22:57:07,196:INFO:             mlxtend: Not installed
2025-03-15 22:57:07,196:INFO:       statsforecast: Not installed
2025-03-15 22:57:07,196:INFO:        tune_sklearn: Not installed
2025-03-15 22:57:07,196:INFO:                 ray: Not installed
2025-03-15 22:57:07,196:INFO:            hyperopt: Not installed
2025-03-15 22:57:07,196:INFO:              optuna: Not installed
2025-03-15 22:57:07,196:INFO:               skopt: Not installed
2025-03-15 22:57:07,196:INFO:              mlflow: Not installed
2025-03-15 22:57:07,196:INFO:              gradio: Not installed
2025-03-15 22:57:07,196:INFO:             fastapi: Not installed
2025-03-15 22:57:07,196:INFO:             uvicorn: Not installed
2025-03-15 22:57:07,196:INFO:              m2cgen: Not installed
2025-03-15 22:57:07,196:INFO:           evidently: Not installed
2025-03-15 22:57:07,196:INFO:               fugue: Not installed
2025-03-15 22:57:07,196:INFO:           streamlit: 1.40.0
2025-03-15 22:57:07,196:INFO:             prophet: Not installed
2025-03-15 22:57:07,196:INFO:None
2025-03-15 22:57:07,196:INFO:Set up data.
2025-03-15 22:57:07,205:INFO:Set up folding strategy.
2025-03-15 22:57:07,205:INFO:Set up train/test split.
2025-03-15 22:57:07,213:INFO:Set up index.
2025-03-15 22:57:07,213:INFO:Assigning column types.
2025-03-15 22:57:07,218:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-15 22:57:07,264:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:57:07,268:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 22:57:07,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,341:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 22:57:07,342:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 22:57:07,368:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,368:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,369:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-15 22:57:07,412:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 22:57:07,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,480:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 22:57:07,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,508:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-15 22:57:07,577:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,647:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:07,649:INFO:Preparing preprocessing pipeline...
2025-03-15 22:57:07,650:INFO:Set up simple imputation.
2025-03-15 22:57:07,652:INFO:Set up encoding of ordinal features.
2025-03-15 22:57:07,654:INFO:Set up encoding of categorical features.
2025-03-15 22:57:07,775:INFO:Finished creating preprocessing pipeline.
2025-03-15 22:57:07,797:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-03-15 22:57:07,797:INFO:Creating final display dataframe.
2025-03-15 22:57:08,181:INFO:Setup _display_container:                     Description             Value
0                    Session id              6529
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              4a46
2025-03-15 22:57:08,257:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:08,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:08,327:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:08,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 22:57:08,329:INFO:setup() successfully completed in 1.14s...............
2025-03-15 22:57:08,334:INFO:Initializing compare_models()
2025-03-15 22:57:08,335:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-15 22:57:08,335:INFO:Checking exceptions
2025-03-15 22:57:08,361:INFO:Preparing display monitor
2025-03-15 22:57:08,364:INFO:Initializing Logistic Regression
2025-03-15 22:57:08,365:INFO:Total runtime is 1.6601880391438804e-05 minutes
2025-03-15 22:57:08,365:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:08,365:INFO:Initializing create_model()
2025-03-15 22:57:08,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:08,365:INFO:Checking exceptions
2025-03-15 22:57:08,365:INFO:Importing libraries
2025-03-15 22:57:08,365:INFO:Copying training dataset
2025-03-15 22:57:08,371:INFO:Defining folds
2025-03-15 22:57:08,371:INFO:Declaring metric variables
2025-03-15 22:57:08,372:INFO:Importing untrained model
2025-03-15 22:57:08,373:INFO:Logistic Regression Imported successfully
2025-03-15 22:57:08,373:INFO:Starting cross validation
2025-03-15 22:57:08,375:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:08,766:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,766:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,766:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,766:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,768:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,769:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,772:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,772:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,787:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,792:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:08,865:INFO:Calculating mean and std
2025-03-15 22:57:08,866:INFO:Creating metrics dataframe
2025-03-15 22:57:08,868:INFO:Uploading results into container
2025-03-15 22:57:08,868:INFO:Uploading model into container now
2025-03-15 22:57:08,868:INFO:_master_model_container: 1
2025-03-15 22:57:08,868:INFO:_display_container: 2
2025-03-15 22:57:08,869:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6529, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 22:57:08,869:INFO:create_model() successfully completed......................................
2025-03-15 22:57:08,967:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:08,967:INFO:Creating metrics dataframe
2025-03-15 22:57:08,969:INFO:Initializing K Neighbors Classifier
2025-03-15 22:57:08,969:INFO:Total runtime is 0.010088634490966796 minutes
2025-03-15 22:57:08,969:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:08,969:INFO:Initializing create_model()
2025-03-15 22:57:08,969:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:08,969:INFO:Checking exceptions
2025-03-15 22:57:08,969:INFO:Importing libraries
2025-03-15 22:57:08,969:INFO:Copying training dataset
2025-03-15 22:57:08,973:INFO:Defining folds
2025-03-15 22:57:08,973:INFO:Declaring metric variables
2025-03-15 22:57:08,974:INFO:Importing untrained model
2025-03-15 22:57:08,974:INFO:K Neighbors Classifier Imported successfully
2025-03-15 22:57:08,974:INFO:Starting cross validation
2025-03-15 22:57:08,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:09,283:INFO:Calculating mean and std
2025-03-15 22:57:09,284:INFO:Creating metrics dataframe
2025-03-15 22:57:09,285:INFO:Uploading results into container
2025-03-15 22:57:09,285:INFO:Uploading model into container now
2025-03-15 22:57:09,286:INFO:_master_model_container: 2
2025-03-15 22:57:09,286:INFO:_display_container: 2
2025-03-15 22:57:09,286:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-15 22:57:09,286:INFO:create_model() successfully completed......................................
2025-03-15 22:57:09,379:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:09,379:INFO:Creating metrics dataframe
2025-03-15 22:57:09,382:INFO:Initializing Naive Bayes
2025-03-15 22:57:09,382:INFO:Total runtime is 0.016971385478973387 minutes
2025-03-15 22:57:09,382:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:09,382:INFO:Initializing create_model()
2025-03-15 22:57:09,382:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:09,382:INFO:Checking exceptions
2025-03-15 22:57:09,382:INFO:Importing libraries
2025-03-15 22:57:09,382:INFO:Copying training dataset
2025-03-15 22:57:09,387:INFO:Defining folds
2025-03-15 22:57:09,387:INFO:Declaring metric variables
2025-03-15 22:57:09,387:INFO:Importing untrained model
2025-03-15 22:57:09,387:INFO:Naive Bayes Imported successfully
2025-03-15 22:57:09,387:INFO:Starting cross validation
2025-03-15 22:57:09,388:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:09,657:INFO:Calculating mean and std
2025-03-15 22:57:09,657:INFO:Creating metrics dataframe
2025-03-15 22:57:09,659:INFO:Uploading results into container
2025-03-15 22:57:09,659:INFO:Uploading model into container now
2025-03-15 22:57:09,660:INFO:_master_model_container: 3
2025-03-15 22:57:09,660:INFO:_display_container: 2
2025-03-15 22:57:09,660:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-15 22:57:09,660:INFO:create_model() successfully completed......................................
2025-03-15 22:57:09,757:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:09,757:INFO:Creating metrics dataframe
2025-03-15 22:57:09,760:INFO:Initializing Decision Tree Classifier
2025-03-15 22:57:09,760:INFO:Total runtime is 0.02325894037882487 minutes
2025-03-15 22:57:09,761:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:09,761:INFO:Initializing create_model()
2025-03-15 22:57:09,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:09,761:INFO:Checking exceptions
2025-03-15 22:57:09,761:INFO:Importing libraries
2025-03-15 22:57:09,761:INFO:Copying training dataset
2025-03-15 22:57:09,765:INFO:Defining folds
2025-03-15 22:57:09,765:INFO:Declaring metric variables
2025-03-15 22:57:09,765:INFO:Importing untrained model
2025-03-15 22:57:09,766:INFO:Decision Tree Classifier Imported successfully
2025-03-15 22:57:09,766:INFO:Starting cross validation
2025-03-15 22:57:09,767:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:10,004:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:10,004:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:10,004:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:10,004:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:10,004:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:10,005:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:10,008:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:10,008:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:10,022:INFO:Calculating mean and std
2025-03-15 22:57:10,023:INFO:Creating metrics dataframe
2025-03-15 22:57:10,024:INFO:Uploading results into container
2025-03-15 22:57:10,025:INFO:Uploading model into container now
2025-03-15 22:57:10,025:INFO:_master_model_container: 4
2025-03-15 22:57:10,025:INFO:_display_container: 2
2025-03-15 22:57:10,025:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=6529, splitter='best')
2025-03-15 22:57:10,025:INFO:create_model() successfully completed......................................
2025-03-15 22:57:10,124:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:10,124:INFO:Creating metrics dataframe
2025-03-15 22:57:10,127:INFO:Initializing SVM - Linear Kernel
2025-03-15 22:57:10,127:INFO:Total runtime is 0.029390184084574382 minutes
2025-03-15 22:57:10,127:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:10,127:INFO:Initializing create_model()
2025-03-15 22:57:10,127:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:10,127:INFO:Checking exceptions
2025-03-15 22:57:10,127:INFO:Importing libraries
2025-03-15 22:57:10,128:INFO:Copying training dataset
2025-03-15 22:57:10,132:INFO:Defining folds
2025-03-15 22:57:10,132:INFO:Declaring metric variables
2025-03-15 22:57:10,132:INFO:Importing untrained model
2025-03-15 22:57:10,133:INFO:SVM - Linear Kernel Imported successfully
2025-03-15 22:57:10,133:INFO:Starting cross validation
2025-03-15 22:57:10,134:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:10,391:INFO:Calculating mean and std
2025-03-15 22:57:10,392:INFO:Creating metrics dataframe
2025-03-15 22:57:10,394:INFO:Uploading results into container
2025-03-15 22:57:10,394:INFO:Uploading model into container now
2025-03-15 22:57:10,395:INFO:_master_model_container: 5
2025-03-15 22:57:10,395:INFO:_display_container: 2
2025-03-15 22:57:10,395:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=6529, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-15 22:57:10,395:INFO:create_model() successfully completed......................................
2025-03-15 22:57:10,501:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:10,501:INFO:Creating metrics dataframe
2025-03-15 22:57:10,503:INFO:Initializing Ridge Classifier
2025-03-15 22:57:10,503:INFO:Total runtime is 0.03564771016438802 minutes
2025-03-15 22:57:10,503:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:10,504:INFO:Initializing create_model()
2025-03-15 22:57:10,504:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:10,504:INFO:Checking exceptions
2025-03-15 22:57:10,504:INFO:Importing libraries
2025-03-15 22:57:10,504:INFO:Copying training dataset
2025-03-15 22:57:10,508:INFO:Defining folds
2025-03-15 22:57:10,508:INFO:Declaring metric variables
2025-03-15 22:57:10,508:INFO:Importing untrained model
2025-03-15 22:57:10,508:INFO:Ridge Classifier Imported successfully
2025-03-15 22:57:10,509:INFO:Starting cross validation
2025-03-15 22:57:10,510:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:10,757:INFO:Calculating mean and std
2025-03-15 22:57:10,757:INFO:Creating metrics dataframe
2025-03-15 22:57:10,759:INFO:Uploading results into container
2025-03-15 22:57:10,759:INFO:Uploading model into container now
2025-03-15 22:57:10,760:INFO:_master_model_container: 6
2025-03-15 22:57:10,760:INFO:_display_container: 2
2025-03-15 22:57:10,760:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=6529, solver='auto',
                tol=0.0001)
2025-03-15 22:57:10,760:INFO:create_model() successfully completed......................................
2025-03-15 22:57:10,857:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:10,857:INFO:Creating metrics dataframe
2025-03-15 22:57:10,860:INFO:Initializing Random Forest Classifier
2025-03-15 22:57:10,860:INFO:Total runtime is 0.041599746545155844 minutes
2025-03-15 22:57:10,860:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:10,860:INFO:Initializing create_model()
2025-03-15 22:57:10,860:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:10,860:INFO:Checking exceptions
2025-03-15 22:57:10,860:INFO:Importing libraries
2025-03-15 22:57:10,860:INFO:Copying training dataset
2025-03-15 22:57:10,864:INFO:Defining folds
2025-03-15 22:57:10,864:INFO:Declaring metric variables
2025-03-15 22:57:10,865:INFO:Importing untrained model
2025-03-15 22:57:10,865:INFO:Random Forest Classifier Imported successfully
2025-03-15 22:57:10,865:INFO:Starting cross validation
2025-03-15 22:57:10,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:11,401:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,403:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,405:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,411:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,416:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,467:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,483:INFO:Calculating mean and std
2025-03-15 22:57:11,484:INFO:Creating metrics dataframe
2025-03-15 22:57:11,486:INFO:Uploading results into container
2025-03-15 22:57:11,486:INFO:Uploading model into container now
2025-03-15 22:57:11,486:INFO:_master_model_container: 7
2025-03-15 22:57:11,486:INFO:_display_container: 2
2025-03-15 22:57:11,487:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=6529, verbose=0,
                       warm_start=False)
2025-03-15 22:57:11,487:INFO:create_model() successfully completed......................................
2025-03-15 22:57:11,586:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:11,587:INFO:Creating metrics dataframe
2025-03-15 22:57:11,589:INFO:Initializing Quadratic Discriminant Analysis
2025-03-15 22:57:11,589:INFO:Total runtime is 0.05374269485473633 minutes
2025-03-15 22:57:11,590:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:11,590:INFO:Initializing create_model()
2025-03-15 22:57:11,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:11,590:INFO:Checking exceptions
2025-03-15 22:57:11,590:INFO:Importing libraries
2025-03-15 22:57:11,590:INFO:Copying training dataset
2025-03-15 22:57:11,594:INFO:Defining folds
2025-03-15 22:57:11,594:INFO:Declaring metric variables
2025-03-15 22:57:11,594:INFO:Importing untrained model
2025-03-15 22:57:11,595:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-15 22:57:11,595:INFO:Starting cross validation
2025-03-15 22:57:11,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:11,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 22:57:11,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 22:57:11,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 22:57:11,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 22:57:11,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 22:57:11,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 22:57:11,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 22:57:11,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 22:57:11,784:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 22:57:11,843:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,843:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,843:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,844:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,845:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,845:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,847:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,848:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:11,867:INFO:Calculating mean and std
2025-03-15 22:57:11,867:INFO:Creating metrics dataframe
2025-03-15 22:57:11,869:INFO:Uploading results into container
2025-03-15 22:57:11,870:INFO:Uploading model into container now
2025-03-15 22:57:11,870:INFO:_master_model_container: 8
2025-03-15 22:57:11,870:INFO:_display_container: 2
2025-03-15 22:57:11,871:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-15 22:57:11,871:INFO:create_model() successfully completed......................................
2025-03-15 22:57:11,970:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:11,970:INFO:Creating metrics dataframe
2025-03-15 22:57:11,972:INFO:Initializing Ada Boost Classifier
2025-03-15 22:57:11,972:INFO:Total runtime is 0.06013962427775065 minutes
2025-03-15 22:57:11,972:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:11,972:INFO:Initializing create_model()
2025-03-15 22:57:11,973:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:11,973:INFO:Checking exceptions
2025-03-15 22:57:11,973:INFO:Importing libraries
2025-03-15 22:57:11,973:INFO:Copying training dataset
2025-03-15 22:57:11,977:INFO:Defining folds
2025-03-15 22:57:11,977:INFO:Declaring metric variables
2025-03-15 22:57:11,977:INFO:Importing untrained model
2025-03-15 22:57:11,978:INFO:Ada Boost Classifier Imported successfully
2025-03-15 22:57:11,978:INFO:Starting cross validation
2025-03-15 22:57:11,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:12,149:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 22:57:12,149:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 22:57:12,149:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 22:57:12,149:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 22:57:12,149:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 22:57:12,149:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 22:57:12,149:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 22:57:12,215:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,217:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,217:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,218:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,218:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,218:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,219:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,219:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,219:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,224:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,237:INFO:Calculating mean and std
2025-03-15 22:57:12,237:INFO:Creating metrics dataframe
2025-03-15 22:57:12,239:INFO:Uploading results into container
2025-03-15 22:57:12,239:INFO:Uploading model into container now
2025-03-15 22:57:12,240:INFO:_master_model_container: 9
2025-03-15 22:57:12,240:INFO:_display_container: 2
2025-03-15 22:57:12,240:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=6529)
2025-03-15 22:57:12,240:INFO:create_model() successfully completed......................................
2025-03-15 22:57:12,335:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:12,335:INFO:Creating metrics dataframe
2025-03-15 22:57:12,340:INFO:Initializing Gradient Boosting Classifier
2025-03-15 22:57:12,340:INFO:Total runtime is 0.06625731786092122 minutes
2025-03-15 22:57:12,340:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:12,340:INFO:Initializing create_model()
2025-03-15 22:57:12,340:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:12,340:INFO:Checking exceptions
2025-03-15 22:57:12,340:INFO:Importing libraries
2025-03-15 22:57:12,340:INFO:Copying training dataset
2025-03-15 22:57:12,345:INFO:Defining folds
2025-03-15 22:57:12,345:INFO:Declaring metric variables
2025-03-15 22:57:12,345:INFO:Importing untrained model
2025-03-15 22:57:12,345:INFO:Gradient Boosting Classifier Imported successfully
2025-03-15 22:57:12,345:INFO:Starting cross validation
2025-03-15 22:57:12,346:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:12,702:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,704:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,710:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,712:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,716:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,718:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,723:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,724:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,728:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,737:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:12,744:INFO:Calculating mean and std
2025-03-15 22:57:12,745:INFO:Creating metrics dataframe
2025-03-15 22:57:12,746:INFO:Uploading results into container
2025-03-15 22:57:12,746:INFO:Uploading model into container now
2025-03-15 22:57:12,746:INFO:_master_model_container: 10
2025-03-15 22:57:12,746:INFO:_display_container: 2
2025-03-15 22:57:12,748:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=6529, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-15 22:57:12,748:INFO:create_model() successfully completed......................................
2025-03-15 22:57:12,844:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:12,844:INFO:Creating metrics dataframe
2025-03-15 22:57:12,847:INFO:Initializing Linear Discriminant Analysis
2025-03-15 22:57:12,847:INFO:Total runtime is 0.07471974690755208 minutes
2025-03-15 22:57:12,847:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:12,847:INFO:Initializing create_model()
2025-03-15 22:57:12,847:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:12,847:INFO:Checking exceptions
2025-03-15 22:57:12,847:INFO:Importing libraries
2025-03-15 22:57:12,847:INFO:Copying training dataset
2025-03-15 22:57:12,852:INFO:Defining folds
2025-03-15 22:57:12,852:INFO:Declaring metric variables
2025-03-15 22:57:12,852:INFO:Importing untrained model
2025-03-15 22:57:12,852:INFO:Linear Discriminant Analysis Imported successfully
2025-03-15 22:57:12,853:INFO:Starting cross validation
2025-03-15 22:57:12,854:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:13,080:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:13,081:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:13,083:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:13,083:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:13,084:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:13,088:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:13,089:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:13,089:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:13,092:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:13,105:INFO:Calculating mean and std
2025-03-15 22:57:13,106:INFO:Creating metrics dataframe
2025-03-15 22:57:13,107:INFO:Uploading results into container
2025-03-15 22:57:13,108:INFO:Uploading model into container now
2025-03-15 22:57:13,108:INFO:_master_model_container: 11
2025-03-15 22:57:13,108:INFO:_display_container: 2
2025-03-15 22:57:13,108:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-15 22:57:13,108:INFO:create_model() successfully completed......................................
2025-03-15 22:57:13,203:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:13,203:INFO:Creating metrics dataframe
2025-03-15 22:57:13,206:INFO:Initializing Extra Trees Classifier
2025-03-15 22:57:13,206:INFO:Total runtime is 0.08070160547892252 minutes
2025-03-15 22:57:13,206:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:13,206:INFO:Initializing create_model()
2025-03-15 22:57:13,206:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:13,206:INFO:Checking exceptions
2025-03-15 22:57:13,206:INFO:Importing libraries
2025-03-15 22:57:13,206:INFO:Copying training dataset
2025-03-15 22:57:13,211:INFO:Defining folds
2025-03-15 22:57:13,211:INFO:Declaring metric variables
2025-03-15 22:57:13,211:INFO:Importing untrained model
2025-03-15 22:57:13,212:INFO:Extra Trees Classifier Imported successfully
2025-03-15 22:57:13,212:INFO:Starting cross validation
2025-03-15 22:57:13,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:13,760:INFO:Calculating mean and std
2025-03-15 22:57:13,761:INFO:Creating metrics dataframe
2025-03-15 22:57:13,762:INFO:Uploading results into container
2025-03-15 22:57:13,763:INFO:Uploading model into container now
2025-03-15 22:57:13,763:INFO:_master_model_container: 12
2025-03-15 22:57:13,763:INFO:_display_container: 2
2025-03-15 22:57:13,763:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=6529, verbose=0,
                     warm_start=False)
2025-03-15 22:57:13,763:INFO:create_model() successfully completed......................................
2025-03-15 22:57:13,874:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:13,875:INFO:Creating metrics dataframe
2025-03-15 22:57:13,878:INFO:Initializing Light Gradient Boosting Machine
2025-03-15 22:57:13,878:INFO:Total runtime is 0.09189758698145548 minutes
2025-03-15 22:57:13,878:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:13,878:INFO:Initializing create_model()
2025-03-15 22:57:13,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:13,878:INFO:Checking exceptions
2025-03-15 22:57:13,878:INFO:Importing libraries
2025-03-15 22:57:13,878:INFO:Copying training dataset
2025-03-15 22:57:13,882:INFO:Defining folds
2025-03-15 22:57:13,882:INFO:Declaring metric variables
2025-03-15 22:57:13,882:INFO:Importing untrained model
2025-03-15 22:57:13,883:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 22:57:13,883:INFO:Starting cross validation
2025-03-15 22:57:13,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:14,615:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,625:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,625:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,650:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,657:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,752:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,766:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,783:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,799:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,846:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:14,864:INFO:Calculating mean and std
2025-03-15 22:57:14,865:INFO:Creating metrics dataframe
2025-03-15 22:57:14,867:INFO:Uploading results into container
2025-03-15 22:57:14,868:INFO:Uploading model into container now
2025-03-15 22:57:14,868:INFO:_master_model_container: 13
2025-03-15 22:57:14,868:INFO:_display_container: 2
2025-03-15 22:57:14,869:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=6529, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-15 22:57:14,869:INFO:create_model() successfully completed......................................
2025-03-15 22:57:14,979:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:14,979:INFO:Creating metrics dataframe
2025-03-15 22:57:14,981:INFO:Initializing Dummy Classifier
2025-03-15 22:57:14,981:INFO:Total runtime is 0.11028692722320556 minutes
2025-03-15 22:57:14,982:INFO:SubProcess create_model() called ==================================
2025-03-15 22:57:14,982:INFO:Initializing create_model()
2025-03-15 22:57:14,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002286BB458A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:14,982:INFO:Checking exceptions
2025-03-15 22:57:14,982:INFO:Importing libraries
2025-03-15 22:57:14,982:INFO:Copying training dataset
2025-03-15 22:57:14,987:INFO:Defining folds
2025-03-15 22:57:14,987:INFO:Declaring metric variables
2025-03-15 22:57:14,987:INFO:Importing untrained model
2025-03-15 22:57:14,987:INFO:Dummy Classifier Imported successfully
2025-03-15 22:57:14,987:INFO:Starting cross validation
2025-03-15 22:57:14,988:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 22:57:15,203:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:15,203:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:15,208:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:15,211:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:15,212:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:15,212:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:15,217:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:15,222:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:15,223:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 22:57:15,235:INFO:Calculating mean and std
2025-03-15 22:57:15,235:INFO:Creating metrics dataframe
2025-03-15 22:57:15,237:INFO:Uploading results into container
2025-03-15 22:57:15,238:INFO:Uploading model into container now
2025-03-15 22:57:15,238:INFO:_master_model_container: 14
2025-03-15 22:57:15,238:INFO:_display_container: 2
2025-03-15 22:57:15,238:INFO:DummyClassifier(constant=None, random_state=6529, strategy='prior')
2025-03-15 22:57:15,238:INFO:create_model() successfully completed......................................
2025-03-15 22:57:15,334:INFO:SubProcess create_model() end ==================================
2025-03-15 22:57:15,334:INFO:Creating metrics dataframe
2025-03-15 22:57:15,337:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-15 22:57:15,339:INFO:Initializing create_model()
2025-03-15 22:57:15,339:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6529, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 22:57:15,339:INFO:Checking exceptions
2025-03-15 22:57:15,339:INFO:Importing libraries
2025-03-15 22:57:15,340:INFO:Copying training dataset
2025-03-15 22:57:15,343:INFO:Defining folds
2025-03-15 22:57:15,343:INFO:Declaring metric variables
2025-03-15 22:57:15,343:INFO:Importing untrained model
2025-03-15 22:57:15,343:INFO:Declaring custom model
2025-03-15 22:57:15,344:INFO:Logistic Regression Imported successfully
2025-03-15 22:57:15,345:INFO:Cross validation set to False
2025-03-15 22:57:15,345:INFO:Fitting Model
2025-03-15 22:57:15,523:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 22:57:15,524:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6529, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 22:57:15,524:INFO:create_model() successfully completed......................................
2025-03-15 22:57:15,637:INFO:_master_model_container: 14
2025-03-15 22:57:15,637:INFO:_display_container: 2
2025-03-15 22:57:15,637:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6529, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 22:57:15,637:INFO:compare_models() successfully completed......................................
2025-03-15 22:57:15,662:INFO:Initializing save_model()
2025-03-15 22:57:15,662:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=6529, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-15 22:57:15,662:INFO:Adding model into prep_pipe
2025-03-15 22:57:15,673:INFO:best_classifier.pkl saved in current working directory
2025-03-15 22:57:15,694:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=6529,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-15 22:57:15,695:INFO:save_model() successfully completed......................................
2025-03-15 22:57:32,049:INFO:Initializing load_model()
2025-03-15 22:57:32,049:INFO:load_model(model_name=best_classifier, platform=None, authentication=None, verbose=True)
2025-03-15 22:57:32,095:INFO:Initializing predict_model()
2025-03-15 22:57:32,097:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002286B6E09A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=6529))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002286B5537F0>)
2025-03-15 22:57:32,097:INFO:Checking exceptions
2025-03-15 22:57:32,097:INFO:Preloading libraries
2025-03-15 22:57:32,097:INFO:Set up data.
2025-03-15 22:57:32,102:INFO:Set up index.
2025-03-15 22:59:55,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 22:59:55,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 22:59:55,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 22:59:55,654:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:02:04,029:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:02:04,029:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:02:04,029:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:02:04,029:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:02:30,563:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x0000018AEFA75DC0, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-03-15 23:04:24,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:04:24,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:04:24,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:04:24,028:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:05:32,635:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:05:32,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:05:32,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:05:32,636:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:08:29,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:08:29,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:08:29,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:08:29,055:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:08:56,350:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x00000208003E1B00, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-03-15 23:09:20,856:INFO:PyCaret ClassificationExperiment
2025-03-15 23:09:20,856:INFO:Logging name: clf-default-name
2025-03-15 23:09:20,856:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-15 23:09:20,856:INFO:version 3.3.2
2025-03-15 23:09:20,856:INFO:Initializing setup()
2025-03-15 23:09:20,856:INFO:self.USI: 5bf4
2025-03-15 23:09:20,856:INFO:self._variable_keys: {'fold_generator', 'y_train', 'data', 'is_multiclass', 'fix_imbalance', 'seed', 'html_param', 'target_param', 'memory', 'n_jobs_param', 'exp_id', 'logging_param', 'gpu_param', 'fold_groups_param', 'log_plots_param', 'X', '_ml_usecase', 'fold_shuffle_param', '_available_plots', 'exp_name_log', 'gpu_n_jobs_param', 'USI', 'X_train', 'pipeline', 'X_test', 'y_test', 'idx', 'y'}
2025-03-15 23:09:20,856:INFO:Checking environment
2025-03-15 23:09:20,856:INFO:python_version: 3.10.0
2025-03-15 23:09:20,856:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-15 23:09:20,856:INFO:machine: AMD64
2025-03-15 23:09:20,868:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-15 23:09:20,874:INFO:Memory: svmem(total=17037209600, available=5758533632, percent=66.2, used=11278675968, free=5758533632)
2025-03-15 23:09:20,874:INFO:Physical Core: 6
2025-03-15 23:09:20,874:INFO:Logical Core: 12
2025-03-15 23:09:20,874:INFO:Checking libraries
2025-03-15 23:09:20,874:INFO:System:
2025-03-15 23:09:20,874:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-15 23:09:20,874:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-15 23:09:20,874:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-15 23:09:20,874:INFO:PyCaret required dependencies:
2025-03-15 23:09:20,907:INFO:                 pip: 21.2.3
2025-03-15 23:09:20,907:INFO:          setuptools: 57.4.0
2025-03-15 23:09:20,907:INFO:             pycaret: 3.3.2
2025-03-15 23:09:20,907:INFO:             IPython: 8.29.0
2025-03-15 23:09:20,907:INFO:          ipywidgets: 8.1.5
2025-03-15 23:09:20,907:INFO:                tqdm: 4.67.0
2025-03-15 23:09:20,907:INFO:               numpy: 1.26.4
2025-03-15 23:09:20,907:INFO:              pandas: 2.1.4
2025-03-15 23:09:20,907:INFO:              jinja2: 3.1.4
2025-03-15 23:09:20,907:INFO:               scipy: 1.11.4
2025-03-15 23:09:20,907:INFO:              joblib: 1.3.2
2025-03-15 23:09:20,907:INFO:             sklearn: 1.4.2
2025-03-15 23:09:20,907:INFO:                pyod: 2.0.2
2025-03-15 23:09:20,907:INFO:            imblearn: 0.12.4
2025-03-15 23:09:20,907:INFO:   category_encoders: 2.6.4
2025-03-15 23:09:20,907:INFO:            lightgbm: 4.5.0
2025-03-15 23:09:20,907:INFO:               numba: 0.60.0
2025-03-15 23:09:20,907:INFO:            requests: 2.32.3
2025-03-15 23:09:20,907:INFO:          matplotlib: 3.7.5
2025-03-15 23:09:20,907:INFO:          scikitplot: 0.3.7
2025-03-15 23:09:20,907:INFO:         yellowbrick: 1.5
2025-03-15 23:09:20,907:INFO:              plotly: 5.24.1
2025-03-15 23:09:20,907:INFO:    plotly-resampler: Not installed
2025-03-15 23:09:20,907:INFO:             kaleido: 0.2.1
2025-03-15 23:09:20,907:INFO:           schemdraw: 0.15
2025-03-15 23:09:20,908:INFO:         statsmodels: 0.14.4
2025-03-15 23:09:20,908:INFO:              sktime: 0.26.0
2025-03-15 23:09:20,908:INFO:               tbats: 1.1.3
2025-03-15 23:09:20,908:INFO:            pmdarima: 2.0.4
2025-03-15 23:09:20,908:INFO:              psutil: 6.1.0
2025-03-15 23:09:20,908:INFO:          markupsafe: 3.0.2
2025-03-15 23:09:20,908:INFO:             pickle5: Not installed
2025-03-15 23:09:20,908:INFO:         cloudpickle: 3.1.0
2025-03-15 23:09:20,908:INFO:         deprecation: 2.1.0
2025-03-15 23:09:20,908:INFO:              xxhash: 3.5.0
2025-03-15 23:09:20,908:INFO:           wurlitzer: Not installed
2025-03-15 23:09:20,908:INFO:PyCaret optional dependencies:
2025-03-15 23:09:20,922:INFO:                shap: Not installed
2025-03-15 23:09:20,923:INFO:           interpret: Not installed
2025-03-15 23:09:20,923:INFO:                umap: Not installed
2025-03-15 23:09:20,923:INFO:     ydata_profiling: 4.12.0
2025-03-15 23:09:20,923:INFO:  explainerdashboard: Not installed
2025-03-15 23:09:20,923:INFO:             autoviz: Not installed
2025-03-15 23:09:20,923:INFO:           fairlearn: Not installed
2025-03-15 23:09:20,923:INFO:          deepchecks: Not installed
2025-03-15 23:09:20,923:INFO:             xgboost: Not installed
2025-03-15 23:09:20,923:INFO:            catboost: Not installed
2025-03-15 23:09:20,923:INFO:              kmodes: Not installed
2025-03-15 23:09:20,923:INFO:             mlxtend: Not installed
2025-03-15 23:09:20,923:INFO:       statsforecast: Not installed
2025-03-15 23:09:20,923:INFO:        tune_sklearn: Not installed
2025-03-15 23:09:20,923:INFO:                 ray: Not installed
2025-03-15 23:09:20,923:INFO:            hyperopt: Not installed
2025-03-15 23:09:20,924:INFO:              optuna: Not installed
2025-03-15 23:09:20,924:INFO:               skopt: Not installed
2025-03-15 23:09:20,924:INFO:              mlflow: Not installed
2025-03-15 23:09:20,924:INFO:              gradio: Not installed
2025-03-15 23:09:20,924:INFO:             fastapi: Not installed
2025-03-15 23:09:20,924:INFO:             uvicorn: Not installed
2025-03-15 23:09:20,924:INFO:              m2cgen: Not installed
2025-03-15 23:09:20,924:INFO:           evidently: Not installed
2025-03-15 23:09:20,924:INFO:               fugue: Not installed
2025-03-15 23:09:20,924:INFO:           streamlit: 1.40.0
2025-03-15 23:09:20,924:INFO:             prophet: Not installed
2025-03-15 23:09:20,924:INFO:None
2025-03-15 23:09:20,924:INFO:Set up data.
2025-03-15 23:09:20,932:INFO:Set up folding strategy.
2025-03-15 23:09:20,932:INFO:Set up train/test split.
2025-03-15 23:09:20,938:INFO:Set up index.
2025-03-15 23:09:20,938:INFO:Assigning column types.
2025-03-15 23:09:20,942:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-15 23:09:20,985:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:09:20,988:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:09:21,021:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,065:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:09:21,066:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:09:21,094:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,095:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-15 23:09:21,140:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:09:21,167:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,167:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,209:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:09:21,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,235:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,236:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-15 23:09:21,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,305:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,374:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,374:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:21,379:INFO:Preparing preprocessing pipeline...
2025-03-15 23:09:21,380:INFO:Set up simple imputation.
2025-03-15 23:09:21,383:INFO:Set up encoding of ordinal features.
2025-03-15 23:09:21,384:INFO:Set up encoding of categorical features.
2025-03-15 23:09:21,531:INFO:Finished creating preprocessing pipeline.
2025-03-15 23:09:21,554:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-03-15 23:09:21,554:INFO:Creating final display dataframe.
2025-03-15 23:09:21,959:INFO:Setup _display_container:                     Description             Value
0                    Session id              1880
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              5bf4
2025-03-15 23:09:22,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:22,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:22,118:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:22,118:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:09:22,119:INFO:setup() successfully completed in 1.27s...............
2025-03-15 23:09:22,122:INFO:Initializing compare_models()
2025-03-15 23:09:22,123:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-15 23:09:22,123:INFO:Checking exceptions
2025-03-15 23:09:22,126:INFO:Preparing display monitor
2025-03-15 23:09:22,131:INFO:Initializing Logistic Regression
2025-03-15 23:09:22,131:INFO:Total runtime is 0.0 minutes
2025-03-15 23:09:22,131:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:22,131:INFO:Initializing create_model()
2025-03-15 23:09:22,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:22,132:INFO:Checking exceptions
2025-03-15 23:09:22,132:INFO:Importing libraries
2025-03-15 23:09:22,132:INFO:Copying training dataset
2025-03-15 23:09:22,137:INFO:Defining folds
2025-03-15 23:09:22,137:INFO:Declaring metric variables
2025-03-15 23:09:22,137:INFO:Importing untrained model
2025-03-15 23:09:22,137:INFO:Logistic Regression Imported successfully
2025-03-15 23:09:22,137:INFO:Starting cross validation
2025-03-15 23:09:22,139:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:27,468:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,474:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,495:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,509:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,554:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,591:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,601:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,642:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,655:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:27,750:INFO:Calculating mean and std
2025-03-15 23:09:27,751:INFO:Creating metrics dataframe
2025-03-15 23:09:27,755:INFO:Uploading results into container
2025-03-15 23:09:27,756:INFO:Uploading model into container now
2025-03-15 23:09:27,756:INFO:_master_model_container: 1
2025-03-15 23:09:27,756:INFO:_display_container: 2
2025-03-15 23:09:27,758:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1880, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:09:27,758:INFO:create_model() successfully completed......................................
2025-03-15 23:09:27,890:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:27,890:INFO:Creating metrics dataframe
2025-03-15 23:09:27,893:INFO:Initializing K Neighbors Classifier
2025-03-15 23:09:27,893:INFO:Total runtime is 0.09604040384292603 minutes
2025-03-15 23:09:27,894:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:27,894:INFO:Initializing create_model()
2025-03-15 23:09:27,894:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:27,894:INFO:Checking exceptions
2025-03-15 23:09:27,894:INFO:Importing libraries
2025-03-15 23:09:27,894:INFO:Copying training dataset
2025-03-15 23:09:27,898:INFO:Defining folds
2025-03-15 23:09:27,898:INFO:Declaring metric variables
2025-03-15 23:09:27,898:INFO:Importing untrained model
2025-03-15 23:09:27,898:INFO:K Neighbors Classifier Imported successfully
2025-03-15 23:09:27,899:INFO:Starting cross validation
2025-03-15 23:09:27,900:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:30,315:INFO:Calculating mean and std
2025-03-15 23:09:30,316:INFO:Creating metrics dataframe
2025-03-15 23:09:30,319:INFO:Uploading results into container
2025-03-15 23:09:30,319:INFO:Uploading model into container now
2025-03-15 23:09:30,320:INFO:_master_model_container: 2
2025-03-15 23:09:30,320:INFO:_display_container: 2
2025-03-15 23:09:30,320:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-15 23:09:30,320:INFO:create_model() successfully completed......................................
2025-03-15 23:09:30,428:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:30,428:INFO:Creating metrics dataframe
2025-03-15 23:09:30,430:INFO:Initializing Naive Bayes
2025-03-15 23:09:30,430:INFO:Total runtime is 0.1383171280225118 minutes
2025-03-15 23:09:30,430:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:30,431:INFO:Initializing create_model()
2025-03-15 23:09:30,431:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:30,431:INFO:Checking exceptions
2025-03-15 23:09:30,431:INFO:Importing libraries
2025-03-15 23:09:30,431:INFO:Copying training dataset
2025-03-15 23:09:30,435:INFO:Defining folds
2025-03-15 23:09:30,435:INFO:Declaring metric variables
2025-03-15 23:09:30,436:INFO:Importing untrained model
2025-03-15 23:09:30,436:INFO:Naive Bayes Imported successfully
2025-03-15 23:09:30,436:INFO:Starting cross validation
2025-03-15 23:09:30,437:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:30,693:INFO:Calculating mean and std
2025-03-15 23:09:30,694:INFO:Creating metrics dataframe
2025-03-15 23:09:30,695:INFO:Uploading results into container
2025-03-15 23:09:30,696:INFO:Uploading model into container now
2025-03-15 23:09:30,696:INFO:_master_model_container: 3
2025-03-15 23:09:30,696:INFO:_display_container: 2
2025-03-15 23:09:30,696:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-15 23:09:30,696:INFO:create_model() successfully completed......................................
2025-03-15 23:09:30,790:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:30,791:INFO:Creating metrics dataframe
2025-03-15 23:09:30,793:INFO:Initializing Decision Tree Classifier
2025-03-15 23:09:30,793:INFO:Total runtime is 0.14436970551808676 minutes
2025-03-15 23:09:30,793:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:30,793:INFO:Initializing create_model()
2025-03-15 23:09:30,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:30,793:INFO:Checking exceptions
2025-03-15 23:09:30,793:INFO:Importing libraries
2025-03-15 23:09:30,793:INFO:Copying training dataset
2025-03-15 23:09:30,797:INFO:Defining folds
2025-03-15 23:09:30,798:INFO:Declaring metric variables
2025-03-15 23:09:30,798:INFO:Importing untrained model
2025-03-15 23:09:30,798:INFO:Decision Tree Classifier Imported successfully
2025-03-15 23:09:30,798:INFO:Starting cross validation
2025-03-15 23:09:30,799:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:31,030:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,031:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,034:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,034:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,035:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,043:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,046:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,046:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,051:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,052:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,062:INFO:Calculating mean and std
2025-03-15 23:09:31,063:INFO:Creating metrics dataframe
2025-03-15 23:09:31,064:INFO:Uploading results into container
2025-03-15 23:09:31,065:INFO:Uploading model into container now
2025-03-15 23:09:31,065:INFO:_master_model_container: 4
2025-03-15 23:09:31,065:INFO:_display_container: 2
2025-03-15 23:09:31,066:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1880, splitter='best')
2025-03-15 23:09:31,066:INFO:create_model() successfully completed......................................
2025-03-15 23:09:31,161:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:31,161:INFO:Creating metrics dataframe
2025-03-15 23:09:31,163:INFO:Initializing SVM - Linear Kernel
2025-03-15 23:09:31,164:INFO:Total runtime is 0.15055219332377115 minutes
2025-03-15 23:09:31,164:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:31,164:INFO:Initializing create_model()
2025-03-15 23:09:31,164:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:31,164:INFO:Checking exceptions
2025-03-15 23:09:31,164:INFO:Importing libraries
2025-03-15 23:09:31,164:INFO:Copying training dataset
2025-03-15 23:09:31,168:INFO:Defining folds
2025-03-15 23:09:31,168:INFO:Declaring metric variables
2025-03-15 23:09:31,168:INFO:Importing untrained model
2025-03-15 23:09:31,168:INFO:SVM - Linear Kernel Imported successfully
2025-03-15 23:09:31,169:INFO:Starting cross validation
2025-03-15 23:09:31,170:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:31,404:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,416:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:31,439:INFO:Calculating mean and std
2025-03-15 23:09:31,440:INFO:Creating metrics dataframe
2025-03-15 23:09:31,442:INFO:Uploading results into container
2025-03-15 23:09:31,442:INFO:Uploading model into container now
2025-03-15 23:09:31,442:INFO:_master_model_container: 5
2025-03-15 23:09:31,442:INFO:_display_container: 2
2025-03-15 23:09:31,443:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1880, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-15 23:09:31,443:INFO:create_model() successfully completed......................................
2025-03-15 23:09:31,549:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:31,549:INFO:Creating metrics dataframe
2025-03-15 23:09:31,552:INFO:Initializing Ridge Classifier
2025-03-15 23:09:31,552:INFO:Total runtime is 0.157021963596344 minutes
2025-03-15 23:09:31,552:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:31,552:INFO:Initializing create_model()
2025-03-15 23:09:31,552:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:31,552:INFO:Checking exceptions
2025-03-15 23:09:31,552:INFO:Importing libraries
2025-03-15 23:09:31,552:INFO:Copying training dataset
2025-03-15 23:09:31,556:INFO:Defining folds
2025-03-15 23:09:31,556:INFO:Declaring metric variables
2025-03-15 23:09:31,556:INFO:Importing untrained model
2025-03-15 23:09:31,558:INFO:Ridge Classifier Imported successfully
2025-03-15 23:09:31,558:INFO:Starting cross validation
2025-03-15 23:09:31,560:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:31,851:INFO:Calculating mean and std
2025-03-15 23:09:31,852:INFO:Creating metrics dataframe
2025-03-15 23:09:31,854:INFO:Uploading results into container
2025-03-15 23:09:31,854:INFO:Uploading model into container now
2025-03-15 23:09:31,855:INFO:_master_model_container: 6
2025-03-15 23:09:31,855:INFO:_display_container: 2
2025-03-15 23:09:31,855:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1880, solver='auto',
                tol=0.0001)
2025-03-15 23:09:31,855:INFO:create_model() successfully completed......................................
2025-03-15 23:09:31,951:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:31,951:INFO:Creating metrics dataframe
2025-03-15 23:09:31,954:INFO:Initializing Random Forest Classifier
2025-03-15 23:09:31,954:INFO:Total runtime is 0.16371533075968425 minutes
2025-03-15 23:09:31,954:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:31,955:INFO:Initializing create_model()
2025-03-15 23:09:31,955:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:31,955:INFO:Checking exceptions
2025-03-15 23:09:31,955:INFO:Importing libraries
2025-03-15 23:09:31,955:INFO:Copying training dataset
2025-03-15 23:09:31,959:INFO:Defining folds
2025-03-15 23:09:31,959:INFO:Declaring metric variables
2025-03-15 23:09:31,959:INFO:Importing untrained model
2025-03-15 23:09:31,960:INFO:Random Forest Classifier Imported successfully
2025-03-15 23:09:31,960:INFO:Starting cross validation
2025-03-15 23:09:31,961:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:32,508:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,530:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,538:INFO:Calculating mean and std
2025-03-15 23:09:32,538:INFO:Creating metrics dataframe
2025-03-15 23:09:32,540:INFO:Uploading results into container
2025-03-15 23:09:32,540:INFO:Uploading model into container now
2025-03-15 23:09:32,541:INFO:_master_model_container: 7
2025-03-15 23:09:32,541:INFO:_display_container: 2
2025-03-15 23:09:32,542:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1880, verbose=0,
                       warm_start=False)
2025-03-15 23:09:32,542:INFO:create_model() successfully completed......................................
2025-03-15 23:09:32,640:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:32,641:INFO:Creating metrics dataframe
2025-03-15 23:09:32,643:INFO:Initializing Quadratic Discriminant Analysis
2025-03-15 23:09:32,643:INFO:Total runtime is 0.17520726521809896 minutes
2025-03-15 23:09:32,643:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:32,644:INFO:Initializing create_model()
2025-03-15 23:09:32,644:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:32,644:INFO:Checking exceptions
2025-03-15 23:09:32,644:INFO:Importing libraries
2025-03-15 23:09:32,644:INFO:Copying training dataset
2025-03-15 23:09:32,648:INFO:Defining folds
2025-03-15 23:09:32,648:INFO:Declaring metric variables
2025-03-15 23:09:32,648:INFO:Importing untrained model
2025-03-15 23:09:32,649:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-15 23:09:32,649:INFO:Starting cross validation
2025-03-15 23:09:32,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:32,809:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,811:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,815:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,816:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,819:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,826:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,833:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,834:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,838:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,844:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:09:32,880:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,885:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,888:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,889:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,897:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,902:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,906:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,910:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,912:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:32,927:INFO:Calculating mean and std
2025-03-15 23:09:32,928:INFO:Creating metrics dataframe
2025-03-15 23:09:32,930:INFO:Uploading results into container
2025-03-15 23:09:32,930:INFO:Uploading model into container now
2025-03-15 23:09:32,931:INFO:_master_model_container: 8
2025-03-15 23:09:32,931:INFO:_display_container: 2
2025-03-15 23:09:32,931:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-15 23:09:32,931:INFO:create_model() successfully completed......................................
2025-03-15 23:09:33,029:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:33,029:INFO:Creating metrics dataframe
2025-03-15 23:09:33,031:INFO:Initializing Ada Boost Classifier
2025-03-15 23:09:33,031:INFO:Total runtime is 0.1816754698753357 minutes
2025-03-15 23:09:33,032:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:33,032:INFO:Initializing create_model()
2025-03-15 23:09:33,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:33,032:INFO:Checking exceptions
2025-03-15 23:09:33,032:INFO:Importing libraries
2025-03-15 23:09:33,032:INFO:Copying training dataset
2025-03-15 23:09:33,036:INFO:Defining folds
2025-03-15 23:09:33,036:INFO:Declaring metric variables
2025-03-15 23:09:33,036:INFO:Importing untrained model
2025-03-15 23:09:33,036:INFO:Ada Boost Classifier Imported successfully
2025-03-15 23:09:33,036:INFO:Starting cross validation
2025-03-15 23:09:33,039:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:33,192:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,192:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,193:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,196:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,203:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,208:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,209:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,214:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,217:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,220:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:09:33,265:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,267:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,268:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,270:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,276:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,279:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,281:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,283:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,283:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,287:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,293:INFO:Calculating mean and std
2025-03-15 23:09:33,294:INFO:Creating metrics dataframe
2025-03-15 23:09:33,296:INFO:Uploading results into container
2025-03-15 23:09:33,296:INFO:Uploading model into container now
2025-03-15 23:09:33,296:INFO:_master_model_container: 9
2025-03-15 23:09:33,296:INFO:_display_container: 2
2025-03-15 23:09:33,296:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1880)
2025-03-15 23:09:33,296:INFO:create_model() successfully completed......................................
2025-03-15 23:09:33,402:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:33,402:INFO:Creating metrics dataframe
2025-03-15 23:09:33,405:INFO:Initializing Gradient Boosting Classifier
2025-03-15 23:09:33,405:INFO:Total runtime is 0.18790780703226725 minutes
2025-03-15 23:09:33,405:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:33,405:INFO:Initializing create_model()
2025-03-15 23:09:33,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:33,405:INFO:Checking exceptions
2025-03-15 23:09:33,405:INFO:Importing libraries
2025-03-15 23:09:33,405:INFO:Copying training dataset
2025-03-15 23:09:33,411:INFO:Defining folds
2025-03-15 23:09:33,411:INFO:Declaring metric variables
2025-03-15 23:09:33,411:INFO:Importing untrained model
2025-03-15 23:09:33,411:INFO:Gradient Boosting Classifier Imported successfully
2025-03-15 23:09:33,412:INFO:Starting cross validation
2025-03-15 23:09:33,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:33,870:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,876:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,889:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,893:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,894:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,896:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,900:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,901:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,908:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,911:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:33,926:INFO:Calculating mean and std
2025-03-15 23:09:33,927:INFO:Creating metrics dataframe
2025-03-15 23:09:33,928:INFO:Uploading results into container
2025-03-15 23:09:33,929:INFO:Uploading model into container now
2025-03-15 23:09:33,929:INFO:_master_model_container: 10
2025-03-15 23:09:33,929:INFO:_display_container: 2
2025-03-15 23:09:33,930:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1880, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-15 23:09:33,930:INFO:create_model() successfully completed......................................
2025-03-15 23:09:34,024:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:34,024:INFO:Creating metrics dataframe
2025-03-15 23:09:34,026:INFO:Initializing Linear Discriminant Analysis
2025-03-15 23:09:34,028:INFO:Total runtime is 0.19828217824300132 minutes
2025-03-15 23:09:34,028:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:34,028:INFO:Initializing create_model()
2025-03-15 23:09:34,028:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:34,028:INFO:Checking exceptions
2025-03-15 23:09:34,028:INFO:Importing libraries
2025-03-15 23:09:34,028:INFO:Copying training dataset
2025-03-15 23:09:34,032:INFO:Defining folds
2025-03-15 23:09:34,032:INFO:Declaring metric variables
2025-03-15 23:09:34,032:INFO:Importing untrained model
2025-03-15 23:09:34,032:INFO:Linear Discriminant Analysis Imported successfully
2025-03-15 23:09:34,033:INFO:Starting cross validation
2025-03-15 23:09:34,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:34,289:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:34,299:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:34,303:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:34,313:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:34,316:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:34,321:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:34,323:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:34,326:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:34,335:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:34,354:INFO:Calculating mean and std
2025-03-15 23:09:34,354:INFO:Creating metrics dataframe
2025-03-15 23:09:34,357:INFO:Uploading results into container
2025-03-15 23:09:34,358:INFO:Uploading model into container now
2025-03-15 23:09:34,358:INFO:_master_model_container: 11
2025-03-15 23:09:34,358:INFO:_display_container: 2
2025-03-15 23:09:34,358:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-15 23:09:34,358:INFO:create_model() successfully completed......................................
2025-03-15 23:09:34,464:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:34,464:INFO:Creating metrics dataframe
2025-03-15 23:09:34,466:INFO:Initializing Extra Trees Classifier
2025-03-15 23:09:34,467:INFO:Total runtime is 0.20560118357340496 minutes
2025-03-15 23:09:34,467:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:34,467:INFO:Initializing create_model()
2025-03-15 23:09:34,467:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:34,467:INFO:Checking exceptions
2025-03-15 23:09:34,467:INFO:Importing libraries
2025-03-15 23:09:34,467:INFO:Copying training dataset
2025-03-15 23:09:34,471:INFO:Defining folds
2025-03-15 23:09:34,471:INFO:Declaring metric variables
2025-03-15 23:09:34,472:INFO:Importing untrained model
2025-03-15 23:09:34,472:INFO:Extra Trees Classifier Imported successfully
2025-03-15 23:09:34,472:INFO:Starting cross validation
2025-03-15 23:09:34,474:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:35,133:INFO:Calculating mean and std
2025-03-15 23:09:35,134:INFO:Creating metrics dataframe
2025-03-15 23:09:35,136:INFO:Uploading results into container
2025-03-15 23:09:35,136:INFO:Uploading model into container now
2025-03-15 23:09:35,136:INFO:_master_model_container: 12
2025-03-15 23:09:35,136:INFO:_display_container: 2
2025-03-15 23:09:35,136:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1880, verbose=0,
                     warm_start=False)
2025-03-15 23:09:35,136:INFO:create_model() successfully completed......................................
2025-03-15 23:09:35,252:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:35,252:INFO:Creating metrics dataframe
2025-03-15 23:09:35,255:INFO:Initializing Light Gradient Boosting Machine
2025-03-15 23:09:35,255:INFO:Total runtime is 0.21873699426651003 minutes
2025-03-15 23:09:35,256:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:35,256:INFO:Initializing create_model()
2025-03-15 23:09:35,256:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:35,256:INFO:Checking exceptions
2025-03-15 23:09:35,256:INFO:Importing libraries
2025-03-15 23:09:35,256:INFO:Copying training dataset
2025-03-15 23:09:35,261:INFO:Defining folds
2025-03-15 23:09:35,262:INFO:Declaring metric variables
2025-03-15 23:09:35,262:INFO:Importing untrained model
2025-03-15 23:09:35,262:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 23:09:35,262:INFO:Starting cross validation
2025-03-15 23:09:35,264:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:36,310:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,326:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,357:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,396:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,406:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,471:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,493:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,539:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,564:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,591:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,604:INFO:Calculating mean and std
2025-03-15 23:09:36,605:INFO:Creating metrics dataframe
2025-03-15 23:09:36,608:INFO:Uploading results into container
2025-03-15 23:09:36,608:INFO:Uploading model into container now
2025-03-15 23:09:36,609:INFO:_master_model_container: 13
2025-03-15 23:09:36,609:INFO:_display_container: 2
2025-03-15 23:09:36,610:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1880, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-15 23:09:36,610:INFO:create_model() successfully completed......................................
2025-03-15 23:09:36,723:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:36,724:INFO:Creating metrics dataframe
2025-03-15 23:09:36,726:INFO:Initializing Dummy Classifier
2025-03-15 23:09:36,726:INFO:Total runtime is 0.24326248566309613 minutes
2025-03-15 23:09:36,726:INFO:SubProcess create_model() called ==================================
2025-03-15 23:09:36,726:INFO:Initializing create_model()
2025-03-15 23:09:36,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000208204736D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:36,726:INFO:Checking exceptions
2025-03-15 23:09:36,726:INFO:Importing libraries
2025-03-15 23:09:36,726:INFO:Copying training dataset
2025-03-15 23:09:36,732:INFO:Defining folds
2025-03-15 23:09:36,732:INFO:Declaring metric variables
2025-03-15 23:09:36,732:INFO:Importing untrained model
2025-03-15 23:09:36,733:INFO:Dummy Classifier Imported successfully
2025-03-15 23:09:36,733:INFO:Starting cross validation
2025-03-15 23:09:36,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:09:36,971:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,971:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,979:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,980:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,982:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,984:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,984:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,986:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,995:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:36,996:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:09:37,012:INFO:Calculating mean and std
2025-03-15 23:09:37,013:INFO:Creating metrics dataframe
2025-03-15 23:09:37,015:INFO:Uploading results into container
2025-03-15 23:09:37,016:INFO:Uploading model into container now
2025-03-15 23:09:37,016:INFO:_master_model_container: 14
2025-03-15 23:09:37,016:INFO:_display_container: 2
2025-03-15 23:09:37,016:INFO:DummyClassifier(constant=None, random_state=1880, strategy='prior')
2025-03-15 23:09:37,016:INFO:create_model() successfully completed......................................
2025-03-15 23:09:37,122:INFO:SubProcess create_model() end ==================================
2025-03-15 23:09:37,122:INFO:Creating metrics dataframe
2025-03-15 23:09:37,126:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-15 23:09:37,130:INFO:Initializing create_model()
2025-03-15 23:09:37,130:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002081E7A5240>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1880, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:09:37,130:INFO:Checking exceptions
2025-03-15 23:09:37,131:INFO:Importing libraries
2025-03-15 23:09:37,131:INFO:Copying training dataset
2025-03-15 23:09:37,136:INFO:Defining folds
2025-03-15 23:09:37,136:INFO:Declaring metric variables
2025-03-15 23:09:37,137:INFO:Importing untrained model
2025-03-15 23:09:37,137:INFO:Declaring custom model
2025-03-15 23:09:37,137:INFO:Logistic Regression Imported successfully
2025-03-15 23:09:37,138:INFO:Cross validation set to False
2025-03-15 23:09:37,139:INFO:Fitting Model
2025-03-15 23:09:37,335:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:09:37,336:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1880, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:09:37,336:INFO:create_model() successfully completed......................................
2025-03-15 23:09:37,454:INFO:_master_model_container: 14
2025-03-15 23:09:37,454:INFO:_display_container: 2
2025-03-15 23:09:37,455:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1880, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:09:37,455:INFO:compare_models() successfully completed......................................
2025-03-15 23:09:37,483:INFO:Initializing save_model()
2025-03-15 23:09:37,483:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1880, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-15 23:09:37,483:INFO:Adding model into prep_pipe
2025-03-15 23:09:37,496:INFO:best_classifier.pkl saved in current working directory
2025-03-15 23:09:37,521:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1880,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-15 23:09:37,521:INFO:save_model() successfully completed......................................
2025-03-15 23:12:23,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:12:23,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:12:23,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:12:23,605:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:14:16,552:INFO:PyCaret ClassificationExperiment
2025-03-15 23:14:16,552:INFO:Logging name: clf-default-name
2025-03-15 23:14:16,552:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-15 23:14:16,552:INFO:version 3.3.2
2025-03-15 23:14:16,552:INFO:Initializing setup()
2025-03-15 23:14:16,552:INFO:self.USI: 16d0
2025-03-15 23:14:16,552:INFO:self._variable_keys: {'exp_id', 'n_jobs_param', 'target_param', 'pipeline', 'idx', 'y_train', 'X', 'X_test', 'is_multiclass', 'logging_param', 'y', 'gpu_param', 'memory', 'fold_shuffle_param', 'fold_groups_param', 'html_param', 'gpu_n_jobs_param', '_ml_usecase', 'fix_imbalance', 'y_test', 'USI', 'X_train', 'fold_generator', '_available_plots', 'data', 'seed', 'log_plots_param', 'exp_name_log'}
2025-03-15 23:14:16,552:INFO:Checking environment
2025-03-15 23:14:16,552:INFO:python_version: 3.10.0
2025-03-15 23:14:16,552:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-15 23:14:16,552:INFO:machine: AMD64
2025-03-15 23:14:16,574:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-15 23:14:16,580:INFO:Memory: svmem(total=17037209600, available=4509392896, percent=73.5, used=12527816704, free=4509392896)
2025-03-15 23:14:16,580:INFO:Physical Core: 6
2025-03-15 23:14:16,580:INFO:Logical Core: 12
2025-03-15 23:14:16,580:INFO:Checking libraries
2025-03-15 23:14:16,580:INFO:System:
2025-03-15 23:14:16,582:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-15 23:14:16,582:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-15 23:14:16,582:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-15 23:14:16,582:INFO:PyCaret required dependencies:
2025-03-15 23:14:16,611:INFO:                 pip: 21.2.3
2025-03-15 23:14:16,611:INFO:          setuptools: 57.4.0
2025-03-15 23:14:16,611:INFO:             pycaret: 3.3.2
2025-03-15 23:14:16,611:INFO:             IPython: 8.29.0
2025-03-15 23:14:16,611:INFO:          ipywidgets: 8.1.5
2025-03-15 23:14:16,612:INFO:                tqdm: 4.67.0
2025-03-15 23:14:16,612:INFO:               numpy: 1.26.4
2025-03-15 23:14:16,612:INFO:              pandas: 2.1.4
2025-03-15 23:14:16,612:INFO:              jinja2: 3.1.4
2025-03-15 23:14:16,612:INFO:               scipy: 1.11.4
2025-03-15 23:14:16,612:INFO:              joblib: 1.3.2
2025-03-15 23:14:16,612:INFO:             sklearn: 1.4.2
2025-03-15 23:14:16,612:INFO:                pyod: 2.0.2
2025-03-15 23:14:16,612:INFO:            imblearn: 0.12.4
2025-03-15 23:14:16,612:INFO:   category_encoders: 2.6.4
2025-03-15 23:14:16,612:INFO:            lightgbm: 4.5.0
2025-03-15 23:14:16,612:INFO:               numba: 0.60.0
2025-03-15 23:14:16,612:INFO:            requests: 2.32.3
2025-03-15 23:14:16,612:INFO:          matplotlib: 3.7.5
2025-03-15 23:14:16,612:INFO:          scikitplot: 0.3.7
2025-03-15 23:14:16,612:INFO:         yellowbrick: 1.5
2025-03-15 23:14:16,612:INFO:              plotly: 5.24.1
2025-03-15 23:14:16,612:INFO:    plotly-resampler: Not installed
2025-03-15 23:14:16,612:INFO:             kaleido: 0.2.1
2025-03-15 23:14:16,612:INFO:           schemdraw: 0.15
2025-03-15 23:14:16,612:INFO:         statsmodels: 0.14.4
2025-03-15 23:14:16,612:INFO:              sktime: 0.26.0
2025-03-15 23:14:16,612:INFO:               tbats: 1.1.3
2025-03-15 23:14:16,612:INFO:            pmdarima: 2.0.4
2025-03-15 23:14:16,612:INFO:              psutil: 6.1.0
2025-03-15 23:14:16,612:INFO:          markupsafe: 3.0.2
2025-03-15 23:14:16,612:INFO:             pickle5: Not installed
2025-03-15 23:14:16,613:INFO:         cloudpickle: 3.1.0
2025-03-15 23:14:16,613:INFO:         deprecation: 2.1.0
2025-03-15 23:14:16,613:INFO:              xxhash: 3.5.0
2025-03-15 23:14:16,613:INFO:           wurlitzer: Not installed
2025-03-15 23:14:16,613:INFO:PyCaret optional dependencies:
2025-03-15 23:14:16,628:INFO:                shap: Not installed
2025-03-15 23:14:16,628:INFO:           interpret: Not installed
2025-03-15 23:14:16,628:INFO:                umap: Not installed
2025-03-15 23:14:16,628:INFO:     ydata_profiling: 4.12.0
2025-03-15 23:14:16,628:INFO:  explainerdashboard: Not installed
2025-03-15 23:14:16,628:INFO:             autoviz: Not installed
2025-03-15 23:14:16,628:INFO:           fairlearn: Not installed
2025-03-15 23:14:16,628:INFO:          deepchecks: Not installed
2025-03-15 23:14:16,628:INFO:             xgboost: Not installed
2025-03-15 23:14:16,628:INFO:            catboost: Not installed
2025-03-15 23:14:16,628:INFO:              kmodes: Not installed
2025-03-15 23:14:16,628:INFO:             mlxtend: Not installed
2025-03-15 23:14:16,628:INFO:       statsforecast: Not installed
2025-03-15 23:14:16,628:INFO:        tune_sklearn: Not installed
2025-03-15 23:14:16,628:INFO:                 ray: Not installed
2025-03-15 23:14:16,628:INFO:            hyperopt: Not installed
2025-03-15 23:14:16,628:INFO:              optuna: Not installed
2025-03-15 23:14:16,628:INFO:               skopt: Not installed
2025-03-15 23:14:16,628:INFO:              mlflow: Not installed
2025-03-15 23:14:16,628:INFO:              gradio: Not installed
2025-03-15 23:14:16,629:INFO:             fastapi: Not installed
2025-03-15 23:14:16,629:INFO:             uvicorn: Not installed
2025-03-15 23:14:16,629:INFO:              m2cgen: Not installed
2025-03-15 23:14:16,629:INFO:           evidently: Not installed
2025-03-15 23:14:16,629:INFO:               fugue: Not installed
2025-03-15 23:14:16,629:INFO:           streamlit: 1.40.0
2025-03-15 23:14:16,629:INFO:             prophet: Not installed
2025-03-15 23:14:16,629:INFO:None
2025-03-15 23:14:16,629:INFO:Set up data.
2025-03-15 23:14:16,633:INFO:Set up folding strategy.
2025-03-15 23:14:16,634:INFO:Set up train/test split.
2025-03-15 23:14:16,638:INFO:Set up index.
2025-03-15 23:14:16,638:INFO:Assigning column types.
2025-03-15 23:14:16,642:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-15 23:14:16,686:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:14:16,689:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:14:16,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:16,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:16,765:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:14:16,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:14:16,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:16,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:16,793:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-15 23:14:16,837:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:14:16,864:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:16,864:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:16,908:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:14:16,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:16,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:16,936:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-15 23:14:17,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:17,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:17,076:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:17,076:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:17,078:INFO:Preparing preprocessing pipeline...
2025-03-15 23:14:17,079:INFO:Set up label encoding.
2025-03-15 23:14:17,079:INFO:Set up simple imputation.
2025-03-15 23:14:17,109:INFO:Finished creating preprocessing pipeline.
2025-03-15 23:14:17,114:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Name',
                                             'Sex', 'Age', 'SibSp', 'Parch',
                                             'Ticket', 'Fare', 'Cabin',
                                             'Embarked'],
                                    transf...SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-03-15 23:14:17,114:INFO:Creating final display dataframe.
2025-03-15 23:14:17,195:INFO:Setup _display_container:                     Description                        Value
0                    Session id                         8819
1                        Target                     Survived
2                   Target type                       Binary
3                Target mapping  -0.7892723: 0, 1.2669898: 1
4           Original data shape                    (891, 12)
5        Transformed data shape                    (891, 12)
6   Transformed train set shape                    (623, 12)
7    Transformed test set shape                    (268, 12)
8              Numeric features                           11
9                    Preprocess                         True
10              Imputation type                       simple
11           Numeric imputation                         mean
12       Categorical imputation                         mode
13               Fold Generator              StratifiedKFold
14                  Fold Number                           10
15                     CPU Jobs                           -1
16                      Use GPU                        False
17               Log Experiment                        False
18              Experiment Name             clf-default-name
19                          USI                         16d0
2025-03-15 23:14:17,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:17,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:17,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:17,351:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:14:17,352:INFO:setup() successfully completed in 0.8s...............
2025-03-15 23:14:17,357:INFO:Initializing compare_models()
2025-03-15 23:14:17,357:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-15 23:14:17,357:INFO:Checking exceptions
2025-03-15 23:14:17,367:INFO:Preparing display monitor
2025-03-15 23:14:17,371:INFO:Initializing Logistic Regression
2025-03-15 23:14:17,371:INFO:Total runtime is 0.0 minutes
2025-03-15 23:14:17,371:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,372:INFO:Initializing create_model()
2025-03-15 23:14:17,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,372:INFO:Checking exceptions
2025-03-15 23:14:17,372:INFO:Importing libraries
2025-03-15 23:14:17,372:INFO:Copying training dataset
2025-03-15 23:14:17,377:INFO:Defining folds
2025-03-15 23:14:17,377:INFO:Declaring metric variables
2025-03-15 23:14:17,378:INFO:Importing untrained model
2025-03-15 23:14:17,378:INFO:Logistic Regression Imported successfully
2025-03-15 23:14:17,379:INFO:Starting cross validation
2025-03-15 23:14:17,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,391:WARNING:create_model() for lr raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,481:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,481:INFO:Initializing create_model()
2025-03-15 23:14:17,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,481:INFO:Checking exceptions
2025-03-15 23:14:17,482:INFO:Importing libraries
2025-03-15 23:14:17,482:INFO:Copying training dataset
2025-03-15 23:14:17,488:INFO:Defining folds
2025-03-15 23:14:17,488:INFO:Declaring metric variables
2025-03-15 23:14:17,488:INFO:Importing untrained model
2025-03-15 23:14:17,489:INFO:Logistic Regression Imported successfully
2025-03-15 23:14:17,489:INFO:Starting cross validation
2025-03-15 23:14:17,490:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,494:ERROR:create_model() for lr raised an exception or returned all 0.0:
2025-03-15 23:14:17,495:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,496:INFO:Initializing K Neighbors Classifier
2025-03-15 23:14:17,496:INFO:Total runtime is 0.0020818034807840984 minutes
2025-03-15 23:14:17,496:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,496:INFO:Initializing create_model()
2025-03-15 23:14:17,496:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,496:INFO:Checking exceptions
2025-03-15 23:14:17,496:INFO:Importing libraries
2025-03-15 23:14:17,496:INFO:Copying training dataset
2025-03-15 23:14:17,502:INFO:Defining folds
2025-03-15 23:14:17,503:INFO:Declaring metric variables
2025-03-15 23:14:17,503:INFO:Importing untrained model
2025-03-15 23:14:17,503:INFO:K Neighbors Classifier Imported successfully
2025-03-15 23:14:17,503:INFO:Starting cross validation
2025-03-15 23:14:17,504:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,507:WARNING:create_model() for knn raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,508:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,508:INFO:Initializing create_model()
2025-03-15 23:14:17,508:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,508:INFO:Checking exceptions
2025-03-15 23:14:17,508:INFO:Importing libraries
2025-03-15 23:14:17,508:INFO:Copying training dataset
2025-03-15 23:14:17,514:INFO:Defining folds
2025-03-15 23:14:17,514:INFO:Declaring metric variables
2025-03-15 23:14:17,514:INFO:Importing untrained model
2025-03-15 23:14:17,514:INFO:K Neighbors Classifier Imported successfully
2025-03-15 23:14:17,515:INFO:Starting cross validation
2025-03-15 23:14:17,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,519:ERROR:create_model() for knn raised an exception or returned all 0.0:
2025-03-15 23:14:17,520:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,520:INFO:Initializing Naive Bayes
2025-03-15 23:14:17,521:INFO:Total runtime is 0.0025029301643371585 minutes
2025-03-15 23:14:17,521:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,521:INFO:Initializing create_model()
2025-03-15 23:14:17,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,521:INFO:Checking exceptions
2025-03-15 23:14:17,521:INFO:Importing libraries
2025-03-15 23:14:17,521:INFO:Copying training dataset
2025-03-15 23:14:17,525:INFO:Defining folds
2025-03-15 23:14:17,526:INFO:Declaring metric variables
2025-03-15 23:14:17,526:INFO:Importing untrained model
2025-03-15 23:14:17,526:INFO:Naive Bayes Imported successfully
2025-03-15 23:14:17,526:INFO:Starting cross validation
2025-03-15 23:14:17,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,532:WARNING:create_model() for nb raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,532:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,533:INFO:Initializing create_model()
2025-03-15 23:14:17,533:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,533:INFO:Checking exceptions
2025-03-15 23:14:17,533:INFO:Importing libraries
2025-03-15 23:14:17,533:INFO:Copying training dataset
2025-03-15 23:14:17,537:INFO:Defining folds
2025-03-15 23:14:17,537:INFO:Declaring metric variables
2025-03-15 23:14:17,537:INFO:Importing untrained model
2025-03-15 23:14:17,537:INFO:Naive Bayes Imported successfully
2025-03-15 23:14:17,537:INFO:Starting cross validation
2025-03-15 23:14:17,539:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,543:ERROR:create_model() for nb raised an exception or returned all 0.0:
2025-03-15 23:14:17,544:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,545:INFO:Initializing Decision Tree Classifier
2025-03-15 23:14:17,545:INFO:Total runtime is 0.0029020905494689946 minutes
2025-03-15 23:14:17,545:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,545:INFO:Initializing create_model()
2025-03-15 23:14:17,545:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,545:INFO:Checking exceptions
2025-03-15 23:14:17,545:INFO:Importing libraries
2025-03-15 23:14:17,545:INFO:Copying training dataset
2025-03-15 23:14:17,551:INFO:Defining folds
2025-03-15 23:14:17,551:INFO:Declaring metric variables
2025-03-15 23:14:17,551:INFO:Importing untrained model
2025-03-15 23:14:17,552:INFO:Decision Tree Classifier Imported successfully
2025-03-15 23:14:17,552:INFO:Starting cross validation
2025-03-15 23:14:17,553:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,557:WARNING:create_model() for dt raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,557:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,557:INFO:Initializing create_model()
2025-03-15 23:14:17,558:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,558:INFO:Checking exceptions
2025-03-15 23:14:17,558:INFO:Importing libraries
2025-03-15 23:14:17,558:INFO:Copying training dataset
2025-03-15 23:14:17,564:INFO:Defining folds
2025-03-15 23:14:17,564:INFO:Declaring metric variables
2025-03-15 23:14:17,564:INFO:Importing untrained model
2025-03-15 23:14:17,565:INFO:Decision Tree Classifier Imported successfully
2025-03-15 23:14:17,565:INFO:Starting cross validation
2025-03-15 23:14:17,566:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,570:ERROR:create_model() for dt raised an exception or returned all 0.0:
2025-03-15 23:14:17,571:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,571:INFO:Initializing SVM - Linear Kernel
2025-03-15 23:14:17,572:INFO:Total runtime is 0.003350762526194255 minutes
2025-03-15 23:14:17,572:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,572:INFO:Initializing create_model()
2025-03-15 23:14:17,572:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,572:INFO:Checking exceptions
2025-03-15 23:14:17,572:INFO:Importing libraries
2025-03-15 23:14:17,572:INFO:Copying training dataset
2025-03-15 23:14:17,576:INFO:Defining folds
2025-03-15 23:14:17,576:INFO:Declaring metric variables
2025-03-15 23:14:17,577:INFO:Importing untrained model
2025-03-15 23:14:17,577:INFO:SVM - Linear Kernel Imported successfully
2025-03-15 23:14:17,578:INFO:Starting cross validation
2025-03-15 23:14:17,579:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,583:WARNING:create_model() for svm raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,584:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,584:INFO:Initializing create_model()
2025-03-15 23:14:17,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,585:INFO:Checking exceptions
2025-03-15 23:14:17,585:INFO:Importing libraries
2025-03-15 23:14:17,585:INFO:Copying training dataset
2025-03-15 23:14:17,589:INFO:Defining folds
2025-03-15 23:14:17,590:INFO:Declaring metric variables
2025-03-15 23:14:17,590:INFO:Importing untrained model
2025-03-15 23:14:17,591:INFO:SVM - Linear Kernel Imported successfully
2025-03-15 23:14:17,591:INFO:Starting cross validation
2025-03-15 23:14:17,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,597:ERROR:create_model() for svm raised an exception or returned all 0.0:
2025-03-15 23:14:17,601:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,601:INFO:Initializing Ridge Classifier
2025-03-15 23:14:17,601:INFO:Total runtime is 0.003826932112375896 minutes
2025-03-15 23:14:17,602:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,602:INFO:Initializing create_model()
2025-03-15 23:14:17,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,603:INFO:Checking exceptions
2025-03-15 23:14:17,603:INFO:Importing libraries
2025-03-15 23:14:17,603:INFO:Copying training dataset
2025-03-15 23:14:17,609:INFO:Defining folds
2025-03-15 23:14:17,610:INFO:Declaring metric variables
2025-03-15 23:14:17,610:INFO:Importing untrained model
2025-03-15 23:14:17,610:INFO:Ridge Classifier Imported successfully
2025-03-15 23:14:17,610:INFO:Starting cross validation
2025-03-15 23:14:17,612:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,616:WARNING:create_model() for ridge raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,617:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,617:INFO:Initializing create_model()
2025-03-15 23:14:17,617:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,617:INFO:Checking exceptions
2025-03-15 23:14:17,617:INFO:Importing libraries
2025-03-15 23:14:17,617:INFO:Copying training dataset
2025-03-15 23:14:17,623:INFO:Defining folds
2025-03-15 23:14:17,623:INFO:Declaring metric variables
2025-03-15 23:14:17,623:INFO:Importing untrained model
2025-03-15 23:14:17,623:INFO:Ridge Classifier Imported successfully
2025-03-15 23:14:17,624:INFO:Starting cross validation
2025-03-15 23:14:17,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,629:ERROR:create_model() for ridge raised an exception or returned all 0.0:
2025-03-15 23:14:17,630:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,630:INFO:Initializing Random Forest Classifier
2025-03-15 23:14:17,630:INFO:Total runtime is 0.004319985707600912 minutes
2025-03-15 23:14:17,630:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,631:INFO:Initializing create_model()
2025-03-15 23:14:17,631:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,631:INFO:Checking exceptions
2025-03-15 23:14:17,631:INFO:Importing libraries
2025-03-15 23:14:17,631:INFO:Copying training dataset
2025-03-15 23:14:17,635:INFO:Defining folds
2025-03-15 23:14:17,635:INFO:Declaring metric variables
2025-03-15 23:14:17,635:INFO:Importing untrained model
2025-03-15 23:14:17,636:INFO:Random Forest Classifier Imported successfully
2025-03-15 23:14:17,636:INFO:Starting cross validation
2025-03-15 23:14:17,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,641:WARNING:create_model() for rf raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,642:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,642:INFO:Initializing create_model()
2025-03-15 23:14:17,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,642:INFO:Checking exceptions
2025-03-15 23:14:17,642:INFO:Importing libraries
2025-03-15 23:14:17,642:INFO:Copying training dataset
2025-03-15 23:14:17,648:INFO:Defining folds
2025-03-15 23:14:17,648:INFO:Declaring metric variables
2025-03-15 23:14:17,648:INFO:Importing untrained model
2025-03-15 23:14:17,649:INFO:Random Forest Classifier Imported successfully
2025-03-15 23:14:17,649:INFO:Starting cross validation
2025-03-15 23:14:17,650:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,740:ERROR:create_model() for rf raised an exception or returned all 0.0:
2025-03-15 23:14:17,742:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,742:INFO:Initializing Quadratic Discriminant Analysis
2025-03-15 23:14:17,742:INFO:Total runtime is 0.0061848402023315435 minutes
2025-03-15 23:14:17,742:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,743:INFO:Initializing create_model()
2025-03-15 23:14:17,743:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,743:INFO:Checking exceptions
2025-03-15 23:14:17,743:INFO:Importing libraries
2025-03-15 23:14:17,743:INFO:Copying training dataset
2025-03-15 23:14:17,746:INFO:Defining folds
2025-03-15 23:14:17,747:INFO:Declaring metric variables
2025-03-15 23:14:17,747:INFO:Importing untrained model
2025-03-15 23:14:17,747:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-15 23:14:17,747:INFO:Starting cross validation
2025-03-15 23:14:17,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,751:WARNING:create_model() for qda raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,752:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,752:INFO:Initializing create_model()
2025-03-15 23:14:17,752:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,752:INFO:Checking exceptions
2025-03-15 23:14:17,752:INFO:Importing libraries
2025-03-15 23:14:17,752:INFO:Copying training dataset
2025-03-15 23:14:17,757:INFO:Defining folds
2025-03-15 23:14:17,757:INFO:Declaring metric variables
2025-03-15 23:14:17,757:INFO:Importing untrained model
2025-03-15 23:14:17,757:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-15 23:14:17,758:INFO:Starting cross validation
2025-03-15 23:14:17,759:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,763:ERROR:create_model() for qda raised an exception or returned all 0.0:
2025-03-15 23:14:17,764:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,764:INFO:Initializing Ada Boost Classifier
2025-03-15 23:14:17,764:INFO:Total runtime is 0.0065442085266113285 minutes
2025-03-15 23:14:17,764:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,765:INFO:Initializing create_model()
2025-03-15 23:14:17,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,765:INFO:Checking exceptions
2025-03-15 23:14:17,765:INFO:Importing libraries
2025-03-15 23:14:17,765:INFO:Copying training dataset
2025-03-15 23:14:17,769:INFO:Defining folds
2025-03-15 23:14:17,769:INFO:Declaring metric variables
2025-03-15 23:14:17,769:INFO:Importing untrained model
2025-03-15 23:14:17,770:INFO:Ada Boost Classifier Imported successfully
2025-03-15 23:14:17,770:INFO:Starting cross validation
2025-03-15 23:14:17,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,774:WARNING:create_model() for ada raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,775:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,775:INFO:Initializing create_model()
2025-03-15 23:14:17,775:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,775:INFO:Checking exceptions
2025-03-15 23:14:17,775:INFO:Importing libraries
2025-03-15 23:14:17,775:INFO:Copying training dataset
2025-03-15 23:14:17,780:INFO:Defining folds
2025-03-15 23:14:17,781:INFO:Declaring metric variables
2025-03-15 23:14:17,781:INFO:Importing untrained model
2025-03-15 23:14:17,781:INFO:Ada Boost Classifier Imported successfully
2025-03-15 23:14:17,781:INFO:Starting cross validation
2025-03-15 23:14:17,782:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,785:ERROR:create_model() for ada raised an exception or returned all 0.0:
2025-03-15 23:14:17,786:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,787:INFO:Initializing Gradient Boosting Classifier
2025-03-15 23:14:17,787:INFO:Total runtime is 0.006936426957448324 minutes
2025-03-15 23:14:17,787:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,787:INFO:Initializing create_model()
2025-03-15 23:14:17,787:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,787:INFO:Checking exceptions
2025-03-15 23:14:17,787:INFO:Importing libraries
2025-03-15 23:14:17,787:INFO:Copying training dataset
2025-03-15 23:14:17,792:INFO:Defining folds
2025-03-15 23:14:17,792:INFO:Declaring metric variables
2025-03-15 23:14:17,792:INFO:Importing untrained model
2025-03-15 23:14:17,793:INFO:Gradient Boosting Classifier Imported successfully
2025-03-15 23:14:17,793:INFO:Starting cross validation
2025-03-15 23:14:17,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,797:WARNING:create_model() for gbc raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,798:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,798:INFO:Initializing create_model()
2025-03-15 23:14:17,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,798:INFO:Checking exceptions
2025-03-15 23:14:17,798:INFO:Importing libraries
2025-03-15 23:14:17,798:INFO:Copying training dataset
2025-03-15 23:14:17,801:INFO:Defining folds
2025-03-15 23:14:17,802:INFO:Declaring metric variables
2025-03-15 23:14:17,802:INFO:Importing untrained model
2025-03-15 23:14:17,802:INFO:Gradient Boosting Classifier Imported successfully
2025-03-15 23:14:17,802:INFO:Starting cross validation
2025-03-15 23:14:17,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,806:ERROR:create_model() for gbc raised an exception or returned all 0.0:
2025-03-15 23:14:17,808:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,808:INFO:Initializing Linear Discriminant Analysis
2025-03-15 23:14:17,808:INFO:Total runtime is 0.007287017504374186 minutes
2025-03-15 23:14:17,808:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,808:INFO:Initializing create_model()
2025-03-15 23:14:17,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,808:INFO:Checking exceptions
2025-03-15 23:14:17,808:INFO:Importing libraries
2025-03-15 23:14:17,808:INFO:Copying training dataset
2025-03-15 23:14:17,812:INFO:Defining folds
2025-03-15 23:14:17,812:INFO:Declaring metric variables
2025-03-15 23:14:17,812:INFO:Importing untrained model
2025-03-15 23:14:17,813:INFO:Linear Discriminant Analysis Imported successfully
2025-03-15 23:14:17,813:INFO:Starting cross validation
2025-03-15 23:14:17,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,818:WARNING:create_model() for lda raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,818:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,818:INFO:Initializing create_model()
2025-03-15 23:14:17,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,819:INFO:Checking exceptions
2025-03-15 23:14:17,819:INFO:Importing libraries
2025-03-15 23:14:17,819:INFO:Copying training dataset
2025-03-15 23:14:17,823:INFO:Defining folds
2025-03-15 23:14:17,823:INFO:Declaring metric variables
2025-03-15 23:14:17,823:INFO:Importing untrained model
2025-03-15 23:14:17,824:INFO:Linear Discriminant Analysis Imported successfully
2025-03-15 23:14:17,824:INFO:Starting cross validation
2025-03-15 23:14:17,824:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,828:ERROR:create_model() for lda raised an exception or returned all 0.0:
2025-03-15 23:14:17,830:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,830:INFO:Initializing Extra Trees Classifier
2025-03-15 23:14:17,830:INFO:Total runtime is 0.007654440402984619 minutes
2025-03-15 23:14:17,830:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,830:INFO:Initializing create_model()
2025-03-15 23:14:17,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,830:INFO:Checking exceptions
2025-03-15 23:14:17,830:INFO:Importing libraries
2025-03-15 23:14:17,830:INFO:Copying training dataset
2025-03-15 23:14:17,835:INFO:Defining folds
2025-03-15 23:14:17,835:INFO:Declaring metric variables
2025-03-15 23:14:17,835:INFO:Importing untrained model
2025-03-15 23:14:17,835:INFO:Extra Trees Classifier Imported successfully
2025-03-15 23:14:17,835:INFO:Starting cross validation
2025-03-15 23:14:17,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,840:WARNING:create_model() for et raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,840:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,841:INFO:Initializing create_model()
2025-03-15 23:14:17,841:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,841:INFO:Checking exceptions
2025-03-15 23:14:17,841:INFO:Importing libraries
2025-03-15 23:14:17,841:INFO:Copying training dataset
2025-03-15 23:14:17,845:INFO:Defining folds
2025-03-15 23:14:17,845:INFO:Declaring metric variables
2025-03-15 23:14:17,845:INFO:Importing untrained model
2025-03-15 23:14:17,846:INFO:Extra Trees Classifier Imported successfully
2025-03-15 23:14:17,846:INFO:Starting cross validation
2025-03-15 23:14:17,846:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,851:ERROR:create_model() for et raised an exception or returned all 0.0:
2025-03-15 23:14:17,852:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,852:INFO:Initializing Light Gradient Boosting Machine
2025-03-15 23:14:17,852:INFO:Total runtime is 0.008013574282328288 minutes
2025-03-15 23:14:17,852:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,852:INFO:Initializing create_model()
2025-03-15 23:14:17,852:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,852:INFO:Checking exceptions
2025-03-15 23:14:17,853:INFO:Importing libraries
2025-03-15 23:14:17,853:INFO:Copying training dataset
2025-03-15 23:14:17,857:INFO:Defining folds
2025-03-15 23:14:17,857:INFO:Declaring metric variables
2025-03-15 23:14:17,857:INFO:Importing untrained model
2025-03-15 23:14:17,857:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 23:14:17,858:INFO:Starting cross validation
2025-03-15 23:14:17,859:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,863:WARNING:create_model() for lightgbm raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,864:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,864:INFO:Initializing create_model()
2025-03-15 23:14:17,864:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,864:INFO:Checking exceptions
2025-03-15 23:14:17,864:INFO:Importing libraries
2025-03-15 23:14:17,864:INFO:Copying training dataset
2025-03-15 23:14:17,868:INFO:Defining folds
2025-03-15 23:14:17,868:INFO:Declaring metric variables
2025-03-15 23:14:17,869:INFO:Importing untrained model
2025-03-15 23:14:17,869:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 23:14:17,870:INFO:Starting cross validation
2025-03-15 23:14:17,870:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,876:ERROR:create_model() for lightgbm raised an exception or returned all 0.0:
2025-03-15 23:14:17,876:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,878:INFO:Initializing Dummy Classifier
2025-03-15 23:14:17,878:INFO:Total runtime is 0.008446566263834636 minutes
2025-03-15 23:14:17,878:INFO:SubProcess create_model() called ==================================
2025-03-15 23:14:17,878:INFO:Initializing create_model()
2025-03-15 23:14:17,878:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,878:INFO:Checking exceptions
2025-03-15 23:14:17,878:INFO:Importing libraries
2025-03-15 23:14:17,878:INFO:Copying training dataset
2025-03-15 23:14:17,884:INFO:Defining folds
2025-03-15 23:14:17,884:INFO:Declaring metric variables
2025-03-15 23:14:17,884:INFO:Importing untrained model
2025-03-15 23:14:17,884:INFO:Dummy Classifier Imported successfully
2025-03-15 23:14:17,884:INFO:Starting cross validation
2025-03-15 23:14:17,885:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,890:WARNING:create_model() for dummy raised an exception or returned all 0.0, trying without fit_kwargs:
2025-03-15 23:14:17,890:WARNING:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,891:INFO:Initializing create_model()
2025-03-15 23:14:17,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002C3577E1DE0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:14:17,891:INFO:Checking exceptions
2025-03-15 23:14:17,891:INFO:Importing libraries
2025-03-15 23:14:17,891:INFO:Copying training dataset
2025-03-15 23:14:17,896:INFO:Defining folds
2025-03-15 23:14:17,896:INFO:Declaring metric variables
2025-03-15 23:14:17,896:INFO:Importing untrained model
2025-03-15 23:14:17,896:INFO:Dummy Classifier Imported successfully
2025-03-15 23:14:17,897:INFO:Starting cross validation
2025-03-15 23:14:17,897:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:14:17,902:ERROR:create_model() for dummy raised an exception or returned all 0.0:
2025-03-15 23:14:17,903:ERROR:Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1423, in dispatch_one_batch
    tasks = self._ready_batches.get(block=False)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\queue.py", line 168, in get
    raise Empty
_queue.Empty

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 815, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1533, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1126, in _create_model_with_cv
    scores = cross_validate(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in cross_validate
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 67, in __call__
    return super().__call__(iterable_with_config)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1950, in __call__
    next(output)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1588, in _get_outputs
    self._start(iterator, pre_dispatch)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1571, in _start
    if self.dispatch_one_batch(iterator):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\joblib\parallel.py", line 1434, in dispatch_one_batch
    islice = list(itertools.islice(iterator, big_batch_size))
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\utils\parallel.py", line 63, in <genexpr>
    iterable_with_config = (
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_validation.py", line 430, in <genexpr>
    results = parallel(
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 377, in split
    for train, test in super().split(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 108, in split
    for test_index in self._iter_test_masks(X, y, groups):
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 770, in _iter_test_masks
    test_folds = self._make_test_folds(X, y)
  File "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\model_selection\_split.py", line 713, in _make_test_folds
    raise ValueError(
ValueError: Supported target types are: ('binary', 'multiclass'). Got 'continuous' instead.

2025-03-15 23:14:17,904:INFO:_master_model_container: 0
2025-03-15 23:14:17,904:INFO:_display_container: 2
2025-03-15 23:14:17,904:INFO:[]
2025-03-15 23:14:17,904:INFO:compare_models() successfully completed......................................
2025-03-15 23:14:17,911:INFO:Initializing save_model()
2025-03-15 23:14:17,911:INFO:save_model(model=[], model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Name',
                                             'Sex', 'Age', 'SibSp', 'Parch',
                                             'Ticket', 'Fare', 'Cabin',
                                             'Embarked'],
                                    transf...SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-15 23:14:17,911:INFO:Adding model into prep_pipe
2025-03-15 23:14:17,915:INFO:best_classifier.pkl saved in current working directory
2025-03-15 23:14:17,919:INFO:Pipeline(memory=Memory(location=None),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Name',
                                             'Sex', 'Age', 'SibSp', 'Parch',
                                             'Ticket', 'Fare', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('trained_model', [])],
         verbose=False)
2025-03-15 23:14:17,919:INFO:save_model() successfully completed......................................
2025-03-15 23:15:18,523:INFO:Initializing load_model()
2025-03-15 23:15:18,523:INFO:load_model(model_name=best_classifier, platform=None, authentication=None, verbose=True)
2025-03-15 23:15:18,537:INFO:Initializing predict_model()
2025-03-15 23:15:18,537:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002C3577E1510>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Name',
                                             'Sex', 'Age', 'SibSp', 'Parch',
                                             'Ticket', 'Fare', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', [])]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002C358DCD750>)
2025-03-15 23:15:18,537:INFO:Checking exceptions
2025-03-15 23:15:18,537:INFO:Preloading libraries
2025-03-15 23:15:18,538:INFO:Set up data.
2025-03-15 23:15:18,546:INFO:Set up index.
2025-03-15 23:16:57,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:16:57,803:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:16:57,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:16:57,804:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:18:31,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:18:31,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:18:31,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:18:31,684:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:20:18,418:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:20:18,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:20:18,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:20:18,419:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:20:38,943:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000002491BB7DB00, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-03-15 23:21:00,389:INFO:PyCaret ClassificationExperiment
2025-03-15 23:21:00,389:INFO:Logging name: clf-default-name
2025-03-15 23:21:00,389:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-15 23:21:00,389:INFO:version 3.3.2
2025-03-15 23:21:00,389:INFO:Initializing setup()
2025-03-15 23:21:00,389:INFO:self.USI: 4beb
2025-03-15 23:21:00,389:INFO:self._variable_keys: {'X_train', 'n_jobs_param', 'idx', 'USI', 'exp_id', 'fold_generator', 'X', 'data', 'is_multiclass', 'logging_param', 'y_train', 'memory', 'fold_shuffle_param', 'target_param', 'pipeline', 'X_test', '_available_plots', 'gpu_param', 'gpu_n_jobs_param', 'y_test', '_ml_usecase', 'fix_imbalance', 'exp_name_log', 'seed', 'html_param', 'fold_groups_param', 'y', 'log_plots_param'}
2025-03-15 23:21:00,389:INFO:Checking environment
2025-03-15 23:21:00,389:INFO:python_version: 3.10.0
2025-03-15 23:21:00,389:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-15 23:21:00,389:INFO:machine: AMD64
2025-03-15 23:21:00,401:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-15 23:21:00,406:INFO:Memory: svmem(total=17037209600, available=6800683008, percent=60.1, used=10236526592, free=6800683008)
2025-03-15 23:21:00,406:INFO:Physical Core: 6
2025-03-15 23:21:00,406:INFO:Logical Core: 12
2025-03-15 23:21:00,406:INFO:Checking libraries
2025-03-15 23:21:00,406:INFO:System:
2025-03-15 23:21:00,406:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-15 23:21:00,406:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-15 23:21:00,406:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-15 23:21:00,406:INFO:PyCaret required dependencies:
2025-03-15 23:21:00,437:INFO:                 pip: 21.2.3
2025-03-15 23:21:00,437:INFO:          setuptools: 57.4.0
2025-03-15 23:21:00,437:INFO:             pycaret: 3.3.2
2025-03-15 23:21:00,437:INFO:             IPython: 8.29.0
2025-03-15 23:21:00,437:INFO:          ipywidgets: 8.1.5
2025-03-15 23:21:00,437:INFO:                tqdm: 4.67.0
2025-03-15 23:21:00,437:INFO:               numpy: 1.26.4
2025-03-15 23:21:00,439:INFO:              pandas: 2.1.4
2025-03-15 23:21:00,439:INFO:              jinja2: 3.1.4
2025-03-15 23:21:00,439:INFO:               scipy: 1.11.4
2025-03-15 23:21:00,439:INFO:              joblib: 1.3.2
2025-03-15 23:21:00,439:INFO:             sklearn: 1.4.2
2025-03-15 23:21:00,439:INFO:                pyod: 2.0.2
2025-03-15 23:21:00,439:INFO:            imblearn: 0.12.4
2025-03-15 23:21:00,439:INFO:   category_encoders: 2.6.4
2025-03-15 23:21:00,439:INFO:            lightgbm: 4.5.0
2025-03-15 23:21:00,439:INFO:               numba: 0.60.0
2025-03-15 23:21:00,439:INFO:            requests: 2.32.3
2025-03-15 23:21:00,439:INFO:          matplotlib: 3.7.5
2025-03-15 23:21:00,439:INFO:          scikitplot: 0.3.7
2025-03-15 23:21:00,439:INFO:         yellowbrick: 1.5
2025-03-15 23:21:00,439:INFO:              plotly: 5.24.1
2025-03-15 23:21:00,439:INFO:    plotly-resampler: Not installed
2025-03-15 23:21:00,439:INFO:             kaleido: 0.2.1
2025-03-15 23:21:00,439:INFO:           schemdraw: 0.15
2025-03-15 23:21:00,439:INFO:         statsmodels: 0.14.4
2025-03-15 23:21:00,439:INFO:              sktime: 0.26.0
2025-03-15 23:21:00,439:INFO:               tbats: 1.1.3
2025-03-15 23:21:00,439:INFO:            pmdarima: 2.0.4
2025-03-15 23:21:00,439:INFO:              psutil: 6.1.0
2025-03-15 23:21:00,439:INFO:          markupsafe: 3.0.2
2025-03-15 23:21:00,439:INFO:             pickle5: Not installed
2025-03-15 23:21:00,439:INFO:         cloudpickle: 3.1.0
2025-03-15 23:21:00,439:INFO:         deprecation: 2.1.0
2025-03-15 23:21:00,439:INFO:              xxhash: 3.5.0
2025-03-15 23:21:00,440:INFO:           wurlitzer: Not installed
2025-03-15 23:21:00,440:INFO:PyCaret optional dependencies:
2025-03-15 23:21:00,452:INFO:                shap: Not installed
2025-03-15 23:21:00,452:INFO:           interpret: Not installed
2025-03-15 23:21:00,452:INFO:                umap: Not installed
2025-03-15 23:21:00,452:INFO:     ydata_profiling: 4.12.0
2025-03-15 23:21:00,452:INFO:  explainerdashboard: Not installed
2025-03-15 23:21:00,452:INFO:             autoviz: Not installed
2025-03-15 23:21:00,452:INFO:           fairlearn: Not installed
2025-03-15 23:21:00,452:INFO:          deepchecks: Not installed
2025-03-15 23:21:00,452:INFO:             xgboost: Not installed
2025-03-15 23:21:00,452:INFO:            catboost: Not installed
2025-03-15 23:21:00,452:INFO:              kmodes: Not installed
2025-03-15 23:21:00,452:INFO:             mlxtend: Not installed
2025-03-15 23:21:00,452:INFO:       statsforecast: Not installed
2025-03-15 23:21:00,452:INFO:        tune_sklearn: Not installed
2025-03-15 23:21:00,452:INFO:                 ray: Not installed
2025-03-15 23:21:00,453:INFO:            hyperopt: Not installed
2025-03-15 23:21:00,453:INFO:              optuna: Not installed
2025-03-15 23:21:00,453:INFO:               skopt: Not installed
2025-03-15 23:21:00,453:INFO:              mlflow: Not installed
2025-03-15 23:21:00,453:INFO:              gradio: Not installed
2025-03-15 23:21:00,453:INFO:             fastapi: Not installed
2025-03-15 23:21:00,453:INFO:             uvicorn: Not installed
2025-03-15 23:21:00,453:INFO:              m2cgen: Not installed
2025-03-15 23:21:00,453:INFO:           evidently: Not installed
2025-03-15 23:21:00,453:INFO:               fugue: Not installed
2025-03-15 23:21:00,453:INFO:           streamlit: 1.40.0
2025-03-15 23:21:00,453:INFO:             prophet: Not installed
2025-03-15 23:21:00,453:INFO:None
2025-03-15 23:21:00,453:INFO:Set up data.
2025-03-15 23:21:00,460:INFO:Set up folding strategy.
2025-03-15 23:21:00,460:INFO:Set up train/test split.
2025-03-15 23:21:00,468:INFO:Set up index.
2025-03-15 23:21:00,468:INFO:Assigning column types.
2025-03-15 23:21:00,471:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-15 23:21:00,516:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:21:00,519:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:21:00,551:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,551:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:21:00,594:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:21:00,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,619:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-15 23:21:00,660:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:21:00,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,686:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,727:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:21:00,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,752:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,752:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-15 23:21:00,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,884:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:00,888:INFO:Preparing preprocessing pipeline...
2025-03-15 23:21:00,889:INFO:Set up simple imputation.
2025-03-15 23:21:00,891:INFO:Set up encoding of ordinal features.
2025-03-15 23:21:00,893:INFO:Set up encoding of categorical features.
2025-03-15 23:21:01,019:INFO:Finished creating preprocessing pipeline.
2025-03-15 23:21:01,040:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-03-15 23:21:01,040:INFO:Creating final display dataframe.
2025-03-15 23:21:01,428:INFO:Setup _display_container:                     Description             Value
0                    Session id              1744
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              4beb
2025-03-15 23:21:01,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:01,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:01,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:01,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:21:01,580:INFO:setup() successfully completed in 1.19s...............
2025-03-15 23:21:01,584:INFO:Initializing compare_models()
2025-03-15 23:21:01,584:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-15 23:21:01,584:INFO:Checking exceptions
2025-03-15 23:21:01,587:INFO:Preparing display monitor
2025-03-15 23:21:01,591:INFO:Initializing Logistic Regression
2025-03-15 23:21:01,591:INFO:Total runtime is 0.0 minutes
2025-03-15 23:21:01,591:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:01,592:INFO:Initializing create_model()
2025-03-15 23:21:01,592:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:01,592:INFO:Checking exceptions
2025-03-15 23:21:01,592:INFO:Importing libraries
2025-03-15 23:21:01,592:INFO:Copying training dataset
2025-03-15 23:21:01,597:INFO:Defining folds
2025-03-15 23:21:01,597:INFO:Declaring metric variables
2025-03-15 23:21:01,597:INFO:Importing untrained model
2025-03-15 23:21:01,598:INFO:Logistic Regression Imported successfully
2025-03-15 23:21:01,598:INFO:Starting cross validation
2025-03-15 23:21:01,599:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:06,713:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:06,744:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:06,751:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:06,790:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:06,797:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:06,803:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:06,811:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:06,837:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:06,941:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:06,947:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:07,024:INFO:Calculating mean and std
2025-03-15 23:21:07,025:INFO:Creating metrics dataframe
2025-03-15 23:21:07,027:INFO:Uploading results into container
2025-03-15 23:21:07,029:INFO:Uploading model into container now
2025-03-15 23:21:07,029:INFO:_master_model_container: 1
2025-03-15 23:21:07,029:INFO:_display_container: 2
2025-03-15 23:21:07,030:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1744, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:21:07,030:INFO:create_model() successfully completed......................................
2025-03-15 23:21:07,144:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:07,145:INFO:Creating metrics dataframe
2025-03-15 23:21:07,147:INFO:Initializing K Neighbors Classifier
2025-03-15 23:21:07,147:INFO:Total runtime is 0.09261383215586344 minutes
2025-03-15 23:21:07,147:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:07,147:INFO:Initializing create_model()
2025-03-15 23:21:07,147:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:07,147:INFO:Checking exceptions
2025-03-15 23:21:07,148:INFO:Importing libraries
2025-03-15 23:21:07,148:INFO:Copying training dataset
2025-03-15 23:21:07,153:INFO:Defining folds
2025-03-15 23:21:07,153:INFO:Declaring metric variables
2025-03-15 23:21:07,153:INFO:Importing untrained model
2025-03-15 23:21:07,154:INFO:K Neighbors Classifier Imported successfully
2025-03-15 23:21:07,154:INFO:Starting cross validation
2025-03-15 23:21:07,155:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:09,537:INFO:Calculating mean and std
2025-03-15 23:21:09,538:INFO:Creating metrics dataframe
2025-03-15 23:21:09,541:INFO:Uploading results into container
2025-03-15 23:21:09,541:INFO:Uploading model into container now
2025-03-15 23:21:09,542:INFO:_master_model_container: 2
2025-03-15 23:21:09,542:INFO:_display_container: 2
2025-03-15 23:21:09,542:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-15 23:21:09,542:INFO:create_model() successfully completed......................................
2025-03-15 23:21:09,661:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:09,661:INFO:Creating metrics dataframe
2025-03-15 23:21:09,664:INFO:Initializing Naive Bayes
2025-03-15 23:21:09,664:INFO:Total runtime is 0.13455263376235962 minutes
2025-03-15 23:21:09,664:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:09,664:INFO:Initializing create_model()
2025-03-15 23:21:09,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:09,664:INFO:Checking exceptions
2025-03-15 23:21:09,664:INFO:Importing libraries
2025-03-15 23:21:09,664:INFO:Copying training dataset
2025-03-15 23:21:09,669:INFO:Defining folds
2025-03-15 23:21:09,669:INFO:Declaring metric variables
2025-03-15 23:21:09,669:INFO:Importing untrained model
2025-03-15 23:21:09,669:INFO:Naive Bayes Imported successfully
2025-03-15 23:21:09,670:INFO:Starting cross validation
2025-03-15 23:21:09,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:10,025:INFO:Calculating mean and std
2025-03-15 23:21:10,026:INFO:Creating metrics dataframe
2025-03-15 23:21:10,027:INFO:Uploading results into container
2025-03-15 23:21:10,027:INFO:Uploading model into container now
2025-03-15 23:21:10,028:INFO:_master_model_container: 3
2025-03-15 23:21:10,028:INFO:_display_container: 2
2025-03-15 23:21:10,028:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-15 23:21:10,028:INFO:create_model() successfully completed......................................
2025-03-15 23:21:10,137:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:10,137:INFO:Creating metrics dataframe
2025-03-15 23:21:10,140:INFO:Initializing Decision Tree Classifier
2025-03-15 23:21:10,140:INFO:Total runtime is 0.1424975355466207 minutes
2025-03-15 23:21:10,140:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:10,140:INFO:Initializing create_model()
2025-03-15 23:21:10,140:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:10,140:INFO:Checking exceptions
2025-03-15 23:21:10,140:INFO:Importing libraries
2025-03-15 23:21:10,140:INFO:Copying training dataset
2025-03-15 23:21:10,145:INFO:Defining folds
2025-03-15 23:21:10,145:INFO:Declaring metric variables
2025-03-15 23:21:10,145:INFO:Importing untrained model
2025-03-15 23:21:10,146:INFO:Decision Tree Classifier Imported successfully
2025-03-15 23:21:10,146:INFO:Starting cross validation
2025-03-15 23:21:10,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:10,396:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,405:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,410:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,410:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,416:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,420:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,420:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,422:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,425:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,432:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:10,444:INFO:Calculating mean and std
2025-03-15 23:21:10,445:INFO:Creating metrics dataframe
2025-03-15 23:21:10,446:INFO:Uploading results into container
2025-03-15 23:21:10,447:INFO:Uploading model into container now
2025-03-15 23:21:10,447:INFO:_master_model_container: 4
2025-03-15 23:21:10,447:INFO:_display_container: 2
2025-03-15 23:21:10,447:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1744, splitter='best')
2025-03-15 23:21:10,447:INFO:create_model() successfully completed......................................
2025-03-15 23:21:10,544:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:10,544:INFO:Creating metrics dataframe
2025-03-15 23:21:10,547:INFO:Initializing SVM - Linear Kernel
2025-03-15 23:21:10,547:INFO:Total runtime is 0.1492803732554118 minutes
2025-03-15 23:21:10,548:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:10,548:INFO:Initializing create_model()
2025-03-15 23:21:10,548:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:10,548:INFO:Checking exceptions
2025-03-15 23:21:10,548:INFO:Importing libraries
2025-03-15 23:21:10,548:INFO:Copying training dataset
2025-03-15 23:21:10,554:INFO:Defining folds
2025-03-15 23:21:10,554:INFO:Declaring metric variables
2025-03-15 23:21:10,554:INFO:Importing untrained model
2025-03-15 23:21:10,554:INFO:SVM - Linear Kernel Imported successfully
2025-03-15 23:21:10,554:INFO:Starting cross validation
2025-03-15 23:21:10,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:10,819:INFO:Calculating mean and std
2025-03-15 23:21:10,820:INFO:Creating metrics dataframe
2025-03-15 23:21:10,821:INFO:Uploading results into container
2025-03-15 23:21:10,822:INFO:Uploading model into container now
2025-03-15 23:21:10,822:INFO:_master_model_container: 5
2025-03-15 23:21:10,822:INFO:_display_container: 2
2025-03-15 23:21:10,822:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1744, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-15 23:21:10,822:INFO:create_model() successfully completed......................................
2025-03-15 23:21:10,919:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:10,919:INFO:Creating metrics dataframe
2025-03-15 23:21:10,922:INFO:Initializing Ridge Classifier
2025-03-15 23:21:10,922:INFO:Total runtime is 0.15551720062891644 minutes
2025-03-15 23:21:10,922:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:10,922:INFO:Initializing create_model()
2025-03-15 23:21:10,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:10,923:INFO:Checking exceptions
2025-03-15 23:21:10,923:INFO:Importing libraries
2025-03-15 23:21:10,923:INFO:Copying training dataset
2025-03-15 23:21:10,927:INFO:Defining folds
2025-03-15 23:21:10,927:INFO:Declaring metric variables
2025-03-15 23:21:10,927:INFO:Importing untrained model
2025-03-15 23:21:10,927:INFO:Ridge Classifier Imported successfully
2025-03-15 23:21:10,928:INFO:Starting cross validation
2025-03-15 23:21:10,929:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:11,202:INFO:Calculating mean and std
2025-03-15 23:21:11,203:INFO:Creating metrics dataframe
2025-03-15 23:21:11,204:INFO:Uploading results into container
2025-03-15 23:21:11,205:INFO:Uploading model into container now
2025-03-15 23:21:11,205:INFO:_master_model_container: 6
2025-03-15 23:21:11,205:INFO:_display_container: 2
2025-03-15 23:21:11,205:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1744, solver='auto',
                tol=0.0001)
2025-03-15 23:21:11,205:INFO:create_model() successfully completed......................................
2025-03-15 23:21:11,303:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:11,303:INFO:Creating metrics dataframe
2025-03-15 23:21:11,305:INFO:Initializing Random Forest Classifier
2025-03-15 23:21:11,305:INFO:Total runtime is 0.16190001567204795 minutes
2025-03-15 23:21:11,306:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:11,306:INFO:Initializing create_model()
2025-03-15 23:21:11,306:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:11,306:INFO:Checking exceptions
2025-03-15 23:21:11,306:INFO:Importing libraries
2025-03-15 23:21:11,306:INFO:Copying training dataset
2025-03-15 23:21:11,310:INFO:Defining folds
2025-03-15 23:21:11,310:INFO:Declaring metric variables
2025-03-15 23:21:11,310:INFO:Importing untrained model
2025-03-15 23:21:11,311:INFO:Random Forest Classifier Imported successfully
2025-03-15 23:21:11,311:INFO:Starting cross validation
2025-03-15 23:21:11,312:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:11,886:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:11,887:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:11,890:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:11,901:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:11,905:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:11,906:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:11,916:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:11,918:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:11,920:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:11,926:INFO:Calculating mean and std
2025-03-15 23:21:11,927:INFO:Creating metrics dataframe
2025-03-15 23:21:11,929:INFO:Uploading results into container
2025-03-15 23:21:11,930:INFO:Uploading model into container now
2025-03-15 23:21:11,930:INFO:_master_model_container: 7
2025-03-15 23:21:11,930:INFO:_display_container: 2
2025-03-15 23:21:11,930:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1744, verbose=0,
                       warm_start=False)
2025-03-15 23:21:11,931:INFO:create_model() successfully completed......................................
2025-03-15 23:21:12,023:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:12,024:INFO:Creating metrics dataframe
2025-03-15 23:21:12,026:INFO:Initializing Quadratic Discriminant Analysis
2025-03-15 23:21:12,026:INFO:Total runtime is 0.17391837437947594 minutes
2025-03-15 23:21:12,026:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:12,027:INFO:Initializing create_model()
2025-03-15 23:21:12,027:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:12,027:INFO:Checking exceptions
2025-03-15 23:21:12,027:INFO:Importing libraries
2025-03-15 23:21:12,027:INFO:Copying training dataset
2025-03-15 23:21:12,030:INFO:Defining folds
2025-03-15 23:21:12,030:INFO:Declaring metric variables
2025-03-15 23:21:12,031:INFO:Importing untrained model
2025-03-15 23:21:12,031:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-15 23:21:12,031:INFO:Starting cross validation
2025-03-15 23:21:12,032:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:12,196:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,203:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,210:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,216:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,216:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,221:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,222:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,225:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,228:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,236:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:21:12,286:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,294:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,299:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,302:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,302:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,302:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,306:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,317:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,329:INFO:Calculating mean and std
2025-03-15 23:21:12,330:INFO:Creating metrics dataframe
2025-03-15 23:21:12,331:INFO:Uploading results into container
2025-03-15 23:21:12,332:INFO:Uploading model into container now
2025-03-15 23:21:12,332:INFO:_master_model_container: 8
2025-03-15 23:21:12,332:INFO:_display_container: 2
2025-03-15 23:21:12,332:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-15 23:21:12,332:INFO:create_model() successfully completed......................................
2025-03-15 23:21:12,427:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:12,427:INFO:Creating metrics dataframe
2025-03-15 23:21:12,429:INFO:Initializing Ada Boost Classifier
2025-03-15 23:21:12,430:INFO:Total runtime is 0.1806507428487142 minutes
2025-03-15 23:21:12,430:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:12,430:INFO:Initializing create_model()
2025-03-15 23:21:12,430:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:12,430:INFO:Checking exceptions
2025-03-15 23:21:12,430:INFO:Importing libraries
2025-03-15 23:21:12,430:INFO:Copying training dataset
2025-03-15 23:21:12,434:INFO:Defining folds
2025-03-15 23:21:12,434:INFO:Declaring metric variables
2025-03-15 23:21:12,435:INFO:Importing untrained model
2025-03-15 23:21:12,435:INFO:Ada Boost Classifier Imported successfully
2025-03-15 23:21:12,435:INFO:Starting cross validation
2025-03-15 23:21:12,437:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:12,616:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:21:12,622:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:21:12,626:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:21:12,628:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:21:12,630:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:21:12,631:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:21:12,637:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:21:12,646:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:21:12,649:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:21:12,693:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,697:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,698:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,701:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,702:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,705:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,707:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,711:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,712:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,717:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:12,725:INFO:Calculating mean and std
2025-03-15 23:21:12,726:INFO:Creating metrics dataframe
2025-03-15 23:21:12,727:INFO:Uploading results into container
2025-03-15 23:21:12,727:INFO:Uploading model into container now
2025-03-15 23:21:12,728:INFO:_master_model_container: 9
2025-03-15 23:21:12,728:INFO:_display_container: 2
2025-03-15 23:21:12,728:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1744)
2025-03-15 23:21:12,728:INFO:create_model() successfully completed......................................
2025-03-15 23:21:12,826:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:12,826:INFO:Creating metrics dataframe
2025-03-15 23:21:12,828:INFO:Initializing Gradient Boosting Classifier
2025-03-15 23:21:12,828:INFO:Total runtime is 0.187296462059021 minutes
2025-03-15 23:21:12,829:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:12,829:INFO:Initializing create_model()
2025-03-15 23:21:12,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:12,829:INFO:Checking exceptions
2025-03-15 23:21:12,829:INFO:Importing libraries
2025-03-15 23:21:12,829:INFO:Copying training dataset
2025-03-15 23:21:12,834:INFO:Defining folds
2025-03-15 23:21:12,834:INFO:Declaring metric variables
2025-03-15 23:21:12,834:INFO:Importing untrained model
2025-03-15 23:21:12,834:INFO:Gradient Boosting Classifier Imported successfully
2025-03-15 23:21:12,834:INFO:Starting cross validation
2025-03-15 23:21:12,836:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:13,195:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,206:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,214:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,215:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,215:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,217:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,219:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,221:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,228:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,240:INFO:Calculating mean and std
2025-03-15 23:21:13,241:INFO:Creating metrics dataframe
2025-03-15 23:21:13,242:INFO:Uploading results into container
2025-03-15 23:21:13,243:INFO:Uploading model into container now
2025-03-15 23:21:13,243:INFO:_master_model_container: 10
2025-03-15 23:21:13,243:INFO:_display_container: 2
2025-03-15 23:21:13,244:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1744, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-15 23:21:13,244:INFO:create_model() successfully completed......................................
2025-03-15 23:21:13,343:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:13,343:INFO:Creating metrics dataframe
2025-03-15 23:21:13,346:INFO:Initializing Linear Discriminant Analysis
2025-03-15 23:21:13,346:INFO:Total runtime is 0.1959161996841431 minutes
2025-03-15 23:21:13,346:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:13,346:INFO:Initializing create_model()
2025-03-15 23:21:13,346:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:13,347:INFO:Checking exceptions
2025-03-15 23:21:13,347:INFO:Importing libraries
2025-03-15 23:21:13,347:INFO:Copying training dataset
2025-03-15 23:21:13,351:INFO:Defining folds
2025-03-15 23:21:13,351:INFO:Declaring metric variables
2025-03-15 23:21:13,352:INFO:Importing untrained model
2025-03-15 23:21:13,352:INFO:Linear Discriminant Analysis Imported successfully
2025-03-15 23:21:13,352:INFO:Starting cross validation
2025-03-15 23:21:13,354:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:13,605:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,607:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,616:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,616:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,621:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,625:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,635:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,636:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,636:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:13,651:INFO:Calculating mean and std
2025-03-15 23:21:13,652:INFO:Creating metrics dataframe
2025-03-15 23:21:13,653:INFO:Uploading results into container
2025-03-15 23:21:13,654:INFO:Uploading model into container now
2025-03-15 23:21:13,654:INFO:_master_model_container: 11
2025-03-15 23:21:13,654:INFO:_display_container: 2
2025-03-15 23:21:13,654:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-15 23:21:13,654:INFO:create_model() successfully completed......................................
2025-03-15 23:21:13,755:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:13,755:INFO:Creating metrics dataframe
2025-03-15 23:21:13,757:INFO:Initializing Extra Trees Classifier
2025-03-15 23:21:13,757:INFO:Total runtime is 0.2027776638666789 minutes
2025-03-15 23:21:13,757:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:13,759:INFO:Initializing create_model()
2025-03-15 23:21:13,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:13,759:INFO:Checking exceptions
2025-03-15 23:21:13,759:INFO:Importing libraries
2025-03-15 23:21:13,759:INFO:Copying training dataset
2025-03-15 23:21:13,763:INFO:Defining folds
2025-03-15 23:21:13,763:INFO:Declaring metric variables
2025-03-15 23:21:13,763:INFO:Importing untrained model
2025-03-15 23:21:13,764:INFO:Extra Trees Classifier Imported successfully
2025-03-15 23:21:13,764:INFO:Starting cross validation
2025-03-15 23:21:13,765:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:14,314:INFO:Calculating mean and std
2025-03-15 23:21:14,315:INFO:Creating metrics dataframe
2025-03-15 23:21:14,316:INFO:Uploading results into container
2025-03-15 23:21:14,317:INFO:Uploading model into container now
2025-03-15 23:21:14,317:INFO:_master_model_container: 12
2025-03-15 23:21:14,317:INFO:_display_container: 2
2025-03-15 23:21:14,318:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1744, verbose=0,
                     warm_start=False)
2025-03-15 23:21:14,318:INFO:create_model() successfully completed......................................
2025-03-15 23:21:14,416:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:14,416:INFO:Creating metrics dataframe
2025-03-15 23:21:14,418:INFO:Initializing Light Gradient Boosting Machine
2025-03-15 23:21:14,419:INFO:Total runtime is 0.2138025720914205 minutes
2025-03-15 23:21:14,419:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:14,419:INFO:Initializing create_model()
2025-03-15 23:21:14,419:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:14,419:INFO:Checking exceptions
2025-03-15 23:21:14,419:INFO:Importing libraries
2025-03-15 23:21:14,420:INFO:Copying training dataset
2025-03-15 23:21:14,424:INFO:Defining folds
2025-03-15 23:21:14,424:INFO:Declaring metric variables
2025-03-15 23:21:14,424:INFO:Importing untrained model
2025-03-15 23:21:14,424:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 23:21:14,425:INFO:Starting cross validation
2025-03-15 23:21:14,426:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:15,137:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,147:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,165:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,193:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,271:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,289:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,293:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,312:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,368:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,378:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,387:INFO:Calculating mean and std
2025-03-15 23:21:15,388:INFO:Creating metrics dataframe
2025-03-15 23:21:15,390:INFO:Uploading results into container
2025-03-15 23:21:15,391:INFO:Uploading model into container now
2025-03-15 23:21:15,391:INFO:_master_model_container: 13
2025-03-15 23:21:15,391:INFO:_display_container: 2
2025-03-15 23:21:15,392:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1744, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-15 23:21:15,392:INFO:create_model() successfully completed......................................
2025-03-15 23:21:15,507:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:15,507:INFO:Creating metrics dataframe
2025-03-15 23:21:15,510:INFO:Initializing Dummy Classifier
2025-03-15 23:21:15,510:INFO:Total runtime is 0.2319874127705892 minutes
2025-03-15 23:21:15,510:INFO:SubProcess create_model() called ==================================
2025-03-15 23:21:15,511:INFO:Initializing create_model()
2025-03-15 23:21:15,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000024939DF55D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:15,511:INFO:Checking exceptions
2025-03-15 23:21:15,511:INFO:Importing libraries
2025-03-15 23:21:15,511:INFO:Copying training dataset
2025-03-15 23:21:15,515:INFO:Defining folds
2025-03-15 23:21:15,516:INFO:Declaring metric variables
2025-03-15 23:21:15,516:INFO:Importing untrained model
2025-03-15 23:21:15,516:INFO:Dummy Classifier Imported successfully
2025-03-15 23:21:15,516:INFO:Starting cross validation
2025-03-15 23:21:15,517:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:21:15,746:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,751:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,755:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,762:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,764:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,770:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,771:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,772:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,773:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:21:15,790:INFO:Calculating mean and std
2025-03-15 23:21:15,791:INFO:Creating metrics dataframe
2025-03-15 23:21:15,792:INFO:Uploading results into container
2025-03-15 23:21:15,793:INFO:Uploading model into container now
2025-03-15 23:21:15,793:INFO:_master_model_container: 14
2025-03-15 23:21:15,793:INFO:_display_container: 2
2025-03-15 23:21:15,793:INFO:DummyClassifier(constant=None, random_state=1744, strategy='prior')
2025-03-15 23:21:15,793:INFO:create_model() successfully completed......................................
2025-03-15 23:21:15,892:INFO:SubProcess create_model() end ==================================
2025-03-15 23:21:15,892:INFO:Creating metrics dataframe
2025-03-15 23:21:15,896:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-15 23:21:15,898:INFO:Initializing create_model()
2025-03-15 23:21:15,898:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1744, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:21:15,898:INFO:Checking exceptions
2025-03-15 23:21:15,899:INFO:Importing libraries
2025-03-15 23:21:15,899:INFO:Copying training dataset
2025-03-15 23:21:15,903:INFO:Defining folds
2025-03-15 23:21:15,903:INFO:Declaring metric variables
2025-03-15 23:21:15,904:INFO:Importing untrained model
2025-03-15 23:21:15,904:INFO:Declaring custom model
2025-03-15 23:21:15,904:INFO:Logistic Regression Imported successfully
2025-03-15 23:21:15,906:INFO:Cross validation set to False
2025-03-15 23:21:15,906:INFO:Fitting Model
2025-03-15 23:21:16,092:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:21:16,093:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1744, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:21:16,093:INFO:create_model() successfully completed......................................
2025-03-15 23:21:16,205:INFO:_master_model_container: 14
2025-03-15 23:21:16,206:INFO:_display_container: 2
2025-03-15 23:21:16,206:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1744, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:21:16,206:INFO:compare_models() successfully completed......................................
2025-03-15 23:21:16,229:INFO:Initializing save_model()
2025-03-15 23:21:16,230:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1744, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-15 23:21:16,230:INFO:Adding model into prep_pipe
2025-03-15 23:21:16,244:INFO:best_classifier.pkl saved in current working directory
2025-03-15 23:21:16,268:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1744,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-15 23:21:16,269:INFO:save_model() successfully completed......................................
2025-03-15 23:21:37,081:INFO:Initializing load_model()
2025-03-15 23:21:37,082:INFO:load_model(model_name=best_classifier, platform=None, authentication=None, verbose=True)
2025-03-15 23:21:37,122:INFO:Initializing predict_model()
2025-03-15 23:21:37,123:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000024939ED7130>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=1744))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002493B1CEE60>)
2025-03-15 23:21:37,123:INFO:Checking exceptions
2025-03-15 23:21:37,123:INFO:Preloading libraries
2025-03-15 23:21:37,124:INFO:Set up data.
2025-03-15 23:21:37,131:INFO:Set up index.
2025-03-15 23:23:27,432:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:23:27,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:23:27,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:23:27,433:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:28:17,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:28:17,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:28:17,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:28:17,069:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:29:09,972:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001A470F13D60, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-03-15 23:29:29,911:INFO:PyCaret ClassificationExperiment
2025-03-15 23:29:29,911:INFO:Logging name: clf-default-name
2025-03-15 23:29:29,911:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-15 23:29:29,911:INFO:version 3.3.2
2025-03-15 23:29:29,911:INFO:Initializing setup()
2025-03-15 23:29:29,911:INFO:self.USI: 0226
2025-03-15 23:29:29,911:INFO:self._variable_keys: {'gpu_n_jobs_param', 'data', 'n_jobs_param', 'fold_generator', 'X', 'logging_param', 'y_train', '_available_plots', 'USI', 'idx', 'X_train', 'fix_imbalance', 'html_param', 'is_multiclass', 'target_param', 'y', 'pipeline', 'exp_name_log', 'X_test', 'gpu_param', 'seed', 'fold_shuffle_param', 'y_test', 'exp_id', 'memory', 'fold_groups_param', '_ml_usecase', 'log_plots_param'}
2025-03-15 23:29:29,911:INFO:Checking environment
2025-03-15 23:29:29,911:INFO:python_version: 3.10.0
2025-03-15 23:29:29,912:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-15 23:29:29,912:INFO:machine: AMD64
2025-03-15 23:29:29,922:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-15 23:29:29,928:INFO:Memory: svmem(total=17037209600, available=6539071488, percent=61.6, used=10498138112, free=6539071488)
2025-03-15 23:29:29,929:INFO:Physical Core: 6
2025-03-15 23:29:29,929:INFO:Logical Core: 12
2025-03-15 23:29:29,929:INFO:Checking libraries
2025-03-15 23:29:29,929:INFO:System:
2025-03-15 23:29:29,929:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-15 23:29:29,929:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-15 23:29:29,929:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-15 23:29:29,929:INFO:PyCaret required dependencies:
2025-03-15 23:29:29,963:INFO:                 pip: 21.2.3
2025-03-15 23:29:29,963:INFO:          setuptools: 57.4.0
2025-03-15 23:29:29,963:INFO:             pycaret: 3.3.2
2025-03-15 23:29:29,963:INFO:             IPython: 8.29.0
2025-03-15 23:29:29,963:INFO:          ipywidgets: 8.1.5
2025-03-15 23:29:29,963:INFO:                tqdm: 4.67.0
2025-03-15 23:29:29,963:INFO:               numpy: 1.26.4
2025-03-15 23:29:29,963:INFO:              pandas: 2.1.4
2025-03-15 23:29:29,963:INFO:              jinja2: 3.1.4
2025-03-15 23:29:29,963:INFO:               scipy: 1.11.4
2025-03-15 23:29:29,963:INFO:              joblib: 1.3.2
2025-03-15 23:29:29,963:INFO:             sklearn: 1.4.2
2025-03-15 23:29:29,963:INFO:                pyod: 2.0.2
2025-03-15 23:29:29,963:INFO:            imblearn: 0.12.4
2025-03-15 23:29:29,963:INFO:   category_encoders: 2.6.4
2025-03-15 23:29:29,963:INFO:            lightgbm: 4.5.0
2025-03-15 23:29:29,963:INFO:               numba: 0.60.0
2025-03-15 23:29:29,963:INFO:            requests: 2.32.3
2025-03-15 23:29:29,963:INFO:          matplotlib: 3.7.5
2025-03-15 23:29:29,963:INFO:          scikitplot: 0.3.7
2025-03-15 23:29:29,963:INFO:         yellowbrick: 1.5
2025-03-15 23:29:29,963:INFO:              plotly: 5.24.1
2025-03-15 23:29:29,963:INFO:    plotly-resampler: Not installed
2025-03-15 23:29:29,963:INFO:             kaleido: 0.2.1
2025-03-15 23:29:29,964:INFO:           schemdraw: 0.15
2025-03-15 23:29:29,964:INFO:         statsmodels: 0.14.4
2025-03-15 23:29:29,964:INFO:              sktime: 0.26.0
2025-03-15 23:29:29,964:INFO:               tbats: 1.1.3
2025-03-15 23:29:29,964:INFO:            pmdarima: 2.0.4
2025-03-15 23:29:29,964:INFO:              psutil: 6.1.0
2025-03-15 23:29:29,964:INFO:          markupsafe: 3.0.2
2025-03-15 23:29:29,964:INFO:             pickle5: Not installed
2025-03-15 23:29:29,964:INFO:         cloudpickle: 3.1.0
2025-03-15 23:29:29,964:INFO:         deprecation: 2.1.0
2025-03-15 23:29:29,964:INFO:              xxhash: 3.5.0
2025-03-15 23:29:29,964:INFO:           wurlitzer: Not installed
2025-03-15 23:29:29,964:INFO:PyCaret optional dependencies:
2025-03-15 23:29:29,979:INFO:                shap: Not installed
2025-03-15 23:29:29,979:INFO:           interpret: Not installed
2025-03-15 23:29:29,979:INFO:                umap: Not installed
2025-03-15 23:29:29,979:INFO:     ydata_profiling: 4.12.0
2025-03-15 23:29:29,979:INFO:  explainerdashboard: Not installed
2025-03-15 23:29:29,979:INFO:             autoviz: Not installed
2025-03-15 23:29:29,979:INFO:           fairlearn: Not installed
2025-03-15 23:29:29,979:INFO:          deepchecks: Not installed
2025-03-15 23:29:29,979:INFO:             xgboost: Not installed
2025-03-15 23:29:29,979:INFO:            catboost: Not installed
2025-03-15 23:29:29,979:INFO:              kmodes: Not installed
2025-03-15 23:29:29,979:INFO:             mlxtend: Not installed
2025-03-15 23:29:29,979:INFO:       statsforecast: Not installed
2025-03-15 23:29:29,979:INFO:        tune_sklearn: Not installed
2025-03-15 23:29:29,979:INFO:                 ray: Not installed
2025-03-15 23:29:29,979:INFO:            hyperopt: Not installed
2025-03-15 23:29:29,980:INFO:              optuna: Not installed
2025-03-15 23:29:29,980:INFO:               skopt: Not installed
2025-03-15 23:29:29,980:INFO:              mlflow: Not installed
2025-03-15 23:29:29,980:INFO:              gradio: Not installed
2025-03-15 23:29:29,980:INFO:             fastapi: Not installed
2025-03-15 23:29:29,980:INFO:             uvicorn: Not installed
2025-03-15 23:29:29,980:INFO:              m2cgen: Not installed
2025-03-15 23:29:29,980:INFO:           evidently: Not installed
2025-03-15 23:29:29,980:INFO:               fugue: Not installed
2025-03-15 23:29:29,980:INFO:           streamlit: 1.40.0
2025-03-15 23:29:29,980:INFO:             prophet: Not installed
2025-03-15 23:29:29,980:INFO:None
2025-03-15 23:29:29,980:INFO:Set up data.
2025-03-15 23:29:29,988:INFO:Set up folding strategy.
2025-03-15 23:29:29,988:INFO:Set up train/test split.
2025-03-15 23:29:29,995:INFO:Set up index.
2025-03-15 23:29:29,995:INFO:Assigning column types.
2025-03-15 23:29:30,000:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-15 23:29:30,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:29:30,050:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:29:30,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,083:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:29:30,129:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:29:30,157:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,157:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-15 23:29:30,200:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:29:30,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,269:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:29:30,296:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,296:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,297:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-15 23:29:30,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:30,447:INFO:Preparing preprocessing pipeline...
2025-03-15 23:29:30,448:INFO:Set up simple imputation.
2025-03-15 23:29:30,451:INFO:Set up encoding of ordinal features.
2025-03-15 23:29:30,452:INFO:Set up encoding of categorical features.
2025-03-15 23:29:30,576:INFO:Finished creating preprocessing pipeline.
2025-03-15 23:29:30,599:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-03-15 23:29:30,599:INFO:Creating final display dataframe.
2025-03-15 23:29:30,992:INFO:Setup _display_container:                     Description             Value
0                    Session id              3008
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              0226
2025-03-15 23:29:31,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:31,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:31,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:31,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:29:31,147:INFO:setup() successfully completed in 1.24s...............
2025-03-15 23:29:31,147:INFO:Initializing compare_models()
2025-03-15 23:29:31,147:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-15 23:29:31,147:INFO:Checking exceptions
2025-03-15 23:29:31,152:INFO:Preparing display monitor
2025-03-15 23:29:31,154:INFO:Initializing Logistic Regression
2025-03-15 23:29:31,154:INFO:Total runtime is 0.0 minutes
2025-03-15 23:29:31,155:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:31,155:INFO:Initializing create_model()
2025-03-15 23:29:31,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:31,155:INFO:Checking exceptions
2025-03-15 23:29:31,155:INFO:Importing libraries
2025-03-15 23:29:31,155:INFO:Copying training dataset
2025-03-15 23:29:31,159:INFO:Defining folds
2025-03-15 23:29:31,159:INFO:Declaring metric variables
2025-03-15 23:29:31,159:INFO:Importing untrained model
2025-03-15 23:29:31,160:INFO:Logistic Regression Imported successfully
2025-03-15 23:29:31,160:INFO:Starting cross validation
2025-03-15 23:29:31,162:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:36,278:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,288:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,293:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,297:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,301:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,310:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,317:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,325:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,327:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,401:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:36,512:INFO:Calculating mean and std
2025-03-15 23:29:36,514:INFO:Creating metrics dataframe
2025-03-15 23:29:36,517:INFO:Uploading results into container
2025-03-15 23:29:36,517:INFO:Uploading model into container now
2025-03-15 23:29:36,519:INFO:_master_model_container: 1
2025-03-15 23:29:36,519:INFO:_display_container: 2
2025-03-15 23:29:36,519:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:29:36,519:INFO:create_model() successfully completed......................................
2025-03-15 23:29:36,629:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:36,629:INFO:Creating metrics dataframe
2025-03-15 23:29:36,631:INFO:Initializing K Neighbors Classifier
2025-03-15 23:29:36,631:INFO:Total runtime is 0.09129159053166708 minutes
2025-03-15 23:29:36,631:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:36,632:INFO:Initializing create_model()
2025-03-15 23:29:36,632:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:36,632:INFO:Checking exceptions
2025-03-15 23:29:36,632:INFO:Importing libraries
2025-03-15 23:29:36,632:INFO:Copying training dataset
2025-03-15 23:29:36,637:INFO:Defining folds
2025-03-15 23:29:36,637:INFO:Declaring metric variables
2025-03-15 23:29:36,638:INFO:Importing untrained model
2025-03-15 23:29:36,638:INFO:K Neighbors Classifier Imported successfully
2025-03-15 23:29:36,638:INFO:Starting cross validation
2025-03-15 23:29:36,639:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:39,058:INFO:Calculating mean and std
2025-03-15 23:29:39,059:INFO:Creating metrics dataframe
2025-03-15 23:29:39,061:INFO:Uploading results into container
2025-03-15 23:29:39,062:INFO:Uploading model into container now
2025-03-15 23:29:39,062:INFO:_master_model_container: 2
2025-03-15 23:29:39,062:INFO:_display_container: 2
2025-03-15 23:29:39,062:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-15 23:29:39,062:INFO:create_model() successfully completed......................................
2025-03-15 23:29:39,172:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:39,172:INFO:Creating metrics dataframe
2025-03-15 23:29:39,175:INFO:Initializing Naive Bayes
2025-03-15 23:29:39,175:INFO:Total runtime is 0.13369230031967164 minutes
2025-03-15 23:29:39,176:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:39,176:INFO:Initializing create_model()
2025-03-15 23:29:39,176:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:39,176:INFO:Checking exceptions
2025-03-15 23:29:39,176:INFO:Importing libraries
2025-03-15 23:29:39,176:INFO:Copying training dataset
2025-03-15 23:29:39,182:INFO:Defining folds
2025-03-15 23:29:39,182:INFO:Declaring metric variables
2025-03-15 23:29:39,182:INFO:Importing untrained model
2025-03-15 23:29:39,183:INFO:Naive Bayes Imported successfully
2025-03-15 23:29:39,183:INFO:Starting cross validation
2025-03-15 23:29:39,184:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:39,443:INFO:Calculating mean and std
2025-03-15 23:29:39,444:INFO:Creating metrics dataframe
2025-03-15 23:29:39,446:INFO:Uploading results into container
2025-03-15 23:29:39,446:INFO:Uploading model into container now
2025-03-15 23:29:39,447:INFO:_master_model_container: 3
2025-03-15 23:29:39,447:INFO:_display_container: 2
2025-03-15 23:29:39,447:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-15 23:29:39,447:INFO:create_model() successfully completed......................................
2025-03-15 23:29:39,543:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:39,543:INFO:Creating metrics dataframe
2025-03-15 23:29:39,546:INFO:Initializing Decision Tree Classifier
2025-03-15 23:29:39,546:INFO:Total runtime is 0.1398755192756653 minutes
2025-03-15 23:29:39,546:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:39,546:INFO:Initializing create_model()
2025-03-15 23:29:39,546:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:39,546:INFO:Checking exceptions
2025-03-15 23:29:39,546:INFO:Importing libraries
2025-03-15 23:29:39,546:INFO:Copying training dataset
2025-03-15 23:29:39,551:INFO:Defining folds
2025-03-15 23:29:39,552:INFO:Declaring metric variables
2025-03-15 23:29:39,552:INFO:Importing untrained model
2025-03-15 23:29:39,552:INFO:Decision Tree Classifier Imported successfully
2025-03-15 23:29:39,552:INFO:Starting cross validation
2025-03-15 23:29:39,554:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:39,784:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,791:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,792:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,793:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,794:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,795:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,797:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,798:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,803:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,809:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:39,817:INFO:Calculating mean and std
2025-03-15 23:29:39,818:INFO:Creating metrics dataframe
2025-03-15 23:29:39,819:INFO:Uploading results into container
2025-03-15 23:29:39,819:INFO:Uploading model into container now
2025-03-15 23:29:39,819:INFO:_master_model_container: 4
2025-03-15 23:29:39,819:INFO:_display_container: 2
2025-03-15 23:29:39,820:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3008, splitter='best')
2025-03-15 23:29:39,820:INFO:create_model() successfully completed......................................
2025-03-15 23:29:39,914:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:39,915:INFO:Creating metrics dataframe
2025-03-15 23:29:39,917:INFO:Initializing SVM - Linear Kernel
2025-03-15 23:29:39,917:INFO:Total runtime is 0.14605807860692344 minutes
2025-03-15 23:29:39,917:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:39,917:INFO:Initializing create_model()
2025-03-15 23:29:39,917:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:39,917:INFO:Checking exceptions
2025-03-15 23:29:39,917:INFO:Importing libraries
2025-03-15 23:29:39,917:INFO:Copying training dataset
2025-03-15 23:29:39,922:INFO:Defining folds
2025-03-15 23:29:39,922:INFO:Declaring metric variables
2025-03-15 23:29:39,922:INFO:Importing untrained model
2025-03-15 23:29:39,923:INFO:SVM - Linear Kernel Imported successfully
2025-03-15 23:29:39,923:INFO:Starting cross validation
2025-03-15 23:29:39,925:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:40,192:INFO:Calculating mean and std
2025-03-15 23:29:40,193:INFO:Creating metrics dataframe
2025-03-15 23:29:40,194:INFO:Uploading results into container
2025-03-15 23:29:40,195:INFO:Uploading model into container now
2025-03-15 23:29:40,195:INFO:_master_model_container: 5
2025-03-15 23:29:40,195:INFO:_display_container: 2
2025-03-15 23:29:40,195:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3008, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-15 23:29:40,196:INFO:create_model() successfully completed......................................
2025-03-15 23:29:40,287:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:40,287:INFO:Creating metrics dataframe
2025-03-15 23:29:40,289:INFO:Initializing Ridge Classifier
2025-03-15 23:29:40,290:INFO:Total runtime is 0.15227076212565105 minutes
2025-03-15 23:29:40,290:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:40,290:INFO:Initializing create_model()
2025-03-15 23:29:40,290:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:40,290:INFO:Checking exceptions
2025-03-15 23:29:40,290:INFO:Importing libraries
2025-03-15 23:29:40,290:INFO:Copying training dataset
2025-03-15 23:29:40,294:INFO:Defining folds
2025-03-15 23:29:40,294:INFO:Declaring metric variables
2025-03-15 23:29:40,294:INFO:Importing untrained model
2025-03-15 23:29:40,295:INFO:Ridge Classifier Imported successfully
2025-03-15 23:29:40,295:INFO:Starting cross validation
2025-03-15 23:29:40,296:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:40,561:INFO:Calculating mean and std
2025-03-15 23:29:40,562:INFO:Creating metrics dataframe
2025-03-15 23:29:40,564:INFO:Uploading results into container
2025-03-15 23:29:40,564:INFO:Uploading model into container now
2025-03-15 23:29:40,564:INFO:_master_model_container: 6
2025-03-15 23:29:40,564:INFO:_display_container: 2
2025-03-15 23:29:40,565:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3008, solver='auto',
                tol=0.0001)
2025-03-15 23:29:40,565:INFO:create_model() successfully completed......................................
2025-03-15 23:29:40,670:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:40,670:INFO:Creating metrics dataframe
2025-03-15 23:29:40,673:INFO:Initializing Random Forest Classifier
2025-03-15 23:29:40,673:INFO:Total runtime is 0.15865840117136637 minutes
2025-03-15 23:29:40,673:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:40,673:INFO:Initializing create_model()
2025-03-15 23:29:40,673:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:40,673:INFO:Checking exceptions
2025-03-15 23:29:40,673:INFO:Importing libraries
2025-03-15 23:29:40,673:INFO:Copying training dataset
2025-03-15 23:29:40,677:INFO:Defining folds
2025-03-15 23:29:40,677:INFO:Declaring metric variables
2025-03-15 23:29:40,677:INFO:Importing untrained model
2025-03-15 23:29:40,679:INFO:Random Forest Classifier Imported successfully
2025-03-15 23:29:40,679:INFO:Starting cross validation
2025-03-15 23:29:40,680:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:41,213:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,226:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,232:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,240:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,244:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,270:INFO:Calculating mean and std
2025-03-15 23:29:41,271:INFO:Creating metrics dataframe
2025-03-15 23:29:41,272:INFO:Uploading results into container
2025-03-15 23:29:41,273:INFO:Uploading model into container now
2025-03-15 23:29:41,273:INFO:_master_model_container: 7
2025-03-15 23:29:41,273:INFO:_display_container: 2
2025-03-15 23:29:41,273:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3008, verbose=0,
                       warm_start=False)
2025-03-15 23:29:41,273:INFO:create_model() successfully completed......................................
2025-03-15 23:29:41,374:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:41,374:INFO:Creating metrics dataframe
2025-03-15 23:29:41,377:INFO:Initializing Quadratic Discriminant Analysis
2025-03-15 23:29:41,377:INFO:Total runtime is 0.17038577795028687 minutes
2025-03-15 23:29:41,377:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:41,377:INFO:Initializing create_model()
2025-03-15 23:29:41,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:41,377:INFO:Checking exceptions
2025-03-15 23:29:41,377:INFO:Importing libraries
2025-03-15 23:29:41,377:INFO:Copying training dataset
2025-03-15 23:29:41,382:INFO:Defining folds
2025-03-15 23:29:41,382:INFO:Declaring metric variables
2025-03-15 23:29:41,383:INFO:Importing untrained model
2025-03-15 23:29:41,383:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-15 23:29:41,383:INFO:Starting cross validation
2025-03-15 23:29:41,385:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:41,545:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:29:41,551:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:29:41,554:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:29:41,557:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:29:41,562:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:29:41,562:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:29:41,564:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:29:41,565:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:29:41,569:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:29:41,610:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,619:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,622:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,625:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,626:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,628:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,631:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,632:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,642:INFO:Calculating mean and std
2025-03-15 23:29:41,643:INFO:Creating metrics dataframe
2025-03-15 23:29:41,644:INFO:Uploading results into container
2025-03-15 23:29:41,645:INFO:Uploading model into container now
2025-03-15 23:29:41,645:INFO:_master_model_container: 8
2025-03-15 23:29:41,645:INFO:_display_container: 2
2025-03-15 23:29:41,645:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-15 23:29:41,645:INFO:create_model() successfully completed......................................
2025-03-15 23:29:41,737:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:41,737:INFO:Creating metrics dataframe
2025-03-15 23:29:41,741:INFO:Initializing Ada Boost Classifier
2025-03-15 23:29:41,741:INFO:Total runtime is 0.17645089626312255 minutes
2025-03-15 23:29:41,741:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:41,741:INFO:Initializing create_model()
2025-03-15 23:29:41,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:41,741:INFO:Checking exceptions
2025-03-15 23:29:41,741:INFO:Importing libraries
2025-03-15 23:29:41,741:INFO:Copying training dataset
2025-03-15 23:29:41,746:INFO:Defining folds
2025-03-15 23:29:41,746:INFO:Declaring metric variables
2025-03-15 23:29:41,746:INFO:Importing untrained model
2025-03-15 23:29:41,746:INFO:Ada Boost Classifier Imported successfully
2025-03-15 23:29:41,747:INFO:Starting cross validation
2025-03-15 23:29:41,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:41,899:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,904:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,909:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,913:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,916:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,920:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,921:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,927:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,930:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,930:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:29:41,970:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,982:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,983:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,987:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,989:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,991:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,994:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,994:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,996:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:41,998:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,009:INFO:Calculating mean and std
2025-03-15 23:29:42,010:INFO:Creating metrics dataframe
2025-03-15 23:29:42,011:INFO:Uploading results into container
2025-03-15 23:29:42,012:INFO:Uploading model into container now
2025-03-15 23:29:42,012:INFO:_master_model_container: 9
2025-03-15 23:29:42,012:INFO:_display_container: 2
2025-03-15 23:29:42,012:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3008)
2025-03-15 23:29:42,012:INFO:create_model() successfully completed......................................
2025-03-15 23:29:42,107:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:42,107:INFO:Creating metrics dataframe
2025-03-15 23:29:42,110:INFO:Initializing Gradient Boosting Classifier
2025-03-15 23:29:42,110:INFO:Total runtime is 0.1826084534327189 minutes
2025-03-15 23:29:42,110:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:42,110:INFO:Initializing create_model()
2025-03-15 23:29:42,110:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:42,111:INFO:Checking exceptions
2025-03-15 23:29:42,111:INFO:Importing libraries
2025-03-15 23:29:42,111:INFO:Copying training dataset
2025-03-15 23:29:42,116:INFO:Defining folds
2025-03-15 23:29:42,116:INFO:Declaring metric variables
2025-03-15 23:29:42,116:INFO:Importing untrained model
2025-03-15 23:29:42,117:INFO:Gradient Boosting Classifier Imported successfully
2025-03-15 23:29:42,117:INFO:Starting cross validation
2025-03-15 23:29:42,119:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:42,474:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,476:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,478:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,483:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,485:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,487:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,490:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,494:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,494:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,494:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,504:INFO:Calculating mean and std
2025-03-15 23:29:42,505:INFO:Creating metrics dataframe
2025-03-15 23:29:42,507:INFO:Uploading results into container
2025-03-15 23:29:42,507:INFO:Uploading model into container now
2025-03-15 23:29:42,507:INFO:_master_model_container: 10
2025-03-15 23:29:42,507:INFO:_display_container: 2
2025-03-15 23:29:42,509:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3008, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-15 23:29:42,509:INFO:create_model() successfully completed......................................
2025-03-15 23:29:42,608:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:42,608:INFO:Creating metrics dataframe
2025-03-15 23:29:42,610:INFO:Initializing Linear Discriminant Analysis
2025-03-15 23:29:42,610:INFO:Total runtime is 0.19094252586364743 minutes
2025-03-15 23:29:42,611:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:42,611:INFO:Initializing create_model()
2025-03-15 23:29:42,611:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:42,611:INFO:Checking exceptions
2025-03-15 23:29:42,611:INFO:Importing libraries
2025-03-15 23:29:42,611:INFO:Copying training dataset
2025-03-15 23:29:42,615:INFO:Defining folds
2025-03-15 23:29:42,615:INFO:Declaring metric variables
2025-03-15 23:29:42,616:INFO:Importing untrained model
2025-03-15 23:29:42,616:INFO:Linear Discriminant Analysis Imported successfully
2025-03-15 23:29:42,616:INFO:Starting cross validation
2025-03-15 23:29:42,617:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:42,842:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,843:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,848:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,853:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,855:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,856:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,857:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,859:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:42,876:INFO:Calculating mean and std
2025-03-15 23:29:42,878:INFO:Creating metrics dataframe
2025-03-15 23:29:42,884:INFO:Uploading results into container
2025-03-15 23:29:42,885:INFO:Uploading model into container now
2025-03-15 23:29:42,886:INFO:_master_model_container: 11
2025-03-15 23:29:42,887:INFO:_display_container: 2
2025-03-15 23:29:42,887:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-15 23:29:42,887:INFO:create_model() successfully completed......................................
2025-03-15 23:29:42,998:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:42,999:INFO:Creating metrics dataframe
2025-03-15 23:29:43,001:INFO:Initializing Extra Trees Classifier
2025-03-15 23:29:43,001:INFO:Total runtime is 0.19746075868606563 minutes
2025-03-15 23:29:43,001:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:43,001:INFO:Initializing create_model()
2025-03-15 23:29:43,002:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:43,002:INFO:Checking exceptions
2025-03-15 23:29:43,002:INFO:Importing libraries
2025-03-15 23:29:43,002:INFO:Copying training dataset
2025-03-15 23:29:43,007:INFO:Defining folds
2025-03-15 23:29:43,009:INFO:Declaring metric variables
2025-03-15 23:29:43,009:INFO:Importing untrained model
2025-03-15 23:29:43,009:INFO:Extra Trees Classifier Imported successfully
2025-03-15 23:29:43,010:INFO:Starting cross validation
2025-03-15 23:29:43,011:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:43,558:INFO:Calculating mean and std
2025-03-15 23:29:43,561:INFO:Creating metrics dataframe
2025-03-15 23:29:43,563:INFO:Uploading results into container
2025-03-15 23:29:43,563:INFO:Uploading model into container now
2025-03-15 23:29:43,564:INFO:_master_model_container: 12
2025-03-15 23:29:43,564:INFO:_display_container: 2
2025-03-15 23:29:43,564:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3008, verbose=0,
                     warm_start=False)
2025-03-15 23:29:43,564:INFO:create_model() successfully completed......................................
2025-03-15 23:29:43,676:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:43,676:INFO:Creating metrics dataframe
2025-03-15 23:29:43,679:INFO:Initializing Light Gradient Boosting Machine
2025-03-15 23:29:43,679:INFO:Total runtime is 0.20875258843104041 minutes
2025-03-15 23:29:43,679:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:43,679:INFO:Initializing create_model()
2025-03-15 23:29:43,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:43,679:INFO:Checking exceptions
2025-03-15 23:29:43,680:INFO:Importing libraries
2025-03-15 23:29:43,680:INFO:Copying training dataset
2025-03-15 23:29:43,684:INFO:Defining folds
2025-03-15 23:29:43,684:INFO:Declaring metric variables
2025-03-15 23:29:43,684:INFO:Importing untrained model
2025-03-15 23:29:43,684:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 23:29:43,684:INFO:Starting cross validation
2025-03-15 23:29:43,686:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:44,432:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,443:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,473:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,493:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,565:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,589:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,603:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,622:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,659:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,678:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:44,695:INFO:Calculating mean and std
2025-03-15 23:29:44,696:INFO:Creating metrics dataframe
2025-03-15 23:29:44,698:INFO:Uploading results into container
2025-03-15 23:29:44,699:INFO:Uploading model into container now
2025-03-15 23:29:44,700:INFO:_master_model_container: 13
2025-03-15 23:29:44,700:INFO:_display_container: 2
2025-03-15 23:29:44,700:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3008, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-15 23:29:44,700:INFO:create_model() successfully completed......................................
2025-03-15 23:29:44,810:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:44,810:INFO:Creating metrics dataframe
2025-03-15 23:29:44,813:INFO:Initializing Dummy Classifier
2025-03-15 23:29:44,813:INFO:Total runtime is 0.22765361865361528 minutes
2025-03-15 23:29:44,813:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:44,813:INFO:Initializing create_model()
2025-03-15 23:29:44,813:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475C1A2F0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:44,813:INFO:Checking exceptions
2025-03-15 23:29:44,813:INFO:Importing libraries
2025-03-15 23:29:44,813:INFO:Copying training dataset
2025-03-15 23:29:44,818:INFO:Defining folds
2025-03-15 23:29:44,818:INFO:Declaring metric variables
2025-03-15 23:29:44,818:INFO:Importing untrained model
2025-03-15 23:29:44,818:INFO:Dummy Classifier Imported successfully
2025-03-15 23:29:44,818:INFO:Starting cross validation
2025-03-15 23:29:44,820:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:45,047:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,050:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,056:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,065:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,066:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,066:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,069:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,070:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,072:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,077:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:29:45,087:INFO:Calculating mean and std
2025-03-15 23:29:45,087:INFO:Creating metrics dataframe
2025-03-15 23:29:45,089:INFO:Uploading results into container
2025-03-15 23:29:45,090:INFO:Uploading model into container now
2025-03-15 23:29:45,090:INFO:_master_model_container: 14
2025-03-15 23:29:45,090:INFO:_display_container: 2
2025-03-15 23:29:45,090:INFO:DummyClassifier(constant=None, random_state=3008, strategy='prior')
2025-03-15 23:29:45,090:INFO:create_model() successfully completed......................................
2025-03-15 23:29:45,193:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:45,193:INFO:Creating metrics dataframe
2025-03-15 23:29:45,198:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-15 23:29:45,200:INFO:Initializing create_model()
2025-03-15 23:29:45,200:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:45,200:INFO:Checking exceptions
2025-03-15 23:29:45,200:INFO:Importing libraries
2025-03-15 23:29:45,201:INFO:Copying training dataset
2025-03-15 23:29:45,206:INFO:Defining folds
2025-03-15 23:29:45,206:INFO:Declaring metric variables
2025-03-15 23:29:45,206:INFO:Importing untrained model
2025-03-15 23:29:45,206:INFO:Declaring custom model
2025-03-15 23:29:45,206:INFO:Logistic Regression Imported successfully
2025-03-15 23:29:45,208:INFO:Cross validation set to False
2025-03-15 23:29:45,208:INFO:Fitting Model
2025-03-15 23:29:45,431:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:45,432:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:29:45,432:INFO:create_model() successfully completed......................................
2025-03-15 23:29:45,544:INFO:_master_model_container: 14
2025-03-15 23:29:45,544:INFO:_display_container: 2
2025-03-15 23:29:45,546:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:29:45,546:INFO:compare_models() successfully completed......................................
2025-03-15 23:29:45,546:INFO:Initializing tune_model()
2025-03-15 23:29:45,546:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>)
2025-03-15 23:29:45,546:INFO:Checking exceptions
2025-03-15 23:29:45,549:INFO:Copying training dataset
2025-03-15 23:29:45,553:INFO:Checking base model
2025-03-15 23:29:45,553:INFO:Base model : Logistic Regression
2025-03-15 23:29:45,554:INFO:Declaring metric variables
2025-03-15 23:29:45,554:INFO:Defining Hyperparameters
2025-03-15 23:29:45,650:INFO:Tuning with n_jobs=-1
2025-03-15 23:29:45,651:INFO:Initializing RandomizedSearchCV
2025-03-15 23:29:46,060:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,064:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,072:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,082:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,101:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,107:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,110:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,150:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,210:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,214:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,220:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,474:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,512:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,547:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,562:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,600:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,620:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,633:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,641:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,671:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,688:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,789:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,843:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,880:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,914:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:46,959:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,012:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,070:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,080:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,104:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,162:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,226:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,290:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,292:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,334:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,373:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,379:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,401:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,490:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,502:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,600:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,601:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,682:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,729:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,811:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,813:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,820:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,869:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:47,955:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,007:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,023:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,031:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,064:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,071:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,133:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,168:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,235:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,261:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,376:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,395:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,407:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,492:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,516:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,548:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,578:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,581:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,615:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,644:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,679:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,797:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,955:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,988:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:48,995:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,006:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,011:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,016:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,023:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,072:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,091:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,156:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,189:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,194:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,408:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,447:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,449:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,473:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,482:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,490:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,527:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,587:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,599:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,614:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,668:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,687:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,762:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,773:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,779:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,795:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:49,834:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 5.380000000000001}
2025-03-15 23:29:49,835:INFO:Hyperparameter search completed
2025-03-15 23:29:49,835:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:49,835:INFO:Initializing create_model()
2025-03-15 23:29:49,835:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001A475B5D2A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': 'balanced', 'C': 5.380000000000001})
2025-03-15 23:29:49,835:INFO:Checking exceptions
2025-03-15 23:29:49,835:INFO:Importing libraries
2025-03-15 23:29:49,836:INFO:Copying training dataset
2025-03-15 23:29:49,840:INFO:Defining folds
2025-03-15 23:29:49,840:INFO:Declaring metric variables
2025-03-15 23:29:49,840:INFO:Importing untrained model
2025-03-15 23:29:49,840:INFO:Declaring custom model
2025-03-15 23:29:49,841:INFO:Logistic Regression Imported successfully
2025-03-15 23:29:49,841:INFO:Starting cross validation
2025-03-15 23:29:49,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:50,206:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,206:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,215:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,221:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,222:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,223:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,233:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,234:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,243:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,243:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,313:INFO:Calculating mean and std
2025-03-15 23:29:50,314:INFO:Creating metrics dataframe
2025-03-15 23:29:50,315:INFO:Finalizing model
2025-03-15 23:29:50,503:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,504:INFO:Uploading results into container
2025-03-15 23:29:50,504:INFO:Uploading model into container now
2025-03-15 23:29:50,505:INFO:_master_model_container: 15
2025-03-15 23:29:50,505:INFO:_display_container: 3
2025-03-15 23:29:50,505:INFO:LogisticRegression(C=5.380000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:29:50,505:INFO:create_model() successfully completed......................................
2025-03-15 23:29:50,617:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:50,617:INFO:choose_better activated
2025-03-15 23:29:50,619:INFO:SubProcess create_model() called ==================================
2025-03-15 23:29:50,619:INFO:Initializing create_model()
2025-03-15 23:29:50,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:29:50,619:INFO:Checking exceptions
2025-03-15 23:29:50,620:INFO:Importing libraries
2025-03-15 23:29:50,620:INFO:Copying training dataset
2025-03-15 23:29:50,624:INFO:Defining folds
2025-03-15 23:29:50,624:INFO:Declaring metric variables
2025-03-15 23:29:50,624:INFO:Importing untrained model
2025-03-15 23:29:50,624:INFO:Declaring custom model
2025-03-15 23:29:50,625:INFO:Logistic Regression Imported successfully
2025-03-15 23:29:50,625:INFO:Starting cross validation
2025-03-15 23:29:50,626:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:29:50,987:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,987:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,988:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,988:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,989:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,989:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:50,993:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:51,000:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:51,004:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:51,012:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:51,087:INFO:Calculating mean and std
2025-03-15 23:29:51,087:INFO:Creating metrics dataframe
2025-03-15 23:29:51,089:INFO:Finalizing model
2025-03-15 23:29:51,287:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:29:51,287:INFO:Uploading results into container
2025-03-15 23:29:51,287:INFO:Uploading model into container now
2025-03-15 23:29:51,289:INFO:_master_model_container: 16
2025-03-15 23:29:51,289:INFO:_display_container: 4
2025-03-15 23:29:51,289:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:29:51,289:INFO:create_model() successfully completed......................................
2025-03-15 23:29:51,379:INFO:SubProcess create_model() end ==================================
2025-03-15 23:29:51,380:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8362
2025-03-15 23:29:51,380:INFO:LogisticRegression(C=5.380000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8427
2025-03-15 23:29:51,381:INFO:LogisticRegression(C=5.380000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-03-15 23:29:51,381:INFO:choose_better completed
2025-03-15 23:29:51,391:INFO:_master_model_container: 16
2025-03-15 23:29:51,391:INFO:_display_container: 3
2025-03-15 23:29:51,391:INFO:LogisticRegression(C=5.380000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:29:51,391:INFO:tune_model() successfully completed......................................
2025-03-15 23:29:51,504:INFO:Initializing save_model()
2025-03-15 23:29:51,505:INFO:save_model(model=LogisticRegression(C=5.380000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-15 23:29:51,505:INFO:Adding model into prep_pipe
2025-03-15 23:29:51,516:INFO:best_classifier.pkl saved in current working directory
2025-03-15 23:29:51,539:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=5.380000000000001,
                                    class_weight='balanced', dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=3008,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-15 23:29:51,539:INFO:save_model() successfully completed......................................
2025-03-15 23:29:51,631:INFO:Initializing interpret_model()
2025-03-15 23:29:51,631:INFO:interpret_model(estimator=LogisticRegression(C=5.380000000000001, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3008, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), use_train_data=False, X_new_sample=None, y_new_sample=None, feature=None, kwargs={}, observation=None, plot=summary, save=False, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001A474726C20>)
2025-03-15 23:29:51,632:INFO:Checking exceptions
2025-03-15 23:29:51,632:ERROR:
'shap' is a soft dependency and not included in the pycaret installation. Please run: `pip install shap` to install.
Alternately, you can install this by running `pip install pycaret[analysis]`
NoneType: None
2025-03-15 23:32:43,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:32:43,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:32:43,863:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:32:43,864:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:33:07,318:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:33:07,319:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:33:07,319:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:33:07,319:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:33:21,472:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001E5EF9D4870, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-03-15 23:33:40,554:INFO:PyCaret ClassificationExperiment
2025-03-15 23:33:40,554:INFO:Logging name: clf-default-name
2025-03-15 23:33:40,554:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-15 23:33:40,555:INFO:version 3.3.2
2025-03-15 23:33:40,555:INFO:Initializing setup()
2025-03-15 23:33:40,555:INFO:self.USI: 37dd
2025-03-15 23:33:40,555:INFO:self._variable_keys: {'X_test', 'target_param', 'html_param', '_available_plots', 'fix_imbalance', 'data', 'y_test', 'logging_param', 'exp_name_log', 'seed', 'fold_shuffle_param', 'is_multiclass', 'idx', 'USI', 'gpu_param', 'exp_id', 'memory', 'fold_generator', 'gpu_n_jobs_param', 'pipeline', 'y_train', 'y', 'X', 'X_train', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'n_jobs_param'}
2025-03-15 23:33:40,555:INFO:Checking environment
2025-03-15 23:33:40,555:INFO:python_version: 3.10.0
2025-03-15 23:33:40,555:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-15 23:33:40,555:INFO:machine: AMD64
2025-03-15 23:33:40,574:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-15 23:33:40,581:INFO:Memory: svmem(total=17037209600, available=4341420032, percent=74.5, used=12695789568, free=4341420032)
2025-03-15 23:33:40,581:INFO:Physical Core: 6
2025-03-15 23:33:40,581:INFO:Logical Core: 12
2025-03-15 23:33:40,581:INFO:Checking libraries
2025-03-15 23:33:40,582:INFO:System:
2025-03-15 23:33:40,582:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-15 23:33:40,582:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-15 23:33:40,582:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-15 23:33:40,582:INFO:PyCaret required dependencies:
2025-03-15 23:33:40,612:INFO:                 pip: 21.2.3
2025-03-15 23:33:40,612:INFO:          setuptools: 57.4.0
2025-03-15 23:33:40,612:INFO:             pycaret: 3.3.2
2025-03-15 23:33:40,613:INFO:             IPython: 8.29.0
2025-03-15 23:33:40,613:INFO:          ipywidgets: 8.1.5
2025-03-15 23:33:40,613:INFO:                tqdm: 4.67.0
2025-03-15 23:33:40,613:INFO:               numpy: 1.26.4
2025-03-15 23:33:40,613:INFO:              pandas: 2.1.4
2025-03-15 23:33:40,613:INFO:              jinja2: 3.1.4
2025-03-15 23:33:40,613:INFO:               scipy: 1.11.4
2025-03-15 23:33:40,613:INFO:              joblib: 1.3.2
2025-03-15 23:33:40,613:INFO:             sklearn: 1.4.2
2025-03-15 23:33:40,613:INFO:                pyod: 2.0.2
2025-03-15 23:33:40,613:INFO:            imblearn: 0.12.4
2025-03-15 23:33:40,613:INFO:   category_encoders: 2.6.4
2025-03-15 23:33:40,613:INFO:            lightgbm: 4.5.0
2025-03-15 23:33:40,613:INFO:               numba: 0.60.0
2025-03-15 23:33:40,613:INFO:            requests: 2.32.3
2025-03-15 23:33:40,613:INFO:          matplotlib: 3.7.5
2025-03-15 23:33:40,613:INFO:          scikitplot: 0.3.7
2025-03-15 23:33:40,613:INFO:         yellowbrick: 1.5
2025-03-15 23:33:40,613:INFO:              plotly: 5.24.1
2025-03-15 23:33:40,613:INFO:    plotly-resampler: Not installed
2025-03-15 23:33:40,613:INFO:             kaleido: 0.2.1
2025-03-15 23:33:40,613:INFO:           schemdraw: 0.15
2025-03-15 23:33:40,613:INFO:         statsmodels: 0.14.4
2025-03-15 23:33:40,613:INFO:              sktime: 0.26.0
2025-03-15 23:33:40,613:INFO:               tbats: 1.1.3
2025-03-15 23:33:40,614:INFO:            pmdarima: 2.0.4
2025-03-15 23:33:40,614:INFO:              psutil: 6.1.0
2025-03-15 23:33:40,614:INFO:          markupsafe: 3.0.2
2025-03-15 23:33:40,614:INFO:             pickle5: Not installed
2025-03-15 23:33:40,614:INFO:         cloudpickle: 3.1.0
2025-03-15 23:33:40,614:INFO:         deprecation: 2.1.0
2025-03-15 23:33:40,614:INFO:              xxhash: 3.5.0
2025-03-15 23:33:40,614:INFO:           wurlitzer: Not installed
2025-03-15 23:33:40,614:INFO:PyCaret optional dependencies:
2025-03-15 23:33:40,628:INFO:                shap: 0.47.0
2025-03-15 23:33:40,628:INFO:           interpret: Not installed
2025-03-15 23:33:40,628:INFO:                umap: Not installed
2025-03-15 23:33:40,628:INFO:     ydata_profiling: 4.12.0
2025-03-15 23:33:40,628:INFO:  explainerdashboard: Not installed
2025-03-15 23:33:40,628:INFO:             autoviz: Not installed
2025-03-15 23:33:40,628:INFO:           fairlearn: Not installed
2025-03-15 23:33:40,628:INFO:          deepchecks: Not installed
2025-03-15 23:33:40,628:INFO:             xgboost: Not installed
2025-03-15 23:33:40,628:INFO:            catboost: Not installed
2025-03-15 23:33:40,628:INFO:              kmodes: Not installed
2025-03-15 23:33:40,628:INFO:             mlxtend: Not installed
2025-03-15 23:33:40,628:INFO:       statsforecast: Not installed
2025-03-15 23:33:40,628:INFO:        tune_sklearn: Not installed
2025-03-15 23:33:40,628:INFO:                 ray: Not installed
2025-03-15 23:33:40,628:INFO:            hyperopt: Not installed
2025-03-15 23:33:40,628:INFO:              optuna: Not installed
2025-03-15 23:33:40,628:INFO:               skopt: Not installed
2025-03-15 23:33:40,628:INFO:              mlflow: Not installed
2025-03-15 23:33:40,628:INFO:              gradio: Not installed
2025-03-15 23:33:40,628:INFO:             fastapi: Not installed
2025-03-15 23:33:40,628:INFO:             uvicorn: Not installed
2025-03-15 23:33:40,628:INFO:              m2cgen: Not installed
2025-03-15 23:33:40,628:INFO:           evidently: Not installed
2025-03-15 23:33:40,628:INFO:               fugue: Not installed
2025-03-15 23:33:40,628:INFO:           streamlit: 1.40.0
2025-03-15 23:33:40,629:INFO:             prophet: Not installed
2025-03-15 23:33:40,629:INFO:None
2025-03-15 23:33:40,629:INFO:Set up data.
2025-03-15 23:33:40,636:INFO:Set up folding strategy.
2025-03-15 23:33:40,636:INFO:Set up train/test split.
2025-03-15 23:33:40,642:INFO:Set up index.
2025-03-15 23:33:40,643:INFO:Assigning column types.
2025-03-15 23:33:40,646:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-15 23:33:40,691:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:33:40,695:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:33:40,728:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:40,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:40,770:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:33:40,771:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:33:40,796:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:40,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:40,797:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-15 23:33:40,840:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:33:40,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:40,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:40,909:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-15 23:33:40,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:40,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:40,936:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-15 23:33:41,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:41,005:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:41,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:41,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:41,076:INFO:Preparing preprocessing pipeline...
2025-03-15 23:33:41,077:INFO:Set up simple imputation.
2025-03-15 23:33:41,080:INFO:Set up encoding of ordinal features.
2025-03-15 23:33:41,081:INFO:Set up encoding of categorical features.
2025-03-15 23:33:41,206:INFO:Finished creating preprocessing pipeline.
2025-03-15 23:33:41,227:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-03-15 23:33:41,227:INFO:Creating final display dataframe.
2025-03-15 23:33:41,628:INFO:Setup _display_container:                     Description             Value
0                    Session id              1489
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              37dd
2025-03-15 23:33:41,706:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:41,706:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:41,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:41,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:33:41,779:INFO:setup() successfully completed in 1.23s...............
2025-03-15 23:33:41,779:INFO:Initializing compare_models()
2025-03-15 23:33:41,779:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-15 23:33:41,779:INFO:Checking exceptions
2025-03-15 23:33:41,783:INFO:Preparing display monitor
2025-03-15 23:33:41,785:INFO:Initializing Logistic Regression
2025-03-15 23:33:41,785:INFO:Total runtime is 0.0 minutes
2025-03-15 23:33:41,785:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:41,786:INFO:Initializing create_model()
2025-03-15 23:33:41,786:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:41,786:INFO:Checking exceptions
2025-03-15 23:33:41,786:INFO:Importing libraries
2025-03-15 23:33:41,786:INFO:Copying training dataset
2025-03-15 23:33:41,790:INFO:Defining folds
2025-03-15 23:33:41,790:INFO:Declaring metric variables
2025-03-15 23:33:41,790:INFO:Importing untrained model
2025-03-15 23:33:41,791:INFO:Logistic Regression Imported successfully
2025-03-15 23:33:41,791:INFO:Starting cross validation
2025-03-15 23:33:41,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:47,176:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,208:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,216:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,225:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,234:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,255:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,268:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,307:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,309:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,313:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:47,416:INFO:Calculating mean and std
2025-03-15 23:33:47,418:INFO:Creating metrics dataframe
2025-03-15 23:33:47,421:INFO:Uploading results into container
2025-03-15 23:33:47,422:INFO:Uploading model into container now
2025-03-15 23:33:47,423:INFO:_master_model_container: 1
2025-03-15 23:33:47,423:INFO:_display_container: 2
2025-03-15 23:33:47,423:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:33:47,424:INFO:create_model() successfully completed......................................
2025-03-15 23:33:47,559:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:47,559:INFO:Creating metrics dataframe
2025-03-15 23:33:47,561:INFO:Initializing K Neighbors Classifier
2025-03-15 23:33:47,561:INFO:Total runtime is 0.09626232385635376 minutes
2025-03-15 23:33:47,561:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:47,562:INFO:Initializing create_model()
2025-03-15 23:33:47,562:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:47,562:INFO:Checking exceptions
2025-03-15 23:33:47,562:INFO:Importing libraries
2025-03-15 23:33:47,562:INFO:Copying training dataset
2025-03-15 23:33:47,566:INFO:Defining folds
2025-03-15 23:33:47,566:INFO:Declaring metric variables
2025-03-15 23:33:47,567:INFO:Importing untrained model
2025-03-15 23:33:47,567:INFO:K Neighbors Classifier Imported successfully
2025-03-15 23:33:47,567:INFO:Starting cross validation
2025-03-15 23:33:47,568:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:49,993:INFO:Calculating mean and std
2025-03-15 23:33:49,994:INFO:Creating metrics dataframe
2025-03-15 23:33:49,997:INFO:Uploading results into container
2025-03-15 23:33:49,998:INFO:Uploading model into container now
2025-03-15 23:33:49,998:INFO:_master_model_container: 2
2025-03-15 23:33:49,999:INFO:_display_container: 2
2025-03-15 23:33:50,000:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-15 23:33:50,000:INFO:create_model() successfully completed......................................
2025-03-15 23:33:50,104:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:50,104:INFO:Creating metrics dataframe
2025-03-15 23:33:50,107:INFO:Initializing Naive Bayes
2025-03-15 23:33:50,107:INFO:Total runtime is 0.1386877497037252 minutes
2025-03-15 23:33:50,107:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:50,108:INFO:Initializing create_model()
2025-03-15 23:33:50,108:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:50,108:INFO:Checking exceptions
2025-03-15 23:33:50,108:INFO:Importing libraries
2025-03-15 23:33:50,108:INFO:Copying training dataset
2025-03-15 23:33:50,112:INFO:Defining folds
2025-03-15 23:33:50,112:INFO:Declaring metric variables
2025-03-15 23:33:50,112:INFO:Importing untrained model
2025-03-15 23:33:50,112:INFO:Naive Bayes Imported successfully
2025-03-15 23:33:50,113:INFO:Starting cross validation
2025-03-15 23:33:50,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:50,378:INFO:Calculating mean and std
2025-03-15 23:33:50,379:INFO:Creating metrics dataframe
2025-03-15 23:33:50,380:INFO:Uploading results into container
2025-03-15 23:33:50,380:INFO:Uploading model into container now
2025-03-15 23:33:50,381:INFO:_master_model_container: 3
2025-03-15 23:33:50,381:INFO:_display_container: 2
2025-03-15 23:33:50,381:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-15 23:33:50,381:INFO:create_model() successfully completed......................................
2025-03-15 23:33:50,478:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:50,478:INFO:Creating metrics dataframe
2025-03-15 23:33:50,481:INFO:Initializing Decision Tree Classifier
2025-03-15 23:33:50,481:INFO:Total runtime is 0.14492905934651693 minutes
2025-03-15 23:33:50,481:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:50,481:INFO:Initializing create_model()
2025-03-15 23:33:50,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:50,481:INFO:Checking exceptions
2025-03-15 23:33:50,482:INFO:Importing libraries
2025-03-15 23:33:50,482:INFO:Copying training dataset
2025-03-15 23:33:50,486:INFO:Defining folds
2025-03-15 23:33:50,486:INFO:Declaring metric variables
2025-03-15 23:33:50,486:INFO:Importing untrained model
2025-03-15 23:33:50,487:INFO:Decision Tree Classifier Imported successfully
2025-03-15 23:33:50,487:INFO:Starting cross validation
2025-03-15 23:33:50,488:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:50,716:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,720:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,722:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,722:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,723:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,724:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,725:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,726:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,727:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,736:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:50,752:INFO:Calculating mean and std
2025-03-15 23:33:50,753:INFO:Creating metrics dataframe
2025-03-15 23:33:50,754:INFO:Uploading results into container
2025-03-15 23:33:50,755:INFO:Uploading model into container now
2025-03-15 23:33:50,755:INFO:_master_model_container: 4
2025-03-15 23:33:50,755:INFO:_display_container: 2
2025-03-15 23:33:50,755:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=1489, splitter='best')
2025-03-15 23:33:50,755:INFO:create_model() successfully completed......................................
2025-03-15 23:33:50,854:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:50,854:INFO:Creating metrics dataframe
2025-03-15 23:33:50,857:INFO:Initializing SVM - Linear Kernel
2025-03-15 23:33:50,857:INFO:Total runtime is 0.15119584798812866 minutes
2025-03-15 23:33:50,857:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:50,858:INFO:Initializing create_model()
2025-03-15 23:33:50,858:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:50,858:INFO:Checking exceptions
2025-03-15 23:33:50,858:INFO:Importing libraries
2025-03-15 23:33:50,858:INFO:Copying training dataset
2025-03-15 23:33:50,863:INFO:Defining folds
2025-03-15 23:33:50,863:INFO:Declaring metric variables
2025-03-15 23:33:50,863:INFO:Importing untrained model
2025-03-15 23:33:50,863:INFO:SVM - Linear Kernel Imported successfully
2025-03-15 23:33:50,864:INFO:Starting cross validation
2025-03-15 23:33:50,865:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:51,122:INFO:Calculating mean and std
2025-03-15 23:33:51,123:INFO:Creating metrics dataframe
2025-03-15 23:33:51,124:INFO:Uploading results into container
2025-03-15 23:33:51,125:INFO:Uploading model into container now
2025-03-15 23:33:51,125:INFO:_master_model_container: 5
2025-03-15 23:33:51,125:INFO:_display_container: 2
2025-03-15 23:33:51,125:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=1489, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-15 23:33:51,125:INFO:create_model() successfully completed......................................
2025-03-15 23:33:51,221:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:51,221:INFO:Creating metrics dataframe
2025-03-15 23:33:51,225:INFO:Initializing Ridge Classifier
2025-03-15 23:33:51,225:INFO:Total runtime is 0.15732934077580768 minutes
2025-03-15 23:33:51,225:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:51,225:INFO:Initializing create_model()
2025-03-15 23:33:51,225:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:51,226:INFO:Checking exceptions
2025-03-15 23:33:51,226:INFO:Importing libraries
2025-03-15 23:33:51,226:INFO:Copying training dataset
2025-03-15 23:33:51,230:INFO:Defining folds
2025-03-15 23:33:51,230:INFO:Declaring metric variables
2025-03-15 23:33:51,230:INFO:Importing untrained model
2025-03-15 23:33:51,231:INFO:Ridge Classifier Imported successfully
2025-03-15 23:33:51,231:INFO:Starting cross validation
2025-03-15 23:33:51,232:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:51,487:INFO:Calculating mean and std
2025-03-15 23:33:51,488:INFO:Creating metrics dataframe
2025-03-15 23:33:51,489:INFO:Uploading results into container
2025-03-15 23:33:51,490:INFO:Uploading model into container now
2025-03-15 23:33:51,490:INFO:_master_model_container: 6
2025-03-15 23:33:51,490:INFO:_display_container: 2
2025-03-15 23:33:51,490:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=1489, solver='auto',
                tol=0.0001)
2025-03-15 23:33:51,491:INFO:create_model() successfully completed......................................
2025-03-15 23:33:51,586:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:51,586:INFO:Creating metrics dataframe
2025-03-15 23:33:51,589:INFO:Initializing Random Forest Classifier
2025-03-15 23:33:51,589:INFO:Total runtime is 0.16340064207712807 minutes
2025-03-15 23:33:51,589:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:51,589:INFO:Initializing create_model()
2025-03-15 23:33:51,589:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:51,589:INFO:Checking exceptions
2025-03-15 23:33:51,589:INFO:Importing libraries
2025-03-15 23:33:51,589:INFO:Copying training dataset
2025-03-15 23:33:51,594:INFO:Defining folds
2025-03-15 23:33:51,594:INFO:Declaring metric variables
2025-03-15 23:33:51,594:INFO:Importing untrained model
2025-03-15 23:33:51,595:INFO:Random Forest Classifier Imported successfully
2025-03-15 23:33:51,595:INFO:Starting cross validation
2025-03-15 23:33:51,595:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:52,139:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,145:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,156:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,157:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,157:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,198:INFO:Calculating mean and std
2025-03-15 23:33:52,199:INFO:Creating metrics dataframe
2025-03-15 23:33:52,200:INFO:Uploading results into container
2025-03-15 23:33:52,201:INFO:Uploading model into container now
2025-03-15 23:33:52,201:INFO:_master_model_container: 7
2025-03-15 23:33:52,201:INFO:_display_container: 2
2025-03-15 23:33:52,201:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=1489, verbose=0,
                       warm_start=False)
2025-03-15 23:33:52,201:INFO:create_model() successfully completed......................................
2025-03-15 23:33:52,298:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:52,298:INFO:Creating metrics dataframe
2025-03-15 23:33:52,301:INFO:Initializing Quadratic Discriminant Analysis
2025-03-15 23:33:52,302:INFO:Total runtime is 0.17526892423629759 minutes
2025-03-15 23:33:52,302:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:52,302:INFO:Initializing create_model()
2025-03-15 23:33:52,302:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:52,302:INFO:Checking exceptions
2025-03-15 23:33:52,302:INFO:Importing libraries
2025-03-15 23:33:52,303:INFO:Copying training dataset
2025-03-15 23:33:52,306:INFO:Defining folds
2025-03-15 23:33:52,307:INFO:Declaring metric variables
2025-03-15 23:33:52,307:INFO:Importing untrained model
2025-03-15 23:33:52,307:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-15 23:33:52,307:INFO:Starting cross validation
2025-03-15 23:33:52,308:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:52,468:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:33:52,478:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:33:52,481:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:33:52,482:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:33:52,486:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:33:52,487:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:33:52,489:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:33:52,494:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:33:52,496:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-15 23:33:52,536:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,550:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,551:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,555:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,557:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,557:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,558:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,561:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,561:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,574:INFO:Calculating mean and std
2025-03-15 23:33:52,575:INFO:Creating metrics dataframe
2025-03-15 23:33:52,576:INFO:Uploading results into container
2025-03-15 23:33:52,577:INFO:Uploading model into container now
2025-03-15 23:33:52,577:INFO:_master_model_container: 8
2025-03-15 23:33:52,577:INFO:_display_container: 2
2025-03-15 23:33:52,577:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-15 23:33:52,577:INFO:create_model() successfully completed......................................
2025-03-15 23:33:52,674:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:52,674:INFO:Creating metrics dataframe
2025-03-15 23:33:52,676:INFO:Initializing Ada Boost Classifier
2025-03-15 23:33:52,677:INFO:Total runtime is 0.18152086734771727 minutes
2025-03-15 23:33:52,677:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:52,677:INFO:Initializing create_model()
2025-03-15 23:33:52,677:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:52,677:INFO:Checking exceptions
2025-03-15 23:33:52,677:INFO:Importing libraries
2025-03-15 23:33:52,677:INFO:Copying training dataset
2025-03-15 23:33:52,682:INFO:Defining folds
2025-03-15 23:33:52,682:INFO:Declaring metric variables
2025-03-15 23:33:52,682:INFO:Importing untrained model
2025-03-15 23:33:52,682:INFO:Ada Boost Classifier Imported successfully
2025-03-15 23:33:52,683:INFO:Starting cross validation
2025-03-15 23:33:52,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:52,841:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,843:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,844:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,846:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,849:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,852:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,852:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,858:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,858:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,865:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-15 23:33:52,915:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,917:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,923:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,923:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,925:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,926:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,930:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,932:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,934:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,934:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:52,948:INFO:Calculating mean and std
2025-03-15 23:33:52,948:INFO:Creating metrics dataframe
2025-03-15 23:33:52,950:INFO:Uploading results into container
2025-03-15 23:33:52,951:INFO:Uploading model into container now
2025-03-15 23:33:52,951:INFO:_master_model_container: 9
2025-03-15 23:33:52,951:INFO:_display_container: 2
2025-03-15 23:33:52,951:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=1489)
2025-03-15 23:33:52,952:INFO:create_model() successfully completed......................................
2025-03-15 23:33:53,058:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:53,058:INFO:Creating metrics dataframe
2025-03-15 23:33:53,062:INFO:Initializing Gradient Boosting Classifier
2025-03-15 23:33:53,062:INFO:Total runtime is 0.18794341882069904 minutes
2025-03-15 23:33:53,062:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:53,062:INFO:Initializing create_model()
2025-03-15 23:33:53,062:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:53,062:INFO:Checking exceptions
2025-03-15 23:33:53,062:INFO:Importing libraries
2025-03-15 23:33:53,062:INFO:Copying training dataset
2025-03-15 23:33:53,067:INFO:Defining folds
2025-03-15 23:33:53,067:INFO:Declaring metric variables
2025-03-15 23:33:53,067:INFO:Importing untrained model
2025-03-15 23:33:53,068:INFO:Gradient Boosting Classifier Imported successfully
2025-03-15 23:33:53,068:INFO:Starting cross validation
2025-03-15 23:33:53,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:53,429:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,433:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,434:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,436:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,439:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,444:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,456:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,456:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,465:INFO:Calculating mean and std
2025-03-15 23:33:53,466:INFO:Creating metrics dataframe
2025-03-15 23:33:53,467:INFO:Uploading results into container
2025-03-15 23:33:53,468:INFO:Uploading model into container now
2025-03-15 23:33:53,468:INFO:_master_model_container: 10
2025-03-15 23:33:53,468:INFO:_display_container: 2
2025-03-15 23:33:53,468:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=1489, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-15 23:33:53,468:INFO:create_model() successfully completed......................................
2025-03-15 23:33:53,570:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:53,570:INFO:Creating metrics dataframe
2025-03-15 23:33:53,573:INFO:Initializing Linear Discriminant Analysis
2025-03-15 23:33:53,573:INFO:Total runtime is 0.1964644352595011 minutes
2025-03-15 23:33:53,573:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:53,573:INFO:Initializing create_model()
2025-03-15 23:33:53,573:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:53,573:INFO:Checking exceptions
2025-03-15 23:33:53,573:INFO:Importing libraries
2025-03-15 23:33:53,573:INFO:Copying training dataset
2025-03-15 23:33:53,577:INFO:Defining folds
2025-03-15 23:33:53,577:INFO:Declaring metric variables
2025-03-15 23:33:53,578:INFO:Importing untrained model
2025-03-15 23:33:53,578:INFO:Linear Discriminant Analysis Imported successfully
2025-03-15 23:33:53,578:INFO:Starting cross validation
2025-03-15 23:33:53,580:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:53,792:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,803:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,808:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,810:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,816:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,818:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,820:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,820:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,826:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:53,833:INFO:Calculating mean and std
2025-03-15 23:33:53,834:INFO:Creating metrics dataframe
2025-03-15 23:33:53,835:INFO:Uploading results into container
2025-03-15 23:33:53,836:INFO:Uploading model into container now
2025-03-15 23:33:53,836:INFO:_master_model_container: 11
2025-03-15 23:33:53,836:INFO:_display_container: 2
2025-03-15 23:33:53,836:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-15 23:33:53,837:INFO:create_model() successfully completed......................................
2025-03-15 23:33:53,930:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:53,930:INFO:Creating metrics dataframe
2025-03-15 23:33:53,933:INFO:Initializing Extra Trees Classifier
2025-03-15 23:33:53,933:INFO:Total runtime is 0.20246481895446775 minutes
2025-03-15 23:33:53,933:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:53,933:INFO:Initializing create_model()
2025-03-15 23:33:53,933:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:53,933:INFO:Checking exceptions
2025-03-15 23:33:53,933:INFO:Importing libraries
2025-03-15 23:33:53,933:INFO:Copying training dataset
2025-03-15 23:33:53,937:INFO:Defining folds
2025-03-15 23:33:53,937:INFO:Declaring metric variables
2025-03-15 23:33:53,938:INFO:Importing untrained model
2025-03-15 23:33:53,938:INFO:Extra Trees Classifier Imported successfully
2025-03-15 23:33:53,938:INFO:Starting cross validation
2025-03-15 23:33:53,939:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:54,499:INFO:Calculating mean and std
2025-03-15 23:33:54,500:INFO:Creating metrics dataframe
2025-03-15 23:33:54,502:INFO:Uploading results into container
2025-03-15 23:33:54,502:INFO:Uploading model into container now
2025-03-15 23:33:54,502:INFO:_master_model_container: 12
2025-03-15 23:33:54,502:INFO:_display_container: 2
2025-03-15 23:33:54,503:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=1489, verbose=0,
                     warm_start=False)
2025-03-15 23:33:54,503:INFO:create_model() successfully completed......................................
2025-03-15 23:33:54,600:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:54,601:INFO:Creating metrics dataframe
2025-03-15 23:33:54,603:INFO:Initializing Light Gradient Boosting Machine
2025-03-15 23:33:54,603:INFO:Total runtime is 0.2136316617329915 minutes
2025-03-15 23:33:54,603:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:54,603:INFO:Initializing create_model()
2025-03-15 23:33:54,603:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:54,603:INFO:Checking exceptions
2025-03-15 23:33:54,603:INFO:Importing libraries
2025-03-15 23:33:54,603:INFO:Copying training dataset
2025-03-15 23:33:54,608:INFO:Defining folds
2025-03-15 23:33:54,608:INFO:Declaring metric variables
2025-03-15 23:33:54,608:INFO:Importing untrained model
2025-03-15 23:33:54,608:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 23:33:54,608:INFO:Starting cross validation
2025-03-15 23:33:54,609:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:55,469:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,524:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,554:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,636:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,710:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,720:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,819:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,870:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,885:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,898:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:55,909:INFO:Calculating mean and std
2025-03-15 23:33:55,910:INFO:Creating metrics dataframe
2025-03-15 23:33:55,912:INFO:Uploading results into container
2025-03-15 23:33:55,913:INFO:Uploading model into container now
2025-03-15 23:33:55,914:INFO:_master_model_container: 13
2025-03-15 23:33:55,914:INFO:_display_container: 2
2025-03-15 23:33:55,914:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=1489, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-15 23:33:55,914:INFO:create_model() successfully completed......................................
2025-03-15 23:33:56,031:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:56,031:INFO:Creating metrics dataframe
2025-03-15 23:33:56,033:INFO:Initializing Dummy Classifier
2025-03-15 23:33:56,033:INFO:Total runtime is 0.23745696544647213 minutes
2025-03-15 23:33:56,033:INFO:SubProcess create_model() called ==================================
2025-03-15 23:33:56,033:INFO:Initializing create_model()
2025-03-15 23:33:56,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6A8C160>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:56,034:INFO:Checking exceptions
2025-03-15 23:33:56,034:INFO:Importing libraries
2025-03-15 23:33:56,034:INFO:Copying training dataset
2025-03-15 23:33:56,038:INFO:Defining folds
2025-03-15 23:33:56,038:INFO:Declaring metric variables
2025-03-15 23:33:56,038:INFO:Importing untrained model
2025-03-15 23:33:56,038:INFO:Dummy Classifier Imported successfully
2025-03-15 23:33:56,039:INFO:Starting cross validation
2025-03-15 23:33:56,041:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:33:56,277:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,287:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,290:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,292:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,298:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,301:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,301:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,306:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,311:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,311:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-15 23:33:56,328:INFO:Calculating mean and std
2025-03-15 23:33:56,328:INFO:Creating metrics dataframe
2025-03-15 23:33:56,330:INFO:Uploading results into container
2025-03-15 23:33:56,330:INFO:Uploading model into container now
2025-03-15 23:33:56,331:INFO:_master_model_container: 14
2025-03-15 23:33:56,331:INFO:_display_container: 2
2025-03-15 23:33:56,331:INFO:DummyClassifier(constant=None, random_state=1489, strategy='prior')
2025-03-15 23:33:56,331:INFO:create_model() successfully completed......................................
2025-03-15 23:33:56,432:INFO:SubProcess create_model() end ==================================
2025-03-15 23:33:56,432:INFO:Creating metrics dataframe
2025-03-15 23:33:56,436:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-15 23:33:56,438:INFO:Initializing create_model()
2025-03-15 23:33:56,438:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:33:56,438:INFO:Checking exceptions
2025-03-15 23:33:56,439:INFO:Importing libraries
2025-03-15 23:33:56,439:INFO:Copying training dataset
2025-03-15 23:33:56,444:INFO:Defining folds
2025-03-15 23:33:56,444:INFO:Declaring metric variables
2025-03-15 23:33:56,444:INFO:Importing untrained model
2025-03-15 23:33:56,444:INFO:Declaring custom model
2025-03-15 23:33:56,445:INFO:Logistic Regression Imported successfully
2025-03-15 23:33:56,446:INFO:Cross validation set to False
2025-03-15 23:33:56,447:INFO:Fitting Model
2025-03-15 23:33:56,639:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:56,640:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:33:56,640:INFO:create_model() successfully completed......................................
2025-03-15 23:33:56,743:INFO:_master_model_container: 14
2025-03-15 23:33:56,743:INFO:_display_container: 2
2025-03-15 23:33:56,744:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:33:56,744:INFO:compare_models() successfully completed......................................
2025-03-15 23:33:56,744:INFO:Initializing tune_model()
2025-03-15 23:33:56,744:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>)
2025-03-15 23:33:56,744:INFO:Checking exceptions
2025-03-15 23:33:56,747:INFO:Copying training dataset
2025-03-15 23:33:56,750:INFO:Checking base model
2025-03-15 23:33:56,750:INFO:Base model : Logistic Regression
2025-03-15 23:33:56,751:INFO:Declaring metric variables
2025-03-15 23:33:56,751:INFO:Defining Hyperparameters
2025-03-15 23:33:56,846:INFO:Tuning with n_jobs=-1
2025-03-15 23:33:56,846:INFO:Initializing RandomizedSearchCV
2025-03-15 23:33:57,241:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,264:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,266:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,267:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,301:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,304:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,310:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,320:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,402:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,435:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,456:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,461:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,665:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,699:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,727:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,733:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,764:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,783:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,822:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:57,852:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,044:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,047:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,069:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,077:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,119:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,172:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,178:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,235:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,241:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,253:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,304:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,384:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,510:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,541:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,557:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,612:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,645:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,650:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,652:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,677:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,681:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,766:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,816:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,935:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:58,996:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,013:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,037:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,040:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,076:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,123:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,140:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,224:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,245:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,280:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,369:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,415:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,478:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,481:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,494:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,497:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,557:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,608:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,615:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,690:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,790:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,807:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,884:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,891:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,898:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,920:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,972:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:33:59,985:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,054:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,064:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,157:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,176:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,251:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,350:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,355:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,378:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,411:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,431:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,460:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,490:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,517:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,597:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,662:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,699:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,724:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,783:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,802:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,821:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,847:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,892:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,930:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,944:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:00,961:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,021:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,053:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 4.276}
2025-03-15 23:34:01,053:INFO:Hyperparameter search completed
2025-03-15 23:34:01,053:INFO:SubProcess create_model() called ==================================
2025-03-15 23:34:01,054:INFO:Initializing create_model()
2025-03-15 23:34:01,054:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F6836B90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 4.276})
2025-03-15 23:34:01,054:INFO:Checking exceptions
2025-03-15 23:34:01,054:INFO:Importing libraries
2025-03-15 23:34:01,054:INFO:Copying training dataset
2025-03-15 23:34:01,060:INFO:Defining folds
2025-03-15 23:34:01,060:INFO:Declaring metric variables
2025-03-15 23:34:01,060:INFO:Importing untrained model
2025-03-15 23:34:01,060:INFO:Declaring custom model
2025-03-15 23:34:01,061:INFO:Logistic Regression Imported successfully
2025-03-15 23:34:01,061:INFO:Starting cross validation
2025-03-15 23:34:01,062:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:34:01,420:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,431:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,431:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,437:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,439:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,447:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,447:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,455:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,462:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,533:INFO:Calculating mean and std
2025-03-15 23:34:01,534:INFO:Creating metrics dataframe
2025-03-15 23:34:01,535:INFO:Finalizing model
2025-03-15 23:34:01,724:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:01,725:INFO:Uploading results into container
2025-03-15 23:34:01,726:INFO:Uploading model into container now
2025-03-15 23:34:01,726:INFO:_master_model_container: 15
2025-03-15 23:34:01,726:INFO:_display_container: 3
2025-03-15 23:34:01,726:INFO:LogisticRegression(C=4.276, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:34:01,726:INFO:create_model() successfully completed......................................
2025-03-15 23:34:01,824:INFO:SubProcess create_model() end ==================================
2025-03-15 23:34:01,824:INFO:choose_better activated
2025-03-15 23:34:01,824:INFO:SubProcess create_model() called ==================================
2025-03-15 23:34:01,825:INFO:Initializing create_model()
2025-03-15 23:34:01,825:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:34:01,825:INFO:Checking exceptions
2025-03-15 23:34:01,826:INFO:Importing libraries
2025-03-15 23:34:01,826:INFO:Copying training dataset
2025-03-15 23:34:01,830:INFO:Defining folds
2025-03-15 23:34:01,830:INFO:Declaring metric variables
2025-03-15 23:34:01,830:INFO:Importing untrained model
2025-03-15 23:34:01,830:INFO:Declaring custom model
2025-03-15 23:34:01,831:INFO:Logistic Regression Imported successfully
2025-03-15 23:34:01,831:INFO:Starting cross validation
2025-03-15 23:34:01,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:34:02,194:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,195:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,205:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,205:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,207:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,207:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,211:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,217:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,219:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,223:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,300:INFO:Calculating mean and std
2025-03-15 23:34:02,300:INFO:Creating metrics dataframe
2025-03-15 23:34:02,303:INFO:Finalizing model
2025-03-15 23:34:02,496:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-15 23:34:02,497:INFO:Uploading results into container
2025-03-15 23:34:02,497:INFO:Uploading model into container now
2025-03-15 23:34:02,498:INFO:_master_model_container: 16
2025-03-15 23:34:02,498:INFO:_display_container: 4
2025-03-15 23:34:02,498:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:34:02,498:INFO:create_model() successfully completed......................................
2025-03-15 23:34:02,592:INFO:SubProcess create_model() end ==================================
2025-03-15 23:34:02,593:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8121
2025-03-15 23:34:02,593:INFO:LogisticRegression(C=4.276, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8153
2025-03-15 23:34:02,594:INFO:LogisticRegression(C=4.276, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-03-15 23:34:02,594:INFO:choose_better completed
2025-03-15 23:34:02,602:INFO:_master_model_container: 16
2025-03-15 23:34:02,602:INFO:_display_container: 3
2025-03-15 23:34:02,602:INFO:LogisticRegression(C=4.276, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-15 23:34:02,602:INFO:tune_model() successfully completed......................................
2025-03-15 23:34:02,718:INFO:Initializing save_model()
2025-03-15 23:34:02,719:INFO:save_model(model=LogisticRegression(C=4.276, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=1489, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-15 23:34:02,719:INFO:Adding model into prep_pipe
2025-03-15 23:34:02,729:INFO:best_classifier.pkl saved in current working directory
2025-03-15 23:34:02,749:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=4.276, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=1489,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-15 23:34:02,749:INFO:save_model() successfully completed......................................
2025-03-15 23:34:30,943:INFO:Initializing load_model()
2025-03-15 23:34:30,943:INFO:load_model(model_name=best_classifier, platform=None, authentication=None, verbose=True)
2025-03-15 23:34:30,983:INFO:Initializing predict_model()
2025-03-15 23:34:30,984:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E5BC047760>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(C=4.276, class_weight={}, max_iter=1000,
                                    random_state=1489))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E5F3392170>)
2025-03-15 23:34:30,985:INFO:Checking exceptions
2025-03-15 23:34:30,985:INFO:Preloading libraries
2025-03-15 23:34:30,985:INFO:Set up data.
2025-03-15 23:34:30,993:INFO:Set up index.
2025-03-15 23:35:13,108:INFO:PyCaret RegressionExperiment
2025-03-15 23:35:13,108:INFO:Logging name: reg-default-name
2025-03-15 23:35:13,109:INFO:ML Usecase: MLUsecase.REGRESSION
2025-03-15 23:35:13,109:INFO:version 3.3.2
2025-03-15 23:35:13,109:INFO:Initializing setup()
2025-03-15 23:35:13,109:INFO:self.USI: 7e4b
2025-03-15 23:35:13,110:INFO:self._variable_keys: {'X_test', 'target_param', 'html_param', '_available_plots', 'data', 'y_test', 'logging_param', 'exp_name_log', 'seed', 'fold_shuffle_param', 'idx', 'transform_target_param', 'USI', 'gpu_param', 'exp_id', 'memory', 'fold_generator', 'gpu_n_jobs_param', 'pipeline', 'y_train', 'y', 'X', 'X_train', 'log_plots_param', 'fold_groups_param', '_ml_usecase', 'n_jobs_param'}
2025-03-15 23:35:13,110:INFO:Checking environment
2025-03-15 23:35:13,110:INFO:python_version: 3.10.0
2025-03-15 23:35:13,110:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-15 23:35:13,110:INFO:machine: AMD64
2025-03-15 23:35:13,110:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-15 23:35:13,115:INFO:Memory: svmem(total=17037209600, available=5038313472, percent=70.4, used=11998896128, free=5038313472)
2025-03-15 23:35:13,115:INFO:Physical Core: 6
2025-03-15 23:35:13,115:INFO:Logical Core: 12
2025-03-15 23:35:13,115:INFO:Checking libraries
2025-03-15 23:35:13,115:INFO:System:
2025-03-15 23:35:13,116:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-15 23:35:13,116:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-15 23:35:13,116:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-15 23:35:13,116:INFO:PyCaret required dependencies:
2025-03-15 23:35:13,116:INFO:                 pip: 21.2.3
2025-03-15 23:35:13,116:INFO:          setuptools: 57.4.0
2025-03-15 23:35:13,116:INFO:             pycaret: 3.3.2
2025-03-15 23:35:13,116:INFO:             IPython: 8.29.0
2025-03-15 23:35:13,116:INFO:          ipywidgets: 8.1.5
2025-03-15 23:35:13,116:INFO:                tqdm: 4.67.0
2025-03-15 23:35:13,116:INFO:               numpy: 1.26.4
2025-03-15 23:35:13,116:INFO:              pandas: 2.1.4
2025-03-15 23:35:13,116:INFO:              jinja2: 3.1.4
2025-03-15 23:35:13,116:INFO:               scipy: 1.11.4
2025-03-15 23:35:13,116:INFO:              joblib: 1.3.2
2025-03-15 23:35:13,116:INFO:             sklearn: 1.4.2
2025-03-15 23:35:13,116:INFO:                pyod: 2.0.2
2025-03-15 23:35:13,116:INFO:            imblearn: 0.12.4
2025-03-15 23:35:13,116:INFO:   category_encoders: 2.6.4
2025-03-15 23:35:13,116:INFO:            lightgbm: 4.5.0
2025-03-15 23:35:13,116:INFO:               numba: 0.60.0
2025-03-15 23:35:13,116:INFO:            requests: 2.32.3
2025-03-15 23:35:13,117:INFO:          matplotlib: 3.7.5
2025-03-15 23:35:13,117:INFO:          scikitplot: 0.3.7
2025-03-15 23:35:13,117:INFO:         yellowbrick: 1.5
2025-03-15 23:35:13,117:INFO:              plotly: 5.24.1
2025-03-15 23:35:13,117:INFO:    plotly-resampler: Not installed
2025-03-15 23:35:13,117:INFO:             kaleido: 0.2.1
2025-03-15 23:35:13,117:INFO:           schemdraw: 0.15
2025-03-15 23:35:13,117:INFO:         statsmodels: 0.14.4
2025-03-15 23:35:13,117:INFO:              sktime: 0.26.0
2025-03-15 23:35:13,117:INFO:               tbats: 1.1.3
2025-03-15 23:35:13,117:INFO:            pmdarima: 2.0.4
2025-03-15 23:35:13,117:INFO:              psutil: 6.1.0
2025-03-15 23:35:13,117:INFO:          markupsafe: 3.0.2
2025-03-15 23:35:13,117:INFO:             pickle5: Not installed
2025-03-15 23:35:13,117:INFO:         cloudpickle: 3.1.0
2025-03-15 23:35:13,117:INFO:         deprecation: 2.1.0
2025-03-15 23:35:13,117:INFO:              xxhash: 3.5.0
2025-03-15 23:35:13,118:INFO:           wurlitzer: Not installed
2025-03-15 23:35:13,118:INFO:PyCaret optional dependencies:
2025-03-15 23:35:13,118:INFO:                shap: 0.47.0
2025-03-15 23:35:13,118:INFO:           interpret: Not installed
2025-03-15 23:35:13,118:INFO:                umap: Not installed
2025-03-15 23:35:13,118:INFO:     ydata_profiling: 4.12.0
2025-03-15 23:35:13,118:INFO:  explainerdashboard: Not installed
2025-03-15 23:35:13,118:INFO:             autoviz: Not installed
2025-03-15 23:35:13,118:INFO:           fairlearn: Not installed
2025-03-15 23:35:13,118:INFO:          deepchecks: Not installed
2025-03-15 23:35:13,118:INFO:             xgboost: Not installed
2025-03-15 23:35:13,118:INFO:            catboost: Not installed
2025-03-15 23:35:13,118:INFO:              kmodes: Not installed
2025-03-15 23:35:13,118:INFO:             mlxtend: Not installed
2025-03-15 23:35:13,118:INFO:       statsforecast: Not installed
2025-03-15 23:35:13,118:INFO:        tune_sklearn: Not installed
2025-03-15 23:35:13,118:INFO:                 ray: Not installed
2025-03-15 23:35:13,118:INFO:            hyperopt: Not installed
2025-03-15 23:35:13,118:INFO:              optuna: Not installed
2025-03-15 23:35:13,118:INFO:               skopt: Not installed
2025-03-15 23:35:13,118:INFO:              mlflow: Not installed
2025-03-15 23:35:13,118:INFO:              gradio: Not installed
2025-03-15 23:35:13,118:INFO:             fastapi: Not installed
2025-03-15 23:35:13,118:INFO:             uvicorn: Not installed
2025-03-15 23:35:13,118:INFO:              m2cgen: Not installed
2025-03-15 23:35:13,118:INFO:           evidently: Not installed
2025-03-15 23:35:13,118:INFO:               fugue: Not installed
2025-03-15 23:35:13,118:INFO:           streamlit: 1.40.0
2025-03-15 23:35:13,118:INFO:             prophet: Not installed
2025-03-15 23:35:13,118:INFO:None
2025-03-15 23:35:13,118:INFO:Set up data.
2025-03-15 23:35:13,125:INFO:Set up folding strategy.
2025-03-15 23:35:13,125:INFO:Set up train/test split.
2025-03-15 23:35:13,131:INFO:Set up index.
2025-03-15 23:35:13,132:INFO:Assigning column types.
2025-03-15 23:35:13,135:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-15 23:35:13,135:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,140:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,145:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,206:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,252:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,253:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,257:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,262:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,357:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,358:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,359:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-03-15 23:35:13,364:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,422:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,464:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,470:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,475:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,531:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,575:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,576:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-03-15 23:35:13,585:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,638:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,683:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,693:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,788:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,789:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,789:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-03-15 23:35:13,852:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:35:13,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:13,958:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:14,000:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-15 23:35:14,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,001:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-15 23:35:14,065:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:14,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,177:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-03-15 23:35:14,218:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,220:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-03-15 23:35:14,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,434:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,436:INFO:Preparing preprocessing pipeline...
2025-03-15 23:35:14,436:INFO:Set up simple imputation.
2025-03-15 23:35:14,440:INFO:Set up encoding of ordinal features.
2025-03-15 23:35:14,446:INFO:Set up encoding of categorical features.
2025-03-15 23:35:14,539:INFO:Finished creating preprocessing pipeline.
2025-03-15 23:35:14,624:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-03-15 23:35:14,624:INFO:Creating final display dataframe.
2025-03-15 23:35:14,874:INFO:Setup _display_container:                     Description             Value
0                    Session id              3198
1                        Target             price
2                   Target type        Regression
3           Original data shape         (545, 13)
4        Transformed data shape         (545, 15)
5   Transformed train set shape         (381, 15)
6    Transformed test set shape         (164, 15)
7              Numeric features                 5
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              7e4b
2025-03-15 23:35:14,986:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:14,987:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:15,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:15,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-15 23:35:15,092:INFO:setup() successfully completed in 1.99s...............
2025-03-15 23:35:15,092:INFO:Initializing compare_models()
2025-03-15 23:35:15,092:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-03-15 23:35:15,092:INFO:Checking exceptions
2025-03-15 23:35:15,094:INFO:Preparing display monitor
2025-03-15 23:35:15,096:INFO:Initializing Linear Regression
2025-03-15 23:35:15,096:INFO:Total runtime is 0.0 minutes
2025-03-15 23:35:15,096:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:15,097:INFO:Initializing create_model()
2025-03-15 23:35:15,097:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:15,097:INFO:Checking exceptions
2025-03-15 23:35:15,097:INFO:Importing libraries
2025-03-15 23:35:15,097:INFO:Copying training dataset
2025-03-15 23:35:15,100:INFO:Defining folds
2025-03-15 23:35:15,100:INFO:Declaring metric variables
2025-03-15 23:35:15,100:INFO:Importing untrained model
2025-03-15 23:35:15,101:INFO:Linear Regression Imported successfully
2025-03-15 23:35:15,101:INFO:Starting cross validation
2025-03-15 23:35:15,102:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:15,345:INFO:Calculating mean and std
2025-03-15 23:35:15,346:INFO:Creating metrics dataframe
2025-03-15 23:35:15,347:INFO:Uploading results into container
2025-03-15 23:35:15,348:INFO:Uploading model into container now
2025-03-15 23:35:15,348:INFO:_master_model_container: 1
2025-03-15 23:35:15,348:INFO:_display_container: 2
2025-03-15 23:35:15,348:INFO:LinearRegression(n_jobs=-1)
2025-03-15 23:35:15,348:INFO:create_model() successfully completed......................................
2025-03-15 23:35:15,452:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:15,452:INFO:Creating metrics dataframe
2025-03-15 23:35:15,454:INFO:Initializing Lasso Regression
2025-03-15 23:35:15,454:INFO:Total runtime is 0.005957265694936116 minutes
2025-03-15 23:35:15,454:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:15,455:INFO:Initializing create_model()
2025-03-15 23:35:15,455:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:15,455:INFO:Checking exceptions
2025-03-15 23:35:15,455:INFO:Importing libraries
2025-03-15 23:35:15,455:INFO:Copying training dataset
2025-03-15 23:35:15,459:INFO:Defining folds
2025-03-15 23:35:15,459:INFO:Declaring metric variables
2025-03-15 23:35:15,459:INFO:Importing untrained model
2025-03-15 23:35:15,460:INFO:Lasso Regression Imported successfully
2025-03-15 23:35:15,460:INFO:Starting cross validation
2025-03-15 23:35:15,462:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:15,639:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.725e+13, tolerance: 1.268e+11
  model = cd_fast.enet_coordinate_descent(

2025-03-15 23:35:15,716:INFO:Calculating mean and std
2025-03-15 23:35:15,716:INFO:Creating metrics dataframe
2025-03-15 23:35:15,718:INFO:Uploading results into container
2025-03-15 23:35:15,718:INFO:Uploading model into container now
2025-03-15 23:35:15,719:INFO:_master_model_container: 2
2025-03-15 23:35:15,719:INFO:_display_container: 2
2025-03-15 23:35:15,720:INFO:Lasso(random_state=3198)
2025-03-15 23:35:15,720:INFO:create_model() successfully completed......................................
2025-03-15 23:35:15,813:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:15,813:INFO:Creating metrics dataframe
2025-03-15 23:35:15,816:INFO:Initializing Ridge Regression
2025-03-15 23:35:15,816:INFO:Total runtime is 0.01198973258336385 minutes
2025-03-15 23:35:15,816:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:15,816:INFO:Initializing create_model()
2025-03-15 23:35:15,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:15,817:INFO:Checking exceptions
2025-03-15 23:35:15,817:INFO:Importing libraries
2025-03-15 23:35:15,817:INFO:Copying training dataset
2025-03-15 23:35:15,821:INFO:Defining folds
2025-03-15 23:35:15,821:INFO:Declaring metric variables
2025-03-15 23:35:15,821:INFO:Importing untrained model
2025-03-15 23:35:15,821:INFO:Ridge Regression Imported successfully
2025-03-15 23:35:15,821:INFO:Starting cross validation
2025-03-15 23:35:15,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:16,085:INFO:Calculating mean and std
2025-03-15 23:35:16,086:INFO:Creating metrics dataframe
2025-03-15 23:35:16,087:INFO:Uploading results into container
2025-03-15 23:35:16,088:INFO:Uploading model into container now
2025-03-15 23:35:16,088:INFO:_master_model_container: 3
2025-03-15 23:35:16,088:INFO:_display_container: 2
2025-03-15 23:35:16,088:INFO:Ridge(random_state=3198)
2025-03-15 23:35:16,088:INFO:create_model() successfully completed......................................
2025-03-15 23:35:16,185:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:16,185:INFO:Creating metrics dataframe
2025-03-15 23:35:16,188:INFO:Initializing Elastic Net
2025-03-15 23:35:16,188:INFO:Total runtime is 0.018200973669687905 minutes
2025-03-15 23:35:16,188:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:16,188:INFO:Initializing create_model()
2025-03-15 23:35:16,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:16,188:INFO:Checking exceptions
2025-03-15 23:35:16,188:INFO:Importing libraries
2025-03-15 23:35:16,188:INFO:Copying training dataset
2025-03-15 23:35:16,193:INFO:Defining folds
2025-03-15 23:35:16,193:INFO:Declaring metric variables
2025-03-15 23:35:16,193:INFO:Importing untrained model
2025-03-15 23:35:16,193:INFO:Elastic Net Imported successfully
2025-03-15 23:35:16,194:INFO:Starting cross validation
2025-03-15 23:35:16,195:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:16,445:INFO:Calculating mean and std
2025-03-15 23:35:16,446:INFO:Creating metrics dataframe
2025-03-15 23:35:16,447:INFO:Uploading results into container
2025-03-15 23:35:16,448:INFO:Uploading model into container now
2025-03-15 23:35:16,448:INFO:_master_model_container: 4
2025-03-15 23:35:16,448:INFO:_display_container: 2
2025-03-15 23:35:16,448:INFO:ElasticNet(random_state=3198)
2025-03-15 23:35:16,448:INFO:create_model() successfully completed......................................
2025-03-15 23:35:16,551:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:16,551:INFO:Creating metrics dataframe
2025-03-15 23:35:16,553:INFO:Initializing Least Angle Regression
2025-03-15 23:35:16,553:INFO:Total runtime is 0.024288173516591387 minutes
2025-03-15 23:35:16,554:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:16,554:INFO:Initializing create_model()
2025-03-15 23:35:16,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:16,554:INFO:Checking exceptions
2025-03-15 23:35:16,554:INFO:Importing libraries
2025-03-15 23:35:16,554:INFO:Copying training dataset
2025-03-15 23:35:16,559:INFO:Defining folds
2025-03-15 23:35:16,559:INFO:Declaring metric variables
2025-03-15 23:35:16,559:INFO:Importing untrained model
2025-03-15 23:35:16,559:INFO:Least Angle Regression Imported successfully
2025-03-15 23:35:16,559:INFO:Starting cross validation
2025-03-15 23:35:16,562:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:16,811:INFO:Calculating mean and std
2025-03-15 23:35:16,812:INFO:Creating metrics dataframe
2025-03-15 23:35:16,814:INFO:Uploading results into container
2025-03-15 23:35:16,814:INFO:Uploading model into container now
2025-03-15 23:35:16,814:INFO:_master_model_container: 5
2025-03-15 23:35:16,814:INFO:_display_container: 2
2025-03-15 23:35:16,815:INFO:Lars(random_state=3198)
2025-03-15 23:35:16,815:INFO:create_model() successfully completed......................................
2025-03-15 23:35:16,918:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:16,918:INFO:Creating metrics dataframe
2025-03-15 23:35:16,920:INFO:Initializing Lasso Least Angle Regression
2025-03-15 23:35:16,920:INFO:Total runtime is 0.03039145469665527 minutes
2025-03-15 23:35:16,921:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:16,921:INFO:Initializing create_model()
2025-03-15 23:35:16,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:16,921:INFO:Checking exceptions
2025-03-15 23:35:16,921:INFO:Importing libraries
2025-03-15 23:35:16,921:INFO:Copying training dataset
2025-03-15 23:35:16,925:INFO:Defining folds
2025-03-15 23:35:16,925:INFO:Declaring metric variables
2025-03-15 23:35:16,925:INFO:Importing untrained model
2025-03-15 23:35:16,926:INFO:Lasso Least Angle Regression Imported successfully
2025-03-15 23:35:16,926:INFO:Starting cross validation
2025-03-15 23:35:16,927:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:17,181:INFO:Calculating mean and std
2025-03-15 23:35:17,182:INFO:Creating metrics dataframe
2025-03-15 23:35:17,183:INFO:Uploading results into container
2025-03-15 23:35:17,183:INFO:Uploading model into container now
2025-03-15 23:35:17,184:INFO:_master_model_container: 6
2025-03-15 23:35:17,184:INFO:_display_container: 2
2025-03-15 23:35:17,184:INFO:LassoLars(random_state=3198)
2025-03-15 23:35:17,184:INFO:create_model() successfully completed......................................
2025-03-15 23:35:17,282:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:17,283:INFO:Creating metrics dataframe
2025-03-15 23:35:17,285:INFO:Initializing Orthogonal Matching Pursuit
2025-03-15 23:35:17,285:INFO:Total runtime is 0.03648860454559326 minutes
2025-03-15 23:35:17,286:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:17,286:INFO:Initializing create_model()
2025-03-15 23:35:17,286:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:17,286:INFO:Checking exceptions
2025-03-15 23:35:17,286:INFO:Importing libraries
2025-03-15 23:35:17,286:INFO:Copying training dataset
2025-03-15 23:35:17,290:INFO:Defining folds
2025-03-15 23:35:17,291:INFO:Declaring metric variables
2025-03-15 23:35:17,291:INFO:Importing untrained model
2025-03-15 23:35:17,291:INFO:Orthogonal Matching Pursuit Imported successfully
2025-03-15 23:35:17,291:INFO:Starting cross validation
2025-03-15 23:35:17,292:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:17,539:INFO:Calculating mean and std
2025-03-15 23:35:17,540:INFO:Creating metrics dataframe
2025-03-15 23:35:17,542:INFO:Uploading results into container
2025-03-15 23:35:17,542:INFO:Uploading model into container now
2025-03-15 23:35:17,542:INFO:_master_model_container: 7
2025-03-15 23:35:17,542:INFO:_display_container: 2
2025-03-15 23:35:17,543:INFO:OrthogonalMatchingPursuit()
2025-03-15 23:35:17,543:INFO:create_model() successfully completed......................................
2025-03-15 23:35:17,647:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:17,647:INFO:Creating metrics dataframe
2025-03-15 23:35:17,650:INFO:Initializing Bayesian Ridge
2025-03-15 23:35:17,650:INFO:Total runtime is 0.04256163835525512 minutes
2025-03-15 23:35:17,650:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:17,651:INFO:Initializing create_model()
2025-03-15 23:35:17,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:17,651:INFO:Checking exceptions
2025-03-15 23:35:17,651:INFO:Importing libraries
2025-03-15 23:35:17,651:INFO:Copying training dataset
2025-03-15 23:35:17,656:INFO:Defining folds
2025-03-15 23:35:17,656:INFO:Declaring metric variables
2025-03-15 23:35:17,656:INFO:Importing untrained model
2025-03-15 23:35:17,656:INFO:Bayesian Ridge Imported successfully
2025-03-15 23:35:17,656:INFO:Starting cross validation
2025-03-15 23:35:17,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:17,907:INFO:Calculating mean and std
2025-03-15 23:35:17,908:INFO:Creating metrics dataframe
2025-03-15 23:35:17,910:INFO:Uploading results into container
2025-03-15 23:35:17,910:INFO:Uploading model into container now
2025-03-15 23:35:17,910:INFO:_master_model_container: 8
2025-03-15 23:35:17,911:INFO:_display_container: 2
2025-03-15 23:35:17,911:INFO:BayesianRidge()
2025-03-15 23:35:17,911:INFO:create_model() successfully completed......................................
2025-03-15 23:35:18,010:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:18,011:INFO:Creating metrics dataframe
2025-03-15 23:35:18,013:INFO:Initializing Passive Aggressive Regressor
2025-03-15 23:35:18,013:INFO:Total runtime is 0.04861867427825927 minutes
2025-03-15 23:35:18,013:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:18,014:INFO:Initializing create_model()
2025-03-15 23:35:18,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:18,014:INFO:Checking exceptions
2025-03-15 23:35:18,014:INFO:Importing libraries
2025-03-15 23:35:18,014:INFO:Copying training dataset
2025-03-15 23:35:18,018:INFO:Defining folds
2025-03-15 23:35:18,018:INFO:Declaring metric variables
2025-03-15 23:35:18,018:INFO:Importing untrained model
2025-03-15 23:35:18,018:INFO:Passive Aggressive Regressor Imported successfully
2025-03-15 23:35:18,019:INFO:Starting cross validation
2025-03-15 23:35:18,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:18,279:INFO:Calculating mean and std
2025-03-15 23:35:18,280:INFO:Creating metrics dataframe
2025-03-15 23:35:18,281:INFO:Uploading results into container
2025-03-15 23:35:18,282:INFO:Uploading model into container now
2025-03-15 23:35:18,282:INFO:_master_model_container: 9
2025-03-15 23:35:18,282:INFO:_display_container: 2
2025-03-15 23:35:18,282:INFO:PassiveAggressiveRegressor(random_state=3198)
2025-03-15 23:35:18,282:INFO:create_model() successfully completed......................................
2025-03-15 23:35:18,379:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:18,379:INFO:Creating metrics dataframe
2025-03-15 23:35:18,382:INFO:Initializing Huber Regressor
2025-03-15 23:35:18,382:INFO:Total runtime is 0.054767564932505286 minutes
2025-03-15 23:35:18,382:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:18,382:INFO:Initializing create_model()
2025-03-15 23:35:18,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:18,382:INFO:Checking exceptions
2025-03-15 23:35:18,382:INFO:Importing libraries
2025-03-15 23:35:18,382:INFO:Copying training dataset
2025-03-15 23:35:18,386:INFO:Defining folds
2025-03-15 23:35:18,386:INFO:Declaring metric variables
2025-03-15 23:35:18,386:INFO:Importing untrained model
2025-03-15 23:35:18,387:INFO:Huber Regressor Imported successfully
2025-03-15 23:35:18,387:INFO:Starting cross validation
2025-03-15 23:35:18,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:18,572:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-03-15 23:35:18,660:INFO:Calculating mean and std
2025-03-15 23:35:18,662:INFO:Creating metrics dataframe
2025-03-15 23:35:18,667:INFO:Uploading results into container
2025-03-15 23:35:18,668:INFO:Uploading model into container now
2025-03-15 23:35:18,670:INFO:_master_model_container: 10
2025-03-15 23:35:18,670:INFO:_display_container: 2
2025-03-15 23:35:18,671:INFO:HuberRegressor()
2025-03-15 23:35:18,671:INFO:create_model() successfully completed......................................
2025-03-15 23:35:18,783:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:18,783:INFO:Creating metrics dataframe
2025-03-15 23:35:18,785:INFO:Initializing K Neighbors Regressor
2025-03-15 23:35:18,785:INFO:Total runtime is 0.061484456062316895 minutes
2025-03-15 23:35:18,786:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:18,786:INFO:Initializing create_model()
2025-03-15 23:35:18,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:18,786:INFO:Checking exceptions
2025-03-15 23:35:18,786:INFO:Importing libraries
2025-03-15 23:35:18,786:INFO:Copying training dataset
2025-03-15 23:35:18,790:INFO:Defining folds
2025-03-15 23:35:18,790:INFO:Declaring metric variables
2025-03-15 23:35:18,790:INFO:Importing untrained model
2025-03-15 23:35:18,790:INFO:K Neighbors Regressor Imported successfully
2025-03-15 23:35:18,791:INFO:Starting cross validation
2025-03-15 23:35:18,792:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:19,064:INFO:Calculating mean and std
2025-03-15 23:35:19,065:INFO:Creating metrics dataframe
2025-03-15 23:35:19,066:INFO:Uploading results into container
2025-03-15 23:35:19,066:INFO:Uploading model into container now
2025-03-15 23:35:19,067:INFO:_master_model_container: 11
2025-03-15 23:35:19,067:INFO:_display_container: 2
2025-03-15 23:35:19,067:INFO:KNeighborsRegressor(n_jobs=-1)
2025-03-15 23:35:19,067:INFO:create_model() successfully completed......................................
2025-03-15 23:35:19,176:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:19,176:INFO:Creating metrics dataframe
2025-03-15 23:35:19,179:INFO:Initializing Decision Tree Regressor
2025-03-15 23:35:19,179:INFO:Total runtime is 0.06805500586827597 minutes
2025-03-15 23:35:19,179:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:19,179:INFO:Initializing create_model()
2025-03-15 23:35:19,181:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:19,181:INFO:Checking exceptions
2025-03-15 23:35:19,181:INFO:Importing libraries
2025-03-15 23:35:19,181:INFO:Copying training dataset
2025-03-15 23:35:19,185:INFO:Defining folds
2025-03-15 23:35:19,185:INFO:Declaring metric variables
2025-03-15 23:35:19,185:INFO:Importing untrained model
2025-03-15 23:35:19,186:INFO:Decision Tree Regressor Imported successfully
2025-03-15 23:35:19,186:INFO:Starting cross validation
2025-03-15 23:35:19,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:19,440:INFO:Calculating mean and std
2025-03-15 23:35:19,441:INFO:Creating metrics dataframe
2025-03-15 23:35:19,442:INFO:Uploading results into container
2025-03-15 23:35:19,443:INFO:Uploading model into container now
2025-03-15 23:35:19,443:INFO:_master_model_container: 12
2025-03-15 23:35:19,443:INFO:_display_container: 2
2025-03-15 23:35:19,443:INFO:DecisionTreeRegressor(random_state=3198)
2025-03-15 23:35:19,443:INFO:create_model() successfully completed......................................
2025-03-15 23:35:19,544:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:19,544:INFO:Creating metrics dataframe
2025-03-15 23:35:19,546:INFO:Initializing Random Forest Regressor
2025-03-15 23:35:19,546:INFO:Total runtime is 0.07416791518529257 minutes
2025-03-15 23:35:19,546:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:19,547:INFO:Initializing create_model()
2025-03-15 23:35:19,547:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:19,547:INFO:Checking exceptions
2025-03-15 23:35:19,547:INFO:Importing libraries
2025-03-15 23:35:19,547:INFO:Copying training dataset
2025-03-15 23:35:19,551:INFO:Defining folds
2025-03-15 23:35:19,552:INFO:Declaring metric variables
2025-03-15 23:35:19,552:INFO:Importing untrained model
2025-03-15 23:35:19,552:INFO:Random Forest Regressor Imported successfully
2025-03-15 23:35:19,552:INFO:Starting cross validation
2025-03-15 23:35:19,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:20,166:INFO:Calculating mean and std
2025-03-15 23:35:20,167:INFO:Creating metrics dataframe
2025-03-15 23:35:20,168:INFO:Uploading results into container
2025-03-15 23:35:20,169:INFO:Uploading model into container now
2025-03-15 23:35:20,170:INFO:_master_model_container: 13
2025-03-15 23:35:20,170:INFO:_display_container: 2
2025-03-15 23:35:20,170:INFO:RandomForestRegressor(n_jobs=-1, random_state=3198)
2025-03-15 23:35:20,170:INFO:create_model() successfully completed......................................
2025-03-15 23:35:20,269:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:20,269:INFO:Creating metrics dataframe
2025-03-15 23:35:20,272:INFO:Initializing Extra Trees Regressor
2025-03-15 23:35:20,272:INFO:Total runtime is 0.08626713355382284 minutes
2025-03-15 23:35:20,272:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:20,272:INFO:Initializing create_model()
2025-03-15 23:35:20,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:20,272:INFO:Checking exceptions
2025-03-15 23:35:20,273:INFO:Importing libraries
2025-03-15 23:35:20,273:INFO:Copying training dataset
2025-03-15 23:35:20,277:INFO:Defining folds
2025-03-15 23:35:20,277:INFO:Declaring metric variables
2025-03-15 23:35:20,277:INFO:Importing untrained model
2025-03-15 23:35:20,277:INFO:Extra Trees Regressor Imported successfully
2025-03-15 23:35:20,278:INFO:Starting cross validation
2025-03-15 23:35:20,279:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:20,823:INFO:Calculating mean and std
2025-03-15 23:35:20,824:INFO:Creating metrics dataframe
2025-03-15 23:35:20,825:INFO:Uploading results into container
2025-03-15 23:35:20,826:INFO:Uploading model into container now
2025-03-15 23:35:20,826:INFO:_master_model_container: 14
2025-03-15 23:35:20,826:INFO:_display_container: 2
2025-03-15 23:35:20,827:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=3198)
2025-03-15 23:35:20,827:INFO:create_model() successfully completed......................................
2025-03-15 23:35:20,926:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:20,926:INFO:Creating metrics dataframe
2025-03-15 23:35:20,929:INFO:Initializing AdaBoost Regressor
2025-03-15 23:35:20,929:INFO:Total runtime is 0.09721718231836955 minutes
2025-03-15 23:35:20,929:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:20,929:INFO:Initializing create_model()
2025-03-15 23:35:20,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:20,929:INFO:Checking exceptions
2025-03-15 23:35:20,929:INFO:Importing libraries
2025-03-15 23:35:20,929:INFO:Copying training dataset
2025-03-15 23:35:20,933:INFO:Defining folds
2025-03-15 23:35:20,933:INFO:Declaring metric variables
2025-03-15 23:35:20,933:INFO:Importing untrained model
2025-03-15 23:35:20,934:INFO:AdaBoost Regressor Imported successfully
2025-03-15 23:35:20,934:INFO:Starting cross validation
2025-03-15 23:35:20,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:21,327:INFO:Calculating mean and std
2025-03-15 23:35:21,331:INFO:Creating metrics dataframe
2025-03-15 23:35:21,337:INFO:Uploading results into container
2025-03-15 23:35:21,338:INFO:Uploading model into container now
2025-03-15 23:35:21,339:INFO:_master_model_container: 15
2025-03-15 23:35:21,339:INFO:_display_container: 2
2025-03-15 23:35:21,340:INFO:AdaBoostRegressor(random_state=3198)
2025-03-15 23:35:21,340:INFO:create_model() successfully completed......................................
2025-03-15 23:35:21,437:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:21,437:INFO:Creating metrics dataframe
2025-03-15 23:35:21,439:INFO:Initializing Gradient Boosting Regressor
2025-03-15 23:35:21,440:INFO:Total runtime is 0.10573772192001343 minutes
2025-03-15 23:35:21,440:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:21,440:INFO:Initializing create_model()
2025-03-15 23:35:21,440:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:21,440:INFO:Checking exceptions
2025-03-15 23:35:21,440:INFO:Importing libraries
2025-03-15 23:35:21,440:INFO:Copying training dataset
2025-03-15 23:35:21,444:INFO:Defining folds
2025-03-15 23:35:21,444:INFO:Declaring metric variables
2025-03-15 23:35:21,444:INFO:Importing untrained model
2025-03-15 23:35:21,445:INFO:Gradient Boosting Regressor Imported successfully
2025-03-15 23:35:21,445:INFO:Starting cross validation
2025-03-15 23:35:21,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:21,807:INFO:Calculating mean and std
2025-03-15 23:35:21,808:INFO:Creating metrics dataframe
2025-03-15 23:35:21,809:INFO:Uploading results into container
2025-03-15 23:35:21,809:INFO:Uploading model into container now
2025-03-15 23:35:21,810:INFO:_master_model_container: 16
2025-03-15 23:35:21,810:INFO:_display_container: 2
2025-03-15 23:35:21,810:INFO:GradientBoostingRegressor(random_state=3198)
2025-03-15 23:35:21,810:INFO:create_model() successfully completed......................................
2025-03-15 23:35:21,906:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:21,906:INFO:Creating metrics dataframe
2025-03-15 23:35:21,909:INFO:Initializing Light Gradient Boosting Machine
2025-03-15 23:35:21,909:INFO:Total runtime is 0.113554052511851 minutes
2025-03-15 23:35:21,909:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:21,909:INFO:Initializing create_model()
2025-03-15 23:35:21,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:21,909:INFO:Checking exceptions
2025-03-15 23:35:21,909:INFO:Importing libraries
2025-03-15 23:35:21,909:INFO:Copying training dataset
2025-03-15 23:35:21,914:INFO:Defining folds
2025-03-15 23:35:21,914:INFO:Declaring metric variables
2025-03-15 23:35:21,914:INFO:Importing untrained model
2025-03-15 23:35:21,915:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-15 23:35:21,915:INFO:Starting cross validation
2025-03-15 23:35:21,916:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:23,042:INFO:Calculating mean and std
2025-03-15 23:35:23,043:INFO:Creating metrics dataframe
2025-03-15 23:35:23,045:INFO:Uploading results into container
2025-03-15 23:35:23,046:INFO:Uploading model into container now
2025-03-15 23:35:23,046:INFO:_master_model_container: 17
2025-03-15 23:35:23,046:INFO:_display_container: 2
2025-03-15 23:35:23,047:INFO:LGBMRegressor(n_jobs=-1, random_state=3198)
2025-03-15 23:35:23,047:INFO:create_model() successfully completed......................................
2025-03-15 23:35:23,164:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:23,164:INFO:Creating metrics dataframe
2025-03-15 23:35:23,167:INFO:Initializing Dummy Regressor
2025-03-15 23:35:23,167:INFO:Total runtime is 0.13452146450678507 minutes
2025-03-15 23:35:23,167:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:23,168:INFO:Initializing create_model()
2025-03-15 23:35:23,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F7C5F730>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:23,168:INFO:Checking exceptions
2025-03-15 23:35:23,168:INFO:Importing libraries
2025-03-15 23:35:23,168:INFO:Copying training dataset
2025-03-15 23:35:23,172:INFO:Defining folds
2025-03-15 23:35:23,172:INFO:Declaring metric variables
2025-03-15 23:35:23,172:INFO:Importing untrained model
2025-03-15 23:35:23,172:INFO:Dummy Regressor Imported successfully
2025-03-15 23:35:23,172:INFO:Starting cross validation
2025-03-15 23:35:23,174:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:23,423:INFO:Calculating mean and std
2025-03-15 23:35:23,424:INFO:Creating metrics dataframe
2025-03-15 23:35:23,425:INFO:Uploading results into container
2025-03-15 23:35:23,425:INFO:Uploading model into container now
2025-03-15 23:35:23,426:INFO:_master_model_container: 18
2025-03-15 23:35:23,426:INFO:_display_container: 2
2025-03-15 23:35:23,426:INFO:DummyRegressor()
2025-03-15 23:35:23,426:INFO:create_model() successfully completed......................................
2025-03-15 23:35:23,530:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:23,530:INFO:Creating metrics dataframe
2025-03-15 23:35:23,533:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-15 23:35:23,534:INFO:Initializing create_model()
2025-03-15 23:35:23,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=Ridge(random_state=3198), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:23,534:INFO:Checking exceptions
2025-03-15 23:35:23,535:INFO:Importing libraries
2025-03-15 23:35:23,535:INFO:Copying training dataset
2025-03-15 23:35:23,539:INFO:Defining folds
2025-03-15 23:35:23,539:INFO:Declaring metric variables
2025-03-15 23:35:23,539:INFO:Importing untrained model
2025-03-15 23:35:23,539:INFO:Declaring custom model
2025-03-15 23:35:23,539:INFO:Ridge Regression Imported successfully
2025-03-15 23:35:23,542:INFO:Cross validation set to False
2025-03-15 23:35:23,542:INFO:Fitting Model
2025-03-15 23:35:23,602:INFO:Ridge(random_state=3198)
2025-03-15 23:35:23,602:INFO:create_model() successfully completed......................................
2025-03-15 23:35:23,711:INFO:_master_model_container: 18
2025-03-15 23:35:23,711:INFO:_display_container: 2
2025-03-15 23:35:23,712:INFO:Ridge(random_state=3198)
2025-03-15 23:35:23,712:INFO:compare_models() successfully completed......................................
2025-03-15 23:35:23,712:INFO:Initializing tune_model()
2025-03-15 23:35:23,712:INFO:tune_model(estimator=Ridge(random_state=3198), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>)
2025-03-15 23:35:23,712:INFO:Checking exceptions
2025-03-15 23:35:23,715:INFO:Copying training dataset
2025-03-15 23:35:23,718:INFO:Checking base model
2025-03-15 23:35:23,718:INFO:Base model : Ridge Regression
2025-03-15 23:35:23,718:INFO:Declaring metric variables
2025-03-15 23:35:23,718:INFO:Defining Hyperparameters
2025-03-15 23:35:23,814:INFO:Tuning with n_jobs=-1
2025-03-15 23:35:23,814:INFO:Initializing RandomizedSearchCV
2025-03-15 23:35:25,814:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.84}
2025-03-15 23:35:25,815:INFO:Hyperparameter search completed
2025-03-15 23:35:25,815:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:25,815:INFO:Initializing create_model()
2025-03-15 23:35:25,815:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=Ridge(random_state=3198), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E5F813BB50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.84})
2025-03-15 23:35:25,816:INFO:Checking exceptions
2025-03-15 23:35:25,816:INFO:Importing libraries
2025-03-15 23:35:25,816:INFO:Copying training dataset
2025-03-15 23:35:25,820:INFO:Defining folds
2025-03-15 23:35:25,820:INFO:Declaring metric variables
2025-03-15 23:35:25,820:INFO:Importing untrained model
2025-03-15 23:35:25,820:INFO:Declaring custom model
2025-03-15 23:35:25,821:INFO:Ridge Regression Imported successfully
2025-03-15 23:35:25,821:INFO:Starting cross validation
2025-03-15 23:35:25,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:26,077:INFO:Calculating mean and std
2025-03-15 23:35:26,078:INFO:Creating metrics dataframe
2025-03-15 23:35:26,079:INFO:Finalizing model
2025-03-15 23:35:26,142:INFO:Uploading results into container
2025-03-15 23:35:26,143:INFO:Uploading model into container now
2025-03-15 23:35:26,143:INFO:_master_model_container: 19
2025-03-15 23:35:26,143:INFO:_display_container: 3
2025-03-15 23:35:26,144:INFO:Ridge(alpha=7.84, fit_intercept=False, random_state=3198)
2025-03-15 23:35:26,144:INFO:create_model() successfully completed......................................
2025-03-15 23:35:26,244:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:26,244:INFO:choose_better activated
2025-03-15 23:35:26,245:INFO:SubProcess create_model() called ==================================
2025-03-15 23:35:26,245:INFO:Initializing create_model()
2025-03-15 23:35:26,245:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=Ridge(random_state=3198), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-15 23:35:26,245:INFO:Checking exceptions
2025-03-15 23:35:26,246:INFO:Importing libraries
2025-03-15 23:35:26,246:INFO:Copying training dataset
2025-03-15 23:35:26,250:INFO:Defining folds
2025-03-15 23:35:26,250:INFO:Declaring metric variables
2025-03-15 23:35:26,250:INFO:Importing untrained model
2025-03-15 23:35:26,251:INFO:Declaring custom model
2025-03-15 23:35:26,251:INFO:Ridge Regression Imported successfully
2025-03-15 23:35:26,251:INFO:Starting cross validation
2025-03-15 23:35:26,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-15 23:35:26,494:INFO:Calculating mean and std
2025-03-15 23:35:26,494:INFO:Creating metrics dataframe
2025-03-15 23:35:26,496:INFO:Finalizing model
2025-03-15 23:35:26,558:INFO:Uploading results into container
2025-03-15 23:35:26,558:INFO:Uploading model into container now
2025-03-15 23:35:26,558:INFO:_master_model_container: 20
2025-03-15 23:35:26,558:INFO:_display_container: 4
2025-03-15 23:35:26,559:INFO:Ridge(random_state=3198)
2025-03-15 23:35:26,559:INFO:create_model() successfully completed......................................
2025-03-15 23:35:26,656:INFO:SubProcess create_model() end ==================================
2025-03-15 23:35:26,657:INFO:Ridge(random_state=3198) result for R2 is 0.6051
2025-03-15 23:35:26,657:INFO:Ridge(alpha=7.84, fit_intercept=False, random_state=3198) result for R2 is 0.61
2025-03-15 23:35:26,657:INFO:Ridge(alpha=7.84, fit_intercept=False, random_state=3198) is best model
2025-03-15 23:35:26,657:INFO:choose_better completed
2025-03-15 23:35:26,667:INFO:_master_model_container: 20
2025-03-15 23:35:26,667:INFO:_display_container: 3
2025-03-15 23:35:26,667:INFO:Ridge(alpha=7.84, fit_intercept=False, random_state=3198)
2025-03-15 23:35:26,667:INFO:tune_model() successfully completed......................................
2025-03-15 23:35:26,883:INFO:Initializing save_model()
2025-03-15 23:35:26,883:INFO:save_model(model=Ridge(alpha=7.84, fit_intercept=False, random_state=3198), model_name=best_regressor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-03-15 23:35:26,883:INFO:Adding model into prep_pipe
2025-03-15 23:35:26,892:INFO:best_regressor.pkl saved in current working directory
2025-03-15 23:35:26,978:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'furnishingstatus'],
                                    transformer=SimpleImput...
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 Ridge(alpha=7.84, fit_intercept=False, random_state=3198))])
2025-03-15 23:35:26,978:INFO:save_model() successfully completed......................................
2025-03-15 23:35:53,208:INFO:Initializing load_model()
2025-03-15 23:35:53,208:INFO:load_model(model_name=best_regressor, platform=None, authentication=None, verbose=True)
2025-03-15 23:35:53,316:INFO:Initializing predict_model()
2025-03-15 23:35:53,316:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001E5F80EEE00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 Ridge(alpha=7.84, fit_intercept=False, random_state=3198))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E5F67805E0>)
2025-03-15 23:35:53,316:INFO:Checking exceptions
2025-03-15 23:35:53,316:INFO:Preloading libraries
2025-03-15 23:35:53,317:INFO:Set up data.
2025-03-15 23:35:53,321:INFO:Set up index.
2025-03-15 23:45:25,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:45:25,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:45:25,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:45:25,251:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:45:27,977:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-03-15 23:46:25,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:46:25,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:46:25,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:46:25,920:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:46:27,110:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-03-15 23:53:35,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:53:35,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:53:35,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:53:35,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-15 23:53:36,377:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-03-16 00:06:44,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-16 00:06:44,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-16 00:06:44,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-16 00:06:44,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-16 00:06:45,721:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-03-16 00:07:19,754:INFO:PyCaret ClusteringExperiment
2025-03-16 00:07:19,754:INFO:Logging name: cluster-default-name
2025-03-16 00:07:19,754:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-03-16 00:07:19,754:INFO:version 3.3.2
2025-03-16 00:07:19,755:INFO:Initializing setup()
2025-03-16 00:07:19,755:INFO:self.USI: 841b
2025-03-16 00:07:19,755:INFO:self._variable_keys: {'memory', 'data', 'USI', 'gpu_param', 'log_plots_param', '_available_plots', 'logging_param', 'n_jobs_param', 'exp_id', 'seed', 'X', 'gpu_n_jobs_param', 'html_param', 'idx', '_ml_usecase', 'exp_name_log', 'pipeline'}
2025-03-16 00:07:19,755:INFO:Checking environment
2025-03-16 00:07:19,755:INFO:python_version: 3.10.0
2025-03-16 00:07:19,755:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-16 00:07:19,755:INFO:machine: AMD64
2025-03-16 00:07:19,767:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-16 00:07:19,774:INFO:Memory: svmem(total=17037209600, available=4426903552, percent=74.0, used=12610306048, free=4426903552)
2025-03-16 00:07:19,774:INFO:Physical Core: 6
2025-03-16 00:07:19,774:INFO:Logical Core: 12
2025-03-16 00:07:19,774:INFO:Checking libraries
2025-03-16 00:07:19,774:INFO:System:
2025-03-16 00:07:19,775:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-16 00:07:19,775:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-16 00:07:19,775:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-16 00:07:19,775:INFO:PyCaret required dependencies:
2025-03-16 00:07:19,805:INFO:                 pip: 21.2.3
2025-03-16 00:07:19,805:INFO:          setuptools: 57.4.0
2025-03-16 00:07:19,805:INFO:             pycaret: 3.3.2
2025-03-16 00:07:19,805:INFO:             IPython: 8.29.0
2025-03-16 00:07:19,805:INFO:          ipywidgets: 8.1.5
2025-03-16 00:07:19,805:INFO:                tqdm: 4.67.0
2025-03-16 00:07:19,805:INFO:               numpy: 1.26.4
2025-03-16 00:07:19,805:INFO:              pandas: 2.1.4
2025-03-16 00:07:19,805:INFO:              jinja2: 3.1.4
2025-03-16 00:07:19,805:INFO:               scipy: 1.11.4
2025-03-16 00:07:19,805:INFO:              joblib: 1.3.2
2025-03-16 00:07:19,805:INFO:             sklearn: 1.4.2
2025-03-16 00:07:19,805:INFO:                pyod: 2.0.2
2025-03-16 00:07:19,805:INFO:            imblearn: 0.12.4
2025-03-16 00:07:19,805:INFO:   category_encoders: 2.6.4
2025-03-16 00:07:19,805:INFO:            lightgbm: 4.5.0
2025-03-16 00:07:19,805:INFO:               numba: 0.60.0
2025-03-16 00:07:19,805:INFO:            requests: 2.32.3
2025-03-16 00:07:19,805:INFO:          matplotlib: 3.7.5
2025-03-16 00:07:19,805:INFO:          scikitplot: 0.3.7
2025-03-16 00:07:19,805:INFO:         yellowbrick: 1.5
2025-03-16 00:07:19,805:INFO:              plotly: 5.24.1
2025-03-16 00:07:19,805:INFO:    plotly-resampler: Not installed
2025-03-16 00:07:19,806:INFO:             kaleido: 0.2.1
2025-03-16 00:07:19,806:INFO:           schemdraw: 0.15
2025-03-16 00:07:19,806:INFO:         statsmodels: 0.14.4
2025-03-16 00:07:19,806:INFO:              sktime: 0.26.0
2025-03-16 00:07:19,806:INFO:               tbats: 1.1.3
2025-03-16 00:07:19,806:INFO:            pmdarima: 2.0.4
2025-03-16 00:07:19,806:INFO:              psutil: 6.1.0
2025-03-16 00:07:19,806:INFO:          markupsafe: 3.0.2
2025-03-16 00:07:19,806:INFO:             pickle5: Not installed
2025-03-16 00:07:19,806:INFO:         cloudpickle: 3.1.0
2025-03-16 00:07:19,806:INFO:         deprecation: 2.1.0
2025-03-16 00:07:19,806:INFO:              xxhash: 3.5.0
2025-03-16 00:07:19,806:INFO:           wurlitzer: Not installed
2025-03-16 00:07:19,806:INFO:PyCaret optional dependencies:
2025-03-16 00:07:19,818:INFO:                shap: 0.47.0
2025-03-16 00:07:19,818:INFO:           interpret: Not installed
2025-03-16 00:07:19,818:INFO:                umap: Not installed
2025-03-16 00:07:19,818:INFO:     ydata_profiling: 4.12.0
2025-03-16 00:07:19,818:INFO:  explainerdashboard: Not installed
2025-03-16 00:07:19,818:INFO:             autoviz: Not installed
2025-03-16 00:07:19,818:INFO:           fairlearn: Not installed
2025-03-16 00:07:19,818:INFO:          deepchecks: Not installed
2025-03-16 00:07:19,818:INFO:             xgboost: Not installed
2025-03-16 00:07:19,818:INFO:            catboost: Not installed
2025-03-16 00:07:19,818:INFO:              kmodes: Not installed
2025-03-16 00:07:19,818:INFO:             mlxtend: Not installed
2025-03-16 00:07:19,818:INFO:       statsforecast: Not installed
2025-03-16 00:07:19,818:INFO:        tune_sklearn: Not installed
2025-03-16 00:07:19,818:INFO:                 ray: Not installed
2025-03-16 00:07:19,818:INFO:            hyperopt: Not installed
2025-03-16 00:07:19,818:INFO:              optuna: Not installed
2025-03-16 00:07:19,818:INFO:               skopt: Not installed
2025-03-16 00:07:19,818:INFO:              mlflow: Not installed
2025-03-16 00:07:19,818:INFO:              gradio: Not installed
2025-03-16 00:07:19,819:INFO:             fastapi: Not installed
2025-03-16 00:07:19,819:INFO:             uvicorn: Not installed
2025-03-16 00:07:19,819:INFO:              m2cgen: Not installed
2025-03-16 00:07:19,819:INFO:           evidently: Not installed
2025-03-16 00:07:19,819:INFO:               fugue: Not installed
2025-03-16 00:07:19,819:INFO:           streamlit: 1.40.0
2025-03-16 00:07:19,819:INFO:             prophet: Not installed
2025-03-16 00:07:19,819:INFO:None
2025-03-16 00:07:19,819:INFO:Set up data.
2025-03-16 00:07:19,821:INFO:Set up index.
2025-03-16 00:07:19,821:INFO:Assigning column types.
2025-03-16 00:07:19,823:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-03-16 00:07:19,823:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-03-16 00:07:19,823:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-16 00:07:19,823:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-03-16 00:07:19,823:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-16 00:07:19,823:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-03-16 00:07:19,823:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-16 00:07:19,824:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-16 00:07:19,825:INFO:Preparing preprocessing pipeline...
2025-03-16 00:07:19,825:INFO:Set up simple imputation.
2025-03-16 00:07:19,841:INFO:Finished creating preprocessing pipeline.
2025-03-16 00:07:19,845:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-03-16 00:07:19,846:INFO:Creating final display dataframe.
2025-03-16 00:07:19,860:INFO:Setup _display_container:                Description                 Value
0               Session id                  5259
1      Original data shape              (400, 5)
2   Transformed data shape              (400, 5)
3         Numeric features                     5
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                 CPU Jobs                    -1
9                  Use GPU                 False
10          Log Experiment                 False
11         Experiment Name  cluster-default-name
12                     USI                  841b
2025-03-16 00:07:19,864:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-16 00:07:19,865:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-16 00:07:19,865:INFO:setup() successfully completed in 0.11s...............
2025-03-16 00:07:19,865:INFO:Initializing create_model()
2025-03-16 00:07:19,865:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000234703D0AC0>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-03-16 00:07:19,865:INFO:Checking exceptions
2025-03-16 00:07:19,878:INFO:Importing untrained model
2025-03-16 00:07:19,879:INFO:K-Means Clustering Imported successfully
2025-03-16 00:07:19,879:INFO:Fitting Model
2025-03-16 00:07:20,135:INFO:KMeans(n_clusters=4, random_state=5259)
2025-03-16 00:07:20,136:INFO:create_models() successfully completed......................................
2025-03-16 00:07:20,136:INFO:Uploading results into container
2025-03-16 00:07:20,137:INFO:Uploading model into container now
2025-03-16 00:07:20,145:INFO:_master_model_container: 1
2025-03-16 00:07:20,145:INFO:_display_container: 2
2025-03-16 00:07:20,145:INFO:KMeans(n_clusters=4, random_state=5259)
2025-03-16 00:07:20,145:INFO:create_model() successfully completed......................................
2025-03-16 00:07:20,255:INFO:Initializing save_model()
2025-03-16 00:07:20,255:INFO:save_model(model=KMeans(n_clusters=4, random_state=5259), model_name=best_clustering, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.CLUSTERING, kwargs={})
2025-03-16 00:07:20,256:INFO:Adding model into prep_pipe
2025-03-16 00:07:20,260:INFO:best_clustering.pkl saved in current working directory
2025-03-16 00:07:20,264:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', KMeans(n_clusters=4, random_state=5259))])
2025-03-16 00:07:20,264:INFO:save_model() successfully completed......................................
2025-03-16 00:07:34,601:INFO:Initializing load_model()
2025-03-16 00:07:34,601:INFO:load_model(model_name=best_clustering, platform=None, authentication=None, verbose=True)
2025-03-16 00:07:34,609:INFO:Initializing predict_model()
2025-03-16 00:07:34,609:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000234703D0AC0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', KMeans(n_clusters=4, random_state=5259))]), ml_usecase=None)
2025-03-16 00:07:34,609:INFO:Set up data.
2025-03-16 02:04:26,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-16 02:04:26,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-16 02:04:26,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-16 02:04:26,284:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-16 02:04:28,428:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-03-16 02:04:48,031:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001274F753C00, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-03-25 19:18:01,806:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 19:18:01,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 19:18:01,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 19:18:01,807:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-25 19:18:07,032:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2025-03-25 19:39:18,841:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001FD356B8870, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-03-25 19:41:39,541:INFO:PyCaret ClassificationExperiment
2025-03-25 19:41:39,541:INFO:Logging name: clf-default-name
2025-03-25 19:41:39,541:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-25 19:41:39,541:INFO:version 3.3.2
2025-03-25 19:41:39,541:INFO:Initializing setup()
2025-03-25 19:41:39,541:INFO:self.USI: e45d
2025-03-25 19:41:39,541:INFO:self._variable_keys: {'_available_plots', 'exp_id', 'y', '_ml_usecase', 'target_param', 'fix_imbalance', 'fold_groups_param', 'logging_param', 'X_train', 'y_train', 'is_multiclass', 'idx', 'html_param', 'USI', 'fold_shuffle_param', 'pipeline', 'gpu_n_jobs_param', 'n_jobs_param', 'memory', 'seed', 'fold_generator', 'y_test', 'X_test', 'log_plots_param', 'exp_name_log', 'data', 'X', 'gpu_param'}
2025-03-25 19:41:39,541:INFO:Checking environment
2025-03-25 19:41:39,541:INFO:python_version: 3.10.0
2025-03-25 19:41:39,541:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-25 19:41:39,541:INFO:machine: AMD64
2025-03-25 19:41:39,572:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-25 19:41:39,578:INFO:Memory: svmem(total=17037209600, available=6396715008, percent=62.5, used=10640494592, free=6396715008)
2025-03-25 19:41:39,579:INFO:Physical Core: 6
2025-03-25 19:41:39,579:INFO:Logical Core: 12
2025-03-25 19:41:39,579:INFO:Checking libraries
2025-03-25 19:41:39,579:INFO:System:
2025-03-25 19:41:39,579:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-25 19:41:39,579:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-25 19:41:39,579:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-25 19:41:39,579:INFO:PyCaret required dependencies:
2025-03-25 19:41:39,677:INFO:                 pip: 21.2.3
2025-03-25 19:41:39,677:INFO:          setuptools: 57.4.0
2025-03-25 19:41:39,677:INFO:             pycaret: 3.3.2
2025-03-25 19:41:39,677:INFO:             IPython: 8.29.0
2025-03-25 19:41:39,677:INFO:          ipywidgets: 8.1.5
2025-03-25 19:41:39,677:INFO:                tqdm: 4.67.0
2025-03-25 19:41:39,678:INFO:               numpy: 1.26.4
2025-03-25 19:41:39,678:INFO:              pandas: 2.1.4
2025-03-25 19:41:39,678:INFO:              jinja2: 3.1.4
2025-03-25 19:41:39,678:INFO:               scipy: 1.11.4
2025-03-25 19:41:39,678:INFO:              joblib: 1.3.2
2025-03-25 19:41:39,678:INFO:             sklearn: 1.4.2
2025-03-25 19:41:39,678:INFO:                pyod: 2.0.2
2025-03-25 19:41:39,678:INFO:            imblearn: 0.12.4
2025-03-25 19:41:39,678:INFO:   category_encoders: 2.6.4
2025-03-25 19:41:39,678:INFO:            lightgbm: 4.5.0
2025-03-25 19:41:39,678:INFO:               numba: 0.60.0
2025-03-25 19:41:39,678:INFO:            requests: 2.32.3
2025-03-25 19:41:39,678:INFO:          matplotlib: 3.7.5
2025-03-25 19:41:39,678:INFO:          scikitplot: 0.3.7
2025-03-25 19:41:39,678:INFO:         yellowbrick: 1.5
2025-03-25 19:41:39,678:INFO:              plotly: 5.24.1
2025-03-25 19:41:39,678:INFO:    plotly-resampler: Not installed
2025-03-25 19:41:39,678:INFO:             kaleido: 0.2.1
2025-03-25 19:41:39,678:INFO:           schemdraw: 0.15
2025-03-25 19:41:39,678:INFO:         statsmodels: 0.14.4
2025-03-25 19:41:39,678:INFO:              sktime: 0.26.0
2025-03-25 19:41:39,678:INFO:               tbats: 1.1.3
2025-03-25 19:41:39,678:INFO:            pmdarima: 2.0.4
2025-03-25 19:41:39,678:INFO:              psutil: 6.1.0
2025-03-25 19:41:39,678:INFO:          markupsafe: 3.0.2
2025-03-25 19:41:39,678:INFO:             pickle5: Not installed
2025-03-25 19:41:39,679:INFO:         cloudpickle: 3.1.0
2025-03-25 19:41:39,679:INFO:         deprecation: 2.1.0
2025-03-25 19:41:39,679:INFO:              xxhash: 3.5.0
2025-03-25 19:41:39,679:INFO:           wurlitzer: Not installed
2025-03-25 19:41:39,679:INFO:PyCaret optional dependencies:
2025-03-25 19:41:39,691:INFO:                shap: 0.47.0
2025-03-25 19:41:39,691:INFO:           interpret: Not installed
2025-03-25 19:41:39,691:INFO:                umap: Not installed
2025-03-25 19:41:39,691:INFO:     ydata_profiling: 4.12.0
2025-03-25 19:41:39,691:INFO:  explainerdashboard: Not installed
2025-03-25 19:41:39,692:INFO:             autoviz: Not installed
2025-03-25 19:41:39,692:INFO:           fairlearn: Not installed
2025-03-25 19:41:39,692:INFO:          deepchecks: Not installed
2025-03-25 19:41:39,692:INFO:             xgboost: Not installed
2025-03-25 19:41:39,692:INFO:            catboost: Not installed
2025-03-25 19:41:39,692:INFO:              kmodes: Not installed
2025-03-25 19:41:39,692:INFO:             mlxtend: Not installed
2025-03-25 19:41:39,692:INFO:       statsforecast: Not installed
2025-03-25 19:41:39,692:INFO:        tune_sklearn: Not installed
2025-03-25 19:41:39,692:INFO:                 ray: Not installed
2025-03-25 19:41:39,692:INFO:            hyperopt: Not installed
2025-03-25 19:41:39,692:INFO:              optuna: Not installed
2025-03-25 19:41:39,692:INFO:               skopt: Not installed
2025-03-25 19:41:39,692:INFO:              mlflow: Not installed
2025-03-25 19:41:39,692:INFO:              gradio: Not installed
2025-03-25 19:41:39,692:INFO:             fastapi: Not installed
2025-03-25 19:41:39,692:INFO:             uvicorn: Not installed
2025-03-25 19:41:39,692:INFO:              m2cgen: Not installed
2025-03-25 19:41:39,693:INFO:           evidently: Not installed
2025-03-25 19:41:39,693:INFO:               fugue: Not installed
2025-03-25 19:41:39,693:INFO:           streamlit: 1.40.0
2025-03-25 19:41:39,693:INFO:             prophet: Not installed
2025-03-25 19:41:39,693:INFO:None
2025-03-25 19:41:39,693:INFO:Set up data.
2025-03-25 19:41:39,702:INFO:Set up folding strategy.
2025-03-25 19:41:39,702:INFO:Set up train/test split.
2025-03-25 19:41:39,714:INFO:Set up index.
2025-03-25 19:41:39,714:INFO:Assigning column types.
2025-03-25 19:41:39,718:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-25 19:41:39,762:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 19:41:39,766:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-25 19:41:39,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:39,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:39,848:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-25 19:41:39,849:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-25 19:41:39,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:39,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:39,876:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-25 19:41:39,919:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-25 19:41:39,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:39,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:39,988:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-25 19:41:40,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:40,013:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:40,014:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-25 19:41:40,083:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:40,084:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:40,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:40,157:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:40,161:INFO:Preparing preprocessing pipeline...
2025-03-25 19:41:40,163:INFO:Set up simple imputation.
2025-03-25 19:41:40,168:INFO:Set up encoding of ordinal features.
2025-03-25 19:41:40,169:INFO:Set up encoding of categorical features.
2025-03-25 19:41:40,327:INFO:Finished creating preprocessing pipeline.
2025-03-25 19:41:40,350:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-03-25 19:41:40,350:INFO:Creating final display dataframe.
2025-03-25 19:41:40,873:INFO:Setup _display_container:                     Description             Value
0                    Session id              8363
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              e45d
2025-03-25 19:41:40,957:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:40,958:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:41,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:41,034:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:41:41,035:INFO:setup() successfully completed in 1.5s...............
2025-03-25 19:41:41,035:INFO:Initializing compare_models()
2025-03-25 19:41:41,035:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-25 19:41:41,035:INFO:Checking exceptions
2025-03-25 19:41:41,045:INFO:Preparing display monitor
2025-03-25 19:41:41,048:INFO:Initializing Logistic Regression
2025-03-25 19:41:41,048:INFO:Total runtime is 0.0 minutes
2025-03-25 19:41:41,049:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:41,049:INFO:Initializing create_model()
2025-03-25 19:41:41,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:41,049:INFO:Checking exceptions
2025-03-25 19:41:41,049:INFO:Importing libraries
2025-03-25 19:41:41,049:INFO:Copying training dataset
2025-03-25 19:41:41,053:INFO:Defining folds
2025-03-25 19:41:41,053:INFO:Declaring metric variables
2025-03-25 19:41:41,053:INFO:Importing untrained model
2025-03-25 19:41:41,054:INFO:Logistic Regression Imported successfully
2025-03-25 19:41:41,054:INFO:Starting cross validation
2025-03-25 19:41:41,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:47,671:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:47,671:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:47,671:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:47,752:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:47,773:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:47,781:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:47,785:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:47,810:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:47,813:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:47,937:INFO:Calculating mean and std
2025-03-25 19:41:47,939:INFO:Creating metrics dataframe
2025-03-25 19:41:47,942:INFO:Uploading results into container
2025-03-25 19:41:47,943:INFO:Uploading model into container now
2025-03-25 19:41:47,943:INFO:_master_model_container: 1
2025-03-25 19:41:47,943:INFO:_display_container: 2
2025-03-25 19:41:47,945:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-25 19:41:47,945:INFO:create_model() successfully completed......................................
2025-03-25 19:41:48,139:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:48,140:INFO:Creating metrics dataframe
2025-03-25 19:41:48,142:INFO:Initializing K Neighbors Classifier
2025-03-25 19:41:48,142:INFO:Total runtime is 0.11824328502019246 minutes
2025-03-25 19:41:48,142:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:48,142:INFO:Initializing create_model()
2025-03-25 19:41:48,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:48,143:INFO:Checking exceptions
2025-03-25 19:41:48,143:INFO:Importing libraries
2025-03-25 19:41:48,143:INFO:Copying training dataset
2025-03-25 19:41:48,147:INFO:Defining folds
2025-03-25 19:41:48,147:INFO:Declaring metric variables
2025-03-25 19:41:48,148:INFO:Importing untrained model
2025-03-25 19:41:48,148:INFO:K Neighbors Classifier Imported successfully
2025-03-25 19:41:48,148:INFO:Starting cross validation
2025-03-25 19:41:48,150:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:50,840:INFO:Calculating mean and std
2025-03-25 19:41:50,841:INFO:Creating metrics dataframe
2025-03-25 19:41:50,844:INFO:Uploading results into container
2025-03-25 19:41:50,845:INFO:Uploading model into container now
2025-03-25 19:41:50,845:INFO:_master_model_container: 2
2025-03-25 19:41:50,845:INFO:_display_container: 2
2025-03-25 19:41:50,845:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-25 19:41:50,845:INFO:create_model() successfully completed......................................
2025-03-25 19:41:50,994:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:50,994:INFO:Creating metrics dataframe
2025-03-25 19:41:50,997:INFO:Initializing Naive Bayes
2025-03-25 19:41:50,997:INFO:Total runtime is 0.16582452058792113 minutes
2025-03-25 19:41:50,997:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:50,997:INFO:Initializing create_model()
2025-03-25 19:41:50,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:50,997:INFO:Checking exceptions
2025-03-25 19:41:50,997:INFO:Importing libraries
2025-03-25 19:41:50,997:INFO:Copying training dataset
2025-03-25 19:41:51,003:INFO:Defining folds
2025-03-25 19:41:51,003:INFO:Declaring metric variables
2025-03-25 19:41:51,003:INFO:Importing untrained model
2025-03-25 19:41:51,004:INFO:Naive Bayes Imported successfully
2025-03-25 19:41:51,004:INFO:Starting cross validation
2025-03-25 19:41:51,005:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:51,415:INFO:Calculating mean and std
2025-03-25 19:41:51,416:INFO:Creating metrics dataframe
2025-03-25 19:41:51,417:INFO:Uploading results into container
2025-03-25 19:41:51,418:INFO:Uploading model into container now
2025-03-25 19:41:51,418:INFO:_master_model_container: 3
2025-03-25 19:41:51,418:INFO:_display_container: 2
2025-03-25 19:41:51,418:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-25 19:41:51,418:INFO:create_model() successfully completed......................................
2025-03-25 19:41:51,539:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:51,539:INFO:Creating metrics dataframe
2025-03-25 19:41:51,542:INFO:Initializing Decision Tree Classifier
2025-03-25 19:41:51,542:INFO:Total runtime is 0.1749131162961324 minutes
2025-03-25 19:41:51,542:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:51,542:INFO:Initializing create_model()
2025-03-25 19:41:51,542:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:51,542:INFO:Checking exceptions
2025-03-25 19:41:51,542:INFO:Importing libraries
2025-03-25 19:41:51,542:INFO:Copying training dataset
2025-03-25 19:41:51,548:INFO:Defining folds
2025-03-25 19:41:51,548:INFO:Declaring metric variables
2025-03-25 19:41:51,549:INFO:Importing untrained model
2025-03-25 19:41:51,549:INFO:Decision Tree Classifier Imported successfully
2025-03-25 19:41:51,550:INFO:Starting cross validation
2025-03-25 19:41:51,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:51,893:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,893:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,894:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,894:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,894:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,897:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,902:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,903:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,905:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,905:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:51,916:INFO:Calculating mean and std
2025-03-25 19:41:51,917:INFO:Creating metrics dataframe
2025-03-25 19:41:51,919:INFO:Uploading results into container
2025-03-25 19:41:51,920:INFO:Uploading model into container now
2025-03-25 19:41:51,920:INFO:_master_model_container: 4
2025-03-25 19:41:51,920:INFO:_display_container: 2
2025-03-25 19:41:51,920:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8363, splitter='best')
2025-03-25 19:41:51,920:INFO:create_model() successfully completed......................................
2025-03-25 19:41:52,042:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:52,042:INFO:Creating metrics dataframe
2025-03-25 19:41:52,045:INFO:Initializing SVM - Linear Kernel
2025-03-25 19:41:52,045:INFO:Total runtime is 0.18328870534896852 minutes
2025-03-25 19:41:52,045:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:52,046:INFO:Initializing create_model()
2025-03-25 19:41:52,046:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:52,046:INFO:Checking exceptions
2025-03-25 19:41:52,046:INFO:Importing libraries
2025-03-25 19:41:52,046:INFO:Copying training dataset
2025-03-25 19:41:52,050:INFO:Defining folds
2025-03-25 19:41:52,050:INFO:Declaring metric variables
2025-03-25 19:41:52,051:INFO:Importing untrained model
2025-03-25 19:41:52,051:INFO:SVM - Linear Kernel Imported successfully
2025-03-25 19:41:52,051:INFO:Starting cross validation
2025-03-25 19:41:52,052:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:52,366:INFO:Calculating mean and std
2025-03-25 19:41:52,367:INFO:Creating metrics dataframe
2025-03-25 19:41:52,368:INFO:Uploading results into container
2025-03-25 19:41:52,369:INFO:Uploading model into container now
2025-03-25 19:41:52,369:INFO:_master_model_container: 5
2025-03-25 19:41:52,369:INFO:_display_container: 2
2025-03-25 19:41:52,370:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8363, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-25 19:41:52,370:INFO:create_model() successfully completed......................................
2025-03-25 19:41:52,492:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:52,492:INFO:Creating metrics dataframe
2025-03-25 19:41:52,495:INFO:Initializing Ridge Classifier
2025-03-25 19:41:52,495:INFO:Total runtime is 0.19079490105311078 minutes
2025-03-25 19:41:52,495:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:52,495:INFO:Initializing create_model()
2025-03-25 19:41:52,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:52,495:INFO:Checking exceptions
2025-03-25 19:41:52,495:INFO:Importing libraries
2025-03-25 19:41:52,495:INFO:Copying training dataset
2025-03-25 19:41:52,500:INFO:Defining folds
2025-03-25 19:41:52,500:INFO:Declaring metric variables
2025-03-25 19:41:52,500:INFO:Importing untrained model
2025-03-25 19:41:52,501:INFO:Ridge Classifier Imported successfully
2025-03-25 19:41:52,501:INFO:Starting cross validation
2025-03-25 19:41:52,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:52,844:INFO:Calculating mean and std
2025-03-25 19:41:52,845:INFO:Creating metrics dataframe
2025-03-25 19:41:52,847:INFO:Uploading results into container
2025-03-25 19:41:52,848:INFO:Uploading model into container now
2025-03-25 19:41:52,849:INFO:_master_model_container: 6
2025-03-25 19:41:52,849:INFO:_display_container: 2
2025-03-25 19:41:52,849:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8363, solver='auto',
                tol=0.0001)
2025-03-25 19:41:52,849:INFO:create_model() successfully completed......................................
2025-03-25 19:41:52,979:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:52,980:INFO:Creating metrics dataframe
2025-03-25 19:41:52,983:INFO:Initializing Random Forest Classifier
2025-03-25 19:41:52,984:INFO:Total runtime is 0.19894076585769654 minutes
2025-03-25 19:41:52,984:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:52,985:INFO:Initializing create_model()
2025-03-25 19:41:52,985:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:52,985:INFO:Checking exceptions
2025-03-25 19:41:52,985:INFO:Importing libraries
2025-03-25 19:41:52,985:INFO:Copying training dataset
2025-03-25 19:41:52,990:INFO:Defining folds
2025-03-25 19:41:52,990:INFO:Declaring metric variables
2025-03-25 19:41:52,990:INFO:Importing untrained model
2025-03-25 19:41:52,991:INFO:Random Forest Classifier Imported successfully
2025-03-25 19:41:52,991:INFO:Starting cross validation
2025-03-25 19:41:52,992:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:53,673:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:53,713:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:53,722:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:53,743:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:53,752:INFO:Calculating mean and std
2025-03-25 19:41:53,753:INFO:Creating metrics dataframe
2025-03-25 19:41:53,755:INFO:Uploading results into container
2025-03-25 19:41:53,755:INFO:Uploading model into container now
2025-03-25 19:41:53,756:INFO:_master_model_container: 7
2025-03-25 19:41:53,756:INFO:_display_container: 2
2025-03-25 19:41:53,756:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8363, verbose=0,
                       warm_start=False)
2025-03-25 19:41:53,756:INFO:create_model() successfully completed......................................
2025-03-25 19:41:53,874:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:53,874:INFO:Creating metrics dataframe
2025-03-25 19:41:53,876:INFO:Initializing Quadratic Discriminant Analysis
2025-03-25 19:41:53,876:INFO:Total runtime is 0.2138070066769918 minutes
2025-03-25 19:41:53,877:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:53,877:INFO:Initializing create_model()
2025-03-25 19:41:53,877:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:53,877:INFO:Checking exceptions
2025-03-25 19:41:53,877:INFO:Importing libraries
2025-03-25 19:41:53,877:INFO:Copying training dataset
2025-03-25 19:41:53,881:INFO:Defining folds
2025-03-25 19:41:53,881:INFO:Declaring metric variables
2025-03-25 19:41:53,881:INFO:Importing untrained model
2025-03-25 19:41:53,881:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-25 19:41:53,882:INFO:Starting cross validation
2025-03-25 19:41:53,883:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:54,096:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-25 19:41:54,096:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-25 19:41:54,096:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-25 19:41:54,096:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-25 19:41:54,096:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-25 19:41:54,096:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-25 19:41:54,172:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,175:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,177:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,180:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,183:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,185:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,187:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,187:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,191:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,192:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,202:INFO:Calculating mean and std
2025-03-25 19:41:54,203:INFO:Creating metrics dataframe
2025-03-25 19:41:54,204:INFO:Uploading results into container
2025-03-25 19:41:54,205:INFO:Uploading model into container now
2025-03-25 19:41:54,205:INFO:_master_model_container: 8
2025-03-25 19:41:54,205:INFO:_display_container: 2
2025-03-25 19:41:54,205:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-25 19:41:54,205:INFO:create_model() successfully completed......................................
2025-03-25 19:41:54,325:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:54,325:INFO:Creating metrics dataframe
2025-03-25 19:41:54,328:INFO:Initializing Ada Boost Classifier
2025-03-25 19:41:54,328:INFO:Total runtime is 0.2213337500890096 minutes
2025-03-25 19:41:54,328:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:54,329:INFO:Initializing create_model()
2025-03-25 19:41:54,329:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:54,329:INFO:Checking exceptions
2025-03-25 19:41:54,329:INFO:Importing libraries
2025-03-25 19:41:54,329:INFO:Copying training dataset
2025-03-25 19:41:54,333:INFO:Defining folds
2025-03-25 19:41:54,333:INFO:Declaring metric variables
2025-03-25 19:41:54,333:INFO:Importing untrained model
2025-03-25 19:41:54,334:INFO:Ada Boost Classifier Imported successfully
2025-03-25 19:41:54,334:INFO:Starting cross validation
2025-03-25 19:41:54,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:54,555:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-25 19:41:54,555:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-25 19:41:54,555:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-25 19:41:54,555:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-25 19:41:54,555:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-25 19:41:54,555:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-25 19:41:54,556:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-25 19:41:54,560:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-25 19:41:54,640:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,651:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,653:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,653:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,656:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,656:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,657:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,658:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,659:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,665:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:54,681:INFO:Calculating mean and std
2025-03-25 19:41:54,682:INFO:Creating metrics dataframe
2025-03-25 19:41:54,683:INFO:Uploading results into container
2025-03-25 19:41:54,684:INFO:Uploading model into container now
2025-03-25 19:41:54,684:INFO:_master_model_container: 9
2025-03-25 19:41:54,684:INFO:_display_container: 2
2025-03-25 19:41:54,684:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8363)
2025-03-25 19:41:54,685:INFO:create_model() successfully completed......................................
2025-03-25 19:41:54,804:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:54,804:INFO:Creating metrics dataframe
2025-03-25 19:41:54,807:INFO:Initializing Gradient Boosting Classifier
2025-03-25 19:41:54,808:INFO:Total runtime is 0.22933288812637329 minutes
2025-03-25 19:41:54,808:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:54,808:INFO:Initializing create_model()
2025-03-25 19:41:54,808:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:54,808:INFO:Checking exceptions
2025-03-25 19:41:54,808:INFO:Importing libraries
2025-03-25 19:41:54,808:INFO:Copying training dataset
2025-03-25 19:41:54,812:INFO:Defining folds
2025-03-25 19:41:54,812:INFO:Declaring metric variables
2025-03-25 19:41:54,812:INFO:Importing untrained model
2025-03-25 19:41:54,813:INFO:Gradient Boosting Classifier Imported successfully
2025-03-25 19:41:54,813:INFO:Starting cross validation
2025-03-25 19:41:54,814:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:55,263:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,265:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,270:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,277:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,278:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,278:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,287:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,293:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,305:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,307:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,315:INFO:Calculating mean and std
2025-03-25 19:41:55,316:INFO:Creating metrics dataframe
2025-03-25 19:41:55,318:INFO:Uploading results into container
2025-03-25 19:41:55,319:INFO:Uploading model into container now
2025-03-25 19:41:55,319:INFO:_master_model_container: 10
2025-03-25 19:41:55,319:INFO:_display_container: 2
2025-03-25 19:41:55,320:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8363, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-25 19:41:55,320:INFO:create_model() successfully completed......................................
2025-03-25 19:41:55,440:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:55,440:INFO:Creating metrics dataframe
2025-03-25 19:41:55,442:INFO:Initializing Linear Discriminant Analysis
2025-03-25 19:41:55,442:INFO:Total runtime is 0.23990732431411743 minutes
2025-03-25 19:41:55,442:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:55,443:INFO:Initializing create_model()
2025-03-25 19:41:55,443:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:55,443:INFO:Checking exceptions
2025-03-25 19:41:55,443:INFO:Importing libraries
2025-03-25 19:41:55,443:INFO:Copying training dataset
2025-03-25 19:41:55,448:INFO:Defining folds
2025-03-25 19:41:55,448:INFO:Declaring metric variables
2025-03-25 19:41:55,448:INFO:Importing untrained model
2025-03-25 19:41:55,449:INFO:Linear Discriminant Analysis Imported successfully
2025-03-25 19:41:55,449:INFO:Starting cross validation
2025-03-25 19:41:55,452:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:55,747:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,748:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,765:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,765:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,768:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,771:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,773:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,778:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,781:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:55,796:INFO:Calculating mean and std
2025-03-25 19:41:55,797:INFO:Creating metrics dataframe
2025-03-25 19:41:55,799:INFO:Uploading results into container
2025-03-25 19:41:55,799:INFO:Uploading model into container now
2025-03-25 19:41:55,799:INFO:_master_model_container: 11
2025-03-25 19:41:55,799:INFO:_display_container: 2
2025-03-25 19:41:55,800:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-25 19:41:55,800:INFO:create_model() successfully completed......................................
2025-03-25 19:41:55,921:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:55,921:INFO:Creating metrics dataframe
2025-03-25 19:41:55,925:INFO:Initializing Extra Trees Classifier
2025-03-25 19:41:55,925:INFO:Total runtime is 0.24795252084732056 minutes
2025-03-25 19:41:55,925:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:55,926:INFO:Initializing create_model()
2025-03-25 19:41:55,926:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:55,926:INFO:Checking exceptions
2025-03-25 19:41:55,926:INFO:Importing libraries
2025-03-25 19:41:55,926:INFO:Copying training dataset
2025-03-25 19:41:55,932:INFO:Defining folds
2025-03-25 19:41:55,932:INFO:Declaring metric variables
2025-03-25 19:41:55,932:INFO:Importing untrained model
2025-03-25 19:41:55,933:INFO:Extra Trees Classifier Imported successfully
2025-03-25 19:41:55,933:INFO:Starting cross validation
2025-03-25 19:41:55,935:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:56,567:INFO:Calculating mean and std
2025-03-25 19:41:56,568:INFO:Creating metrics dataframe
2025-03-25 19:41:56,569:INFO:Uploading results into container
2025-03-25 19:41:56,570:INFO:Uploading model into container now
2025-03-25 19:41:56,570:INFO:_master_model_container: 12
2025-03-25 19:41:56,570:INFO:_display_container: 2
2025-03-25 19:41:56,570:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8363, verbose=0,
                     warm_start=False)
2025-03-25 19:41:56,570:INFO:create_model() successfully completed......................................
2025-03-25 19:41:56,701:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:56,701:INFO:Creating metrics dataframe
2025-03-25 19:41:56,704:INFO:Initializing Light Gradient Boosting Machine
2025-03-25 19:41:56,705:INFO:Total runtime is 0.260956068833669 minutes
2025-03-25 19:41:56,705:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:56,705:INFO:Initializing create_model()
2025-03-25 19:41:56,705:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:56,705:INFO:Checking exceptions
2025-03-25 19:41:56,705:INFO:Importing libraries
2025-03-25 19:41:56,705:INFO:Copying training dataset
2025-03-25 19:41:56,709:INFO:Defining folds
2025-03-25 19:41:56,709:INFO:Declaring metric variables
2025-03-25 19:41:56,710:INFO:Importing untrained model
2025-03-25 19:41:56,710:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-25 19:41:56,710:INFO:Starting cross validation
2025-03-25 19:41:56,712:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:57,955:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:57,975:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,046:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,148:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,162:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,221:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,268:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,291:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,311:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,348:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,367:INFO:Calculating mean and std
2025-03-25 19:41:58,369:INFO:Creating metrics dataframe
2025-03-25 19:41:58,373:INFO:Uploading results into container
2025-03-25 19:41:58,373:INFO:Uploading model into container now
2025-03-25 19:41:58,374:INFO:_master_model_container: 13
2025-03-25 19:41:58,374:INFO:_display_container: 2
2025-03-25 19:41:58,375:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8363, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-25 19:41:58,375:INFO:create_model() successfully completed......................................
2025-03-25 19:41:58,520:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:58,520:INFO:Creating metrics dataframe
2025-03-25 19:41:58,524:INFO:Initializing Dummy Classifier
2025-03-25 19:41:58,524:INFO:Total runtime is 0.2912701368331909 minutes
2025-03-25 19:41:58,525:INFO:SubProcess create_model() called ==================================
2025-03-25 19:41:58,525:INFO:Initializing create_model()
2025-03-25 19:41:58,525:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD3AEA08B0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:58,525:INFO:Checking exceptions
2025-03-25 19:41:58,525:INFO:Importing libraries
2025-03-25 19:41:58,525:INFO:Copying training dataset
2025-03-25 19:41:58,532:INFO:Defining folds
2025-03-25 19:41:58,532:INFO:Declaring metric variables
2025-03-25 19:41:58,532:INFO:Importing untrained model
2025-03-25 19:41:58,532:INFO:Dummy Classifier Imported successfully
2025-03-25 19:41:58,533:INFO:Starting cross validation
2025-03-25 19:41:58,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:41:58,830:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,854:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,859:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,870:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,871:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,872:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,872:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,873:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,895:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,897:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-25 19:41:58,912:INFO:Calculating mean and std
2025-03-25 19:41:58,913:INFO:Creating metrics dataframe
2025-03-25 19:41:58,915:INFO:Uploading results into container
2025-03-25 19:41:58,915:INFO:Uploading model into container now
2025-03-25 19:41:58,916:INFO:_master_model_container: 14
2025-03-25 19:41:58,916:INFO:_display_container: 2
2025-03-25 19:41:58,916:INFO:DummyClassifier(constant=None, random_state=8363, strategy='prior')
2025-03-25 19:41:58,917:INFO:create_model() successfully completed......................................
2025-03-25 19:41:59,045:INFO:SubProcess create_model() end ==================================
2025-03-25 19:41:59,045:INFO:Creating metrics dataframe
2025-03-25 19:41:59,051:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-25 19:41:59,053:INFO:Initializing create_model()
2025-03-25 19:41:59,053:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:41:59,053:INFO:Checking exceptions
2025-03-25 19:41:59,055:INFO:Importing libraries
2025-03-25 19:41:59,055:INFO:Copying training dataset
2025-03-25 19:41:59,060:INFO:Defining folds
2025-03-25 19:41:59,060:INFO:Declaring metric variables
2025-03-25 19:41:59,060:INFO:Importing untrained model
2025-03-25 19:41:59,060:INFO:Declaring custom model
2025-03-25 19:41:59,060:INFO:Logistic Regression Imported successfully
2025-03-25 19:41:59,063:INFO:Cross validation set to False
2025-03-25 19:41:59,063:INFO:Fitting Model
2025-03-25 19:41:59,263:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:59,263:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-25 19:41:59,263:INFO:create_model() successfully completed......................................
2025-03-25 19:41:59,393:INFO:_master_model_container: 14
2025-03-25 19:41:59,393:INFO:_display_container: 2
2025-03-25 19:41:59,394:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-25 19:41:59,394:INFO:compare_models() successfully completed......................................
2025-03-25 19:41:59,394:INFO:Initializing tune_model()
2025-03-25 19:41:59,394:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>)
2025-03-25 19:41:59,394:INFO:Checking exceptions
2025-03-25 19:41:59,399:INFO:Copying training dataset
2025-03-25 19:41:59,403:INFO:Checking base model
2025-03-25 19:41:59,403:INFO:Base model : Logistic Regression
2025-03-25 19:41:59,403:INFO:Declaring metric variables
2025-03-25 19:41:59,403:INFO:Defining Hyperparameters
2025-03-25 19:41:59,525:INFO:Tuning with n_jobs=-1
2025-03-25 19:41:59,525:INFO:Initializing RandomizedSearchCV
2025-03-25 19:41:59,992:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:41:59,998:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,022:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,040:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,121:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,132:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,157:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,179:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,192:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,198:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,242:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,264:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,472:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,504:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,505:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,650:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,720:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,747:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,793:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,841:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,893:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,902:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,920:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,925:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,938:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:00,989:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,107:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,133:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,209:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,411:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,416:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,420:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,427:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,479:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,587:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,603:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,641:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,653:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,659:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,732:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:01,935:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,023:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,066:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,066:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,097:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,102:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,129:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,147:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,259:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,302:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,348:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,355:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,397:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,547:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,563:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,619:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,689:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,696:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,755:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,844:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,868:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,933:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,963:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,975:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:02,984:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,011:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,028:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,104:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,317:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,365:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,399:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,442:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,487:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,530:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,581:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,614:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,680:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,738:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,743:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,765:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,911:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:03,975:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,058:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,091:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,174:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,228:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,247:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,276:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,309:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,362:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,412:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,417:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,425:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,496:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,612:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,617:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:04,661:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 3.529}
2025-03-25 19:42:04,662:INFO:Hyperparameter search completed
2025-03-25 19:42:04,662:INFO:SubProcess create_model() called ==================================
2025-03-25 19:42:04,663:INFO:Initializing create_model()
2025-03-25 19:42:04,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001FD400172E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 3.529})
2025-03-25 19:42:04,663:INFO:Checking exceptions
2025-03-25 19:42:04,663:INFO:Importing libraries
2025-03-25 19:42:04,663:INFO:Copying training dataset
2025-03-25 19:42:04,667:INFO:Defining folds
2025-03-25 19:42:04,668:INFO:Declaring metric variables
2025-03-25 19:42:04,668:INFO:Importing untrained model
2025-03-25 19:42:04,668:INFO:Declaring custom model
2025-03-25 19:42:04,669:INFO:Logistic Regression Imported successfully
2025-03-25 19:42:04,669:INFO:Starting cross validation
2025-03-25 19:42:04,670:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:42:05,108:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,109:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,124:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,125:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,135:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,138:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,138:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,141:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,165:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,178:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,256:INFO:Calculating mean and std
2025-03-25 19:42:05,257:INFO:Creating metrics dataframe
2025-03-25 19:42:05,258:INFO:Finalizing model
2025-03-25 19:42:05,471:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:05,472:INFO:Uploading results into container
2025-03-25 19:42:05,473:INFO:Uploading model into container now
2025-03-25 19:42:05,474:INFO:_master_model_container: 15
2025-03-25 19:42:05,474:INFO:_display_container: 3
2025-03-25 19:42:05,474:INFO:LogisticRegression(C=3.529, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-25 19:42:05,475:INFO:create_model() successfully completed......................................
2025-03-25 19:42:05,594:INFO:SubProcess create_model() end ==================================
2025-03-25 19:42:05,595:INFO:choose_better activated
2025-03-25 19:42:05,595:INFO:SubProcess create_model() called ==================================
2025-03-25 19:42:05,596:INFO:Initializing create_model()
2025-03-25 19:42:05,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-25 19:42:05,596:INFO:Checking exceptions
2025-03-25 19:42:05,596:INFO:Importing libraries
2025-03-25 19:42:05,597:INFO:Copying training dataset
2025-03-25 19:42:05,601:INFO:Defining folds
2025-03-25 19:42:05,601:INFO:Declaring metric variables
2025-03-25 19:42:05,601:INFO:Importing untrained model
2025-03-25 19:42:05,601:INFO:Declaring custom model
2025-03-25 19:42:05,602:INFO:Logistic Regression Imported successfully
2025-03-25 19:42:05,602:INFO:Starting cross validation
2025-03-25 19:42:05,604:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-25 19:42:06,020:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,030:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,039:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,041:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,054:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,055:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,060:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,074:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,084:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,089:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,219:INFO:Calculating mean and std
2025-03-25 19:42:06,220:INFO:Creating metrics dataframe
2025-03-25 19:42:06,222:INFO:Finalizing model
2025-03-25 19:42:06,417:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-25 19:42:06,418:INFO:Uploading results into container
2025-03-25 19:42:06,419:INFO:Uploading model into container now
2025-03-25 19:42:06,419:INFO:_master_model_container: 16
2025-03-25 19:42:06,419:INFO:_display_container: 4
2025-03-25 19:42:06,421:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-25 19:42:06,421:INFO:create_model() successfully completed......................................
2025-03-25 19:42:06,539:INFO:SubProcess create_model() end ==================================
2025-03-25 19:42:06,539:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8088
2025-03-25 19:42:06,540:INFO:LogisticRegression(C=3.529, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8105
2025-03-25 19:42:06,540:INFO:LogisticRegression(C=3.529, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-03-25 19:42:06,540:INFO:choose_better completed
2025-03-25 19:42:06,549:INFO:_master_model_container: 16
2025-03-25 19:42:06,549:INFO:_display_container: 3
2025-03-25 19:42:06,549:INFO:LogisticRegression(C=3.529, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-25 19:42:06,550:INFO:tune_model() successfully completed......................................
2025-03-25 19:42:06,688:INFO:Initializing save_model()
2025-03-25 19:42:06,689:INFO:save_model(model=LogisticRegression(C=3.529, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8363, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-25 19:42:06,689:INFO:Adding model into prep_pipe
2025-03-25 19:42:06,700:INFO:best_classifier.pkl saved in current working directory
2025-03-25 19:42:06,723:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=3.529, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=8363,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-25 19:42:06,723:INFO:save_model() successfully completed......................................
2025-03-25 19:43:13,439:INFO:Initializing load_model()
2025-03-25 19:43:13,439:INFO:load_model(model_name=best_classifier, platform=None, authentication=None, verbose=True)
2025-03-25 19:43:13,517:INFO:Initializing predict_model()
2025-03-25 19:43:13,517:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001FD3AEA2BF0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(C=3.529, class_weight={}, max_iter=1000,
                                    random_state=8363))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001FD3B50BE20>)
2025-03-25 19:43:13,517:INFO:Checking exceptions
2025-03-25 19:43:13,517:INFO:Preloading libraries
2025-03-25 19:43:13,517:INFO:Set up data.
2025-03-25 19:43:13,523:INFO:Set up index.
2025-03-25 19:47:10,581:INFO:PyCaret ClusteringExperiment
2025-03-25 19:47:10,581:INFO:Logging name: cluster-default-name
2025-03-25 19:47:10,581:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-03-25 19:47:10,582:INFO:version 3.3.2
2025-03-25 19:47:10,582:INFO:Initializing setup()
2025-03-25 19:47:10,582:INFO:self.USI: b9a3
2025-03-25 19:47:10,582:INFO:self._variable_keys: {'_available_plots', 'exp_id', '_ml_usecase', 'logging_param', 'idx', 'html_param', 'USI', 'pipeline', 'gpu_n_jobs_param', 'n_jobs_param', 'memory', 'seed', 'log_plots_param', 'exp_name_log', 'data', 'X', 'gpu_param'}
2025-03-25 19:47:10,582:INFO:Checking environment
2025-03-25 19:47:10,582:INFO:python_version: 3.10.0
2025-03-25 19:47:10,582:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-25 19:47:10,582:INFO:machine: AMD64
2025-03-25 19:47:10,582:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-25 19:47:10,587:INFO:Memory: svmem(total=17037209600, available=7186472960, percent=57.8, used=9850736640, free=7186472960)
2025-03-25 19:47:10,592:INFO:Physical Core: 6
2025-03-25 19:47:10,592:INFO:Logical Core: 12
2025-03-25 19:47:10,592:INFO:Checking libraries
2025-03-25 19:47:10,593:INFO:System:
2025-03-25 19:47:10,593:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-25 19:47:10,593:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-25 19:47:10,593:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-25 19:47:10,594:INFO:PyCaret required dependencies:
2025-03-25 19:47:10,594:INFO:                 pip: 21.2.3
2025-03-25 19:47:10,594:INFO:          setuptools: 57.4.0
2025-03-25 19:47:10,595:INFO:             pycaret: 3.3.2
2025-03-25 19:47:10,596:INFO:             IPython: 8.29.0
2025-03-25 19:47:10,596:INFO:          ipywidgets: 8.1.5
2025-03-25 19:47:10,596:INFO:                tqdm: 4.67.0
2025-03-25 19:47:10,596:INFO:               numpy: 1.26.4
2025-03-25 19:47:10,596:INFO:              pandas: 2.1.4
2025-03-25 19:47:10,596:INFO:              jinja2: 3.1.4
2025-03-25 19:47:10,597:INFO:               scipy: 1.11.4
2025-03-25 19:47:10,597:INFO:              joblib: 1.3.2
2025-03-25 19:47:10,597:INFO:             sklearn: 1.4.2
2025-03-25 19:47:10,597:INFO:                pyod: 2.0.2
2025-03-25 19:47:10,597:INFO:            imblearn: 0.12.4
2025-03-25 19:47:10,597:INFO:   category_encoders: 2.6.4
2025-03-25 19:47:10,598:INFO:            lightgbm: 4.5.0
2025-03-25 19:47:10,598:INFO:               numba: 0.60.0
2025-03-25 19:47:10,598:INFO:            requests: 2.32.3
2025-03-25 19:47:10,598:INFO:          matplotlib: 3.7.5
2025-03-25 19:47:10,598:INFO:          scikitplot: 0.3.7
2025-03-25 19:47:10,598:INFO:         yellowbrick: 1.5
2025-03-25 19:47:10,599:INFO:              plotly: 5.24.1
2025-03-25 19:47:10,599:INFO:    plotly-resampler: Not installed
2025-03-25 19:47:10,599:INFO:             kaleido: 0.2.1
2025-03-25 19:47:10,599:INFO:           schemdraw: 0.15
2025-03-25 19:47:10,600:INFO:         statsmodels: 0.14.4
2025-03-25 19:47:10,600:INFO:              sktime: 0.26.0
2025-03-25 19:47:10,600:INFO:               tbats: 1.1.3
2025-03-25 19:47:10,600:INFO:            pmdarima: 2.0.4
2025-03-25 19:47:10,601:INFO:              psutil: 6.1.0
2025-03-25 19:47:10,601:INFO:          markupsafe: 3.0.2
2025-03-25 19:47:10,601:INFO:             pickle5: Not installed
2025-03-25 19:47:10,601:INFO:         cloudpickle: 3.1.0
2025-03-25 19:47:10,601:INFO:         deprecation: 2.1.0
2025-03-25 19:47:10,601:INFO:              xxhash: 3.5.0
2025-03-25 19:47:10,602:INFO:           wurlitzer: Not installed
2025-03-25 19:47:10,602:INFO:PyCaret optional dependencies:
2025-03-25 19:47:10,602:INFO:                shap: 0.47.0
2025-03-25 19:47:10,602:INFO:           interpret: Not installed
2025-03-25 19:47:10,603:INFO:                umap: Not installed
2025-03-25 19:47:10,603:INFO:     ydata_profiling: 4.12.0
2025-03-25 19:47:10,603:INFO:  explainerdashboard: Not installed
2025-03-25 19:47:10,603:INFO:             autoviz: Not installed
2025-03-25 19:47:10,604:INFO:           fairlearn: Not installed
2025-03-25 19:47:10,604:INFO:          deepchecks: Not installed
2025-03-25 19:47:10,604:INFO:             xgboost: Not installed
2025-03-25 19:47:10,604:INFO:            catboost: Not installed
2025-03-25 19:47:10,604:INFO:              kmodes: Not installed
2025-03-25 19:47:10,605:INFO:             mlxtend: Not installed
2025-03-25 19:47:10,605:INFO:       statsforecast: Not installed
2025-03-25 19:47:10,605:INFO:        tune_sklearn: Not installed
2025-03-25 19:47:10,605:INFO:                 ray: Not installed
2025-03-25 19:47:10,605:INFO:            hyperopt: Not installed
2025-03-25 19:47:10,606:INFO:              optuna: Not installed
2025-03-25 19:47:10,606:INFO:               skopt: Not installed
2025-03-25 19:47:10,606:INFO:              mlflow: Not installed
2025-03-25 19:47:10,606:INFO:              gradio: Not installed
2025-03-25 19:47:10,607:INFO:             fastapi: Not installed
2025-03-25 19:47:10,607:INFO:             uvicorn: Not installed
2025-03-25 19:47:10,607:INFO:              m2cgen: Not installed
2025-03-25 19:47:10,607:INFO:           evidently: Not installed
2025-03-25 19:47:10,607:INFO:               fugue: Not installed
2025-03-25 19:47:10,608:INFO:           streamlit: 1.40.0
2025-03-25 19:47:10,608:INFO:             prophet: Not installed
2025-03-25 19:47:10,609:INFO:None
2025-03-25 19:47:10,609:INFO:Set up data.
2025-03-25 19:47:10,616:INFO:Set up index.
2025-03-25 19:47:10,616:INFO:Assigning column types.
2025-03-25 19:47:10,618:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-03-25 19:47:10,619:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-03-25 19:47:10,620:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:47:10,620:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-03-25 19:47:10,621:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:47:10,621:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-03-25 19:47:10,621:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:47:10,622:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:47:10,625:INFO:Preparing preprocessing pipeline...
2025-03-25 19:47:10,625:INFO:Set up simple imputation.
2025-03-25 19:47:10,640:INFO:Finished creating preprocessing pipeline.
2025-03-25 19:47:10,644:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-03-25 19:47:10,644:INFO:Creating final display dataframe.
2025-03-25 19:47:10,661:INFO:Setup _display_container:                Description                 Value
0               Session id                   977
1      Original data shape              (400, 5)
2   Transformed data shape              (400, 5)
3         Numeric features                     5
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                 CPU Jobs                    -1
9                  Use GPU                 False
10          Log Experiment                 False
11         Experiment Name  cluster-default-name
12                     USI                  b9a3
2025-03-25 19:47:10,666:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:47:10,667:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-25 19:47:10,667:INFO:setup() successfully completed in 0.09s...............
2025-03-25 19:47:10,667:INFO:Initializing create_model()
2025-03-25 19:47:10,667:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001FD3AEA36A0>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-03-25 19:47:10,667:INFO:Checking exceptions
2025-03-25 19:47:10,685:INFO:Importing untrained model
2025-03-25 19:47:10,685:INFO:K-Means Clustering Imported successfully
2025-03-25 19:47:10,686:INFO:Fitting Model
2025-03-25 19:47:10,948:INFO:KMeans(n_clusters=4, random_state=977)
2025-03-25 19:47:10,948:INFO:create_models() successfully completed......................................
2025-03-25 19:47:10,949:INFO:Uploading results into container
2025-03-25 19:47:10,950:INFO:Uploading model into container now
2025-03-25 19:47:10,957:INFO:_master_model_container: 1
2025-03-25 19:47:10,957:INFO:_display_container: 2
2025-03-25 19:47:10,957:INFO:KMeans(n_clusters=4, random_state=977)
2025-03-25 19:47:10,957:INFO:create_model() successfully completed......................................
2025-03-25 19:47:11,094:INFO:Initializing save_model()
2025-03-25 19:47:11,094:INFO:save_model(model=KMeans(n_clusters=4, random_state=977), model_name=best_clustering, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.CLUSTERING, kwargs={})
2025-03-25 19:47:11,094:INFO:Adding model into prep_pipe
2025-03-25 19:47:11,098:INFO:best_clustering.pkl saved in current working directory
2025-03-25 19:47:11,102:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', KMeans(n_clusters=4, random_state=977))])
2025-03-25 19:47:11,102:INFO:save_model() successfully completed......................................
2025-03-25 19:47:22,549:INFO:Initializing load_model()
2025-03-25 19:47:22,549:INFO:load_model(model_name=best_clustering, platform=None, authentication=None, verbose=True)
2025-03-25 19:47:22,561:INFO:Initializing predict_model()
2025-03-25 19:47:22,561:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x000001FD3AEA36A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', KMeans(n_clusters=4, random_state=977))]), ml_usecase=None)
2025-03-25 19:47:22,561:INFO:Set up data.
2025-03-31 23:48:04,873:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 23:48:04,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 23:48:04,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 23:48:04,874:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-03-31 23:49:35,841:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x0000019E6BD33EC0, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-03-31 23:51:41,930:INFO:PyCaret ClassificationExperiment
2025-03-31 23:51:41,931:INFO:Logging name: clf-default-name
2025-03-31 23:51:41,931:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-03-31 23:51:41,931:INFO:version 3.3.2
2025-03-31 23:51:41,931:INFO:Initializing setup()
2025-03-31 23:51:41,931:INFO:self.USI: d07c
2025-03-31 23:51:41,931:INFO:self._variable_keys: {'target_param', '_available_plots', 'y_test', 'exp_name_log', 'n_jobs_param', 'USI', 'idx', 'gpu_n_jobs_param', 'fold_generator', 'data', 'fold_groups_param', 'html_param', 'y_train', 'memory', 'seed', 'fold_shuffle_param', '_ml_usecase', 'pipeline', 'exp_id', 'X', 'y', 'gpu_param', 'fix_imbalance', 'logging_param', 'X_test', 'is_multiclass', 'log_plots_param', 'X_train'}
2025-03-31 23:51:41,931:INFO:Checking environment
2025-03-31 23:51:41,931:INFO:python_version: 3.10.0
2025-03-31 23:51:41,931:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-03-31 23:51:41,931:INFO:machine: AMD64
2025-03-31 23:51:41,959:INFO:platform: Windows-10-10.0.26100-SP0
2025-03-31 23:51:41,965:INFO:Memory: svmem(total=17037209600, available=6567596032, percent=61.5, used=10469613568, free=6567596032)
2025-03-31 23:51:41,965:INFO:Physical Core: 6
2025-03-31 23:51:41,965:INFO:Logical Core: 12
2025-03-31 23:51:41,966:INFO:Checking libraries
2025-03-31 23:51:41,966:INFO:System:
2025-03-31 23:51:41,966:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-03-31 23:51:41,966:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-03-31 23:51:41,966:INFO:   machine: Windows-10-10.0.26100-SP0
2025-03-31 23:51:41,966:INFO:PyCaret required dependencies:
2025-03-31 23:51:42,058:INFO:                 pip: 21.2.3
2025-03-31 23:51:42,058:INFO:          setuptools: 57.4.0
2025-03-31 23:51:42,058:INFO:             pycaret: 3.3.2
2025-03-31 23:51:42,058:INFO:             IPython: 8.29.0
2025-03-31 23:51:42,058:INFO:          ipywidgets: 8.1.5
2025-03-31 23:51:42,058:INFO:                tqdm: 4.67.0
2025-03-31 23:51:42,058:INFO:               numpy: 1.26.4
2025-03-31 23:51:42,058:INFO:              pandas: 2.1.4
2025-03-31 23:51:42,058:INFO:              jinja2: 3.1.4
2025-03-31 23:51:42,058:INFO:               scipy: 1.11.4
2025-03-31 23:51:42,058:INFO:              joblib: 1.3.2
2025-03-31 23:51:42,058:INFO:             sklearn: 1.4.2
2025-03-31 23:51:42,058:INFO:                pyod: 2.0.2
2025-03-31 23:51:42,058:INFO:            imblearn: 0.12.4
2025-03-31 23:51:42,058:INFO:   category_encoders: 2.6.4
2025-03-31 23:51:42,058:INFO:            lightgbm: 4.5.0
2025-03-31 23:51:42,058:INFO:               numba: 0.60.0
2025-03-31 23:51:42,058:INFO:            requests: 2.32.3
2025-03-31 23:51:42,058:INFO:          matplotlib: 3.7.5
2025-03-31 23:51:42,058:INFO:          scikitplot: 0.3.7
2025-03-31 23:51:42,059:INFO:         yellowbrick: 1.5
2025-03-31 23:51:42,059:INFO:              plotly: 5.24.1
2025-03-31 23:51:42,059:INFO:    plotly-resampler: Not installed
2025-03-31 23:51:42,059:INFO:             kaleido: 0.2.1
2025-03-31 23:51:42,059:INFO:           schemdraw: 0.15
2025-03-31 23:51:42,059:INFO:         statsmodels: 0.14.4
2025-03-31 23:51:42,059:INFO:              sktime: 0.26.0
2025-03-31 23:51:42,059:INFO:               tbats: 1.1.3
2025-03-31 23:51:42,059:INFO:            pmdarima: 2.0.4
2025-03-31 23:51:42,059:INFO:              psutil: 6.1.0
2025-03-31 23:51:42,059:INFO:          markupsafe: 3.0.2
2025-03-31 23:51:42,059:INFO:             pickle5: Not installed
2025-03-31 23:51:42,060:INFO:         cloudpickle: 3.1.0
2025-03-31 23:51:42,060:INFO:         deprecation: 2.1.0
2025-03-31 23:51:42,060:INFO:              xxhash: 3.5.0
2025-03-31 23:51:42,060:INFO:           wurlitzer: Not installed
2025-03-31 23:51:42,060:INFO:PyCaret optional dependencies:
2025-03-31 23:51:42,072:INFO:                shap: 0.47.0
2025-03-31 23:51:42,072:INFO:           interpret: Not installed
2025-03-31 23:51:42,072:INFO:                umap: Not installed
2025-03-31 23:51:42,072:INFO:     ydata_profiling: 4.12.0
2025-03-31 23:51:42,072:INFO:  explainerdashboard: Not installed
2025-03-31 23:51:42,072:INFO:             autoviz: Not installed
2025-03-31 23:51:42,072:INFO:           fairlearn: Not installed
2025-03-31 23:51:42,072:INFO:          deepchecks: Not installed
2025-03-31 23:51:42,072:INFO:             xgboost: Not installed
2025-03-31 23:51:42,072:INFO:            catboost: Not installed
2025-03-31 23:51:42,072:INFO:              kmodes: Not installed
2025-03-31 23:51:42,072:INFO:             mlxtend: Not installed
2025-03-31 23:51:42,072:INFO:       statsforecast: Not installed
2025-03-31 23:51:42,072:INFO:        tune_sklearn: Not installed
2025-03-31 23:51:42,072:INFO:                 ray: Not installed
2025-03-31 23:51:42,072:INFO:            hyperopt: Not installed
2025-03-31 23:51:42,072:INFO:              optuna: Not installed
2025-03-31 23:51:42,072:INFO:               skopt: Not installed
2025-03-31 23:51:42,072:INFO:              mlflow: Not installed
2025-03-31 23:51:42,072:INFO:              gradio: Not installed
2025-03-31 23:51:42,073:INFO:             fastapi: Not installed
2025-03-31 23:51:42,073:INFO:             uvicorn: Not installed
2025-03-31 23:51:42,073:INFO:              m2cgen: Not installed
2025-03-31 23:51:42,073:INFO:           evidently: Not installed
2025-03-31 23:51:42,073:INFO:               fugue: Not installed
2025-03-31 23:51:42,073:INFO:           streamlit: 1.40.0
2025-03-31 23:51:42,073:INFO:             prophet: Not installed
2025-03-31 23:51:42,073:INFO:None
2025-03-31 23:51:42,073:INFO:Set up data.
2025-03-31 23:51:42,080:INFO:Set up folding strategy.
2025-03-31 23:51:42,081:INFO:Set up train/test split.
2025-03-31 23:51:42,094:INFO:Set up index.
2025-03-31 23:51:42,094:INFO:Assigning column types.
2025-03-31 23:51:42,098:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-03-31 23:51:42,141:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 23:51:42,145:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-31 23:51:42,182:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,225:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-03-31 23:51:42,225:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-31 23:51:42,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,253:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,254:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-03-31 23:51:42,306:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-31 23:51:42,334:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,383:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-03-31 23:51:42,408:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,409:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-03-31 23:51:42,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:42,571:INFO:Preparing preprocessing pipeline...
2025-03-31 23:51:42,578:INFO:Set up simple imputation.
2025-03-31 23:51:42,583:INFO:Set up encoding of ordinal features.
2025-03-31 23:51:42,585:INFO:Set up encoding of categorical features.
2025-03-31 23:51:42,746:INFO:Finished creating preprocessing pipeline.
2025-03-31 23:51:42,770:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-03-31 23:51:42,770:INFO:Creating final display dataframe.
2025-03-31 23:51:43,197:INFO:Setup _display_container:                     Description             Value
0                    Session id              7649
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              d07c
2025-03-31 23:51:43,281:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:43,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:43,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:43,358:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-03-31 23:51:43,359:INFO:setup() successfully completed in 1.44s...............
2025-03-31 23:51:43,359:INFO:Initializing compare_models()
2025-03-31 23:51:43,359:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-03-31 23:51:43,359:INFO:Checking exceptions
2025-03-31 23:51:43,370:INFO:Preparing display monitor
2025-03-31 23:51:43,372:INFO:Initializing Logistic Regression
2025-03-31 23:51:43,372:INFO:Total runtime is 0.0 minutes
2025-03-31 23:51:43,372:INFO:SubProcess create_model() called ==================================
2025-03-31 23:51:43,373:INFO:Initializing create_model()
2025-03-31 23:51:43,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:51:43,373:INFO:Checking exceptions
2025-03-31 23:51:43,373:INFO:Importing libraries
2025-03-31 23:51:43,373:INFO:Copying training dataset
2025-03-31 23:51:43,377:INFO:Defining folds
2025-03-31 23:51:43,377:INFO:Declaring metric variables
2025-03-31 23:51:43,377:INFO:Importing untrained model
2025-03-31 23:51:43,377:INFO:Logistic Regression Imported successfully
2025-03-31 23:51:43,378:INFO:Starting cross validation
2025-03-31 23:51:43,379:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:51:57,952:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:51:57,952:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:51:57,952:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:51:57,952:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:51:57,952:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:51:57,952:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:51:57,952:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:51:57,952:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:51:58,064:INFO:Calculating mean and std
2025-03-31 23:51:58,066:INFO:Creating metrics dataframe
2025-03-31 23:51:58,072:INFO:Uploading results into container
2025-03-31 23:51:58,074:INFO:Uploading model into container now
2025-03-31 23:51:58,075:INFO:_master_model_container: 1
2025-03-31 23:51:58,075:INFO:_display_container: 2
2025-03-31 23:51:58,076:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-31 23:51:58,076:INFO:create_model() successfully completed......................................
2025-03-31 23:51:58,330:INFO:SubProcess create_model() end ==================================
2025-03-31 23:51:58,330:INFO:Creating metrics dataframe
2025-03-31 23:51:58,332:INFO:Initializing K Neighbors Classifier
2025-03-31 23:51:58,333:INFO:Total runtime is 0.24933764934539795 minutes
2025-03-31 23:51:58,333:INFO:SubProcess create_model() called ==================================
2025-03-31 23:51:58,333:INFO:Initializing create_model()
2025-03-31 23:51:58,333:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:51:58,333:INFO:Checking exceptions
2025-03-31 23:51:58,333:INFO:Importing libraries
2025-03-31 23:51:58,333:INFO:Copying training dataset
2025-03-31 23:51:58,337:INFO:Defining folds
2025-03-31 23:51:58,337:INFO:Declaring metric variables
2025-03-31 23:51:58,337:INFO:Importing untrained model
2025-03-31 23:51:58,338:INFO:K Neighbors Classifier Imported successfully
2025-03-31 23:51:58,338:INFO:Starting cross validation
2025-03-31 23:51:58,340:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:01,069:INFO:Calculating mean and std
2025-03-31 23:52:01,070:INFO:Creating metrics dataframe
2025-03-31 23:52:01,072:INFO:Uploading results into container
2025-03-31 23:52:01,073:INFO:Uploading model into container now
2025-03-31 23:52:01,074:INFO:_master_model_container: 2
2025-03-31 23:52:01,074:INFO:_display_container: 2
2025-03-31 23:52:01,074:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-03-31 23:52:01,074:INFO:create_model() successfully completed......................................
2025-03-31 23:52:01,210:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:01,210:INFO:Creating metrics dataframe
2025-03-31 23:52:01,213:INFO:Initializing Naive Bayes
2025-03-31 23:52:01,213:INFO:Total runtime is 0.2973374764124552 minutes
2025-03-31 23:52:01,214:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:01,214:INFO:Initializing create_model()
2025-03-31 23:52:01,214:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:01,214:INFO:Checking exceptions
2025-03-31 23:52:01,214:INFO:Importing libraries
2025-03-31 23:52:01,214:INFO:Copying training dataset
2025-03-31 23:52:01,218:INFO:Defining folds
2025-03-31 23:52:01,218:INFO:Declaring metric variables
2025-03-31 23:52:01,218:INFO:Importing untrained model
2025-03-31 23:52:01,218:INFO:Naive Bayes Imported successfully
2025-03-31 23:52:01,218:INFO:Starting cross validation
2025-03-31 23:52:01,220:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:01,518:INFO:Calculating mean and std
2025-03-31 23:52:01,519:INFO:Creating metrics dataframe
2025-03-31 23:52:01,520:INFO:Uploading results into container
2025-03-31 23:52:01,520:INFO:Uploading model into container now
2025-03-31 23:52:01,521:INFO:_master_model_container: 3
2025-03-31 23:52:01,521:INFO:_display_container: 2
2025-03-31 23:52:01,521:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-03-31 23:52:01,521:INFO:create_model() successfully completed......................................
2025-03-31 23:52:01,622:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:01,622:INFO:Creating metrics dataframe
2025-03-31 23:52:01,625:INFO:Initializing Decision Tree Classifier
2025-03-31 23:52:01,625:INFO:Total runtime is 0.3042087157567342 minutes
2025-03-31 23:52:01,625:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:01,625:INFO:Initializing create_model()
2025-03-31 23:52:01,625:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:01,625:INFO:Checking exceptions
2025-03-31 23:52:01,625:INFO:Importing libraries
2025-03-31 23:52:01,625:INFO:Copying training dataset
2025-03-31 23:52:01,629:INFO:Defining folds
2025-03-31 23:52:01,629:INFO:Declaring metric variables
2025-03-31 23:52:01,629:INFO:Importing untrained model
2025-03-31 23:52:01,630:INFO:Decision Tree Classifier Imported successfully
2025-03-31 23:52:01,630:INFO:Starting cross validation
2025-03-31 23:52:01,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:01,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:01,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:01,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:01,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:01,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:01,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:01,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:01,945:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:01,962:INFO:Calculating mean and std
2025-03-31 23:52:01,963:INFO:Creating metrics dataframe
2025-03-31 23:52:01,964:INFO:Uploading results into container
2025-03-31 23:52:01,965:INFO:Uploading model into container now
2025-03-31 23:52:01,965:INFO:_master_model_container: 4
2025-03-31 23:52:01,965:INFO:_display_container: 2
2025-03-31 23:52:01,965:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7649, splitter='best')
2025-03-31 23:52:01,966:INFO:create_model() successfully completed......................................
2025-03-31 23:52:02,066:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:02,066:INFO:Creating metrics dataframe
2025-03-31 23:52:02,069:INFO:Initializing SVM - Linear Kernel
2025-03-31 23:52:02,069:INFO:Total runtime is 0.31161770423253377 minutes
2025-03-31 23:52:02,069:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:02,069:INFO:Initializing create_model()
2025-03-31 23:52:02,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:02,069:INFO:Checking exceptions
2025-03-31 23:52:02,069:INFO:Importing libraries
2025-03-31 23:52:02,069:INFO:Copying training dataset
2025-03-31 23:52:02,075:INFO:Defining folds
2025-03-31 23:52:02,075:INFO:Declaring metric variables
2025-03-31 23:52:02,075:INFO:Importing untrained model
2025-03-31 23:52:02,075:INFO:SVM - Linear Kernel Imported successfully
2025-03-31 23:52:02,076:INFO:Starting cross validation
2025-03-31 23:52:02,077:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:02,393:INFO:Calculating mean and std
2025-03-31 23:52:02,394:INFO:Creating metrics dataframe
2025-03-31 23:52:02,395:INFO:Uploading results into container
2025-03-31 23:52:02,396:INFO:Uploading model into container now
2025-03-31 23:52:02,396:INFO:_master_model_container: 5
2025-03-31 23:52:02,396:INFO:_display_container: 2
2025-03-31 23:52:02,396:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7649, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-03-31 23:52:02,396:INFO:create_model() successfully completed......................................
2025-03-31 23:52:02,501:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:02,501:INFO:Creating metrics dataframe
2025-03-31 23:52:02,504:INFO:Initializing Ridge Classifier
2025-03-31 23:52:02,504:INFO:Total runtime is 0.31885333061218263 minutes
2025-03-31 23:52:02,504:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:02,504:INFO:Initializing create_model()
2025-03-31 23:52:02,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:02,505:INFO:Checking exceptions
2025-03-31 23:52:02,505:INFO:Importing libraries
2025-03-31 23:52:02,505:INFO:Copying training dataset
2025-03-31 23:52:02,509:INFO:Defining folds
2025-03-31 23:52:02,509:INFO:Declaring metric variables
2025-03-31 23:52:02,509:INFO:Importing untrained model
2025-03-31 23:52:02,510:INFO:Ridge Classifier Imported successfully
2025-03-31 23:52:02,510:INFO:Starting cross validation
2025-03-31 23:52:02,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:02,833:INFO:Calculating mean and std
2025-03-31 23:52:02,834:INFO:Creating metrics dataframe
2025-03-31 23:52:02,836:INFO:Uploading results into container
2025-03-31 23:52:02,836:INFO:Uploading model into container now
2025-03-31 23:52:02,836:INFO:_master_model_container: 6
2025-03-31 23:52:02,836:INFO:_display_container: 2
2025-03-31 23:52:02,836:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7649, solver='auto',
                tol=0.0001)
2025-03-31 23:52:02,837:INFO:create_model() successfully completed......................................
2025-03-31 23:52:02,942:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:02,942:INFO:Creating metrics dataframe
2025-03-31 23:52:02,944:INFO:Initializing Random Forest Classifier
2025-03-31 23:52:02,945:INFO:Total runtime is 0.326206902662913 minutes
2025-03-31 23:52:02,945:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:02,945:INFO:Initializing create_model()
2025-03-31 23:52:02,945:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:02,945:INFO:Checking exceptions
2025-03-31 23:52:02,945:INFO:Importing libraries
2025-03-31 23:52:02,945:INFO:Copying training dataset
2025-03-31 23:52:02,949:INFO:Defining folds
2025-03-31 23:52:02,949:INFO:Declaring metric variables
2025-03-31 23:52:02,949:INFO:Importing untrained model
2025-03-31 23:52:02,950:INFO:Random Forest Classifier Imported successfully
2025-03-31 23:52:02,950:INFO:Starting cross validation
2025-03-31 23:52:02,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:03,600:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:03,605:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:03,610:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:03,612:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:03,618:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:03,621:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:03,625:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:03,634:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:03,688:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:03,699:INFO:Calculating mean and std
2025-03-31 23:52:03,700:INFO:Creating metrics dataframe
2025-03-31 23:52:03,701:INFO:Uploading results into container
2025-03-31 23:52:03,702:INFO:Uploading model into container now
2025-03-31 23:52:03,702:INFO:_master_model_container: 7
2025-03-31 23:52:03,702:INFO:_display_container: 2
2025-03-31 23:52:03,703:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7649, verbose=0,
                       warm_start=False)
2025-03-31 23:52:03,703:INFO:create_model() successfully completed......................................
2025-03-31 23:52:03,804:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:03,804:INFO:Creating metrics dataframe
2025-03-31 23:52:03,806:INFO:Initializing Quadratic Discriminant Analysis
2025-03-31 23:52:03,806:INFO:Total runtime is 0.34055912494659424 minutes
2025-03-31 23:52:03,806:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:03,806:INFO:Initializing create_model()
2025-03-31 23:52:03,806:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:03,806:INFO:Checking exceptions
2025-03-31 23:52:03,806:INFO:Importing libraries
2025-03-31 23:52:03,807:INFO:Copying training dataset
2025-03-31 23:52:03,813:INFO:Defining folds
2025-03-31 23:52:03,813:INFO:Declaring metric variables
2025-03-31 23:52:03,813:INFO:Importing untrained model
2025-03-31 23:52:03,813:INFO:Quadratic Discriminant Analysis Imported successfully
2025-03-31 23:52:03,813:INFO:Starting cross validation
2025-03-31 23:52:03,815:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:04,022:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-31 23:52:04,022:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-31 23:52:04,022:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-31 23:52:04,023:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-03-31 23:52:04,099:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,099:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,101:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,103:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,103:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,115:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,132:INFO:Calculating mean and std
2025-03-31 23:52:04,133:INFO:Creating metrics dataframe
2025-03-31 23:52:04,134:INFO:Uploading results into container
2025-03-31 23:52:04,135:INFO:Uploading model into container now
2025-03-31 23:52:04,135:INFO:_master_model_container: 8
2025-03-31 23:52:04,135:INFO:_display_container: 2
2025-03-31 23:52:04,135:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-03-31 23:52:04,136:INFO:create_model() successfully completed......................................
2025-03-31 23:52:04,241:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:04,242:INFO:Creating metrics dataframe
2025-03-31 23:52:04,244:INFO:Initializing Ada Boost Classifier
2025-03-31 23:52:04,244:INFO:Total runtime is 0.347856072584788 minutes
2025-03-31 23:52:04,245:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:04,245:INFO:Initializing create_model()
2025-03-31 23:52:04,245:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:04,245:INFO:Checking exceptions
2025-03-31 23:52:04,245:INFO:Importing libraries
2025-03-31 23:52:04,245:INFO:Copying training dataset
2025-03-31 23:52:04,250:INFO:Defining folds
2025-03-31 23:52:04,250:INFO:Declaring metric variables
2025-03-31 23:52:04,250:INFO:Importing untrained model
2025-03-31 23:52:04,251:INFO:Ada Boost Classifier Imported successfully
2025-03-31 23:52:04,251:INFO:Starting cross validation
2025-03-31 23:52:04,253:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-03-31 23:52:04,530:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,531:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,533:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,535:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,535:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,539:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,540:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,541:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,543:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:04,556:INFO:Calculating mean and std
2025-03-31 23:52:04,556:INFO:Creating metrics dataframe
2025-03-31 23:52:04,558:INFO:Uploading results into container
2025-03-31 23:52:04,558:INFO:Uploading model into container now
2025-03-31 23:52:04,558:INFO:_master_model_container: 9
2025-03-31 23:52:04,558:INFO:_display_container: 2
2025-03-31 23:52:04,560:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7649)
2025-03-31 23:52:04,560:INFO:create_model() successfully completed......................................
2025-03-31 23:52:04,661:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:04,661:INFO:Creating metrics dataframe
2025-03-31 23:52:04,663:INFO:Initializing Gradient Boosting Classifier
2025-03-31 23:52:04,664:INFO:Total runtime is 0.35485570033391317 minutes
2025-03-31 23:52:04,664:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:04,664:INFO:Initializing create_model()
2025-03-31 23:52:04,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:04,664:INFO:Checking exceptions
2025-03-31 23:52:04,664:INFO:Importing libraries
2025-03-31 23:52:04,664:INFO:Copying training dataset
2025-03-31 23:52:04,668:INFO:Defining folds
2025-03-31 23:52:04,668:INFO:Declaring metric variables
2025-03-31 23:52:04,668:INFO:Importing untrained model
2025-03-31 23:52:04,668:INFO:Gradient Boosting Classifier Imported successfully
2025-03-31 23:52:04,668:INFO:Starting cross validation
2025-03-31 23:52:04,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:05,096:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,103:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,107:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,114:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,116:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,118:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,119:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,128:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,131:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,141:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,154:INFO:Calculating mean and std
2025-03-31 23:52:05,155:INFO:Creating metrics dataframe
2025-03-31 23:52:05,156:INFO:Uploading results into container
2025-03-31 23:52:05,158:INFO:Uploading model into container now
2025-03-31 23:52:05,158:INFO:_master_model_container: 10
2025-03-31 23:52:05,158:INFO:_display_container: 2
2025-03-31 23:52:05,159:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7649, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-03-31 23:52:05,159:INFO:create_model() successfully completed......................................
2025-03-31 23:52:05,258:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:05,258:INFO:Creating metrics dataframe
2025-03-31 23:52:05,262:INFO:Initializing Linear Discriminant Analysis
2025-03-31 23:52:05,262:INFO:Total runtime is 0.36482288042704264 minutes
2025-03-31 23:52:05,262:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:05,262:INFO:Initializing create_model()
2025-03-31 23:52:05,262:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:05,262:INFO:Checking exceptions
2025-03-31 23:52:05,262:INFO:Importing libraries
2025-03-31 23:52:05,262:INFO:Copying training dataset
2025-03-31 23:52:05,266:INFO:Defining folds
2025-03-31 23:52:05,266:INFO:Declaring metric variables
2025-03-31 23:52:05,266:INFO:Importing untrained model
2025-03-31 23:52:05,267:INFO:Linear Discriminant Analysis Imported successfully
2025-03-31 23:52:05,267:INFO:Starting cross validation
2025-03-31 23:52:05,268:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:05,545:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,546:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,549:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,549:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,550:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,555:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,559:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,560:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,562:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:05,571:INFO:Calculating mean and std
2025-03-31 23:52:05,572:INFO:Creating metrics dataframe
2025-03-31 23:52:05,573:INFO:Uploading results into container
2025-03-31 23:52:05,574:INFO:Uploading model into container now
2025-03-31 23:52:05,574:INFO:_master_model_container: 11
2025-03-31 23:52:05,574:INFO:_display_container: 2
2025-03-31 23:52:05,574:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-03-31 23:52:05,574:INFO:create_model() successfully completed......................................
2025-03-31 23:52:05,674:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:05,674:INFO:Creating metrics dataframe
2025-03-31 23:52:05,676:INFO:Initializing Extra Trees Classifier
2025-03-31 23:52:05,676:INFO:Total runtime is 0.3717228889465332 minutes
2025-03-31 23:52:05,676:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:05,676:INFO:Initializing create_model()
2025-03-31 23:52:05,676:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:05,676:INFO:Checking exceptions
2025-03-31 23:52:05,676:INFO:Importing libraries
2025-03-31 23:52:05,676:INFO:Copying training dataset
2025-03-31 23:52:05,681:INFO:Defining folds
2025-03-31 23:52:05,681:INFO:Declaring metric variables
2025-03-31 23:52:05,682:INFO:Importing untrained model
2025-03-31 23:52:05,682:INFO:Extra Trees Classifier Imported successfully
2025-03-31 23:52:05,682:INFO:Starting cross validation
2025-03-31 23:52:05,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:06,380:INFO:Calculating mean and std
2025-03-31 23:52:06,381:INFO:Creating metrics dataframe
2025-03-31 23:52:06,382:INFO:Uploading results into container
2025-03-31 23:52:06,383:INFO:Uploading model into container now
2025-03-31 23:52:06,383:INFO:_master_model_container: 12
2025-03-31 23:52:06,383:INFO:_display_container: 2
2025-03-31 23:52:06,383:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7649, verbose=0,
                     warm_start=False)
2025-03-31 23:52:06,383:INFO:create_model() successfully completed......................................
2025-03-31 23:52:06,480:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:06,480:INFO:Creating metrics dataframe
2025-03-31 23:52:06,483:INFO:Initializing Light Gradient Boosting Machine
2025-03-31 23:52:06,483:INFO:Total runtime is 0.3851732889811198 minutes
2025-03-31 23:52:06,484:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:06,484:INFO:Initializing create_model()
2025-03-31 23:52:06,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:06,484:INFO:Checking exceptions
2025-03-31 23:52:06,484:INFO:Importing libraries
2025-03-31 23:52:06,484:INFO:Copying training dataset
2025-03-31 23:52:06,488:INFO:Defining folds
2025-03-31 23:52:06,489:INFO:Declaring metric variables
2025-03-31 23:52:06,489:INFO:Importing untrained model
2025-03-31 23:52:06,489:INFO:Light Gradient Boosting Machine Imported successfully
2025-03-31 23:52:06,489:INFO:Starting cross validation
2025-03-31 23:52:06,491:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:07,233:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,258:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,259:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,262:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,373:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,383:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,386:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,400:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,465:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,466:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,475:INFO:Calculating mean and std
2025-03-31 23:52:07,476:INFO:Creating metrics dataframe
2025-03-31 23:52:07,478:INFO:Uploading results into container
2025-03-31 23:52:07,478:INFO:Uploading model into container now
2025-03-31 23:52:07,479:INFO:_master_model_container: 13
2025-03-31 23:52:07,479:INFO:_display_container: 2
2025-03-31 23:52:07,480:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7649, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-03-31 23:52:07,480:INFO:create_model() successfully completed......................................
2025-03-31 23:52:07,596:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:07,596:INFO:Creating metrics dataframe
2025-03-31 23:52:07,599:INFO:Initializing Dummy Classifier
2025-03-31 23:52:07,599:INFO:Total runtime is 0.4037738005320231 minutes
2025-03-31 23:52:07,599:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:07,599:INFO:Initializing create_model()
2025-03-31 23:52:07,599:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E72D443A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:07,599:INFO:Checking exceptions
2025-03-31 23:52:07,599:INFO:Importing libraries
2025-03-31 23:52:07,599:INFO:Copying training dataset
2025-03-31 23:52:07,603:INFO:Defining folds
2025-03-31 23:52:07,603:INFO:Declaring metric variables
2025-03-31 23:52:07,604:INFO:Importing untrained model
2025-03-31 23:52:07,604:INFO:Dummy Classifier Imported successfully
2025-03-31 23:52:07,604:INFO:Starting cross validation
2025-03-31 23:52:07,605:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:07,878:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,882:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,886:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,892:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,892:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,905:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,905:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,906:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,909:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,913:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-03-31 23:52:07,921:INFO:Calculating mean and std
2025-03-31 23:52:07,922:INFO:Creating metrics dataframe
2025-03-31 23:52:07,923:INFO:Uploading results into container
2025-03-31 23:52:07,924:INFO:Uploading model into container now
2025-03-31 23:52:07,924:INFO:_master_model_container: 14
2025-03-31 23:52:07,925:INFO:_display_container: 2
2025-03-31 23:52:07,925:INFO:DummyClassifier(constant=None, random_state=7649, strategy='prior')
2025-03-31 23:52:07,925:INFO:create_model() successfully completed......................................
2025-03-31 23:52:08,031:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:08,031:INFO:Creating metrics dataframe
2025-03-31 23:52:08,058:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-03-31 23:52:08,060:INFO:Initializing create_model()
2025-03-31 23:52:08,061:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:08,061:INFO:Checking exceptions
2025-03-31 23:52:08,062:INFO:Importing libraries
2025-03-31 23:52:08,062:INFO:Copying training dataset
2025-03-31 23:52:08,066:INFO:Defining folds
2025-03-31 23:52:08,066:INFO:Declaring metric variables
2025-03-31 23:52:08,066:INFO:Importing untrained model
2025-03-31 23:52:08,066:INFO:Declaring custom model
2025-03-31 23:52:08,066:INFO:Logistic Regression Imported successfully
2025-03-31 23:52:08,067:INFO:Cross validation set to False
2025-03-31 23:52:08,067:INFO:Fitting Model
2025-03-31 23:52:08,271:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:08,272:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-31 23:52:08,272:INFO:create_model() successfully completed......................................
2025-03-31 23:52:08,386:INFO:_master_model_container: 14
2025-03-31 23:52:08,386:INFO:_display_container: 2
2025-03-31 23:52:08,387:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-31 23:52:08,387:INFO:compare_models() successfully completed......................................
2025-03-31 23:52:08,387:INFO:Initializing tune_model()
2025-03-31 23:52:08,387:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>)
2025-03-31 23:52:08,388:INFO:Checking exceptions
2025-03-31 23:52:08,391:INFO:Copying training dataset
2025-03-31 23:52:08,394:INFO:Checking base model
2025-03-31 23:52:08,395:INFO:Base model : Logistic Regression
2025-03-31 23:52:08,395:INFO:Declaring metric variables
2025-03-31 23:52:08,396:INFO:Defining Hyperparameters
2025-03-31 23:52:08,497:INFO:Tuning with n_jobs=-1
2025-03-31 23:52:08,497:INFO:Initializing RandomizedSearchCV
2025-03-31 23:52:08,957:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:08,961:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:08,970:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:08,972:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,023:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,027:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,046:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,059:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,112:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,120:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,131:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,262:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,578:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,630:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,636:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,670:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,705:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,707:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,911:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,921:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:09,957:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,078:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,109:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,181:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,208:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,222:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,235:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,254:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,321:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,416:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,438:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,449:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,538:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,586:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,613:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,673:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,726:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,741:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,756:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,874:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,912:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,972:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,975:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:10,999:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,064:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,122:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,148:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,252:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,266:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,284:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,298:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,324:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,485:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,511:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,553:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,598:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,601:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,625:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,788:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,793:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,798:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,803:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,820:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,949:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:11,964:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,019:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,048:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,064:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,294:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,296:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,298:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,321:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,338:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,351:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,421:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,452:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,489:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,536:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,565:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,629:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,786:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,849:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,874:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,899:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,919:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,971:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,972:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:12,996:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,069:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,073:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,150:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,180:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,225:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,245:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,288:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 2.211}
2025-03-31 23:52:13,288:INFO:Hyperparameter search completed
2025-03-31 23:52:13,288:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:13,289:INFO:Initializing create_model()
2025-03-31 23:52:13,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019E6F3E2710>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 2.211})
2025-03-31 23:52:13,289:INFO:Checking exceptions
2025-03-31 23:52:13,289:INFO:Importing libraries
2025-03-31 23:52:13,289:INFO:Copying training dataset
2025-03-31 23:52:13,294:INFO:Defining folds
2025-03-31 23:52:13,294:INFO:Declaring metric variables
2025-03-31 23:52:13,294:INFO:Importing untrained model
2025-03-31 23:52:13,294:INFO:Declaring custom model
2025-03-31 23:52:13,295:INFO:Logistic Regression Imported successfully
2025-03-31 23:52:13,295:INFO:Starting cross validation
2025-03-31 23:52:13,297:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:13,727:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,727:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,733:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,735:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,735:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,736:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,740:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,743:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,755:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,760:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:13,844:INFO:Calculating mean and std
2025-03-31 23:52:13,845:INFO:Creating metrics dataframe
2025-03-31 23:52:13,846:INFO:Finalizing model
2025-03-31 23:52:14,038:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,040:INFO:Uploading results into container
2025-03-31 23:52:14,040:INFO:Uploading model into container now
2025-03-31 23:52:14,041:INFO:_master_model_container: 15
2025-03-31 23:52:14,041:INFO:_display_container: 3
2025-03-31 23:52:14,041:INFO:LogisticRegression(C=2.211, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-31 23:52:14,041:INFO:create_model() successfully completed......................................
2025-03-31 23:52:14,143:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:14,143:INFO:choose_better activated
2025-03-31 23:52:14,144:INFO:SubProcess create_model() called ==================================
2025-03-31 23:52:14,144:INFO:Initializing create_model()
2025-03-31 23:52:14,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-03-31 23:52:14,144:INFO:Checking exceptions
2025-03-31 23:52:14,145:INFO:Importing libraries
2025-03-31 23:52:14,145:INFO:Copying training dataset
2025-03-31 23:52:14,149:INFO:Defining folds
2025-03-31 23:52:14,149:INFO:Declaring metric variables
2025-03-31 23:52:14,149:INFO:Importing untrained model
2025-03-31 23:52:14,149:INFO:Declaring custom model
2025-03-31 23:52:14,150:INFO:Logistic Regression Imported successfully
2025-03-31 23:52:14,150:INFO:Starting cross validation
2025-03-31 23:52:14,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-03-31 23:52:14,544:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,546:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,548:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,548:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,555:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,556:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,559:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,560:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,563:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,565:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,652:INFO:Calculating mean and std
2025-03-31 23:52:14,652:INFO:Creating metrics dataframe
2025-03-31 23:52:14,654:INFO:Finalizing model
2025-03-31 23:52:14,840:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-03-31 23:52:14,840:INFO:Uploading results into container
2025-03-31 23:52:14,841:INFO:Uploading model into container now
2025-03-31 23:52:14,841:INFO:_master_model_container: 16
2025-03-31 23:52:14,841:INFO:_display_container: 4
2025-03-31 23:52:14,841:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-31 23:52:14,841:INFO:create_model() successfully completed......................................
2025-03-31 23:52:14,942:INFO:SubProcess create_model() end ==================================
2025-03-31 23:52:14,943:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8091
2025-03-31 23:52:14,944:INFO:LogisticRegression(C=2.211, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8123
2025-03-31 23:52:14,944:INFO:LogisticRegression(C=2.211, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-03-31 23:52:14,944:INFO:choose_better completed
2025-03-31 23:52:14,954:INFO:_master_model_container: 16
2025-03-31 23:52:14,954:INFO:_display_container: 3
2025-03-31 23:52:14,954:INFO:LogisticRegression(C=2.211, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-03-31 23:52:14,955:INFO:tune_model() successfully completed......................................
2025-03-31 23:52:15,075:INFO:Initializing save_model()
2025-03-31 23:52:15,076:INFO:save_model(model=LogisticRegression(C=2.211, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7649, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-03-31 23:52:15,076:INFO:Adding model into prep_pipe
2025-03-31 23:52:15,087:INFO:best_classifier.pkl saved in current working directory
2025-03-31 23:52:15,108:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=2.211, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=7649,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-03-31 23:52:15,108:INFO:save_model() successfully completed......................................
2025-03-31 23:53:25,337:INFO:Initializing load_model()
2025-03-31 23:53:25,337:INFO:load_model(model_name=best_classifier, platform=None, authentication=None, verbose=True)
2025-03-31 23:53:25,396:INFO:Initializing predict_model()
2025-03-31 23:53:25,396:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019E6F3A0250>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(C=2.211, class_weight={}, max_iter=1000,
                                    random_state=7649))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000019E70A3B640>)
2025-03-31 23:53:25,396:INFO:Checking exceptions
2025-03-31 23:53:25,396:INFO:Preloading libraries
2025-03-31 23:53:25,396:INFO:Set up data.
2025-03-31 23:53:25,406:INFO:Set up index.
2025-04-02 23:08:07,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-02 23:08:07,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-02 23:08:07,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-02 23:08:07,459:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-02 23:08:21,871:INFO:PyCaret ClassificationExperiment
2025-04-02 23:08:21,872:INFO:Logging name: clf-default-name
2025-04-02 23:08:21,872:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-02 23:08:21,872:INFO:version 3.3.2
2025-04-02 23:08:21,872:INFO:Initializing setup()
2025-04-02 23:08:21,872:INFO:self.USI: 01a7
2025-04-02 23:08:21,872:INFO:self._variable_keys: {'logging_param', 'exp_id', 'pipeline', 'fold_generator', 'target_param', 'fold_groups_param', '_available_plots', 'log_plots_param', 'idx', 'seed', 'memory', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'X', 'fold_shuffle_param', 'is_multiclass', 'exp_name_log', 'X_train', 'fix_imbalance', 'y_train', 'X_test', 'y', 'n_jobs_param', 'data', 'gpu_param', 'html_param', 'y_test'}
2025-04-02 23:08:21,872:INFO:Checking environment
2025-04-02 23:08:21,872:INFO:python_version: 3.10.0
2025-04-02 23:08:21,872:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-02 23:08:21,872:INFO:machine: AMD64
2025-04-02 23:08:21,899:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-02 23:08:21,906:INFO:Memory: svmem(total=17037209600, available=5501698048, percent=67.7, used=11535511552, free=5501698048)
2025-04-02 23:08:21,906:INFO:Physical Core: 6
2025-04-02 23:08:21,906:INFO:Logical Core: 12
2025-04-02 23:08:21,906:INFO:Checking libraries
2025-04-02 23:08:21,906:INFO:System:
2025-04-02 23:08:21,906:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-02 23:08:21,906:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-04-02 23:08:21,906:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-02 23:08:21,906:INFO:PyCaret required dependencies:
2025-04-02 23:08:21,992:INFO:                 pip: 21.2.3
2025-04-02 23:08:21,992:INFO:          setuptools: 57.4.0
2025-04-02 23:08:21,992:INFO:             pycaret: 3.3.2
2025-04-02 23:08:21,992:INFO:             IPython: 8.29.0
2025-04-02 23:08:21,992:INFO:          ipywidgets: 8.1.5
2025-04-02 23:08:21,992:INFO:                tqdm: 4.67.0
2025-04-02 23:08:21,992:INFO:               numpy: 1.26.4
2025-04-02 23:08:21,992:INFO:              pandas: 2.1.4
2025-04-02 23:08:21,992:INFO:              jinja2: 3.1.4
2025-04-02 23:08:21,992:INFO:               scipy: 1.11.4
2025-04-02 23:08:21,992:INFO:              joblib: 1.3.2
2025-04-02 23:08:21,992:INFO:             sklearn: 1.4.2
2025-04-02 23:08:21,992:INFO:                pyod: 2.0.2
2025-04-02 23:08:21,993:INFO:            imblearn: 0.12.4
2025-04-02 23:08:21,993:INFO:   category_encoders: 2.6.4
2025-04-02 23:08:21,993:INFO:            lightgbm: 4.5.0
2025-04-02 23:08:21,993:INFO:               numba: 0.60.0
2025-04-02 23:08:21,993:INFO:            requests: 2.32.3
2025-04-02 23:08:21,993:INFO:          matplotlib: 3.7.5
2025-04-02 23:08:21,993:INFO:          scikitplot: 0.3.7
2025-04-02 23:08:21,993:INFO:         yellowbrick: 1.5
2025-04-02 23:08:21,993:INFO:              plotly: 5.24.1
2025-04-02 23:08:21,993:INFO:    plotly-resampler: Not installed
2025-04-02 23:08:21,993:INFO:             kaleido: 0.2.1
2025-04-02 23:08:21,993:INFO:           schemdraw: 0.15
2025-04-02 23:08:21,993:INFO:         statsmodels: 0.14.4
2025-04-02 23:08:21,993:INFO:              sktime: 0.26.0
2025-04-02 23:08:21,993:INFO:               tbats: 1.1.3
2025-04-02 23:08:21,993:INFO:            pmdarima: 2.0.4
2025-04-02 23:08:21,993:INFO:              psutil: 6.1.0
2025-04-02 23:08:21,993:INFO:          markupsafe: 3.0.2
2025-04-02 23:08:21,993:INFO:             pickle5: Not installed
2025-04-02 23:08:21,993:INFO:         cloudpickle: 3.1.0
2025-04-02 23:08:21,993:INFO:         deprecation: 2.1.0
2025-04-02 23:08:21,993:INFO:              xxhash: 3.5.0
2025-04-02 23:08:21,993:INFO:           wurlitzer: Not installed
2025-04-02 23:08:21,993:INFO:PyCaret optional dependencies:
2025-04-02 23:08:22,006:INFO:                shap: 0.47.0
2025-04-02 23:08:22,006:INFO:           interpret: Not installed
2025-04-02 23:08:22,006:INFO:                umap: Not installed
2025-04-02 23:08:22,006:INFO:     ydata_profiling: 4.12.0
2025-04-02 23:08:22,006:INFO:  explainerdashboard: Not installed
2025-04-02 23:08:22,006:INFO:             autoviz: Not installed
2025-04-02 23:08:22,006:INFO:           fairlearn: Not installed
2025-04-02 23:08:22,006:INFO:          deepchecks: Not installed
2025-04-02 23:08:22,006:INFO:             xgboost: Not installed
2025-04-02 23:08:22,006:INFO:            catboost: Not installed
2025-04-02 23:08:22,006:INFO:              kmodes: Not installed
2025-04-02 23:08:22,006:INFO:             mlxtend: Not installed
2025-04-02 23:08:22,006:INFO:       statsforecast: Not installed
2025-04-02 23:08:22,006:INFO:        tune_sklearn: Not installed
2025-04-02 23:08:22,006:INFO:                 ray: Not installed
2025-04-02 23:08:22,006:INFO:            hyperopt: Not installed
2025-04-02 23:08:22,006:INFO:              optuna: Not installed
2025-04-02 23:08:22,006:INFO:               skopt: Not installed
2025-04-02 23:08:22,006:INFO:              mlflow: Not installed
2025-04-02 23:08:22,006:INFO:              gradio: Not installed
2025-04-02 23:08:22,006:INFO:             fastapi: Not installed
2025-04-02 23:08:22,006:INFO:             uvicorn: Not installed
2025-04-02 23:08:22,007:INFO:              m2cgen: Not installed
2025-04-02 23:08:22,007:INFO:           evidently: Not installed
2025-04-02 23:08:22,007:INFO:               fugue: Not installed
2025-04-02 23:08:22,007:INFO:           streamlit: 1.40.0
2025-04-02 23:08:22,007:INFO:             prophet: Not installed
2025-04-02 23:08:22,007:INFO:None
2025-04-02 23:08:22,007:INFO:Set up data.
2025-04-02 23:08:22,029:INFO:Set up folding strategy.
2025-04-02 23:08:22,029:INFO:Set up train/test split.
2025-04-02 23:08:22,043:INFO:Set up index.
2025-04-02 23:08:22,045:INFO:Assigning column types.
2025-04-02 23:08:22,049:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-02 23:08:22,090:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:08:22,094:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-02 23:08:22,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,173:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:08:22,174:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-02 23:08:22,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,201:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,201:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-02 23:08:22,243:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-02 23:08:22,269:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,310:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-02 23:08:22,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,335:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,336:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-02 23:08:22,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,475:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:22,476:INFO:Preparing preprocessing pipeline...
2025-04-02 23:08:22,478:INFO:Set up simple imputation.
2025-04-02 23:08:22,481:INFO:Set up encoding of ordinal features.
2025-04-02 23:08:22,483:INFO:Set up encoding of categorical features.
2025-04-02 23:08:22,627:INFO:Finished creating preprocessing pipeline.
2025-04-02 23:08:22,649:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-04-02 23:08:22,650:INFO:Creating final display dataframe.
2025-04-02 23:08:23,049:INFO:Setup _display_container:                     Description             Value
0                    Session id              3704
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              01a7
2025-04-02 23:08:23,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:23,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:23,191:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:23,192:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:08:23,193:INFO:setup() successfully completed in 1.33s...............
2025-04-02 23:08:23,193:INFO:Initializing compare_models()
2025-04-02 23:08:23,193:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-02 23:08:23,193:INFO:Checking exceptions
2025-04-02 23:08:23,202:INFO:Preparing display monitor
2025-04-02 23:08:23,206:INFO:Initializing Logistic Regression
2025-04-02 23:08:23,206:INFO:Total runtime is 0.0 minutes
2025-04-02 23:08:23,206:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:23,206:INFO:Initializing create_model()
2025-04-02 23:08:23,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:23,207:INFO:Checking exceptions
2025-04-02 23:08:23,207:INFO:Importing libraries
2025-04-02 23:08:23,207:INFO:Copying training dataset
2025-04-02 23:08:23,211:INFO:Defining folds
2025-04-02 23:08:23,211:INFO:Declaring metric variables
2025-04-02 23:08:23,211:INFO:Importing untrained model
2025-04-02 23:08:23,211:INFO:Logistic Regression Imported successfully
2025-04-02 23:08:23,212:INFO:Starting cross validation
2025-04-02 23:08:23,213:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:28,335:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:28,335:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:28,336:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:28,335:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:28,340:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:28,353:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:28,363:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:28,371:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:28,387:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:28,486:INFO:Calculating mean and std
2025-04-02 23:08:28,490:INFO:Creating metrics dataframe
2025-04-02 23:08:28,495:INFO:Uploading results into container
2025-04-02 23:08:28,496:INFO:Uploading model into container now
2025-04-02 23:08:28,502:INFO:_master_model_container: 1
2025-04-02 23:08:28,502:INFO:_display_container: 2
2025-04-02 23:08:28,504:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-02 23:08:28,504:INFO:create_model() successfully completed......................................
2025-04-02 23:08:28,659:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:28,659:INFO:Creating metrics dataframe
2025-04-02 23:08:28,667:INFO:Initializing K Neighbors Classifier
2025-04-02 23:08:28,667:INFO:Total runtime is 0.0910106341044108 minutes
2025-04-02 23:08:28,668:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:28,668:INFO:Initializing create_model()
2025-04-02 23:08:28,668:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:28,668:INFO:Checking exceptions
2025-04-02 23:08:28,668:INFO:Importing libraries
2025-04-02 23:08:28,668:INFO:Copying training dataset
2025-04-02 23:08:28,673:INFO:Defining folds
2025-04-02 23:08:28,673:INFO:Declaring metric variables
2025-04-02 23:08:28,673:INFO:Importing untrained model
2025-04-02 23:08:28,673:INFO:K Neighbors Classifier Imported successfully
2025-04-02 23:08:28,673:INFO:Starting cross validation
2025-04-02 23:08:28,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:31,014:INFO:Calculating mean and std
2025-04-02 23:08:31,015:INFO:Creating metrics dataframe
2025-04-02 23:08:31,017:INFO:Uploading results into container
2025-04-02 23:08:31,017:INFO:Uploading model into container now
2025-04-02 23:08:31,018:INFO:_master_model_container: 2
2025-04-02 23:08:31,018:INFO:_display_container: 2
2025-04-02 23:08:31,018:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-02 23:08:31,018:INFO:create_model() successfully completed......................................
2025-04-02 23:08:31,115:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:31,115:INFO:Creating metrics dataframe
2025-04-02 23:08:31,122:INFO:Initializing Naive Bayes
2025-04-02 23:08:31,122:INFO:Total runtime is 0.13192253510157267 minutes
2025-04-02 23:08:31,122:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:31,122:INFO:Initializing create_model()
2025-04-02 23:08:31,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:31,123:INFO:Checking exceptions
2025-04-02 23:08:31,123:INFO:Importing libraries
2025-04-02 23:08:31,123:INFO:Copying training dataset
2025-04-02 23:08:31,128:INFO:Defining folds
2025-04-02 23:08:31,128:INFO:Declaring metric variables
2025-04-02 23:08:31,128:INFO:Importing untrained model
2025-04-02 23:08:31,128:INFO:Naive Bayes Imported successfully
2025-04-02 23:08:31,129:INFO:Starting cross validation
2025-04-02 23:08:31,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:31,386:INFO:Calculating mean and std
2025-04-02 23:08:31,389:INFO:Creating metrics dataframe
2025-04-02 23:08:31,394:INFO:Uploading results into container
2025-04-02 23:08:31,395:INFO:Uploading model into container now
2025-04-02 23:08:31,396:INFO:_master_model_container: 3
2025-04-02 23:08:31,397:INFO:_display_container: 2
2025-04-02 23:08:31,397:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-02 23:08:31,397:INFO:create_model() successfully completed......................................
2025-04-02 23:08:31,525:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:31,526:INFO:Creating metrics dataframe
2025-04-02 23:08:31,529:INFO:Initializing Decision Tree Classifier
2025-04-02 23:08:31,529:INFO:Total runtime is 0.1387035330136617 minutes
2025-04-02 23:08:31,529:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:31,529:INFO:Initializing create_model()
2025-04-02 23:08:31,529:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:31,530:INFO:Checking exceptions
2025-04-02 23:08:31,530:INFO:Importing libraries
2025-04-02 23:08:31,530:INFO:Copying training dataset
2025-04-02 23:08:31,534:INFO:Defining folds
2025-04-02 23:08:31,534:INFO:Declaring metric variables
2025-04-02 23:08:31,534:INFO:Importing untrained model
2025-04-02 23:08:31,534:INFO:Decision Tree Classifier Imported successfully
2025-04-02 23:08:31,534:INFO:Starting cross validation
2025-04-02 23:08:31,535:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:31,789:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:31,790:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:31,790:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:31,790:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:31,790:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:31,790:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:31,790:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:31,790:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:31,810:INFO:Calculating mean and std
2025-04-02 23:08:31,811:INFO:Creating metrics dataframe
2025-04-02 23:08:31,812:INFO:Uploading results into container
2025-04-02 23:08:31,813:INFO:Uploading model into container now
2025-04-02 23:08:31,813:INFO:_master_model_container: 4
2025-04-02 23:08:31,813:INFO:_display_container: 2
2025-04-02 23:08:31,813:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3704, splitter='best')
2025-04-02 23:08:31,813:INFO:create_model() successfully completed......................................
2025-04-02 23:08:31,900:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:31,900:INFO:Creating metrics dataframe
2025-04-02 23:08:31,903:INFO:Initializing SVM - Linear Kernel
2025-04-02 23:08:31,903:INFO:Total runtime is 0.14493711392084757 minutes
2025-04-02 23:08:31,903:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:31,903:INFO:Initializing create_model()
2025-04-02 23:08:31,903:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:31,903:INFO:Checking exceptions
2025-04-02 23:08:31,903:INFO:Importing libraries
2025-04-02 23:08:31,904:INFO:Copying training dataset
2025-04-02 23:08:31,907:INFO:Defining folds
2025-04-02 23:08:31,907:INFO:Declaring metric variables
2025-04-02 23:08:31,907:INFO:Importing untrained model
2025-04-02 23:08:31,907:INFO:SVM - Linear Kernel Imported successfully
2025-04-02 23:08:31,909:INFO:Starting cross validation
2025-04-02 23:08:31,910:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:32,152:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:32,154:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:32,175:INFO:Calculating mean and std
2025-04-02 23:08:32,176:INFO:Creating metrics dataframe
2025-04-02 23:08:32,177:INFO:Uploading results into container
2025-04-02 23:08:32,177:INFO:Uploading model into container now
2025-04-02 23:08:32,177:INFO:_master_model_container: 5
2025-04-02 23:08:32,177:INFO:_display_container: 2
2025-04-02 23:08:32,179:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3704, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-02 23:08:32,179:INFO:create_model() successfully completed......................................
2025-04-02 23:08:32,264:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:32,264:INFO:Creating metrics dataframe
2025-04-02 23:08:32,266:INFO:Initializing Ridge Classifier
2025-04-02 23:08:32,266:INFO:Total runtime is 0.15099773406982422 minutes
2025-04-02 23:08:32,267:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:32,267:INFO:Initializing create_model()
2025-04-02 23:08:32,267:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:32,267:INFO:Checking exceptions
2025-04-02 23:08:32,267:INFO:Importing libraries
2025-04-02 23:08:32,267:INFO:Copying training dataset
2025-04-02 23:08:32,271:INFO:Defining folds
2025-04-02 23:08:32,271:INFO:Declaring metric variables
2025-04-02 23:08:32,271:INFO:Importing untrained model
2025-04-02 23:08:32,272:INFO:Ridge Classifier Imported successfully
2025-04-02 23:08:32,272:INFO:Starting cross validation
2025-04-02 23:08:32,273:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:32,526:INFO:Calculating mean and std
2025-04-02 23:08:32,527:INFO:Creating metrics dataframe
2025-04-02 23:08:32,529:INFO:Uploading results into container
2025-04-02 23:08:32,530:INFO:Uploading model into container now
2025-04-02 23:08:32,530:INFO:_master_model_container: 6
2025-04-02 23:08:32,530:INFO:_display_container: 2
2025-04-02 23:08:32,530:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3704, solver='auto',
                tol=0.0001)
2025-04-02 23:08:32,530:INFO:create_model() successfully completed......................................
2025-04-02 23:08:32,617:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:32,617:INFO:Creating metrics dataframe
2025-04-02 23:08:32,620:INFO:Initializing Random Forest Classifier
2025-04-02 23:08:32,620:INFO:Total runtime is 0.15688924789428713 minutes
2025-04-02 23:08:32,621:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:32,621:INFO:Initializing create_model()
2025-04-02 23:08:32,621:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:32,621:INFO:Checking exceptions
2025-04-02 23:08:32,621:INFO:Importing libraries
2025-04-02 23:08:32,621:INFO:Copying training dataset
2025-04-02 23:08:32,627:INFO:Defining folds
2025-04-02 23:08:32,627:INFO:Declaring metric variables
2025-04-02 23:08:32,627:INFO:Importing untrained model
2025-04-02 23:08:32,627:INFO:Random Forest Classifier Imported successfully
2025-04-02 23:08:32,627:INFO:Starting cross validation
2025-04-02 23:08:32,630:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:33,177:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,182:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,200:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,215:INFO:Calculating mean and std
2025-04-02 23:08:33,216:INFO:Creating metrics dataframe
2025-04-02 23:08:33,218:INFO:Uploading results into container
2025-04-02 23:08:33,218:INFO:Uploading model into container now
2025-04-02 23:08:33,218:INFO:_master_model_container: 7
2025-04-02 23:08:33,218:INFO:_display_container: 2
2025-04-02 23:08:33,219:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3704, verbose=0,
                       warm_start=False)
2025-04-02 23:08:33,219:INFO:create_model() successfully completed......................................
2025-04-02 23:08:33,317:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:33,317:INFO:Creating metrics dataframe
2025-04-02 23:08:33,321:INFO:Initializing Quadratic Discriminant Analysis
2025-04-02 23:08:33,321:INFO:Total runtime is 0.16857375701268515 minutes
2025-04-02 23:08:33,321:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:33,321:INFO:Initializing create_model()
2025-04-02 23:08:33,321:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:33,321:INFO:Checking exceptions
2025-04-02 23:08:33,321:INFO:Importing libraries
2025-04-02 23:08:33,321:INFO:Copying training dataset
2025-04-02 23:08:33,325:INFO:Defining folds
2025-04-02 23:08:33,325:INFO:Declaring metric variables
2025-04-02 23:08:33,325:INFO:Importing untrained model
2025-04-02 23:08:33,326:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-02 23:08:33,326:INFO:Starting cross validation
2025-04-02 23:08:33,327:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:33,510:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-02 23:08:33,510:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-02 23:08:33,510:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-02 23:08:33,511:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-02 23:08:33,511:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-02 23:08:33,511:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-02 23:08:33,511:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-02 23:08:33,511:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-02 23:08:33,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,576:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,577:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,577:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,577:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,579:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,592:INFO:Calculating mean and std
2025-04-02 23:08:33,593:INFO:Creating metrics dataframe
2025-04-02 23:08:33,594:INFO:Uploading results into container
2025-04-02 23:08:33,594:INFO:Uploading model into container now
2025-04-02 23:08:33,594:INFO:_master_model_container: 8
2025-04-02 23:08:33,594:INFO:_display_container: 2
2025-04-02 23:08:33,595:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-02 23:08:33,595:INFO:create_model() successfully completed......................................
2025-04-02 23:08:33,683:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:33,683:INFO:Creating metrics dataframe
2025-04-02 23:08:33,685:INFO:Initializing Ada Boost Classifier
2025-04-02 23:08:33,686:INFO:Total runtime is 0.17466540733973185 minutes
2025-04-02 23:08:33,686:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:33,686:INFO:Initializing create_model()
2025-04-02 23:08:33,686:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:33,686:INFO:Checking exceptions
2025-04-02 23:08:33,686:INFO:Importing libraries
2025-04-02 23:08:33,686:INFO:Copying training dataset
2025-04-02 23:08:33,691:INFO:Defining folds
2025-04-02 23:08:33,691:INFO:Declaring metric variables
2025-04-02 23:08:33,691:INFO:Importing untrained model
2025-04-02 23:08:33,691:INFO:Ada Boost Classifier Imported successfully
2025-04-02 23:08:33,691:INFO:Starting cross validation
2025-04-02 23:08:33,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:33,853:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-02 23:08:33,853:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-02 23:08:33,853:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-02 23:08:33,854:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-02 23:08:33,854:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-02 23:08:33,862:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-02 23:08:33,919:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,920:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,922:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,922:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,923:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,923:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,923:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,925:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,928:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,931:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:33,946:INFO:Calculating mean and std
2025-04-02 23:08:33,947:INFO:Creating metrics dataframe
2025-04-02 23:08:33,948:INFO:Uploading results into container
2025-04-02 23:08:33,949:INFO:Uploading model into container now
2025-04-02 23:08:33,949:INFO:_master_model_container: 9
2025-04-02 23:08:33,949:INFO:_display_container: 2
2025-04-02 23:08:33,949:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3704)
2025-04-02 23:08:33,949:INFO:create_model() successfully completed......................................
2025-04-02 23:08:34,037:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:34,037:INFO:Creating metrics dataframe
2025-04-02 23:08:34,040:INFO:Initializing Gradient Boosting Classifier
2025-04-02 23:08:34,040:INFO:Total runtime is 0.1805545409520467 minutes
2025-04-02 23:08:34,040:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:34,040:INFO:Initializing create_model()
2025-04-02 23:08:34,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:34,040:INFO:Checking exceptions
2025-04-02 23:08:34,040:INFO:Importing libraries
2025-04-02 23:08:34,040:INFO:Copying training dataset
2025-04-02 23:08:34,044:INFO:Defining folds
2025-04-02 23:08:34,044:INFO:Declaring metric variables
2025-04-02 23:08:34,044:INFO:Importing untrained model
2025-04-02 23:08:34,044:INFO:Gradient Boosting Classifier Imported successfully
2025-04-02 23:08:34,045:INFO:Starting cross validation
2025-04-02 23:08:34,046:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:34,409:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,409:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,412:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,414:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,417:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,417:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,419:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,420:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,435:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,435:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,443:INFO:Calculating mean and std
2025-04-02 23:08:34,443:INFO:Creating metrics dataframe
2025-04-02 23:08:34,445:INFO:Uploading results into container
2025-04-02 23:08:34,445:INFO:Uploading model into container now
2025-04-02 23:08:34,445:INFO:_master_model_container: 10
2025-04-02 23:08:34,445:INFO:_display_container: 2
2025-04-02 23:08:34,446:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3704, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-02 23:08:34,446:INFO:create_model() successfully completed......................................
2025-04-02 23:08:34,534:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:34,534:INFO:Creating metrics dataframe
2025-04-02 23:08:34,537:INFO:Initializing Linear Discriminant Analysis
2025-04-02 23:08:34,537:INFO:Total runtime is 0.18884663979212443 minutes
2025-04-02 23:08:34,537:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:34,537:INFO:Initializing create_model()
2025-04-02 23:08:34,537:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:34,537:INFO:Checking exceptions
2025-04-02 23:08:34,537:INFO:Importing libraries
2025-04-02 23:08:34,537:INFO:Copying training dataset
2025-04-02 23:08:34,541:INFO:Defining folds
2025-04-02 23:08:34,542:INFO:Declaring metric variables
2025-04-02 23:08:34,542:INFO:Importing untrained model
2025-04-02 23:08:34,542:INFO:Linear Discriminant Analysis Imported successfully
2025-04-02 23:08:34,542:INFO:Starting cross validation
2025-04-02 23:08:34,544:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:34,769:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,770:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,770:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,770:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,770:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,771:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,777:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:34,797:INFO:Calculating mean and std
2025-04-02 23:08:34,798:INFO:Creating metrics dataframe
2025-04-02 23:08:34,801:INFO:Uploading results into container
2025-04-02 23:08:34,801:INFO:Uploading model into container now
2025-04-02 23:08:34,802:INFO:_master_model_container: 11
2025-04-02 23:08:34,802:INFO:_display_container: 2
2025-04-02 23:08:34,802:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-02 23:08:34,802:INFO:create_model() successfully completed......................................
2025-04-02 23:08:34,920:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:34,920:INFO:Creating metrics dataframe
2025-04-02 23:08:34,923:INFO:Initializing Extra Trees Classifier
2025-04-02 23:08:34,923:INFO:Total runtime is 0.19527703126271567 minutes
2025-04-02 23:08:34,923:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:34,923:INFO:Initializing create_model()
2025-04-02 23:08:34,923:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:34,923:INFO:Checking exceptions
2025-04-02 23:08:34,923:INFO:Importing libraries
2025-04-02 23:08:34,923:INFO:Copying training dataset
2025-04-02 23:08:34,928:INFO:Defining folds
2025-04-02 23:08:34,928:INFO:Declaring metric variables
2025-04-02 23:08:34,928:INFO:Importing untrained model
2025-04-02 23:08:34,928:INFO:Extra Trees Classifier Imported successfully
2025-04-02 23:08:34,928:INFO:Starting cross validation
2025-04-02 23:08:34,930:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:35,482:INFO:Calculating mean and std
2025-04-02 23:08:35,483:INFO:Creating metrics dataframe
2025-04-02 23:08:35,484:INFO:Uploading results into container
2025-04-02 23:08:35,484:INFO:Uploading model into container now
2025-04-02 23:08:35,485:INFO:_master_model_container: 12
2025-04-02 23:08:35,485:INFO:_display_container: 2
2025-04-02 23:08:35,485:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3704, verbose=0,
                     warm_start=False)
2025-04-02 23:08:35,485:INFO:create_model() successfully completed......................................
2025-04-02 23:08:35,587:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:35,587:INFO:Creating metrics dataframe
2025-04-02 23:08:35,589:INFO:Initializing Light Gradient Boosting Machine
2025-04-02 23:08:35,589:INFO:Total runtime is 0.20637853542963666 minutes
2025-04-02 23:08:35,590:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:35,590:INFO:Initializing create_model()
2025-04-02 23:08:35,590:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:35,590:INFO:Checking exceptions
2025-04-02 23:08:35,590:INFO:Importing libraries
2025-04-02 23:08:35,590:INFO:Copying training dataset
2025-04-02 23:08:35,593:INFO:Defining folds
2025-04-02 23:08:35,593:INFO:Declaring metric variables
2025-04-02 23:08:35,593:INFO:Importing untrained model
2025-04-02 23:08:35,595:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-02 23:08:35,595:INFO:Starting cross validation
2025-04-02 23:08:35,596:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:36,232:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,233:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,249:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,275:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,351:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,362:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,366:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,384:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,443:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,454:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,466:INFO:Calculating mean and std
2025-04-02 23:08:36,467:INFO:Creating metrics dataframe
2025-04-02 23:08:36,470:INFO:Uploading results into container
2025-04-02 23:08:36,470:INFO:Uploading model into container now
2025-04-02 23:08:36,471:INFO:_master_model_container: 13
2025-04-02 23:08:36,471:INFO:_display_container: 2
2025-04-02 23:08:36,471:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3704, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-02 23:08:36,471:INFO:create_model() successfully completed......................................
2025-04-02 23:08:36,582:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:36,582:INFO:Creating metrics dataframe
2025-04-02 23:08:36,584:INFO:Initializing Dummy Classifier
2025-04-02 23:08:36,584:INFO:Total runtime is 0.22295342683792116 minutes
2025-04-02 23:08:36,584:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:36,585:INFO:Initializing create_model()
2025-04-02 23:08:36,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:36,585:INFO:Checking exceptions
2025-04-02 23:08:36,585:INFO:Importing libraries
2025-04-02 23:08:36,585:INFO:Copying training dataset
2025-04-02 23:08:36,590:INFO:Defining folds
2025-04-02 23:08:36,590:INFO:Declaring metric variables
2025-04-02 23:08:36,591:INFO:Importing untrained model
2025-04-02 23:08:36,591:INFO:Dummy Classifier Imported successfully
2025-04-02 23:08:36,591:INFO:Starting cross validation
2025-04-02 23:08:36,592:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:36,812:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,815:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,820:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,823:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,823:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,823:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,824:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,827:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,833:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,833:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-02 23:08:36,846:INFO:Calculating mean and std
2025-04-02 23:08:36,847:INFO:Creating metrics dataframe
2025-04-02 23:08:36,848:INFO:Uploading results into container
2025-04-02 23:08:36,849:INFO:Uploading model into container now
2025-04-02 23:08:36,849:INFO:_master_model_container: 14
2025-04-02 23:08:36,849:INFO:_display_container: 2
2025-04-02 23:08:36,849:INFO:DummyClassifier(constant=None, random_state=3704, strategy='prior')
2025-04-02 23:08:36,849:INFO:create_model() successfully completed......................................
2025-04-02 23:08:36,937:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:36,939:INFO:Creating metrics dataframe
2025-04-02 23:08:36,942:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-02 23:08:36,943:INFO:Initializing create_model()
2025-04-02 23:08:36,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:36,944:INFO:Checking exceptions
2025-04-02 23:08:36,944:INFO:Importing libraries
2025-04-02 23:08:36,944:INFO:Copying training dataset
2025-04-02 23:08:36,948:INFO:Defining folds
2025-04-02 23:08:36,948:INFO:Declaring metric variables
2025-04-02 23:08:36,948:INFO:Importing untrained model
2025-04-02 23:08:36,948:INFO:Declaring custom model
2025-04-02 23:08:36,949:INFO:Logistic Regression Imported successfully
2025-04-02 23:08:36,950:INFO:Cross validation set to False
2025-04-02 23:08:36,950:INFO:Fitting Model
2025-04-02 23:08:37,130:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:37,131:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-02 23:08:37,131:INFO:create_model() successfully completed......................................
2025-04-02 23:08:37,222:INFO:Initializing create_model()
2025-04-02 23:08:37,222:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3704, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:37,222:INFO:Checking exceptions
2025-04-02 23:08:37,223:INFO:Importing libraries
2025-04-02 23:08:37,223:INFO:Copying training dataset
2025-04-02 23:08:37,226:INFO:Defining folds
2025-04-02 23:08:37,226:INFO:Declaring metric variables
2025-04-02 23:08:37,227:INFO:Importing untrained model
2025-04-02 23:08:37,227:INFO:Declaring custom model
2025-04-02 23:08:37,227:INFO:Ridge Classifier Imported successfully
2025-04-02 23:08:37,229:INFO:Cross validation set to False
2025-04-02 23:08:37,229:INFO:Fitting Model
2025-04-02 23:08:37,296:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3704, solver='auto',
                tol=0.0001)
2025-04-02 23:08:37,296:INFO:create_model() successfully completed......................................
2025-04-02 23:08:37,394:INFO:Initializing create_model()
2025-04-02 23:08:37,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3704, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:37,394:INFO:Checking exceptions
2025-04-02 23:08:37,394:INFO:Importing libraries
2025-04-02 23:08:37,394:INFO:Copying training dataset
2025-04-02 23:08:37,398:INFO:Defining folds
2025-04-02 23:08:37,398:INFO:Declaring metric variables
2025-04-02 23:08:37,398:INFO:Importing untrained model
2025-04-02 23:08:37,398:INFO:Declaring custom model
2025-04-02 23:08:37,399:INFO:Extra Trees Classifier Imported successfully
2025-04-02 23:08:37,400:INFO:Cross validation set to False
2025-04-02 23:08:37,400:INFO:Fitting Model
2025-04-02 23:08:37,574:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3704, verbose=0,
                     warm_start=False)
2025-04-02 23:08:37,574:INFO:create_model() successfully completed......................................
2025-04-02 23:08:37,661:INFO:Initializing create_model()
2025-04-02 23:08:37,661:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:37,662:INFO:Checking exceptions
2025-04-02 23:08:37,662:INFO:Importing libraries
2025-04-02 23:08:37,662:INFO:Copying training dataset
2025-04-02 23:08:37,666:INFO:Defining folds
2025-04-02 23:08:37,666:INFO:Declaring metric variables
2025-04-02 23:08:37,666:INFO:Importing untrained model
2025-04-02 23:08:37,666:INFO:Declaring custom model
2025-04-02 23:08:37,666:INFO:Naive Bayes Imported successfully
2025-04-02 23:08:37,667:INFO:Cross validation set to False
2025-04-02 23:08:37,667:INFO:Fitting Model
2025-04-02 23:08:37,728:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-02 23:08:37,728:INFO:create_model() successfully completed......................................
2025-04-02 23:08:37,816:INFO:Initializing create_model()
2025-04-02 23:08:37,816:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3704, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:37,816:INFO:Checking exceptions
2025-04-02 23:08:37,816:INFO:Importing libraries
2025-04-02 23:08:37,817:INFO:Copying training dataset
2025-04-02 23:08:37,820:INFO:Defining folds
2025-04-02 23:08:37,820:INFO:Declaring metric variables
2025-04-02 23:08:37,820:INFO:Importing untrained model
2025-04-02 23:08:37,820:INFO:Declaring custom model
2025-04-02 23:08:37,821:INFO:Random Forest Classifier Imported successfully
2025-04-02 23:08:37,822:INFO:Cross validation set to False
2025-04-02 23:08:37,822:INFO:Fitting Model
2025-04-02 23:08:38,030:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3704, verbose=0,
                       warm_start=False)
2025-04-02 23:08:38,030:INFO:create_model() successfully completed......................................
2025-04-02 23:08:38,132:INFO:_master_model_container: 14
2025-04-02 23:08:38,132:INFO:_display_container: 2
2025-04-02 23:08:38,133:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3704, solver='auto',
                tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3704, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3704, verbose=0,
                       warm_start=False)]
2025-04-02 23:08:38,133:INFO:compare_models() successfully completed......................................
2025-04-02 23:08:38,136:INFO:Initializing tune_model()
2025-04-02 23:08:38,136:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>)
2025-04-02 23:08:38,136:INFO:Checking exceptions
2025-04-02 23:08:38,139:INFO:Copying training dataset
2025-04-02 23:08:38,142:INFO:Checking base model
2025-04-02 23:08:38,142:INFO:Base model : Logistic Regression
2025-04-02 23:08:38,142:INFO:Declaring metric variables
2025-04-02 23:08:38,142:INFO:Defining Hyperparameters
2025-04-02 23:08:38,241:INFO:Tuning with n_jobs=-1
2025-04-02 23:08:38,241:INFO:Initializing RandomizedSearchCV
2025-04-02 23:08:38,654:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,660:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,667:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,670:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,701:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,714:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,721:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,731:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,815:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,819:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,829:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:38,971:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,144:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,202:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,226:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,237:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,242:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,273:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,327:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,376:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,455:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,498:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,505:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,575:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,671:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,681:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,686:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,696:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,700:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,760:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,825:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:39,917:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,043:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,044:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,058:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,142:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,206:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,255:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,264:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,267:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,280:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,305:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,354:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,401:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,446:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,454:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,511:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,554:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,650:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,727:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,736:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,817:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,830:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,848:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,880:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,883:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,901:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,930:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:40,968:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,000:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,091:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,140:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,198:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,291:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,301:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,358:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,369:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,372:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,374:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,384:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,462:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,477:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,550:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,559:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,641:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,684:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,709:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,822:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,860:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,906:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,911:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,921:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,923:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,951:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:41,973:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,066:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,092:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,096:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,107:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,235:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,318:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,350:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,375:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,391:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,392:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,407:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,413:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,460:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,465:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,479:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,517:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 1.756}
2025-04-02 23:08:42,517:INFO:Hyperparameter search completed
2025-04-02 23:08:42,517:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:42,517:INFO:Initializing create_model()
2025-04-02 23:08:42,517:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025291A17550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 1.756})
2025-04-02 23:08:42,518:INFO:Checking exceptions
2025-04-02 23:08:42,518:INFO:Importing libraries
2025-04-02 23:08:42,518:INFO:Copying training dataset
2025-04-02 23:08:42,521:INFO:Defining folds
2025-04-02 23:08:42,522:INFO:Declaring metric variables
2025-04-02 23:08:42,522:INFO:Importing untrained model
2025-04-02 23:08:42,522:INFO:Declaring custom model
2025-04-02 23:08:42,522:INFO:Logistic Regression Imported successfully
2025-04-02 23:08:42,523:INFO:Starting cross validation
2025-04-02 23:08:42,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:42,902:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,911:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,912:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,913:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,914:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,914:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,920:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,922:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,926:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:42,931:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,023:INFO:Calculating mean and std
2025-04-02 23:08:43,024:INFO:Creating metrics dataframe
2025-04-02 23:08:43,025:INFO:Finalizing model
2025-04-02 23:08:43,215:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,215:INFO:Uploading results into container
2025-04-02 23:08:43,216:INFO:Uploading model into container now
2025-04-02 23:08:43,216:INFO:_master_model_container: 15
2025-04-02 23:08:43,216:INFO:_display_container: 3
2025-04-02 23:08:43,217:INFO:LogisticRegression(C=1.756, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-02 23:08:43,217:INFO:create_model() successfully completed......................................
2025-04-02 23:08:43,309:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:43,309:INFO:choose_better activated
2025-04-02 23:08:43,310:INFO:SubProcess create_model() called ==================================
2025-04-02 23:08:43,310:INFO:Initializing create_model()
2025-04-02 23:08:43,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000025291997EB0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:08:43,310:INFO:Checking exceptions
2025-04-02 23:08:43,311:INFO:Importing libraries
2025-04-02 23:08:43,311:INFO:Copying training dataset
2025-04-02 23:08:43,315:INFO:Defining folds
2025-04-02 23:08:43,315:INFO:Declaring metric variables
2025-04-02 23:08:43,315:INFO:Importing untrained model
2025-04-02 23:08:43,315:INFO:Declaring custom model
2025-04-02 23:08:43,316:INFO:Logistic Regression Imported successfully
2025-04-02 23:08:43,316:INFO:Starting cross validation
2025-04-02 23:08:43,317:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:08:43,712:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,719:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,723:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,724:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,725:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,729:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,730:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,731:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,734:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,735:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:43,816:INFO:Calculating mean and std
2025-04-02 23:08:43,817:INFO:Creating metrics dataframe
2025-04-02 23:08:43,819:INFO:Finalizing model
2025-04-02 23:08:44,005:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-02 23:08:44,005:INFO:Uploading results into container
2025-04-02 23:08:44,006:INFO:Uploading model into container now
2025-04-02 23:08:44,006:INFO:_master_model_container: 16
2025-04-02 23:08:44,006:INFO:_display_container: 4
2025-04-02 23:08:44,006:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-02 23:08:44,006:INFO:create_model() successfully completed......................................
2025-04-02 23:08:44,098:INFO:SubProcess create_model() end ==================================
2025-04-02 23:08:44,098:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8218
2025-04-02 23:08:44,099:INFO:LogisticRegression(C=1.756, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8218
2025-04-02 23:08:44,099:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-04-02 23:08:44,099:INFO:choose_better completed
2025-04-02 23:08:44,099:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2025-04-02 23:08:44,108:INFO:_master_model_container: 16
2025-04-02 23:08:44,108:INFO:_display_container: 3
2025-04-02 23:08:44,108:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-02 23:08:44,109:INFO:tune_model() successfully completed......................................
2025-04-02 23:08:44,235:INFO:Initializing save_model()
2025-04-02 23:08:44,235:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3704, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-04-02 23:08:44,235:INFO:Adding model into prep_pipe
2025-04-02 23:08:44,245:INFO:best_classifier.pkl saved in current working directory
2025-04-02 23:08:44,265:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=3704,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-04-02 23:08:44,265:INFO:save_model() successfully completed......................................
2025-04-02 23:09:27,805:INFO:PyCaret RegressionExperiment
2025-04-02 23:09:27,805:INFO:Logging name: reg-default-name
2025-04-02 23:09:27,806:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-02 23:09:27,806:INFO:version 3.3.2
2025-04-02 23:09:27,806:INFO:Initializing setup()
2025-04-02 23:09:27,806:INFO:self.USI: b75a
2025-04-02 23:09:27,806:INFO:self._variable_keys: {'logging_param', 'exp_id', 'pipeline', 'fold_generator', 'target_param', 'fold_groups_param', '_available_plots', 'log_plots_param', 'idx', 'transform_target_param', 'seed', 'memory', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'X', 'fold_shuffle_param', 'exp_name_log', 'X_train', 'y_train', 'X_test', 'y', 'n_jobs_param', 'data', 'gpu_param', 'html_param', 'y_test'}
2025-04-02 23:09:27,806:INFO:Checking environment
2025-04-02 23:09:27,806:INFO:python_version: 3.10.0
2025-04-02 23:09:27,806:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-02 23:09:27,806:INFO:machine: AMD64
2025-04-02 23:09:27,806:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-02 23:09:27,811:INFO:Memory: svmem(total=17037209600, available=4097699840, percent=75.9, used=12939509760, free=4097699840)
2025-04-02 23:09:27,812:INFO:Physical Core: 6
2025-04-02 23:09:27,812:INFO:Logical Core: 12
2025-04-02 23:09:27,812:INFO:Checking libraries
2025-04-02 23:09:27,812:INFO:System:
2025-04-02 23:09:27,812:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-02 23:09:27,812:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-04-02 23:09:27,812:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-02 23:09:27,812:INFO:PyCaret required dependencies:
2025-04-02 23:09:27,812:INFO:                 pip: 21.2.3
2025-04-02 23:09:27,812:INFO:          setuptools: 57.4.0
2025-04-02 23:09:27,812:INFO:             pycaret: 3.3.2
2025-04-02 23:09:27,812:INFO:             IPython: 8.29.0
2025-04-02 23:09:27,812:INFO:          ipywidgets: 8.1.5
2025-04-02 23:09:27,812:INFO:                tqdm: 4.67.0
2025-04-02 23:09:27,812:INFO:               numpy: 1.26.4
2025-04-02 23:09:27,812:INFO:              pandas: 2.1.4
2025-04-02 23:09:27,812:INFO:              jinja2: 3.1.4
2025-04-02 23:09:27,812:INFO:               scipy: 1.11.4
2025-04-02 23:09:27,812:INFO:              joblib: 1.3.2
2025-04-02 23:09:27,812:INFO:             sklearn: 1.4.2
2025-04-02 23:09:27,812:INFO:                pyod: 2.0.2
2025-04-02 23:09:27,812:INFO:            imblearn: 0.12.4
2025-04-02 23:09:27,813:INFO:   category_encoders: 2.6.4
2025-04-02 23:09:27,813:INFO:            lightgbm: 4.5.0
2025-04-02 23:09:27,813:INFO:               numba: 0.60.0
2025-04-02 23:09:27,813:INFO:            requests: 2.32.3
2025-04-02 23:09:27,813:INFO:          matplotlib: 3.7.5
2025-04-02 23:09:27,813:INFO:          scikitplot: 0.3.7
2025-04-02 23:09:27,813:INFO:         yellowbrick: 1.5
2025-04-02 23:09:27,813:INFO:              plotly: 5.24.1
2025-04-02 23:09:27,813:INFO:    plotly-resampler: Not installed
2025-04-02 23:09:27,813:INFO:             kaleido: 0.2.1
2025-04-02 23:09:27,813:INFO:           schemdraw: 0.15
2025-04-02 23:09:27,813:INFO:         statsmodels: 0.14.4
2025-04-02 23:09:27,813:INFO:              sktime: 0.26.0
2025-04-02 23:09:27,813:INFO:               tbats: 1.1.3
2025-04-02 23:09:27,813:INFO:            pmdarima: 2.0.4
2025-04-02 23:09:27,813:INFO:              psutil: 6.1.0
2025-04-02 23:09:27,813:INFO:          markupsafe: 3.0.2
2025-04-02 23:09:27,813:INFO:             pickle5: Not installed
2025-04-02 23:09:27,813:INFO:         cloudpickle: 3.1.0
2025-04-02 23:09:27,813:INFO:         deprecation: 2.1.0
2025-04-02 23:09:27,813:INFO:              xxhash: 3.5.0
2025-04-02 23:09:27,813:INFO:           wurlitzer: Not installed
2025-04-02 23:09:27,813:INFO:PyCaret optional dependencies:
2025-04-02 23:09:27,813:INFO:                shap: 0.47.0
2025-04-02 23:09:27,813:INFO:           interpret: Not installed
2025-04-02 23:09:27,813:INFO:                umap: Not installed
2025-04-02 23:09:27,813:INFO:     ydata_profiling: 4.12.0
2025-04-02 23:09:27,813:INFO:  explainerdashboard: Not installed
2025-04-02 23:09:27,814:INFO:             autoviz: Not installed
2025-04-02 23:09:27,814:INFO:           fairlearn: Not installed
2025-04-02 23:09:27,814:INFO:          deepchecks: Not installed
2025-04-02 23:09:27,814:INFO:             xgboost: Not installed
2025-04-02 23:09:27,814:INFO:            catboost: Not installed
2025-04-02 23:09:27,814:INFO:              kmodes: Not installed
2025-04-02 23:09:27,814:INFO:             mlxtend: Not installed
2025-04-02 23:09:27,814:INFO:       statsforecast: Not installed
2025-04-02 23:09:27,814:INFO:        tune_sklearn: Not installed
2025-04-02 23:09:27,814:INFO:                 ray: Not installed
2025-04-02 23:09:27,814:INFO:            hyperopt: Not installed
2025-04-02 23:09:27,814:INFO:              optuna: Not installed
2025-04-02 23:09:27,814:INFO:               skopt: Not installed
2025-04-02 23:09:27,814:INFO:              mlflow: Not installed
2025-04-02 23:09:27,814:INFO:              gradio: Not installed
2025-04-02 23:09:27,814:INFO:             fastapi: Not installed
2025-04-02 23:09:27,814:INFO:             uvicorn: Not installed
2025-04-02 23:09:27,814:INFO:              m2cgen: Not installed
2025-04-02 23:09:27,815:INFO:           evidently: Not installed
2025-04-02 23:09:27,815:INFO:               fugue: Not installed
2025-04-02 23:09:27,815:INFO:           streamlit: 1.40.0
2025-04-02 23:09:27,815:INFO:             prophet: Not installed
2025-04-02 23:09:27,815:INFO:None
2025-04-02 23:09:27,815:INFO:Set up data.
2025-04-02 23:09:27,821:INFO:Set up folding strategy.
2025-04-02 23:09:27,822:INFO:Set up train/test split.
2025-04-02 23:09:27,826:INFO:Set up index.
2025-04-02 23:09:27,827:INFO:Assigning column types.
2025-04-02 23:09:27,834:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-02 23:09:27,834:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-02 23:09:27,837:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-02 23:09:27,843:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-02 23:09:27,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:27,941:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:09:27,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:27,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:27,942:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-02 23:09:27,946:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-02 23:09:27,951:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,003:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,044:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,044:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,045:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,045:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-02 23:09:28,049:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,053:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,106:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,148:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,152:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,251:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,251:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-02 23:09:28,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,313:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,355:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,355:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,365:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,424:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,466:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,467:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,467:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,467:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-02 23:09:28,529:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,570:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,571:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,571:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,636:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,680:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,680:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,681:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-02 23:09:28,742:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,783:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,845:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-02 23:09:28,886:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,887:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-02 23:09:28,989:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:28,990:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:29,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:29,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:29,106:INFO:Preparing preprocessing pipeline...
2025-04-02 23:09:29,106:INFO:Set up simple imputation.
2025-04-02 23:09:29,110:INFO:Set up encoding of ordinal features.
2025-04-02 23:09:29,117:INFO:Set up encoding of categorical features.
2025-04-02 23:09:29,213:INFO:Finished creating preprocessing pipeline.
2025-04-02 23:09:29,294:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-04-02 23:09:29,294:INFO:Creating final display dataframe.
2025-04-02 23:09:29,542:INFO:Setup _display_container:                     Description             Value
0                    Session id              4685
1                        Target             price
2                   Target type        Regression
3           Original data shape         (545, 13)
4        Transformed data shape         (545, 15)
5   Transformed train set shape         (381, 15)
6    Transformed test set shape         (164, 15)
7              Numeric features                 5
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              b75a
2025-04-02 23:09:29,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:29,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:29,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:29,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:09:29,759:INFO:setup() successfully completed in 1.96s...............
2025-04-02 23:09:29,760:INFO:Initializing compare_models()
2025-04-02 23:09:29,760:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-02 23:09:29,760:INFO:Checking exceptions
2025-04-02 23:09:29,762:INFO:Preparing display monitor
2025-04-02 23:09:29,764:INFO:Initializing Linear Regression
2025-04-02 23:09:29,764:INFO:Total runtime is 0.0 minutes
2025-04-02 23:09:29,764:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:29,764:INFO:Initializing create_model()
2025-04-02 23:09:29,764:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:29,764:INFO:Checking exceptions
2025-04-02 23:09:29,764:INFO:Importing libraries
2025-04-02 23:09:29,764:INFO:Copying training dataset
2025-04-02 23:09:29,769:INFO:Defining folds
2025-04-02 23:09:29,769:INFO:Declaring metric variables
2025-04-02 23:09:29,769:INFO:Importing untrained model
2025-04-02 23:09:29,769:INFO:Linear Regression Imported successfully
2025-04-02 23:09:29,769:INFO:Starting cross validation
2025-04-02 23:09:29,771:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:30,011:INFO:Calculating mean and std
2025-04-02 23:09:30,012:INFO:Creating metrics dataframe
2025-04-02 23:09:30,013:INFO:Uploading results into container
2025-04-02 23:09:30,014:INFO:Uploading model into container now
2025-04-02 23:09:30,014:INFO:_master_model_container: 1
2025-04-02 23:09:30,014:INFO:_display_container: 2
2025-04-02 23:09:30,014:INFO:LinearRegression(n_jobs=-1)
2025-04-02 23:09:30,014:INFO:create_model() successfully completed......................................
2025-04-02 23:09:30,109:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:30,109:INFO:Creating metrics dataframe
2025-04-02 23:09:30,111:INFO:Initializing Lasso Regression
2025-04-02 23:09:30,111:INFO:Total runtime is 0.005782270431518554 minutes
2025-04-02 23:09:30,111:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:30,112:INFO:Initializing create_model()
2025-04-02 23:09:30,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:30,112:INFO:Checking exceptions
2025-04-02 23:09:30,112:INFO:Importing libraries
2025-04-02 23:09:30,112:INFO:Copying training dataset
2025-04-02 23:09:30,115:INFO:Defining folds
2025-04-02 23:09:30,116:INFO:Declaring metric variables
2025-04-02 23:09:30,116:INFO:Importing untrained model
2025-04-02 23:09:30,116:INFO:Lasso Regression Imported successfully
2025-04-02 23:09:30,117:INFO:Starting cross validation
2025-04-02 23:09:30,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:30,329:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.151e+13, tolerance: 1.157e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-02 23:09:30,363:INFO:Calculating mean and std
2025-04-02 23:09:30,363:INFO:Creating metrics dataframe
2025-04-02 23:09:30,365:INFO:Uploading results into container
2025-04-02 23:09:30,365:INFO:Uploading model into container now
2025-04-02 23:09:30,365:INFO:_master_model_container: 2
2025-04-02 23:09:30,365:INFO:_display_container: 2
2025-04-02 23:09:30,365:INFO:Lasso(random_state=4685)
2025-04-02 23:09:30,365:INFO:create_model() successfully completed......................................
2025-04-02 23:09:30,454:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:30,454:INFO:Creating metrics dataframe
2025-04-02 23:09:30,455:INFO:Initializing Ridge Regression
2025-04-02 23:09:30,456:INFO:Total runtime is 0.011523572603861491 minutes
2025-04-02 23:09:30,456:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:30,456:INFO:Initializing create_model()
2025-04-02 23:09:30,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:30,456:INFO:Checking exceptions
2025-04-02 23:09:30,456:INFO:Importing libraries
2025-04-02 23:09:30,456:INFO:Copying training dataset
2025-04-02 23:09:30,461:INFO:Defining folds
2025-04-02 23:09:30,461:INFO:Declaring metric variables
2025-04-02 23:09:30,461:INFO:Importing untrained model
2025-04-02 23:09:30,461:INFO:Ridge Regression Imported successfully
2025-04-02 23:09:30,462:INFO:Starting cross validation
2025-04-02 23:09:30,463:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:30,704:INFO:Calculating mean and std
2025-04-02 23:09:30,704:INFO:Creating metrics dataframe
2025-04-02 23:09:30,706:INFO:Uploading results into container
2025-04-02 23:09:30,706:INFO:Uploading model into container now
2025-04-02 23:09:30,707:INFO:_master_model_container: 3
2025-04-02 23:09:30,707:INFO:_display_container: 2
2025-04-02 23:09:30,707:INFO:Ridge(random_state=4685)
2025-04-02 23:09:30,707:INFO:create_model() successfully completed......................................
2025-04-02 23:09:30,807:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:30,807:INFO:Creating metrics dataframe
2025-04-02 23:09:30,811:INFO:Initializing Elastic Net
2025-04-02 23:09:30,811:INFO:Total runtime is 0.017453519503275554 minutes
2025-04-02 23:09:30,811:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:30,811:INFO:Initializing create_model()
2025-04-02 23:09:30,811:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:30,811:INFO:Checking exceptions
2025-04-02 23:09:30,812:INFO:Importing libraries
2025-04-02 23:09:30,812:INFO:Copying training dataset
2025-04-02 23:09:30,818:INFO:Defining folds
2025-04-02 23:09:30,818:INFO:Declaring metric variables
2025-04-02 23:09:30,818:INFO:Importing untrained model
2025-04-02 23:09:30,818:INFO:Elastic Net Imported successfully
2025-04-02 23:09:30,818:INFO:Starting cross validation
2025-04-02 23:09:30,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:31,055:INFO:Calculating mean and std
2025-04-02 23:09:31,055:INFO:Creating metrics dataframe
2025-04-02 23:09:31,057:INFO:Uploading results into container
2025-04-02 23:09:31,057:INFO:Uploading model into container now
2025-04-02 23:09:31,057:INFO:_master_model_container: 4
2025-04-02 23:09:31,057:INFO:_display_container: 2
2025-04-02 23:09:31,057:INFO:ElasticNet(random_state=4685)
2025-04-02 23:09:31,057:INFO:create_model() successfully completed......................................
2025-04-02 23:09:31,151:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:31,152:INFO:Creating metrics dataframe
2025-04-02 23:09:31,154:INFO:Initializing Least Angle Regression
2025-04-02 23:09:31,154:INFO:Total runtime is 0.02316856781641642 minutes
2025-04-02 23:09:31,154:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:31,154:INFO:Initializing create_model()
2025-04-02 23:09:31,154:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:31,155:INFO:Checking exceptions
2025-04-02 23:09:31,155:INFO:Importing libraries
2025-04-02 23:09:31,155:INFO:Copying training dataset
2025-04-02 23:09:31,159:INFO:Defining folds
2025-04-02 23:09:31,159:INFO:Declaring metric variables
2025-04-02 23:09:31,159:INFO:Importing untrained model
2025-04-02 23:09:31,159:INFO:Least Angle Regression Imported successfully
2025-04-02 23:09:31,160:INFO:Starting cross validation
2025-04-02 23:09:31,161:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:31,401:INFO:Calculating mean and std
2025-04-02 23:09:31,402:INFO:Creating metrics dataframe
2025-04-02 23:09:31,403:INFO:Uploading results into container
2025-04-02 23:09:31,404:INFO:Uploading model into container now
2025-04-02 23:09:31,404:INFO:_master_model_container: 5
2025-04-02 23:09:31,404:INFO:_display_container: 2
2025-04-02 23:09:31,404:INFO:Lars(random_state=4685)
2025-04-02 23:09:31,404:INFO:create_model() successfully completed......................................
2025-04-02 23:09:31,495:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:31,495:INFO:Creating metrics dataframe
2025-04-02 23:09:31,497:INFO:Initializing Lasso Least Angle Regression
2025-04-02 23:09:31,497:INFO:Total runtime is 0.02889306545257568 minutes
2025-04-02 23:09:31,497:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:31,499:INFO:Initializing create_model()
2025-04-02 23:09:31,499:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:31,499:INFO:Checking exceptions
2025-04-02 23:09:31,499:INFO:Importing libraries
2025-04-02 23:09:31,499:INFO:Copying training dataset
2025-04-02 23:09:31,504:INFO:Defining folds
2025-04-02 23:09:31,504:INFO:Declaring metric variables
2025-04-02 23:09:31,504:INFO:Importing untrained model
2025-04-02 23:09:31,505:INFO:Lasso Least Angle Regression Imported successfully
2025-04-02 23:09:31,505:INFO:Starting cross validation
2025-04-02 23:09:31,506:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:31,752:INFO:Calculating mean and std
2025-04-02 23:09:31,753:INFO:Creating metrics dataframe
2025-04-02 23:09:31,754:INFO:Uploading results into container
2025-04-02 23:09:31,755:INFO:Uploading model into container now
2025-04-02 23:09:31,755:INFO:_master_model_container: 6
2025-04-02 23:09:31,755:INFO:_display_container: 2
2025-04-02 23:09:31,755:INFO:LassoLars(random_state=4685)
2025-04-02 23:09:31,755:INFO:create_model() successfully completed......................................
2025-04-02 23:09:31,847:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:31,847:INFO:Creating metrics dataframe
2025-04-02 23:09:31,851:INFO:Initializing Orthogonal Matching Pursuit
2025-04-02 23:09:31,851:INFO:Total runtime is 0.034784511725107825 minutes
2025-04-02 23:09:31,851:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:31,851:INFO:Initializing create_model()
2025-04-02 23:09:31,851:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:31,851:INFO:Checking exceptions
2025-04-02 23:09:31,851:INFO:Importing libraries
2025-04-02 23:09:31,851:INFO:Copying training dataset
2025-04-02 23:09:31,856:INFO:Defining folds
2025-04-02 23:09:31,856:INFO:Declaring metric variables
2025-04-02 23:09:31,856:INFO:Importing untrained model
2025-04-02 23:09:31,856:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-02 23:09:31,856:INFO:Starting cross validation
2025-04-02 23:09:31,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:32,094:INFO:Calculating mean and std
2025-04-02 23:09:32,094:INFO:Creating metrics dataframe
2025-04-02 23:09:32,096:INFO:Uploading results into container
2025-04-02 23:09:32,096:INFO:Uploading model into container now
2025-04-02 23:09:32,096:INFO:_master_model_container: 7
2025-04-02 23:09:32,096:INFO:_display_container: 2
2025-04-02 23:09:32,097:INFO:OrthogonalMatchingPursuit()
2025-04-02 23:09:32,097:INFO:create_model() successfully completed......................................
2025-04-02 23:09:32,189:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:32,189:INFO:Creating metrics dataframe
2025-04-02 23:09:32,192:INFO:Initializing Bayesian Ridge
2025-04-02 23:09:32,192:INFO:Total runtime is 0.040473028024037676 minutes
2025-04-02 23:09:32,192:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:32,193:INFO:Initializing create_model()
2025-04-02 23:09:32,193:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:32,193:INFO:Checking exceptions
2025-04-02 23:09:32,193:INFO:Importing libraries
2025-04-02 23:09:32,193:INFO:Copying training dataset
2025-04-02 23:09:32,197:INFO:Defining folds
2025-04-02 23:09:32,197:INFO:Declaring metric variables
2025-04-02 23:09:32,197:INFO:Importing untrained model
2025-04-02 23:09:32,197:INFO:Bayesian Ridge Imported successfully
2025-04-02 23:09:32,197:INFO:Starting cross validation
2025-04-02 23:09:32,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:32,444:INFO:Calculating mean and std
2025-04-02 23:09:32,444:INFO:Creating metrics dataframe
2025-04-02 23:09:32,446:INFO:Uploading results into container
2025-04-02 23:09:32,446:INFO:Uploading model into container now
2025-04-02 23:09:32,446:INFO:_master_model_container: 8
2025-04-02 23:09:32,446:INFO:_display_container: 2
2025-04-02 23:09:32,447:INFO:BayesianRidge()
2025-04-02 23:09:32,447:INFO:create_model() successfully completed......................................
2025-04-02 23:09:32,537:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:32,537:INFO:Creating metrics dataframe
2025-04-02 23:09:32,540:INFO:Initializing Passive Aggressive Regressor
2025-04-02 23:09:32,540:INFO:Total runtime is 0.046268463134765625 minutes
2025-04-02 23:09:32,540:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:32,540:INFO:Initializing create_model()
2025-04-02 23:09:32,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:32,540:INFO:Checking exceptions
2025-04-02 23:09:32,540:INFO:Importing libraries
2025-04-02 23:09:32,540:INFO:Copying training dataset
2025-04-02 23:09:32,545:INFO:Defining folds
2025-04-02 23:09:32,545:INFO:Declaring metric variables
2025-04-02 23:09:32,545:INFO:Importing untrained model
2025-04-02 23:09:32,545:INFO:Passive Aggressive Regressor Imported successfully
2025-04-02 23:09:32,545:INFO:Starting cross validation
2025-04-02 23:09:32,546:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:32,780:INFO:Calculating mean and std
2025-04-02 23:09:32,781:INFO:Creating metrics dataframe
2025-04-02 23:09:32,782:INFO:Uploading results into container
2025-04-02 23:09:32,782:INFO:Uploading model into container now
2025-04-02 23:09:32,783:INFO:_master_model_container: 9
2025-04-02 23:09:32,783:INFO:_display_container: 2
2025-04-02 23:09:32,783:INFO:PassiveAggressiveRegressor(random_state=4685)
2025-04-02 23:09:32,783:INFO:create_model() successfully completed......................................
2025-04-02 23:09:32,872:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:32,872:INFO:Creating metrics dataframe
2025-04-02 23:09:32,874:INFO:Initializing Huber Regressor
2025-04-02 23:09:32,874:INFO:Total runtime is 0.051833724975585936 minutes
2025-04-02 23:09:32,874:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:32,875:INFO:Initializing create_model()
2025-04-02 23:09:32,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:32,875:INFO:Checking exceptions
2025-04-02 23:09:32,875:INFO:Importing libraries
2025-04-02 23:09:32,875:INFO:Copying training dataset
2025-04-02 23:09:32,879:INFO:Defining folds
2025-04-02 23:09:32,879:INFO:Declaring metric variables
2025-04-02 23:09:32,879:INFO:Importing untrained model
2025-04-02 23:09:32,879:INFO:Huber Regressor Imported successfully
2025-04-02 23:09:32,879:INFO:Starting cross validation
2025-04-02 23:09:32,881:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:33,062:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-02 23:09:33,062:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-02 23:09:33,064:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-02 23:09:33,107:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-02 23:09:33,146:INFO:Calculating mean and std
2025-04-02 23:09:33,150:INFO:Creating metrics dataframe
2025-04-02 23:09:33,155:INFO:Uploading results into container
2025-04-02 23:09:33,156:INFO:Uploading model into container now
2025-04-02 23:09:33,157:INFO:_master_model_container: 10
2025-04-02 23:09:33,157:INFO:_display_container: 2
2025-04-02 23:09:33,159:INFO:HuberRegressor()
2025-04-02 23:09:33,159:INFO:create_model() successfully completed......................................
2025-04-02 23:09:33,311:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:33,311:INFO:Creating metrics dataframe
2025-04-02 23:09:33,315:INFO:Initializing K Neighbors Regressor
2025-04-02 23:09:33,315:INFO:Total runtime is 0.05919084151585897 minutes
2025-04-02 23:09:33,315:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:33,315:INFO:Initializing create_model()
2025-04-02 23:09:33,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:33,316:INFO:Checking exceptions
2025-04-02 23:09:33,316:INFO:Importing libraries
2025-04-02 23:09:33,316:INFO:Copying training dataset
2025-04-02 23:09:33,321:INFO:Defining folds
2025-04-02 23:09:33,321:INFO:Declaring metric variables
2025-04-02 23:09:33,321:INFO:Importing untrained model
2025-04-02 23:09:33,321:INFO:K Neighbors Regressor Imported successfully
2025-04-02 23:09:33,321:INFO:Starting cross validation
2025-04-02 23:09:33,323:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:33,588:INFO:Calculating mean and std
2025-04-02 23:09:33,589:INFO:Creating metrics dataframe
2025-04-02 23:09:33,590:INFO:Uploading results into container
2025-04-02 23:09:33,591:INFO:Uploading model into container now
2025-04-02 23:09:33,591:INFO:_master_model_container: 11
2025-04-02 23:09:33,591:INFO:_display_container: 2
2025-04-02 23:09:33,591:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-02 23:09:33,591:INFO:create_model() successfully completed......................................
2025-04-02 23:09:33,680:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:33,680:INFO:Creating metrics dataframe
2025-04-02 23:09:33,683:INFO:Initializing Decision Tree Regressor
2025-04-02 23:09:33,683:INFO:Total runtime is 0.06531646649042765 minutes
2025-04-02 23:09:33,683:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:33,683:INFO:Initializing create_model()
2025-04-02 23:09:33,683:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:33,684:INFO:Checking exceptions
2025-04-02 23:09:33,684:INFO:Importing libraries
2025-04-02 23:09:33,684:INFO:Copying training dataset
2025-04-02 23:09:33,687:INFO:Defining folds
2025-04-02 23:09:33,687:INFO:Declaring metric variables
2025-04-02 23:09:33,687:INFO:Importing untrained model
2025-04-02 23:09:33,687:INFO:Decision Tree Regressor Imported successfully
2025-04-02 23:09:33,687:INFO:Starting cross validation
2025-04-02 23:09:33,690:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:33,922:INFO:Calculating mean and std
2025-04-02 23:09:33,923:INFO:Creating metrics dataframe
2025-04-02 23:09:33,924:INFO:Uploading results into container
2025-04-02 23:09:33,925:INFO:Uploading model into container now
2025-04-02 23:09:33,925:INFO:_master_model_container: 12
2025-04-02 23:09:33,925:INFO:_display_container: 2
2025-04-02 23:09:33,925:INFO:DecisionTreeRegressor(random_state=4685)
2025-04-02 23:09:33,925:INFO:create_model() successfully completed......................................
2025-04-02 23:09:34,018:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:34,019:INFO:Creating metrics dataframe
2025-04-02 23:09:34,021:INFO:Initializing Random Forest Regressor
2025-04-02 23:09:34,021:INFO:Total runtime is 0.07095507383346557 minutes
2025-04-02 23:09:34,021:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:34,022:INFO:Initializing create_model()
2025-04-02 23:09:34,022:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:34,022:INFO:Checking exceptions
2025-04-02 23:09:34,022:INFO:Importing libraries
2025-04-02 23:09:34,022:INFO:Copying training dataset
2025-04-02 23:09:34,026:INFO:Defining folds
2025-04-02 23:09:34,026:INFO:Declaring metric variables
2025-04-02 23:09:34,026:INFO:Importing untrained model
2025-04-02 23:09:34,027:INFO:Random Forest Regressor Imported successfully
2025-04-02 23:09:34,027:INFO:Starting cross validation
2025-04-02 23:09:34,028:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:34,609:INFO:Calculating mean and std
2025-04-02 23:09:34,610:INFO:Creating metrics dataframe
2025-04-02 23:09:34,611:INFO:Uploading results into container
2025-04-02 23:09:34,612:INFO:Uploading model into container now
2025-04-02 23:09:34,612:INFO:_master_model_container: 13
2025-04-02 23:09:34,612:INFO:_display_container: 2
2025-04-02 23:09:34,612:INFO:RandomForestRegressor(n_jobs=-1, random_state=4685)
2025-04-02 23:09:34,612:INFO:create_model() successfully completed......................................
2025-04-02 23:09:34,705:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:34,705:INFO:Creating metrics dataframe
2025-04-02 23:09:34,709:INFO:Initializing Extra Trees Regressor
2025-04-02 23:09:34,710:INFO:Total runtime is 0.08243255217870075 minutes
2025-04-02 23:09:34,710:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:34,710:INFO:Initializing create_model()
2025-04-02 23:09:34,710:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:34,710:INFO:Checking exceptions
2025-04-02 23:09:34,710:INFO:Importing libraries
2025-04-02 23:09:34,710:INFO:Copying training dataset
2025-04-02 23:09:34,714:INFO:Defining folds
2025-04-02 23:09:34,714:INFO:Declaring metric variables
2025-04-02 23:09:34,714:INFO:Importing untrained model
2025-04-02 23:09:34,714:INFO:Extra Trees Regressor Imported successfully
2025-04-02 23:09:34,715:INFO:Starting cross validation
2025-04-02 23:09:34,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:35,235:INFO:Calculating mean and std
2025-04-02 23:09:35,236:INFO:Creating metrics dataframe
2025-04-02 23:09:35,237:INFO:Uploading results into container
2025-04-02 23:09:35,238:INFO:Uploading model into container now
2025-04-02 23:09:35,238:INFO:_master_model_container: 14
2025-04-02 23:09:35,238:INFO:_display_container: 2
2025-04-02 23:09:35,239:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=4685)
2025-04-02 23:09:35,239:INFO:create_model() successfully completed......................................
2025-04-02 23:09:35,341:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:35,341:INFO:Creating metrics dataframe
2025-04-02 23:09:35,343:INFO:Initializing AdaBoost Regressor
2025-04-02 23:09:35,344:INFO:Total runtime is 0.09298259417215982 minutes
2025-04-02 23:09:35,344:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:35,344:INFO:Initializing create_model()
2025-04-02 23:09:35,344:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:35,344:INFO:Checking exceptions
2025-04-02 23:09:35,344:INFO:Importing libraries
2025-04-02 23:09:35,344:INFO:Copying training dataset
2025-04-02 23:09:35,347:INFO:Defining folds
2025-04-02 23:09:35,349:INFO:Declaring metric variables
2025-04-02 23:09:35,349:INFO:Importing untrained model
2025-04-02 23:09:35,349:INFO:AdaBoost Regressor Imported successfully
2025-04-02 23:09:35,349:INFO:Starting cross validation
2025-04-02 23:09:35,351:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:35,709:INFO:Calculating mean and std
2025-04-02 23:09:35,710:INFO:Creating metrics dataframe
2025-04-02 23:09:35,711:INFO:Uploading results into container
2025-04-02 23:09:35,712:INFO:Uploading model into container now
2025-04-02 23:09:35,712:INFO:_master_model_container: 15
2025-04-02 23:09:35,712:INFO:_display_container: 2
2025-04-02 23:09:35,712:INFO:AdaBoostRegressor(random_state=4685)
2025-04-02 23:09:35,712:INFO:create_model() successfully completed......................................
2025-04-02 23:09:35,804:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:35,805:INFO:Creating metrics dataframe
2025-04-02 23:09:35,807:INFO:Initializing Gradient Boosting Regressor
2025-04-02 23:09:35,807:INFO:Total runtime is 0.10072617530822753 minutes
2025-04-02 23:09:35,807:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:35,807:INFO:Initializing create_model()
2025-04-02 23:09:35,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:35,807:INFO:Checking exceptions
2025-04-02 23:09:35,807:INFO:Importing libraries
2025-04-02 23:09:35,807:INFO:Copying training dataset
2025-04-02 23:09:35,813:INFO:Defining folds
2025-04-02 23:09:35,813:INFO:Declaring metric variables
2025-04-02 23:09:35,813:INFO:Importing untrained model
2025-04-02 23:09:35,814:INFO:Gradient Boosting Regressor Imported successfully
2025-04-02 23:09:35,814:INFO:Starting cross validation
2025-04-02 23:09:35,815:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:36,170:INFO:Calculating mean and std
2025-04-02 23:09:36,171:INFO:Creating metrics dataframe
2025-04-02 23:09:36,172:INFO:Uploading results into container
2025-04-02 23:09:36,173:INFO:Uploading model into container now
2025-04-02 23:09:36,173:INFO:_master_model_container: 16
2025-04-02 23:09:36,173:INFO:_display_container: 2
2025-04-02 23:09:36,173:INFO:GradientBoostingRegressor(random_state=4685)
2025-04-02 23:09:36,173:INFO:create_model() successfully completed......................................
2025-04-02 23:09:36,264:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:36,264:INFO:Creating metrics dataframe
2025-04-02 23:09:36,266:INFO:Initializing Light Gradient Boosting Machine
2025-04-02 23:09:36,266:INFO:Total runtime is 0.10837812821070351 minutes
2025-04-02 23:09:36,266:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:36,266:INFO:Initializing create_model()
2025-04-02 23:09:36,266:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:36,266:INFO:Checking exceptions
2025-04-02 23:09:36,267:INFO:Importing libraries
2025-04-02 23:09:36,267:INFO:Copying training dataset
2025-04-02 23:09:36,271:INFO:Defining folds
2025-04-02 23:09:36,271:INFO:Declaring metric variables
2025-04-02 23:09:36,271:INFO:Importing untrained model
2025-04-02 23:09:36,272:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-02 23:09:36,272:INFO:Starting cross validation
2025-04-02 23:09:36,273:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:37,175:INFO:Calculating mean and std
2025-04-02 23:09:37,176:INFO:Creating metrics dataframe
2025-04-02 23:09:37,179:INFO:Uploading results into container
2025-04-02 23:09:37,179:INFO:Uploading model into container now
2025-04-02 23:09:37,180:INFO:_master_model_container: 17
2025-04-02 23:09:37,180:INFO:_display_container: 2
2025-04-02 23:09:37,180:INFO:LGBMRegressor(n_jobs=-1, random_state=4685)
2025-04-02 23:09:37,180:INFO:create_model() successfully completed......................................
2025-04-02 23:09:37,285:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:37,285:INFO:Creating metrics dataframe
2025-04-02 23:09:37,287:INFO:Initializing Dummy Regressor
2025-04-02 23:09:37,287:INFO:Total runtime is 0.1253899256388346 minutes
2025-04-02 23:09:37,287:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:37,287:INFO:Initializing create_model()
2025-04-02 23:09:37,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025297539FF0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:37,287:INFO:Checking exceptions
2025-04-02 23:09:37,287:INFO:Importing libraries
2025-04-02 23:09:37,287:INFO:Copying training dataset
2025-04-02 23:09:37,292:INFO:Defining folds
2025-04-02 23:09:37,292:INFO:Declaring metric variables
2025-04-02 23:09:37,292:INFO:Importing untrained model
2025-04-02 23:09:37,292:INFO:Dummy Regressor Imported successfully
2025-04-02 23:09:37,293:INFO:Starting cross validation
2025-04-02 23:09:37,294:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:37,533:INFO:Calculating mean and std
2025-04-02 23:09:37,536:INFO:Creating metrics dataframe
2025-04-02 23:09:37,542:INFO:Uploading results into container
2025-04-02 23:09:37,544:INFO:Uploading model into container now
2025-04-02 23:09:37,545:INFO:_master_model_container: 18
2025-04-02 23:09:37,545:INFO:_display_container: 2
2025-04-02 23:09:37,545:INFO:DummyRegressor()
2025-04-02 23:09:37,545:INFO:create_model() successfully completed......................................
2025-04-02 23:09:37,661:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:37,661:INFO:Creating metrics dataframe
2025-04-02 23:09:37,664:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-02 23:09:37,666:INFO:Initializing create_model()
2025-04-02 23:09:37,666:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=Ridge(random_state=4685), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:37,666:INFO:Checking exceptions
2025-04-02 23:09:37,667:INFO:Importing libraries
2025-04-02 23:09:37,667:INFO:Copying training dataset
2025-04-02 23:09:37,670:INFO:Defining folds
2025-04-02 23:09:37,670:INFO:Declaring metric variables
2025-04-02 23:09:37,671:INFO:Importing untrained model
2025-04-02 23:09:37,671:INFO:Declaring custom model
2025-04-02 23:09:37,671:INFO:Ridge Regression Imported successfully
2025-04-02 23:09:37,672:INFO:Cross validation set to False
2025-04-02 23:09:37,672:INFO:Fitting Model
2025-04-02 23:09:37,730:INFO:Ridge(random_state=4685)
2025-04-02 23:09:37,731:INFO:create_model() successfully completed......................................
2025-04-02 23:09:37,817:INFO:Initializing create_model()
2025-04-02 23:09:37,818:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:37,818:INFO:Checking exceptions
2025-04-02 23:09:37,818:INFO:Importing libraries
2025-04-02 23:09:37,818:INFO:Copying training dataset
2025-04-02 23:09:37,822:INFO:Defining folds
2025-04-02 23:09:37,822:INFO:Declaring metric variables
2025-04-02 23:09:37,822:INFO:Importing untrained model
2025-04-02 23:09:37,822:INFO:Declaring custom model
2025-04-02 23:09:37,822:INFO:Linear Regression Imported successfully
2025-04-02 23:09:37,824:INFO:Cross validation set to False
2025-04-02 23:09:37,824:INFO:Fitting Model
2025-04-02 23:09:37,881:INFO:LinearRegression(n_jobs=-1)
2025-04-02 23:09:37,881:INFO:create_model() successfully completed......................................
2025-04-02 23:09:37,969:INFO:Initializing create_model()
2025-04-02 23:09:37,969:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=Lasso(random_state=4685), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:37,969:INFO:Checking exceptions
2025-04-02 23:09:37,970:INFO:Importing libraries
2025-04-02 23:09:37,970:INFO:Copying training dataset
2025-04-02 23:09:37,973:INFO:Defining folds
2025-04-02 23:09:37,974:INFO:Declaring metric variables
2025-04-02 23:09:37,974:INFO:Importing untrained model
2025-04-02 23:09:37,974:INFO:Declaring custom model
2025-04-02 23:09:37,974:INFO:Lasso Regression Imported successfully
2025-04-02 23:09:37,976:INFO:Cross validation set to False
2025-04-02 23:09:37,976:INFO:Fitting Model
2025-04-02 23:09:38,033:INFO:Lasso(random_state=4685)
2025-04-02 23:09:38,033:INFO:create_model() successfully completed......................................
2025-04-02 23:09:38,122:INFO:Initializing create_model()
2025-04-02 23:09:38,122:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=Lars(random_state=4685), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:38,122:INFO:Checking exceptions
2025-04-02 23:09:38,123:INFO:Importing libraries
2025-04-02 23:09:38,123:INFO:Copying training dataset
2025-04-02 23:09:38,126:INFO:Defining folds
2025-04-02 23:09:38,126:INFO:Declaring metric variables
2025-04-02 23:09:38,126:INFO:Importing untrained model
2025-04-02 23:09:38,126:INFO:Declaring custom model
2025-04-02 23:09:38,127:INFO:Least Angle Regression Imported successfully
2025-04-02 23:09:38,127:INFO:Cross validation set to False
2025-04-02 23:09:38,127:INFO:Fitting Model
2025-04-02 23:09:38,187:INFO:Lars(random_state=4685)
2025-04-02 23:09:38,187:INFO:create_model() successfully completed......................................
2025-04-02 23:09:38,274:INFO:Initializing create_model()
2025-04-02 23:09:38,274:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=LassoLars(random_state=4685), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:38,274:INFO:Checking exceptions
2025-04-02 23:09:38,275:INFO:Importing libraries
2025-04-02 23:09:38,275:INFO:Copying training dataset
2025-04-02 23:09:38,279:INFO:Defining folds
2025-04-02 23:09:38,279:INFO:Declaring metric variables
2025-04-02 23:09:38,279:INFO:Importing untrained model
2025-04-02 23:09:38,279:INFO:Declaring custom model
2025-04-02 23:09:38,280:INFO:Lasso Least Angle Regression Imported successfully
2025-04-02 23:09:38,281:INFO:Cross validation set to False
2025-04-02 23:09:38,281:INFO:Fitting Model
2025-04-02 23:09:38,339:INFO:LassoLars(random_state=4685)
2025-04-02 23:09:38,339:INFO:create_model() successfully completed......................................
2025-04-02 23:09:38,438:INFO:_master_model_container: 18
2025-04-02 23:09:38,438:INFO:_display_container: 2
2025-04-02 23:09:38,439:INFO:[Ridge(random_state=4685), LinearRegression(n_jobs=-1), Lasso(random_state=4685), Lars(random_state=4685), LassoLars(random_state=4685)]
2025-04-02 23:09:38,439:INFO:compare_models() successfully completed......................................
2025-04-02 23:09:38,442:INFO:Initializing tune_model()
2025-04-02 23:09:38,442:INFO:tune_model(estimator=Ridge(random_state=4685), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>)
2025-04-02 23:09:38,442:INFO:Checking exceptions
2025-04-02 23:09:38,445:INFO:Copying training dataset
2025-04-02 23:09:38,448:INFO:Checking base model
2025-04-02 23:09:38,448:INFO:Base model : Ridge Regression
2025-04-02 23:09:38,448:INFO:Declaring metric variables
2025-04-02 23:09:38,448:INFO:Defining Hyperparameters
2025-04-02 23:09:38,571:INFO:Tuning with n_jobs=-1
2025-04-02 23:09:38,571:INFO:Initializing RandomizedSearchCV
2025-04-02 23:09:40,645:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 9.86}
2025-04-02 23:09:40,645:INFO:Hyperparameter search completed
2025-04-02 23:09:40,646:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:40,646:INFO:Initializing create_model()
2025-04-02 23:09:40,646:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=Ridge(random_state=4685), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000025292FCE4A0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 9.86})
2025-04-02 23:09:40,646:INFO:Checking exceptions
2025-04-02 23:09:40,646:INFO:Importing libraries
2025-04-02 23:09:40,646:INFO:Copying training dataset
2025-04-02 23:09:40,650:INFO:Defining folds
2025-04-02 23:09:40,650:INFO:Declaring metric variables
2025-04-02 23:09:40,650:INFO:Importing untrained model
2025-04-02 23:09:40,650:INFO:Declaring custom model
2025-04-02 23:09:40,651:INFO:Ridge Regression Imported successfully
2025-04-02 23:09:40,651:INFO:Starting cross validation
2025-04-02 23:09:40,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:40,885:INFO:Calculating mean and std
2025-04-02 23:09:40,885:INFO:Creating metrics dataframe
2025-04-02 23:09:40,887:INFO:Finalizing model
2025-04-02 23:09:40,947:INFO:Uploading results into container
2025-04-02 23:09:40,948:INFO:Uploading model into container now
2025-04-02 23:09:40,949:INFO:_master_model_container: 19
2025-04-02 23:09:40,949:INFO:_display_container: 3
2025-04-02 23:09:40,949:INFO:Ridge(alpha=9.86, fit_intercept=False, random_state=4685)
2025-04-02 23:09:40,949:INFO:create_model() successfully completed......................................
2025-04-02 23:09:41,047:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:41,047:INFO:choose_better activated
2025-04-02 23:09:41,048:INFO:SubProcess create_model() called ==================================
2025-04-02 23:09:41,048:INFO:Initializing create_model()
2025-04-02 23:09:41,048:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000252918DE890>, estimator=Ridge(random_state=4685), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-02 23:09:41,048:INFO:Checking exceptions
2025-04-02 23:09:41,049:INFO:Importing libraries
2025-04-02 23:09:41,049:INFO:Copying training dataset
2025-04-02 23:09:41,053:INFO:Defining folds
2025-04-02 23:09:41,053:INFO:Declaring metric variables
2025-04-02 23:09:41,053:INFO:Importing untrained model
2025-04-02 23:09:41,053:INFO:Declaring custom model
2025-04-02 23:09:41,054:INFO:Ridge Regression Imported successfully
2025-04-02 23:09:41,054:INFO:Starting cross validation
2025-04-02 23:09:41,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-02 23:09:41,330:INFO:Calculating mean and std
2025-04-02 23:09:41,330:INFO:Creating metrics dataframe
2025-04-02 23:09:41,331:INFO:Finalizing model
2025-04-02 23:09:41,389:INFO:Uploading results into container
2025-04-02 23:09:41,389:INFO:Uploading model into container now
2025-04-02 23:09:41,390:INFO:_master_model_container: 20
2025-04-02 23:09:41,390:INFO:_display_container: 4
2025-04-02 23:09:41,390:INFO:Ridge(random_state=4685)
2025-04-02 23:09:41,390:INFO:create_model() successfully completed......................................
2025-04-02 23:09:41,482:INFO:SubProcess create_model() end ==================================
2025-04-02 23:09:41,482:INFO:Ridge(random_state=4685) result for R2 is 0.6359
2025-04-02 23:09:41,483:INFO:Ridge(alpha=9.86, fit_intercept=False, random_state=4685) result for R2 is 0.6406
2025-04-02 23:09:41,483:INFO:Ridge(alpha=9.86, fit_intercept=False, random_state=4685) is best model
2025-04-02 23:09:41,483:INFO:choose_better completed
2025-04-02 23:09:41,491:INFO:_master_model_container: 20
2025-04-02 23:09:41,491:INFO:_display_container: 3
2025-04-02 23:09:41,491:INFO:Ridge(alpha=9.86, fit_intercept=False, random_state=4685)
2025-04-02 23:09:41,491:INFO:tune_model() successfully completed......................................
2025-04-02 23:09:41,675:INFO:Initializing save_model()
2025-04-02 23:09:41,675:INFO:save_model(model=Ridge(alpha=9.86, fit_intercept=False, random_state=4685), model_name=best_regressor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-02 23:09:41,675:INFO:Adding model into prep_pipe
2025-04-02 23:09:41,684:INFO:best_regressor.pkl saved in current working directory
2025-04-02 23:09:41,770:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'furnishingstatus'],
                                    transformer=SimpleImput...
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 Ridge(alpha=9.86, fit_intercept=False, random_state=4685))])
2025-04-02 23:09:41,770:INFO:save_model() successfully completed......................................
2025-04-02 23:10:06,304:INFO:PyCaret ClusteringExperiment
2025-04-02 23:10:06,304:INFO:Logging name: cluster-default-name
2025-04-02 23:10:06,304:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-02 23:10:06,304:INFO:version 3.3.2
2025-04-02 23:10:06,304:INFO:Initializing setup()
2025-04-02 23:10:06,304:INFO:self.USI: f1d2
2025-04-02 23:10:06,304:INFO:self._variable_keys: {'logging_param', 'exp_id', 'pipeline', '_available_plots', 'log_plots_param', 'idx', 'seed', 'memory', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'X', 'exp_name_log', 'n_jobs_param', 'data', 'gpu_param', 'html_param'}
2025-04-02 23:10:06,304:INFO:Checking environment
2025-04-02 23:10:06,304:INFO:python_version: 3.10.0
2025-04-02 23:10:06,304:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-02 23:10:06,304:INFO:machine: AMD64
2025-04-02 23:10:06,304:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-02 23:10:06,310:INFO:Memory: svmem(total=17037209600, available=4089860096, percent=76.0, used=12947349504, free=4089860096)
2025-04-02 23:10:06,310:INFO:Physical Core: 6
2025-04-02 23:10:06,310:INFO:Logical Core: 12
2025-04-02 23:10:06,310:INFO:Checking libraries
2025-04-02 23:10:06,310:INFO:System:
2025-04-02 23:10:06,310:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-02 23:10:06,310:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-04-02 23:10:06,310:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-02 23:10:06,310:INFO:PyCaret required dependencies:
2025-04-02 23:10:06,310:INFO:                 pip: 21.2.3
2025-04-02 23:10:06,310:INFO:          setuptools: 57.4.0
2025-04-02 23:10:06,310:INFO:             pycaret: 3.3.2
2025-04-02 23:10:06,310:INFO:             IPython: 8.29.0
2025-04-02 23:10:06,310:INFO:          ipywidgets: 8.1.5
2025-04-02 23:10:06,310:INFO:                tqdm: 4.67.0
2025-04-02 23:10:06,311:INFO:               numpy: 1.26.4
2025-04-02 23:10:06,311:INFO:              pandas: 2.1.4
2025-04-02 23:10:06,311:INFO:              jinja2: 3.1.4
2025-04-02 23:10:06,311:INFO:               scipy: 1.11.4
2025-04-02 23:10:06,311:INFO:              joblib: 1.3.2
2025-04-02 23:10:06,311:INFO:             sklearn: 1.4.2
2025-04-02 23:10:06,311:INFO:                pyod: 2.0.2
2025-04-02 23:10:06,311:INFO:            imblearn: 0.12.4
2025-04-02 23:10:06,311:INFO:   category_encoders: 2.6.4
2025-04-02 23:10:06,311:INFO:            lightgbm: 4.5.0
2025-04-02 23:10:06,311:INFO:               numba: 0.60.0
2025-04-02 23:10:06,311:INFO:            requests: 2.32.3
2025-04-02 23:10:06,311:INFO:          matplotlib: 3.7.5
2025-04-02 23:10:06,311:INFO:          scikitplot: 0.3.7
2025-04-02 23:10:06,311:INFO:         yellowbrick: 1.5
2025-04-02 23:10:06,311:INFO:              plotly: 5.24.1
2025-04-02 23:10:06,311:INFO:    plotly-resampler: Not installed
2025-04-02 23:10:06,311:INFO:             kaleido: 0.2.1
2025-04-02 23:10:06,311:INFO:           schemdraw: 0.15
2025-04-02 23:10:06,312:INFO:         statsmodels: 0.14.4
2025-04-02 23:10:06,312:INFO:              sktime: 0.26.0
2025-04-02 23:10:06,312:INFO:               tbats: 1.1.3
2025-04-02 23:10:06,312:INFO:            pmdarima: 2.0.4
2025-04-02 23:10:06,312:INFO:              psutil: 6.1.0
2025-04-02 23:10:06,312:INFO:          markupsafe: 3.0.2
2025-04-02 23:10:06,312:INFO:             pickle5: Not installed
2025-04-02 23:10:06,312:INFO:         cloudpickle: 3.1.0
2025-04-02 23:10:06,312:INFO:         deprecation: 2.1.0
2025-04-02 23:10:06,312:INFO:              xxhash: 3.5.0
2025-04-02 23:10:06,312:INFO:           wurlitzer: Not installed
2025-04-02 23:10:06,312:INFO:PyCaret optional dependencies:
2025-04-02 23:10:06,312:INFO:                shap: 0.47.0
2025-04-02 23:10:06,312:INFO:           interpret: Not installed
2025-04-02 23:10:06,312:INFO:                umap: Not installed
2025-04-02 23:10:06,312:INFO:     ydata_profiling: 4.12.0
2025-04-02 23:10:06,312:INFO:  explainerdashboard: Not installed
2025-04-02 23:10:06,312:INFO:             autoviz: Not installed
2025-04-02 23:10:06,312:INFO:           fairlearn: Not installed
2025-04-02 23:10:06,312:INFO:          deepchecks: Not installed
2025-04-02 23:10:06,312:INFO:             xgboost: Not installed
2025-04-02 23:10:06,312:INFO:            catboost: Not installed
2025-04-02 23:10:06,312:INFO:              kmodes: Not installed
2025-04-02 23:10:06,312:INFO:             mlxtend: Not installed
2025-04-02 23:10:06,312:INFO:       statsforecast: Not installed
2025-04-02 23:10:06,312:INFO:        tune_sklearn: Not installed
2025-04-02 23:10:06,312:INFO:                 ray: Not installed
2025-04-02 23:10:06,313:INFO:            hyperopt: Not installed
2025-04-02 23:10:06,313:INFO:              optuna: Not installed
2025-04-02 23:10:06,313:INFO:               skopt: Not installed
2025-04-02 23:10:06,313:INFO:              mlflow: Not installed
2025-04-02 23:10:06,313:INFO:              gradio: Not installed
2025-04-02 23:10:06,313:INFO:             fastapi: Not installed
2025-04-02 23:10:06,313:INFO:             uvicorn: Not installed
2025-04-02 23:10:06,313:INFO:              m2cgen: Not installed
2025-04-02 23:10:06,313:INFO:           evidently: Not installed
2025-04-02 23:10:06,313:INFO:               fugue: Not installed
2025-04-02 23:10:06,313:INFO:           streamlit: 1.40.0
2025-04-02 23:10:06,313:INFO:             prophet: Not installed
2025-04-02 23:10:06,313:INFO:None
2025-04-02 23:10:06,313:INFO:Set up data.
2025-04-02 23:10:06,315:INFO:Set up index.
2025-04-02 23:10:06,315:INFO:Assigning column types.
2025-04-02 23:10:06,317:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-02 23:10:06,317:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-02 23:10:06,317:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:10:06,317:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-02 23:10:06,317:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:10:06,317:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-02 23:10:06,317:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:10:06,319:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:10:06,320:INFO:Preparing preprocessing pipeline...
2025-04-02 23:10:06,320:INFO:Set up simple imputation.
2025-04-02 23:10:06,335:INFO:Finished creating preprocessing pipeline.
2025-04-02 23:10:06,338:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-04-02 23:10:06,338:INFO:Creating final display dataframe.
2025-04-02 23:10:06,353:INFO:Setup _display_container:                Description                 Value
0               Session id                  1184
1      Original data shape              (400, 5)
2   Transformed data shape              (400, 5)
3         Numeric features                     5
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                 CPU Jobs                    -1
9                  Use GPU                 False
10          Log Experiment                 False
11         Experiment Name  cluster-default-name
12                     USI                  f1d2
2025-04-02 23:10:06,356:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:10:06,357:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:10:06,357:INFO:setup() successfully completed in 0.06s...............
2025-04-02 23:11:04,472:INFO:PyCaret ClusteringExperiment
2025-04-02 23:11:04,472:INFO:Logging name: cluster-default-name
2025-04-02 23:11:04,472:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-02 23:11:04,472:INFO:version 3.3.2
2025-04-02 23:11:04,472:INFO:Initializing setup()
2025-04-02 23:11:04,473:INFO:self.USI: 44bf
2025-04-02 23:11:04,473:INFO:self._variable_keys: {'logging_param', 'exp_id', 'pipeline', '_available_plots', 'log_plots_param', 'idx', 'seed', 'memory', 'gpu_n_jobs_param', '_ml_usecase', 'USI', 'X', 'exp_name_log', 'n_jobs_param', 'data', 'gpu_param', 'html_param'}
2025-04-02 23:11:04,473:INFO:Checking environment
2025-04-02 23:11:04,473:INFO:python_version: 3.10.0
2025-04-02 23:11:04,473:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-02 23:11:04,473:INFO:machine: AMD64
2025-04-02 23:11:04,473:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-02 23:11:04,478:INFO:Memory: svmem(total=17037209600, available=4107034624, percent=75.9, used=12930174976, free=4107034624)
2025-04-02 23:11:04,478:INFO:Physical Core: 6
2025-04-02 23:11:04,478:INFO:Logical Core: 12
2025-04-02 23:11:04,478:INFO:Checking libraries
2025-04-02 23:11:04,479:INFO:System:
2025-04-02 23:11:04,479:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-02 23:11:04,479:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-04-02 23:11:04,479:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-02 23:11:04,479:INFO:PyCaret required dependencies:
2025-04-02 23:11:04,479:INFO:                 pip: 21.2.3
2025-04-02 23:11:04,479:INFO:          setuptools: 57.4.0
2025-04-02 23:11:04,479:INFO:             pycaret: 3.3.2
2025-04-02 23:11:04,479:INFO:             IPython: 8.29.0
2025-04-02 23:11:04,479:INFO:          ipywidgets: 8.1.5
2025-04-02 23:11:04,479:INFO:                tqdm: 4.67.0
2025-04-02 23:11:04,479:INFO:               numpy: 1.26.4
2025-04-02 23:11:04,479:INFO:              pandas: 2.1.4
2025-04-02 23:11:04,479:INFO:              jinja2: 3.1.4
2025-04-02 23:11:04,479:INFO:               scipy: 1.11.4
2025-04-02 23:11:04,479:INFO:              joblib: 1.3.2
2025-04-02 23:11:04,479:INFO:             sklearn: 1.4.2
2025-04-02 23:11:04,479:INFO:                pyod: 2.0.2
2025-04-02 23:11:04,479:INFO:            imblearn: 0.12.4
2025-04-02 23:11:04,479:INFO:   category_encoders: 2.6.4
2025-04-02 23:11:04,479:INFO:            lightgbm: 4.5.0
2025-04-02 23:11:04,479:INFO:               numba: 0.60.0
2025-04-02 23:11:04,479:INFO:            requests: 2.32.3
2025-04-02 23:11:04,479:INFO:          matplotlib: 3.7.5
2025-04-02 23:11:04,479:INFO:          scikitplot: 0.3.7
2025-04-02 23:11:04,479:INFO:         yellowbrick: 1.5
2025-04-02 23:11:04,479:INFO:              plotly: 5.24.1
2025-04-02 23:11:04,480:INFO:    plotly-resampler: Not installed
2025-04-02 23:11:04,480:INFO:             kaleido: 0.2.1
2025-04-02 23:11:04,480:INFO:           schemdraw: 0.15
2025-04-02 23:11:04,480:INFO:         statsmodels: 0.14.4
2025-04-02 23:11:04,480:INFO:              sktime: 0.26.0
2025-04-02 23:11:04,480:INFO:               tbats: 1.1.3
2025-04-02 23:11:04,480:INFO:            pmdarima: 2.0.4
2025-04-02 23:11:04,480:INFO:              psutil: 6.1.0
2025-04-02 23:11:04,480:INFO:          markupsafe: 3.0.2
2025-04-02 23:11:04,480:INFO:             pickle5: Not installed
2025-04-02 23:11:04,480:INFO:         cloudpickle: 3.1.0
2025-04-02 23:11:04,480:INFO:         deprecation: 2.1.0
2025-04-02 23:11:04,480:INFO:              xxhash: 3.5.0
2025-04-02 23:11:04,480:INFO:           wurlitzer: Not installed
2025-04-02 23:11:04,480:INFO:PyCaret optional dependencies:
2025-04-02 23:11:04,480:INFO:                shap: 0.47.0
2025-04-02 23:11:04,480:INFO:           interpret: Not installed
2025-04-02 23:11:04,480:INFO:                umap: Not installed
2025-04-02 23:11:04,480:INFO:     ydata_profiling: 4.12.0
2025-04-02 23:11:04,480:INFO:  explainerdashboard: Not installed
2025-04-02 23:11:04,480:INFO:             autoviz: Not installed
2025-04-02 23:11:04,480:INFO:           fairlearn: Not installed
2025-04-02 23:11:04,480:INFO:          deepchecks: Not installed
2025-04-02 23:11:04,480:INFO:             xgboost: Not installed
2025-04-02 23:11:04,480:INFO:            catboost: Not installed
2025-04-02 23:11:04,480:INFO:              kmodes: Not installed
2025-04-02 23:11:04,480:INFO:             mlxtend: Not installed
2025-04-02 23:11:04,480:INFO:       statsforecast: Not installed
2025-04-02 23:11:04,481:INFO:        tune_sklearn: Not installed
2025-04-02 23:11:04,481:INFO:                 ray: Not installed
2025-04-02 23:11:04,481:INFO:            hyperopt: Not installed
2025-04-02 23:11:04,481:INFO:              optuna: Not installed
2025-04-02 23:11:04,481:INFO:               skopt: Not installed
2025-04-02 23:11:04,481:INFO:              mlflow: Not installed
2025-04-02 23:11:04,481:INFO:              gradio: Not installed
2025-04-02 23:11:04,481:INFO:             fastapi: Not installed
2025-04-02 23:11:04,481:INFO:             uvicorn: Not installed
2025-04-02 23:11:04,481:INFO:              m2cgen: Not installed
2025-04-02 23:11:04,481:INFO:           evidently: Not installed
2025-04-02 23:11:04,481:INFO:               fugue: Not installed
2025-04-02 23:11:04,481:INFO:           streamlit: 1.40.0
2025-04-02 23:11:04,481:INFO:             prophet: Not installed
2025-04-02 23:11:04,481:INFO:None
2025-04-02 23:11:04,481:INFO:Set up data.
2025-04-02 23:11:04,483:INFO:Set up index.
2025-04-02 23:11:04,483:INFO:Assigning column types.
2025-04-02 23:11:04,485:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-02 23:11:04,485:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-02 23:11:04,485:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:11:04,485:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-02 23:11:04,485:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:11:04,486:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-02 23:11:04,486:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:11:04,486:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:11:04,487:INFO:Preparing preprocessing pipeline...
2025-04-02 23:11:04,487:INFO:Set up simple imputation.
2025-04-02 23:11:04,502:INFO:Finished creating preprocessing pipeline.
2025-04-02 23:11:04,506:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-04-02 23:11:04,506:INFO:Creating final display dataframe.
2025-04-02 23:11:04,523:INFO:Setup _display_container:                Description                 Value
0               Session id                  8870
1      Original data shape              (400, 5)
2   Transformed data shape              (400, 5)
3         Numeric features                     5
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                 CPU Jobs                    -1
9                  Use GPU                 False
10          Log Experiment                 False
11         Experiment Name  cluster-default-name
12                     USI                  44bf
2025-04-02 23:11:04,528:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:11:04,529:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-02 23:11:04,529:INFO:setup() successfully completed in 0.06s...............
2025-04-02 23:11:04,529:INFO:Initializing create_model()
2025-04-02 23:11:04,529:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x00000252918C2FB0>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-04-02 23:11:04,529:INFO:Checking exceptions
2025-04-02 23:11:04,541:INFO:Importing untrained model
2025-04-02 23:11:04,541:INFO:K-Means Clustering Imported successfully
2025-04-02 23:11:04,542:INFO:Fitting Model
2025-04-02 23:11:04,764:INFO:KMeans(n_clusters=4, random_state=8870)
2025-04-02 23:11:04,765:INFO:create_models() successfully completed......................................
2025-04-02 23:11:04,765:INFO:Uploading results into container
2025-04-02 23:11:04,766:INFO:Uploading model into container now
2025-04-02 23:11:04,773:INFO:_master_model_container: 1
2025-04-02 23:11:04,773:INFO:_display_container: 2
2025-04-02 23:11:04,774:INFO:KMeans(n_clusters=4, random_state=8870)
2025-04-02 23:11:04,774:INFO:create_model() successfully completed......................................
2025-04-02 23:11:04,878:INFO:Initializing save_model()
2025-04-02 23:11:04,878:INFO:save_model(model=KMeans(n_clusters=4, random_state=8870), model_name=best_clustering, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.CLUSTERING, kwargs={})
2025-04-02 23:11:04,878:INFO:Adding model into prep_pipe
2025-04-02 23:11:04,881:INFO:best_clustering.pkl saved in current working directory
2025-04-02 23:11:04,885:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', KMeans(n_clusters=4, random_state=8870))])
2025-04-02 23:11:04,885:INFO:save_model() successfully completed......................................
2025-04-03 12:07:03,660:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-03 12:07:03,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-03 12:07:03,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-03 12:07:03,661:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-04-03 12:11:01,895:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x0000028FF7CF7EC0, file "C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 167>')
  warnings.warn(

2025-04-03 12:14:36,625:INFO:PyCaret ClassificationExperiment
2025-04-03 12:14:36,625:INFO:Logging name: clf-default-name
2025-04-03 12:14:36,625:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-04-03 12:14:36,625:INFO:version 3.3.2
2025-04-03 12:14:36,625:INFO:Initializing setup()
2025-04-03 12:14:36,625:INFO:self.USI: 7068
2025-04-03 12:14:36,626:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'fold_groups_param', 'data', 'y_train', 'n_jobs_param', 'logging_param', 'exp_name_log', 'y', 'X', 'X_train', 'fix_imbalance', 'seed', 'fold_generator', 'target_param', 'X_test', 'idx', 'USI', 'html_param', 'y_test', 'gpu_n_jobs_param', 'gpu_param', '_ml_usecase', 'exp_id', 'log_plots_param', '_available_plots', 'memory', 'is_multiclass'}
2025-04-03 12:14:36,626:INFO:Checking environment
2025-04-03 12:14:36,626:INFO:python_version: 3.10.0
2025-04-03 12:14:36,626:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-03 12:14:36,626:INFO:machine: AMD64
2025-04-03 12:14:36,658:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-03 12:14:36,670:INFO:Memory: svmem(total=17037209600, available=5625778176, percent=67.0, used=11411431424, free=5625778176)
2025-04-03 12:14:36,670:INFO:Physical Core: 6
2025-04-03 12:14:36,671:INFO:Logical Core: 12
2025-04-03 12:14:36,671:INFO:Checking libraries
2025-04-03 12:14:36,671:INFO:System:
2025-04-03 12:14:36,671:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-03 12:14:36,671:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-04-03 12:14:36,671:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-03 12:14:36,671:INFO:PyCaret required dependencies:
2025-04-03 12:14:36,761:INFO:                 pip: 21.2.3
2025-04-03 12:14:36,762:INFO:          setuptools: 57.4.0
2025-04-03 12:14:36,762:INFO:             pycaret: 3.3.2
2025-04-03 12:14:36,762:INFO:             IPython: 8.29.0
2025-04-03 12:14:36,762:INFO:          ipywidgets: 8.1.5
2025-04-03 12:14:36,762:INFO:                tqdm: 4.67.0
2025-04-03 12:14:36,762:INFO:               numpy: 1.26.4
2025-04-03 12:14:36,762:INFO:              pandas: 2.1.4
2025-04-03 12:14:36,762:INFO:              jinja2: 3.1.4
2025-04-03 12:14:36,762:INFO:               scipy: 1.11.4
2025-04-03 12:14:36,762:INFO:              joblib: 1.3.2
2025-04-03 12:14:36,762:INFO:             sklearn: 1.4.2
2025-04-03 12:14:36,762:INFO:                pyod: 2.0.2
2025-04-03 12:14:36,762:INFO:            imblearn: 0.12.4
2025-04-03 12:14:36,762:INFO:   category_encoders: 2.6.4
2025-04-03 12:14:36,762:INFO:            lightgbm: 4.5.0
2025-04-03 12:14:36,762:INFO:               numba: 0.60.0
2025-04-03 12:14:36,762:INFO:            requests: 2.32.3
2025-04-03 12:14:36,762:INFO:          matplotlib: 3.7.5
2025-04-03 12:14:36,763:INFO:          scikitplot: 0.3.7
2025-04-03 12:14:36,763:INFO:         yellowbrick: 1.5
2025-04-03 12:14:36,763:INFO:              plotly: 5.24.1
2025-04-03 12:14:36,763:INFO:    plotly-resampler: Not installed
2025-04-03 12:14:36,763:INFO:             kaleido: 0.2.1
2025-04-03 12:14:36,763:INFO:           schemdraw: 0.15
2025-04-03 12:14:36,763:INFO:         statsmodels: 0.14.4
2025-04-03 12:14:36,763:INFO:              sktime: 0.26.0
2025-04-03 12:14:36,763:INFO:               tbats: 1.1.3
2025-04-03 12:14:36,763:INFO:            pmdarima: 2.0.4
2025-04-03 12:14:36,763:INFO:              psutil: 6.1.0
2025-04-03 12:14:36,763:INFO:          markupsafe: 3.0.2
2025-04-03 12:14:36,763:INFO:             pickle5: Not installed
2025-04-03 12:14:36,763:INFO:         cloudpickle: 3.1.0
2025-04-03 12:14:36,764:INFO:         deprecation: 2.1.0
2025-04-03 12:14:36,764:INFO:              xxhash: 3.5.0
2025-04-03 12:14:36,764:INFO:           wurlitzer: Not installed
2025-04-03 12:14:36,764:INFO:PyCaret optional dependencies:
2025-04-03 12:14:36,776:INFO:                shap: 0.47.0
2025-04-03 12:14:36,776:INFO:           interpret: Not installed
2025-04-03 12:14:36,776:INFO:                umap: Not installed
2025-04-03 12:14:36,776:INFO:     ydata_profiling: 4.12.0
2025-04-03 12:14:36,776:INFO:  explainerdashboard: Not installed
2025-04-03 12:14:36,776:INFO:             autoviz: Not installed
2025-04-03 12:14:36,776:INFO:           fairlearn: Not installed
2025-04-03 12:14:36,776:INFO:          deepchecks: Not installed
2025-04-03 12:14:36,776:INFO:             xgboost: Not installed
2025-04-03 12:14:36,776:INFO:            catboost: Not installed
2025-04-03 12:14:36,777:INFO:              kmodes: Not installed
2025-04-03 12:14:36,777:INFO:             mlxtend: Not installed
2025-04-03 12:14:36,777:INFO:       statsforecast: Not installed
2025-04-03 12:14:36,777:INFO:        tune_sklearn: Not installed
2025-04-03 12:14:36,777:INFO:                 ray: Not installed
2025-04-03 12:14:36,777:INFO:            hyperopt: Not installed
2025-04-03 12:14:36,777:INFO:              optuna: Not installed
2025-04-03 12:14:36,777:INFO:               skopt: Not installed
2025-04-03 12:14:36,777:INFO:              mlflow: Not installed
2025-04-03 12:14:36,777:INFO:              gradio: Not installed
2025-04-03 12:14:36,777:INFO:             fastapi: Not installed
2025-04-03 12:14:36,777:INFO:             uvicorn: Not installed
2025-04-03 12:14:36,777:INFO:              m2cgen: Not installed
2025-04-03 12:14:36,777:INFO:           evidently: Not installed
2025-04-03 12:14:36,777:INFO:               fugue: Not installed
2025-04-03 12:14:36,777:INFO:           streamlit: 1.40.0
2025-04-03 12:14:36,777:INFO:             prophet: Not installed
2025-04-03 12:14:36,777:INFO:None
2025-04-03 12:14:36,777:INFO:Set up data.
2025-04-03 12:14:36,787:INFO:Set up folding strategy.
2025-04-03 12:14:36,787:INFO:Set up train/test split.
2025-04-03 12:14:36,801:INFO:Set up index.
2025-04-03 12:14:36,801:INFO:Assigning column types.
2025-04-03 12:14:36,804:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-03 12:14:36,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:14:36,850:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-03 12:14:36,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:36,887:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:36,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:14:36,929:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-03 12:14:36,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:36,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:36,956:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-03 12:14:36,999:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-03 12:14:37,025:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,025:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,067:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-04-03 12:14:37,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,092:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,092:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-04-03 12:14:37,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,233:INFO:Preparing preprocessing pipeline...
2025-04-03 12:14:37,240:INFO:Set up simple imputation.
2025-04-03 12:14:37,244:INFO:Set up encoding of ordinal features.
2025-04-03 12:14:37,245:INFO:Set up encoding of categorical features.
2025-04-03 12:14:37,397:INFO:Finished creating preprocessing pipeline.
2025-04-03 12:14:37,418:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2025-04-03 12:14:37,418:INFO:Creating final display dataframe.
2025-04-03 12:14:37,835:INFO:Setup _display_container:                     Description             Value
0                    Session id              8994
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              7068
2025-04-03 12:14:37,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,908:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:14:37,975:INFO:setup() successfully completed in 1.36s...............
2025-04-03 12:14:37,976:INFO:Initializing compare_models()
2025-04-03 12:14:37,976:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2025-04-03 12:14:37,976:INFO:Checking exceptions
2025-04-03 12:14:37,984:INFO:Preparing display monitor
2025-04-03 12:14:37,987:INFO:Initializing Logistic Regression
2025-04-03 12:14:37,987:INFO:Total runtime is 0.0 minutes
2025-04-03 12:14:37,987:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:37,988:INFO:Initializing create_model()
2025-04-03 12:14:37,988:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:37,988:INFO:Checking exceptions
2025-04-03 12:14:37,988:INFO:Importing libraries
2025-04-03 12:14:37,988:INFO:Copying training dataset
2025-04-03 12:14:37,992:INFO:Defining folds
2025-04-03 12:14:37,992:INFO:Declaring metric variables
2025-04-03 12:14:37,992:INFO:Importing untrained model
2025-04-03 12:14:37,992:INFO:Logistic Regression Imported successfully
2025-04-03 12:14:37,992:INFO:Starting cross validation
2025-04-03 12:14:37,994:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:44,222:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,222:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,242:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,250:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,263:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,277:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,289:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,291:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,304:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,378:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:44,510:INFO:Calculating mean and std
2025-04-03 12:14:44,511:INFO:Creating metrics dataframe
2025-04-03 12:14:44,516:INFO:Uploading results into container
2025-04-03 12:14:44,517:INFO:Uploading model into container now
2025-04-03 12:14:44,517:INFO:_master_model_container: 1
2025-04-03 12:14:44,517:INFO:_display_container: 2
2025-04-03 12:14:44,518:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-03 12:14:44,518:INFO:create_model() successfully completed......................................
2025-04-03 12:14:44,641:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:44,641:INFO:Creating metrics dataframe
2025-04-03 12:14:44,644:INFO:Initializing K Neighbors Classifier
2025-04-03 12:14:44,644:INFO:Total runtime is 0.11093972524007162 minutes
2025-04-03 12:14:44,644:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:44,645:INFO:Initializing create_model()
2025-04-03 12:14:44,645:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:44,645:INFO:Checking exceptions
2025-04-03 12:14:44,645:INFO:Importing libraries
2025-04-03 12:14:44,645:INFO:Copying training dataset
2025-04-03 12:14:44,649:INFO:Defining folds
2025-04-03 12:14:44,649:INFO:Declaring metric variables
2025-04-03 12:14:44,650:INFO:Importing untrained model
2025-04-03 12:14:44,650:INFO:K Neighbors Classifier Imported successfully
2025-04-03 12:14:44,650:INFO:Starting cross validation
2025-04-03 12:14:44,653:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:47,275:INFO:Calculating mean and std
2025-04-03 12:14:47,276:INFO:Creating metrics dataframe
2025-04-03 12:14:47,279:INFO:Uploading results into container
2025-04-03 12:14:47,280:INFO:Uploading model into container now
2025-04-03 12:14:47,280:INFO:_master_model_container: 2
2025-04-03 12:14:47,281:INFO:_display_container: 2
2025-04-03 12:14:47,281:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-04-03 12:14:47,281:INFO:create_model() successfully completed......................................
2025-04-03 12:14:47,401:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:47,401:INFO:Creating metrics dataframe
2025-04-03 12:14:47,403:INFO:Initializing Naive Bayes
2025-04-03 12:14:47,403:INFO:Total runtime is 0.1569326361020406 minutes
2025-04-03 12:14:47,403:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:47,403:INFO:Initializing create_model()
2025-04-03 12:14:47,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:47,404:INFO:Checking exceptions
2025-04-03 12:14:47,404:INFO:Importing libraries
2025-04-03 12:14:47,404:INFO:Copying training dataset
2025-04-03 12:14:47,408:INFO:Defining folds
2025-04-03 12:14:47,408:INFO:Declaring metric variables
2025-04-03 12:14:47,409:INFO:Importing untrained model
2025-04-03 12:14:47,409:INFO:Naive Bayes Imported successfully
2025-04-03 12:14:47,409:INFO:Starting cross validation
2025-04-03 12:14:47,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:47,714:INFO:Calculating mean and std
2025-04-03 12:14:47,715:INFO:Creating metrics dataframe
2025-04-03 12:14:47,716:INFO:Uploading results into container
2025-04-03 12:14:47,717:INFO:Uploading model into container now
2025-04-03 12:14:47,717:INFO:_master_model_container: 3
2025-04-03 12:14:47,717:INFO:_display_container: 2
2025-04-03 12:14:47,717:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-03 12:14:47,717:INFO:create_model() successfully completed......................................
2025-04-03 12:14:47,820:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:47,820:INFO:Creating metrics dataframe
2025-04-03 12:14:47,823:INFO:Initializing Decision Tree Classifier
2025-04-03 12:14:47,823:INFO:Total runtime is 0.16392117738723755 minutes
2025-04-03 12:14:47,823:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:47,823:INFO:Initializing create_model()
2025-04-03 12:14:47,823:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:47,824:INFO:Checking exceptions
2025-04-03 12:14:47,824:INFO:Importing libraries
2025-04-03 12:14:47,824:INFO:Copying training dataset
2025-04-03 12:14:47,828:INFO:Defining folds
2025-04-03 12:14:47,828:INFO:Declaring metric variables
2025-04-03 12:14:47,828:INFO:Importing untrained model
2025-04-03 12:14:47,829:INFO:Decision Tree Classifier Imported successfully
2025-04-03 12:14:47,829:INFO:Starting cross validation
2025-04-03 12:14:47,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:48,118:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:48,118:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:48,118:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:48,118:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:48,118:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:48,118:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:48,118:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:48,138:INFO:Calculating mean and std
2025-04-03 12:14:48,139:INFO:Creating metrics dataframe
2025-04-03 12:14:48,140:INFO:Uploading results into container
2025-04-03 12:14:48,141:INFO:Uploading model into container now
2025-04-03 12:14:48,141:INFO:_master_model_container: 4
2025-04-03 12:14:48,141:INFO:_display_container: 2
2025-04-03 12:14:48,141:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8994, splitter='best')
2025-04-03 12:14:48,141:INFO:create_model() successfully completed......................................
2025-04-03 12:14:48,250:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:48,250:INFO:Creating metrics dataframe
2025-04-03 12:14:48,253:INFO:Initializing SVM - Linear Kernel
2025-04-03 12:14:48,253:INFO:Total runtime is 0.17108875513076782 minutes
2025-04-03 12:14:48,254:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:48,254:INFO:Initializing create_model()
2025-04-03 12:14:48,254:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:48,254:INFO:Checking exceptions
2025-04-03 12:14:48,254:INFO:Importing libraries
2025-04-03 12:14:48,254:INFO:Copying training dataset
2025-04-03 12:14:48,258:INFO:Defining folds
2025-04-03 12:14:48,258:INFO:Declaring metric variables
2025-04-03 12:14:48,258:INFO:Importing untrained model
2025-04-03 12:14:48,259:INFO:SVM - Linear Kernel Imported successfully
2025-04-03 12:14:48,259:INFO:Starting cross validation
2025-04-03 12:14:48,261:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:48,574:INFO:Calculating mean and std
2025-04-03 12:14:48,575:INFO:Creating metrics dataframe
2025-04-03 12:14:48,576:INFO:Uploading results into container
2025-04-03 12:14:48,577:INFO:Uploading model into container now
2025-04-03 12:14:48,577:INFO:_master_model_container: 5
2025-04-03 12:14:48,577:INFO:_display_container: 2
2025-04-03 12:14:48,577:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8994, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-04-03 12:14:48,577:INFO:create_model() successfully completed......................................
2025-04-03 12:14:48,682:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:48,682:INFO:Creating metrics dataframe
2025-04-03 12:14:48,685:INFO:Initializing Ridge Classifier
2025-04-03 12:14:48,685:INFO:Total runtime is 0.17830004692077636 minutes
2025-04-03 12:14:48,685:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:48,685:INFO:Initializing create_model()
2025-04-03 12:14:48,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:48,685:INFO:Checking exceptions
2025-04-03 12:14:48,685:INFO:Importing libraries
2025-04-03 12:14:48,686:INFO:Copying training dataset
2025-04-03 12:14:48,690:INFO:Defining folds
2025-04-03 12:14:48,690:INFO:Declaring metric variables
2025-04-03 12:14:48,690:INFO:Importing untrained model
2025-04-03 12:14:48,691:INFO:Ridge Classifier Imported successfully
2025-04-03 12:14:48,691:INFO:Starting cross validation
2025-04-03 12:14:48,692:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:49,002:INFO:Calculating mean and std
2025-04-03 12:14:49,002:INFO:Creating metrics dataframe
2025-04-03 12:14:49,004:INFO:Uploading results into container
2025-04-03 12:14:49,005:INFO:Uploading model into container now
2025-04-03 12:14:49,005:INFO:_master_model_container: 6
2025-04-03 12:14:49,005:INFO:_display_container: 2
2025-04-03 12:14:49,005:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8994, solver='auto',
                tol=0.0001)
2025-04-03 12:14:49,006:INFO:create_model() successfully completed......................................
2025-04-03 12:14:49,117:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:49,117:INFO:Creating metrics dataframe
2025-04-03 12:14:49,120:INFO:Initializing Random Forest Classifier
2025-04-03 12:14:49,120:INFO:Total runtime is 0.18555042743682862 minutes
2025-04-03 12:14:49,121:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:49,121:INFO:Initializing create_model()
2025-04-03 12:14:49,121:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:49,121:INFO:Checking exceptions
2025-04-03 12:14:49,121:INFO:Importing libraries
2025-04-03 12:14:49,121:INFO:Copying training dataset
2025-04-03 12:14:49,126:INFO:Defining folds
2025-04-03 12:14:49,126:INFO:Declaring metric variables
2025-04-03 12:14:49,126:INFO:Importing untrained model
2025-04-03 12:14:49,127:INFO:Random Forest Classifier Imported successfully
2025-04-03 12:14:49,127:INFO:Starting cross validation
2025-04-03 12:14:49,129:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:49,771:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:49,774:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:49,800:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:49,801:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:49,821:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:49,827:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:49,869:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:49,919:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:49,929:INFO:Calculating mean and std
2025-04-03 12:14:49,930:INFO:Creating metrics dataframe
2025-04-03 12:14:49,931:INFO:Uploading results into container
2025-04-03 12:14:49,932:INFO:Uploading model into container now
2025-04-03 12:14:49,932:INFO:_master_model_container: 7
2025-04-03 12:14:49,932:INFO:_display_container: 2
2025-04-03 12:14:49,933:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8994, verbose=0,
                       warm_start=False)
2025-04-03 12:14:49,933:INFO:create_model() successfully completed......................................
2025-04-03 12:14:50,037:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:50,037:INFO:Creating metrics dataframe
2025-04-03 12:14:50,040:INFO:Initializing Quadratic Discriminant Analysis
2025-04-03 12:14:50,040:INFO:Total runtime is 0.20087351401646933 minutes
2025-04-03 12:14:50,040:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:50,040:INFO:Initializing create_model()
2025-04-03 12:14:50,040:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:50,040:INFO:Checking exceptions
2025-04-03 12:14:50,040:INFO:Importing libraries
2025-04-03 12:14:50,040:INFO:Copying training dataset
2025-04-03 12:14:50,045:INFO:Defining folds
2025-04-03 12:14:50,045:INFO:Declaring metric variables
2025-04-03 12:14:50,045:INFO:Importing untrained model
2025-04-03 12:14:50,045:INFO:Quadratic Discriminant Analysis Imported successfully
2025-04-03 12:14:50,046:INFO:Starting cross validation
2025-04-03 12:14:50,048:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:50,264:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,265:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,265:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,265:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,265:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,265:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,265:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,267:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,267:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,268:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2025-04-03 12:14:50,347:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,350:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,352:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,353:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,354:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,356:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,357:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,359:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,361:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,369:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,379:INFO:Calculating mean and std
2025-04-03 12:14:50,380:INFO:Creating metrics dataframe
2025-04-03 12:14:50,381:INFO:Uploading results into container
2025-04-03 12:14:50,381:INFO:Uploading model into container now
2025-04-03 12:14:50,383:INFO:_master_model_container: 8
2025-04-03 12:14:50,383:INFO:_display_container: 2
2025-04-03 12:14:50,383:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-04-03 12:14:50,383:INFO:create_model() successfully completed......................................
2025-04-03 12:14:50,487:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:50,487:INFO:Creating metrics dataframe
2025-04-03 12:14:50,489:INFO:Initializing Ada Boost Classifier
2025-04-03 12:14:50,490:INFO:Total runtime is 0.20837293068567914 minutes
2025-04-03 12:14:50,490:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:50,490:INFO:Initializing create_model()
2025-04-03 12:14:50,490:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:50,490:INFO:Checking exceptions
2025-04-03 12:14:50,490:INFO:Importing libraries
2025-04-03 12:14:50,490:INFO:Copying training dataset
2025-04-03 12:14:50,494:INFO:Defining folds
2025-04-03 12:14:50,494:INFO:Declaring metric variables
2025-04-03 12:14:50,495:INFO:Importing untrained model
2025-04-03 12:14:50,495:INFO:Ada Boost Classifier Imported successfully
2025-04-03 12:14:50,495:INFO:Starting cross validation
2025-04-03 12:14:50,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:50,688:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-03 12:14:50,688:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-03 12:14:50,689:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-03 12:14:50,689:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-03 12:14:50,689:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-03 12:14:50,689:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-03 12:14:50,689:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-03 12:14:50,689:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-03 12:14:50,689:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-04-03 12:14:50,762:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,765:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,769:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,770:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,770:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,770:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,771:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,771:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,772:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,772:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:50,784:INFO:Calculating mean and std
2025-04-03 12:14:50,785:INFO:Creating metrics dataframe
2025-04-03 12:14:50,786:INFO:Uploading results into container
2025-04-03 12:14:50,787:INFO:Uploading model into container now
2025-04-03 12:14:50,787:INFO:_master_model_container: 9
2025-04-03 12:14:50,787:INFO:_display_container: 2
2025-04-03 12:14:50,787:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8994)
2025-04-03 12:14:50,787:INFO:create_model() successfully completed......................................
2025-04-03 12:14:50,892:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:50,892:INFO:Creating metrics dataframe
2025-04-03 12:14:50,896:INFO:Initializing Gradient Boosting Classifier
2025-04-03 12:14:50,896:INFO:Total runtime is 0.2151493589083354 minutes
2025-04-03 12:14:50,897:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:50,897:INFO:Initializing create_model()
2025-04-03 12:14:50,897:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:50,897:INFO:Checking exceptions
2025-04-03 12:14:50,897:INFO:Importing libraries
2025-04-03 12:14:50,897:INFO:Copying training dataset
2025-04-03 12:14:50,903:INFO:Defining folds
2025-04-03 12:14:50,903:INFO:Declaring metric variables
2025-04-03 12:14:50,903:INFO:Importing untrained model
2025-04-03 12:14:50,904:INFO:Gradient Boosting Classifier Imported successfully
2025-04-03 12:14:50,904:INFO:Starting cross validation
2025-04-03 12:14:50,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:51,330:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,331:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,334:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,342:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,348:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,350:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,353:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,355:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,362:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,369:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,380:INFO:Calculating mean and std
2025-04-03 12:14:51,381:INFO:Creating metrics dataframe
2025-04-03 12:14:51,383:INFO:Uploading results into container
2025-04-03 12:14:51,383:INFO:Uploading model into container now
2025-04-03 12:14:51,384:INFO:_master_model_container: 10
2025-04-03 12:14:51,384:INFO:_display_container: 2
2025-04-03 12:14:51,384:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8994, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-04-03 12:14:51,384:INFO:create_model() successfully completed......................................
2025-04-03 12:14:51,483:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:51,483:INFO:Creating metrics dataframe
2025-04-03 12:14:51,485:INFO:Initializing Linear Discriminant Analysis
2025-04-03 12:14:51,485:INFO:Total runtime is 0.22496703068415327 minutes
2025-04-03 12:14:51,486:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:51,486:INFO:Initializing create_model()
2025-04-03 12:14:51,486:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:51,486:INFO:Checking exceptions
2025-04-03 12:14:51,486:INFO:Importing libraries
2025-04-03 12:14:51,486:INFO:Copying training dataset
2025-04-03 12:14:51,490:INFO:Defining folds
2025-04-03 12:14:51,490:INFO:Declaring metric variables
2025-04-03 12:14:51,490:INFO:Importing untrained model
2025-04-03 12:14:51,490:INFO:Linear Discriminant Analysis Imported successfully
2025-04-03 12:14:51,491:INFO:Starting cross validation
2025-04-03 12:14:51,492:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:51,753:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,753:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,755:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,758:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,758:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,759:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,764:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,765:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,771:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:51,779:INFO:Calculating mean and std
2025-04-03 12:14:51,780:INFO:Creating metrics dataframe
2025-04-03 12:14:51,781:INFO:Uploading results into container
2025-04-03 12:14:51,782:INFO:Uploading model into container now
2025-04-03 12:14:51,782:INFO:_master_model_container: 11
2025-04-03 12:14:51,782:INFO:_display_container: 2
2025-04-03 12:14:51,782:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-04-03 12:14:51,782:INFO:create_model() successfully completed......................................
2025-04-03 12:14:51,889:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:51,889:INFO:Creating metrics dataframe
2025-04-03 12:14:51,892:INFO:Initializing Extra Trees Classifier
2025-04-03 12:14:51,892:INFO:Total runtime is 0.23175228436787926 minutes
2025-04-03 12:14:51,892:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:51,892:INFO:Initializing create_model()
2025-04-03 12:14:51,892:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:51,892:INFO:Checking exceptions
2025-04-03 12:14:51,892:INFO:Importing libraries
2025-04-03 12:14:51,892:INFO:Copying training dataset
2025-04-03 12:14:51,897:INFO:Defining folds
2025-04-03 12:14:51,897:INFO:Declaring metric variables
2025-04-03 12:14:51,897:INFO:Importing untrained model
2025-04-03 12:14:51,897:INFO:Extra Trees Classifier Imported successfully
2025-04-03 12:14:51,898:INFO:Starting cross validation
2025-04-03 12:14:51,899:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:52,511:INFO:Calculating mean and std
2025-04-03 12:14:52,512:INFO:Creating metrics dataframe
2025-04-03 12:14:52,514:INFO:Uploading results into container
2025-04-03 12:14:52,515:INFO:Uploading model into container now
2025-04-03 12:14:52,515:INFO:_master_model_container: 12
2025-04-03 12:14:52,515:INFO:_display_container: 2
2025-04-03 12:14:52,516:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8994, verbose=0,
                     warm_start=False)
2025-04-03 12:14:52,516:INFO:create_model() successfully completed......................................
2025-04-03 12:14:52,615:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:52,615:INFO:Creating metrics dataframe
2025-04-03 12:14:52,618:INFO:Initializing Light Gradient Boosting Machine
2025-04-03 12:14:52,618:INFO:Total runtime is 0.243839168548584 minutes
2025-04-03 12:14:52,618:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:52,619:INFO:Initializing create_model()
2025-04-03 12:14:52,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:52,619:INFO:Checking exceptions
2025-04-03 12:14:52,619:INFO:Importing libraries
2025-04-03 12:14:52,619:INFO:Copying training dataset
2025-04-03 12:14:52,623:INFO:Defining folds
2025-04-03 12:14:52,623:INFO:Declaring metric variables
2025-04-03 12:14:52,623:INFO:Importing untrained model
2025-04-03 12:14:52,623:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-03 12:14:52,624:INFO:Starting cross validation
2025-04-03 12:14:52,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:53,341:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,354:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,357:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,370:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,468:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,471:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,496:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,522:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,528:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,561:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,574:INFO:Calculating mean and std
2025-04-03 12:14:53,575:INFO:Creating metrics dataframe
2025-04-03 12:14:53,577:INFO:Uploading results into container
2025-04-03 12:14:53,577:INFO:Uploading model into container now
2025-04-03 12:14:53,578:INFO:_master_model_container: 13
2025-04-03 12:14:53,578:INFO:_display_container: 2
2025-04-03 12:14:53,579:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8994, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-04-03 12:14:53,579:INFO:create_model() successfully completed......................................
2025-04-03 12:14:53,693:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:53,693:INFO:Creating metrics dataframe
2025-04-03 12:14:53,697:INFO:Initializing Dummy Classifier
2025-04-03 12:14:53,697:INFO:Total runtime is 0.26182075341542566 minutes
2025-04-03 12:14:53,697:INFO:SubProcess create_model() called ==================================
2025-04-03 12:14:53,698:INFO:Initializing create_model()
2025-04-03 12:14:53,698:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFED13EB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:53,698:INFO:Checking exceptions
2025-04-03 12:14:53,698:INFO:Importing libraries
2025-04-03 12:14:53,698:INFO:Copying training dataset
2025-04-03 12:14:53,702:INFO:Defining folds
2025-04-03 12:14:53,702:INFO:Declaring metric variables
2025-04-03 12:14:53,702:INFO:Importing untrained model
2025-04-03 12:14:53,702:INFO:Dummy Classifier Imported successfully
2025-04-03 12:14:53,703:INFO:Starting cross validation
2025-04-03 12:14:53,704:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:14:53,976:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,980:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,983:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:53,995:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:54,004:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:54,007:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:54,007:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:54,007:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:54,008:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:54,014:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-04-03 12:14:54,029:INFO:Calculating mean and std
2025-04-03 12:14:54,030:INFO:Creating metrics dataframe
2025-04-03 12:14:54,032:INFO:Uploading results into container
2025-04-03 12:14:54,033:INFO:Uploading model into container now
2025-04-03 12:14:54,033:INFO:_master_model_container: 14
2025-04-03 12:14:54,033:INFO:_display_container: 2
2025-04-03 12:14:54,033:INFO:DummyClassifier(constant=None, random_state=8994, strategy='prior')
2025-04-03 12:14:54,033:INFO:create_model() successfully completed......................................
2025-04-03 12:14:54,136:INFO:SubProcess create_model() end ==================================
2025-04-03 12:14:54,137:INFO:Creating metrics dataframe
2025-04-03 12:14:54,141:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-03 12:14:54,144:INFO:Initializing create_model()
2025-04-03 12:14:54,144:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:54,145:INFO:Checking exceptions
2025-04-03 12:14:54,145:INFO:Importing libraries
2025-04-03 12:14:54,146:INFO:Copying training dataset
2025-04-03 12:14:54,151:INFO:Defining folds
2025-04-03 12:14:54,151:INFO:Declaring metric variables
2025-04-03 12:14:54,151:INFO:Importing untrained model
2025-04-03 12:14:54,151:INFO:Declaring custom model
2025-04-03 12:14:54,152:INFO:Logistic Regression Imported successfully
2025-04-03 12:14:54,153:INFO:Cross validation set to False
2025-04-03 12:14:54,153:INFO:Fitting Model
2025-04-03 12:14:54,341:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:54,341:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-03 12:14:54,341:INFO:create_model() successfully completed......................................
2025-04-03 12:14:54,445:INFO:Initializing create_model()
2025-04-03 12:14:54,446:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8994, solver='auto',
                tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:54,446:INFO:Checking exceptions
2025-04-03 12:14:54,447:INFO:Importing libraries
2025-04-03 12:14:54,447:INFO:Copying training dataset
2025-04-03 12:14:54,450:INFO:Defining folds
2025-04-03 12:14:54,450:INFO:Declaring metric variables
2025-04-03 12:14:54,450:INFO:Importing untrained model
2025-04-03 12:14:54,450:INFO:Declaring custom model
2025-04-03 12:14:54,451:INFO:Ridge Classifier Imported successfully
2025-04-03 12:14:54,452:INFO:Cross validation set to False
2025-04-03 12:14:54,452:INFO:Fitting Model
2025-04-03 12:14:54,520:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8994, solver='auto',
                tol=0.0001)
2025-04-03 12:14:54,520:INFO:create_model() successfully completed......................................
2025-04-03 12:14:54,618:INFO:Initializing create_model()
2025-04-03 12:14:54,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8994, verbose=0,
                     warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:54,619:INFO:Checking exceptions
2025-04-03 12:14:54,619:INFO:Importing libraries
2025-04-03 12:14:54,619:INFO:Copying training dataset
2025-04-03 12:14:54,623:INFO:Defining folds
2025-04-03 12:14:54,624:INFO:Declaring metric variables
2025-04-03 12:14:54,624:INFO:Importing untrained model
2025-04-03 12:14:54,624:INFO:Declaring custom model
2025-04-03 12:14:54,624:INFO:Extra Trees Classifier Imported successfully
2025-04-03 12:14:54,625:INFO:Cross validation set to False
2025-04-03 12:14:54,625:INFO:Fitting Model
2025-04-03 12:14:54,801:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8994, verbose=0,
                     warm_start=False)
2025-04-03 12:14:54,801:INFO:create_model() successfully completed......................................
2025-04-03 12:14:54,901:INFO:Initializing create_model()
2025-04-03 12:14:54,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=GaussianNB(priors=None, var_smoothing=1e-09), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:54,901:INFO:Checking exceptions
2025-04-03 12:14:54,901:INFO:Importing libraries
2025-04-03 12:14:54,902:INFO:Copying training dataset
2025-04-03 12:14:54,905:INFO:Defining folds
2025-04-03 12:14:54,905:INFO:Declaring metric variables
2025-04-03 12:14:54,906:INFO:Importing untrained model
2025-04-03 12:14:54,906:INFO:Declaring custom model
2025-04-03 12:14:54,906:INFO:Naive Bayes Imported successfully
2025-04-03 12:14:54,907:INFO:Cross validation set to False
2025-04-03 12:14:54,907:INFO:Fitting Model
2025-04-03 12:14:54,973:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-04-03 12:14:54,973:INFO:create_model() successfully completed......................................
2025-04-03 12:14:55,074:INFO:Initializing create_model()
2025-04-03 12:14:55,074:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8994, verbose=0,
                       warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:14:55,074:INFO:Checking exceptions
2025-04-03 12:14:55,075:INFO:Importing libraries
2025-04-03 12:14:55,075:INFO:Copying training dataset
2025-04-03 12:14:55,079:INFO:Defining folds
2025-04-03 12:14:55,080:INFO:Declaring metric variables
2025-04-03 12:14:55,080:INFO:Importing untrained model
2025-04-03 12:14:55,080:INFO:Declaring custom model
2025-04-03 12:14:55,080:INFO:Random Forest Classifier Imported successfully
2025-04-03 12:14:55,082:INFO:Cross validation set to False
2025-04-03 12:14:55,082:INFO:Fitting Model
2025-04-03 12:14:55,300:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8994, verbose=0,
                       warm_start=False)
2025-04-03 12:14:55,300:INFO:create_model() successfully completed......................................
2025-04-03 12:14:55,408:INFO:_master_model_container: 14
2025-04-03 12:14:55,408:INFO:_display_container: 2
2025-04-03 12:14:55,409:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8994, solver='auto',
                tol=0.0001), ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8994, verbose=0,
                     warm_start=False), GaussianNB(priors=None, var_smoothing=1e-09), RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8994, verbose=0,
                       warm_start=False)]
2025-04-03 12:14:55,409:INFO:compare_models() successfully completed......................................
2025-04-03 12:14:55,414:INFO:Initializing tune_model()
2025-04-03 12:14:55,414:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>)
2025-04-03 12:14:55,414:INFO:Checking exceptions
2025-04-03 12:14:55,419:INFO:Copying training dataset
2025-04-03 12:14:55,422:INFO:Checking base model
2025-04-03 12:14:55,422:INFO:Base model : Logistic Regression
2025-04-03 12:14:55,423:INFO:Declaring metric variables
2025-04-03 12:14:55,423:INFO:Defining Hyperparameters
2025-04-03 12:14:55,542:INFO:Tuning with n_jobs=-1
2025-04-03 12:14:55,542:INFO:Initializing RandomizedSearchCV
2025-04-03 12:14:56,011:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,023:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,037:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,117:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,129:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,141:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,191:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,197:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,214:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,261:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,276:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,517:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,574:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,582:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,668:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,746:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,769:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,774:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,781:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,814:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,848:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,856:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:56,929:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,009:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,102:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,195:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,219:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,230:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,275:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,299:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,362:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,403:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,467:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,467:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,486:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,539:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,541:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,646:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,674:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,804:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,830:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,908:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,917:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,927:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,940:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:57,969:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,028:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,068:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,105:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,121:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,237:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,354:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,373:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,409:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,425:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,447:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,508:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,512:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,545:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,604:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,625:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,736:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,841:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,852:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,862:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,916:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,938:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,949:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:58,975:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,015:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,159:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,165:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,271:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,272:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,307:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,371:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,397:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,414:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,469:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,478:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,500:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,558:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,712:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,749:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,800:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,822:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,825:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,850:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,869:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:14:59,891:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,004:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,044:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,065:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,074:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,165:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,174:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,210:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,215:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,230:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,237:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,281:INFO:best_params: {'actual_estimator__class_weight': {}, 'actual_estimator__C': 2.007}
2025-04-03 12:15:00,281:INFO:Hyperparameter search completed
2025-04-03 12:15:00,281:INFO:SubProcess create_model() called ==================================
2025-04-03 12:15:00,282:INFO:Initializing create_model()
2025-04-03 12:15:00,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC42C1C00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'class_weight': {}, 'C': 2.007})
2025-04-03 12:15:00,282:INFO:Checking exceptions
2025-04-03 12:15:00,282:INFO:Importing libraries
2025-04-03 12:15:00,282:INFO:Copying training dataset
2025-04-03 12:15:00,286:INFO:Defining folds
2025-04-03 12:15:00,286:INFO:Declaring metric variables
2025-04-03 12:15:00,287:INFO:Importing untrained model
2025-04-03 12:15:00,287:INFO:Declaring custom model
2025-04-03 12:15:00,287:INFO:Logistic Regression Imported successfully
2025-04-03 12:15:00,287:INFO:Starting cross validation
2025-04-03 12:15:00,289:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:15:00,690:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,693:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,695:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,700:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,704:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,708:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,715:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,720:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,721:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,727:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,805:INFO:Calculating mean and std
2025-04-03 12:15:00,806:INFO:Creating metrics dataframe
2025-04-03 12:15:00,807:INFO:Finalizing model
2025-04-03 12:15:00,994:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:00,995:INFO:Uploading results into container
2025-04-03 12:15:00,995:INFO:Uploading model into container now
2025-04-03 12:15:00,996:INFO:_master_model_container: 15
2025-04-03 12:15:00,996:INFO:_display_container: 3
2025-04-03 12:15:00,996:INFO:LogisticRegression(C=2.007, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-03 12:15:00,996:INFO:create_model() successfully completed......................................
2025-04-03 12:15:01,100:INFO:SubProcess create_model() end ==================================
2025-04-03 12:15:01,100:INFO:choose_better activated
2025-04-03 12:15:01,101:INFO:SubProcess create_model() called ==================================
2025-04-03 12:15:01,101:INFO:Initializing create_model()
2025-04-03 12:15:01,101:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:15:01,101:INFO:Checking exceptions
2025-04-03 12:15:01,102:INFO:Importing libraries
2025-04-03 12:15:01,102:INFO:Copying training dataset
2025-04-03 12:15:01,105:INFO:Defining folds
2025-04-03 12:15:01,105:INFO:Declaring metric variables
2025-04-03 12:15:01,105:INFO:Importing untrained model
2025-04-03 12:15:01,105:INFO:Declaring custom model
2025-04-03 12:15:01,107:INFO:Logistic Regression Imported successfully
2025-04-03 12:15:01,107:INFO:Starting cross validation
2025-04-03 12:15:01,108:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:15:01,521:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,523:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,585:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,597:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,619:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,627:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,642:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,644:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,668:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,696:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,769:INFO:Calculating mean and std
2025-04-03 12:15:01,769:INFO:Creating metrics dataframe
2025-04-03 12:15:01,771:INFO:Finalizing model
2025-04-03 12:15:01,971:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2025-04-03 12:15:01,971:INFO:Uploading results into container
2025-04-03 12:15:01,972:INFO:Uploading model into container now
2025-04-03 12:15:01,972:INFO:_master_model_container: 16
2025-04-03 12:15:01,972:INFO:_display_container: 4
2025-04-03 12:15:01,973:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-03 12:15:01,973:INFO:create_model() successfully completed......................................
2025-04-03 12:15:02,133:INFO:SubProcess create_model() end ==================================
2025-04-03 12:15:02,133:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8026
2025-04-03 12:15:02,134:INFO:LogisticRegression(C=2.007, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.8106
2025-04-03 12:15:02,134:INFO:LogisticRegression(C=2.007, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2025-04-03 12:15:02,134:INFO:choose_better completed
2025-04-03 12:15:02,144:INFO:_master_model_container: 16
2025-04-03 12:15:02,145:INFO:_display_container: 3
2025-04-03 12:15:02,145:INFO:LogisticRegression(C=2.007, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-04-03 12:15:02,145:INFO:tune_model() successfully completed......................................
2025-04-03 12:15:02,289:INFO:Initializing save_model()
2025-04-03 12:15:02,289:INFO:save_model(model=LogisticRegression(C=2.007, class_weight={}, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8994, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2025-04-03 12:15:02,290:INFO:Adding model into prep_pipe
2025-04-03 12:15:02,300:INFO:best_classifier.pkl saved in current working directory
2025-04-03 12:15:02,320:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=2.007, class_weight={}, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=8994,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2025-04-03 12:15:02,321:INFO:save_model() successfully completed......................................
2025-04-03 12:16:09,469:INFO:PyCaret RegressionExperiment
2025-04-03 12:16:09,469:INFO:Logging name: reg-default-name
2025-04-03 12:16:09,469:INFO:ML Usecase: MLUsecase.REGRESSION
2025-04-03 12:16:09,469:INFO:version 3.3.2
2025-04-03 12:16:09,469:INFO:Initializing setup()
2025-04-03 12:16:09,469:INFO:self.USI: af3a
2025-04-03 12:16:09,469:INFO:self._variable_keys: {'pipeline', 'fold_shuffle_param', 'fold_groups_param', 'data', 'y_train', 'n_jobs_param', 'logging_param', 'transform_target_param', 'exp_name_log', 'y', 'X', 'X_train', 'seed', 'fold_generator', 'target_param', 'X_test', 'idx', 'USI', 'html_param', 'y_test', 'gpu_n_jobs_param', 'gpu_param', '_ml_usecase', 'exp_id', 'log_plots_param', '_available_plots', 'memory'}
2025-04-03 12:16:09,469:INFO:Checking environment
2025-04-03 12:16:09,469:INFO:python_version: 3.10.0
2025-04-03 12:16:09,470:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-03 12:16:09,470:INFO:machine: AMD64
2025-04-03 12:16:09,470:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-03 12:16:09,476:INFO:Memory: svmem(total=17037209600, available=3617910784, percent=78.8, used=13419298816, free=3617910784)
2025-04-03 12:16:09,476:INFO:Physical Core: 6
2025-04-03 12:16:09,476:INFO:Logical Core: 12
2025-04-03 12:16:09,476:INFO:Checking libraries
2025-04-03 12:16:09,476:INFO:System:
2025-04-03 12:16:09,476:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-03 12:16:09,476:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-04-03 12:16:09,477:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-03 12:16:09,477:INFO:PyCaret required dependencies:
2025-04-03 12:16:09,477:INFO:                 pip: 21.2.3
2025-04-03 12:16:09,477:INFO:          setuptools: 57.4.0
2025-04-03 12:16:09,477:INFO:             pycaret: 3.3.2
2025-04-03 12:16:09,477:INFO:             IPython: 8.29.0
2025-04-03 12:16:09,477:INFO:          ipywidgets: 8.1.5
2025-04-03 12:16:09,477:INFO:                tqdm: 4.67.0
2025-04-03 12:16:09,477:INFO:               numpy: 1.26.4
2025-04-03 12:16:09,477:INFO:              pandas: 2.1.4
2025-04-03 12:16:09,477:INFO:              jinja2: 3.1.4
2025-04-03 12:16:09,477:INFO:               scipy: 1.11.4
2025-04-03 12:16:09,477:INFO:              joblib: 1.3.2
2025-04-03 12:16:09,477:INFO:             sklearn: 1.4.2
2025-04-03 12:16:09,477:INFO:                pyod: 2.0.2
2025-04-03 12:16:09,477:INFO:            imblearn: 0.12.4
2025-04-03 12:16:09,477:INFO:   category_encoders: 2.6.4
2025-04-03 12:16:09,477:INFO:            lightgbm: 4.5.0
2025-04-03 12:16:09,477:INFO:               numba: 0.60.0
2025-04-03 12:16:09,477:INFO:            requests: 2.32.3
2025-04-03 12:16:09,477:INFO:          matplotlib: 3.7.5
2025-04-03 12:16:09,477:INFO:          scikitplot: 0.3.7
2025-04-03 12:16:09,477:INFO:         yellowbrick: 1.5
2025-04-03 12:16:09,477:INFO:              plotly: 5.24.1
2025-04-03 12:16:09,477:INFO:    plotly-resampler: Not installed
2025-04-03 12:16:09,477:INFO:             kaleido: 0.2.1
2025-04-03 12:16:09,477:INFO:           schemdraw: 0.15
2025-04-03 12:16:09,477:INFO:         statsmodels: 0.14.4
2025-04-03 12:16:09,477:INFO:              sktime: 0.26.0
2025-04-03 12:16:09,477:INFO:               tbats: 1.1.3
2025-04-03 12:16:09,477:INFO:            pmdarima: 2.0.4
2025-04-03 12:16:09,477:INFO:              psutil: 6.1.0
2025-04-03 12:16:09,477:INFO:          markupsafe: 3.0.2
2025-04-03 12:16:09,477:INFO:             pickle5: Not installed
2025-04-03 12:16:09,477:INFO:         cloudpickle: 3.1.0
2025-04-03 12:16:09,477:INFO:         deprecation: 2.1.0
2025-04-03 12:16:09,477:INFO:              xxhash: 3.5.0
2025-04-03 12:16:09,477:INFO:           wurlitzer: Not installed
2025-04-03 12:16:09,477:INFO:PyCaret optional dependencies:
2025-04-03 12:16:09,478:INFO:                shap: 0.47.0
2025-04-03 12:16:09,478:INFO:           interpret: Not installed
2025-04-03 12:16:09,478:INFO:                umap: Not installed
2025-04-03 12:16:09,478:INFO:     ydata_profiling: 4.12.0
2025-04-03 12:16:09,478:INFO:  explainerdashboard: Not installed
2025-04-03 12:16:09,478:INFO:             autoviz: Not installed
2025-04-03 12:16:09,478:INFO:           fairlearn: Not installed
2025-04-03 12:16:09,478:INFO:          deepchecks: Not installed
2025-04-03 12:16:09,478:INFO:             xgboost: Not installed
2025-04-03 12:16:09,478:INFO:            catboost: Not installed
2025-04-03 12:16:09,478:INFO:              kmodes: Not installed
2025-04-03 12:16:09,478:INFO:             mlxtend: Not installed
2025-04-03 12:16:09,478:INFO:       statsforecast: Not installed
2025-04-03 12:16:09,478:INFO:        tune_sklearn: Not installed
2025-04-03 12:16:09,478:INFO:                 ray: Not installed
2025-04-03 12:16:09,478:INFO:            hyperopt: Not installed
2025-04-03 12:16:09,478:INFO:              optuna: Not installed
2025-04-03 12:16:09,478:INFO:               skopt: Not installed
2025-04-03 12:16:09,478:INFO:              mlflow: Not installed
2025-04-03 12:16:09,478:INFO:              gradio: Not installed
2025-04-03 12:16:09,478:INFO:             fastapi: Not installed
2025-04-03 12:16:09,478:INFO:             uvicorn: Not installed
2025-04-03 12:16:09,478:INFO:              m2cgen: Not installed
2025-04-03 12:16:09,478:INFO:           evidently: Not installed
2025-04-03 12:16:09,478:INFO:               fugue: Not installed
2025-04-03 12:16:09,478:INFO:           streamlit: 1.40.0
2025-04-03 12:16:09,478:INFO:             prophet: Not installed
2025-04-03 12:16:09,478:INFO:None
2025-04-03 12:16:09,479:INFO:Set up data.
2025-04-03 12:16:09,486:INFO:Set up folding strategy.
2025-04-03 12:16:09,486:INFO:Set up train/test split.
2025-04-03 12:16:09,490:INFO:Set up index.
2025-04-03 12:16:09,491:INFO:Assigning column types.
2025-04-03 12:16:09,497:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-04-03 12:16:09,498:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,503:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,508:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,570:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:09,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:09,615:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,621:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,624:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,723:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:09,723:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:09,724:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-04-03 12:16:09,728:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,733:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,830:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:09,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:09,835:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,841:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,896:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,938:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:16:09,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:09,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:09,939:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-04-03 12:16:09,948:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,013:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,058:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,059:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,068:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,124:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,166:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,166:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,168:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,168:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-04-03 12:16:10,230:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,271:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,271:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,271:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,375:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,376:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-04-03 12:16:10,437:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,477:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,478:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,539:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-04-03 12:16:10,580:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,580:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-04-03 12:16:10,690:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,690:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:10,803:INFO:Preparing preprocessing pipeline...
2025-04-03 12:16:10,803:INFO:Set up simple imputation.
2025-04-03 12:16:10,807:INFO:Set up encoding of ordinal features.
2025-04-03 12:16:10,814:INFO:Set up encoding of categorical features.
2025-04-03 12:16:10,911:INFO:Finished creating preprocessing pipeline.
2025-04-03 12:16:11,001:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-04-03 12:16:11,001:INFO:Creating final display dataframe.
2025-04-03 12:16:11,269:INFO:Setup _display_container:                     Description             Value
0                    Session id              8186
1                        Target             price
2                   Target type        Regression
3           Original data shape         (545, 13)
4        Transformed data shape         (545, 15)
5   Transformed train set shape         (381, 15)
6    Transformed test set shape         (164, 15)
7              Numeric features                 5
8          Categorical features                 7
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              af3a
2025-04-03 12:16:11,379:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:11,379:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:11,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:11,489:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:16:11,489:INFO:setup() successfully completed in 2.02s...............
2025-04-03 12:16:11,489:INFO:Initializing compare_models()
2025-04-03 12:16:11,490:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=5, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 5, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2025-04-03 12:16:11,490:INFO:Checking exceptions
2025-04-03 12:16:11,491:INFO:Preparing display monitor
2025-04-03 12:16:11,494:INFO:Initializing Linear Regression
2025-04-03 12:16:11,494:INFO:Total runtime is 0.0 minutes
2025-04-03 12:16:11,495:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:11,495:INFO:Initializing create_model()
2025-04-03 12:16:11,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:11,495:INFO:Checking exceptions
2025-04-03 12:16:11,495:INFO:Importing libraries
2025-04-03 12:16:11,495:INFO:Copying training dataset
2025-04-03 12:16:11,499:INFO:Defining folds
2025-04-03 12:16:11,500:INFO:Declaring metric variables
2025-04-03 12:16:11,500:INFO:Importing untrained model
2025-04-03 12:16:11,500:INFO:Linear Regression Imported successfully
2025-04-03 12:16:11,500:INFO:Starting cross validation
2025-04-03 12:16:11,502:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:11,791:INFO:Calculating mean and std
2025-04-03 12:16:11,794:INFO:Creating metrics dataframe
2025-04-03 12:16:11,799:INFO:Uploading results into container
2025-04-03 12:16:11,801:INFO:Uploading model into container now
2025-04-03 12:16:11,802:INFO:_master_model_container: 1
2025-04-03 12:16:11,802:INFO:_display_container: 2
2025-04-03 12:16:11,803:INFO:LinearRegression(n_jobs=-1)
2025-04-03 12:16:11,803:INFO:create_model() successfully completed......................................
2025-04-03 12:16:11,920:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:11,920:INFO:Creating metrics dataframe
2025-04-03 12:16:11,922:INFO:Initializing Lasso Regression
2025-04-03 12:16:11,923:INFO:Total runtime is 0.00715794563293457 minutes
2025-04-03 12:16:11,923:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:11,923:INFO:Initializing create_model()
2025-04-03 12:16:11,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:11,923:INFO:Checking exceptions
2025-04-03 12:16:11,923:INFO:Importing libraries
2025-04-03 12:16:11,923:INFO:Copying training dataset
2025-04-03 12:16:11,928:INFO:Defining folds
2025-04-03 12:16:11,928:INFO:Declaring metric variables
2025-04-03 12:16:11,928:INFO:Importing untrained model
2025-04-03 12:16:11,929:INFO:Lasso Regression Imported successfully
2025-04-03 12:16:11,929:INFO:Starting cross validation
2025-04-03 12:16:11,930:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:12,174:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.083e+13, tolerance: 1.284e+11
  model = cd_fast.enet_coordinate_descent(

2025-04-03 12:16:12,226:INFO:Calculating mean and std
2025-04-03 12:16:12,227:INFO:Creating metrics dataframe
2025-04-03 12:16:12,228:INFO:Uploading results into container
2025-04-03 12:16:12,229:INFO:Uploading model into container now
2025-04-03 12:16:12,229:INFO:_master_model_container: 2
2025-04-03 12:16:12,229:INFO:_display_container: 2
2025-04-03 12:16:12,230:INFO:Lasso(random_state=8186)
2025-04-03 12:16:12,230:INFO:create_model() successfully completed......................................
2025-04-03 12:16:12,336:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:12,337:INFO:Creating metrics dataframe
2025-04-03 12:16:12,339:INFO:Initializing Ridge Regression
2025-04-03 12:16:12,339:INFO:Total runtime is 0.01408387025197347 minutes
2025-04-03 12:16:12,339:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:12,340:INFO:Initializing create_model()
2025-04-03 12:16:12,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:12,340:INFO:Checking exceptions
2025-04-03 12:16:12,340:INFO:Importing libraries
2025-04-03 12:16:12,340:INFO:Copying training dataset
2025-04-03 12:16:12,344:INFO:Defining folds
2025-04-03 12:16:12,344:INFO:Declaring metric variables
2025-04-03 12:16:12,344:INFO:Importing untrained model
2025-04-03 12:16:12,345:INFO:Ridge Regression Imported successfully
2025-04-03 12:16:12,345:INFO:Starting cross validation
2025-04-03 12:16:12,346:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:12,655:INFO:Calculating mean and std
2025-04-03 12:16:12,656:INFO:Creating metrics dataframe
2025-04-03 12:16:12,657:INFO:Uploading results into container
2025-04-03 12:16:12,657:INFO:Uploading model into container now
2025-04-03 12:16:12,658:INFO:_master_model_container: 3
2025-04-03 12:16:12,658:INFO:_display_container: 2
2025-04-03 12:16:12,658:INFO:Ridge(random_state=8186)
2025-04-03 12:16:12,658:INFO:create_model() successfully completed......................................
2025-04-03 12:16:12,766:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:12,767:INFO:Creating metrics dataframe
2025-04-03 12:16:12,769:INFO:Initializing Elastic Net
2025-04-03 12:16:12,769:INFO:Total runtime is 0.02124696175257365 minutes
2025-04-03 12:16:12,769:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:12,769:INFO:Initializing create_model()
2025-04-03 12:16:12,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:12,769:INFO:Checking exceptions
2025-04-03 12:16:12,770:INFO:Importing libraries
2025-04-03 12:16:12,770:INFO:Copying training dataset
2025-04-03 12:16:12,773:INFO:Defining folds
2025-04-03 12:16:12,774:INFO:Declaring metric variables
2025-04-03 12:16:12,774:INFO:Importing untrained model
2025-04-03 12:16:12,774:INFO:Elastic Net Imported successfully
2025-04-03 12:16:12,774:INFO:Starting cross validation
2025-04-03 12:16:12,776:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:13,060:INFO:Calculating mean and std
2025-04-03 12:16:13,061:INFO:Creating metrics dataframe
2025-04-03 12:16:13,062:INFO:Uploading results into container
2025-04-03 12:16:13,063:INFO:Uploading model into container now
2025-04-03 12:16:13,063:INFO:_master_model_container: 4
2025-04-03 12:16:13,063:INFO:_display_container: 2
2025-04-03 12:16:13,064:INFO:ElasticNet(random_state=8186)
2025-04-03 12:16:13,064:INFO:create_model() successfully completed......................................
2025-04-03 12:16:13,170:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:13,170:INFO:Creating metrics dataframe
2025-04-03 12:16:13,173:INFO:Initializing Least Angle Regression
2025-04-03 12:16:13,173:INFO:Total runtime is 0.02799431085586548 minutes
2025-04-03 12:16:13,174:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:13,174:INFO:Initializing create_model()
2025-04-03 12:16:13,174:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:13,174:INFO:Checking exceptions
2025-04-03 12:16:13,174:INFO:Importing libraries
2025-04-03 12:16:13,174:INFO:Copying training dataset
2025-04-03 12:16:13,179:INFO:Defining folds
2025-04-03 12:16:13,179:INFO:Declaring metric variables
2025-04-03 12:16:13,179:INFO:Importing untrained model
2025-04-03 12:16:13,180:INFO:Least Angle Regression Imported successfully
2025-04-03 12:16:13,180:INFO:Starting cross validation
2025-04-03 12:16:13,181:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:13,469:INFO:Calculating mean and std
2025-04-03 12:16:13,470:INFO:Creating metrics dataframe
2025-04-03 12:16:13,472:INFO:Uploading results into container
2025-04-03 12:16:13,472:INFO:Uploading model into container now
2025-04-03 12:16:13,472:INFO:_master_model_container: 5
2025-04-03 12:16:13,472:INFO:_display_container: 2
2025-04-03 12:16:13,473:INFO:Lars(random_state=8186)
2025-04-03 12:16:13,473:INFO:create_model() successfully completed......................................
2025-04-03 12:16:13,577:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:13,578:INFO:Creating metrics dataframe
2025-04-03 12:16:13,581:INFO:Initializing Lasso Least Angle Regression
2025-04-03 12:16:13,581:INFO:Total runtime is 0.03479155699412028 minutes
2025-04-03 12:16:13,581:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:13,581:INFO:Initializing create_model()
2025-04-03 12:16:13,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:13,581:INFO:Checking exceptions
2025-04-03 12:16:13,581:INFO:Importing libraries
2025-04-03 12:16:13,581:INFO:Copying training dataset
2025-04-03 12:16:13,586:INFO:Defining folds
2025-04-03 12:16:13,587:INFO:Declaring metric variables
2025-04-03 12:16:13,587:INFO:Importing untrained model
2025-04-03 12:16:13,587:INFO:Lasso Least Angle Regression Imported successfully
2025-04-03 12:16:13,587:INFO:Starting cross validation
2025-04-03 12:16:13,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:13,870:INFO:Calculating mean and std
2025-04-03 12:16:13,871:INFO:Creating metrics dataframe
2025-04-03 12:16:13,872:INFO:Uploading results into container
2025-04-03 12:16:13,872:INFO:Uploading model into container now
2025-04-03 12:16:13,872:INFO:_master_model_container: 6
2025-04-03 12:16:13,872:INFO:_display_container: 2
2025-04-03 12:16:13,873:INFO:LassoLars(random_state=8186)
2025-04-03 12:16:13,873:INFO:create_model() successfully completed......................................
2025-04-03 12:16:13,978:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:13,978:INFO:Creating metrics dataframe
2025-04-03 12:16:13,981:INFO:Initializing Orthogonal Matching Pursuit
2025-04-03 12:16:13,981:INFO:Total runtime is 0.041448386510213216 minutes
2025-04-03 12:16:13,982:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:13,982:INFO:Initializing create_model()
2025-04-03 12:16:13,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:13,982:INFO:Checking exceptions
2025-04-03 12:16:13,982:INFO:Importing libraries
2025-04-03 12:16:13,982:INFO:Copying training dataset
2025-04-03 12:16:13,987:INFO:Defining folds
2025-04-03 12:16:13,988:INFO:Declaring metric variables
2025-04-03 12:16:13,988:INFO:Importing untrained model
2025-04-03 12:16:13,988:INFO:Orthogonal Matching Pursuit Imported successfully
2025-04-03 12:16:13,988:INFO:Starting cross validation
2025-04-03 12:16:13,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:14,270:INFO:Calculating mean and std
2025-04-03 12:16:14,271:INFO:Creating metrics dataframe
2025-04-03 12:16:14,272:INFO:Uploading results into container
2025-04-03 12:16:14,272:INFO:Uploading model into container now
2025-04-03 12:16:14,273:INFO:_master_model_container: 7
2025-04-03 12:16:14,273:INFO:_display_container: 2
2025-04-03 12:16:14,273:INFO:OrthogonalMatchingPursuit()
2025-04-03 12:16:14,273:INFO:create_model() successfully completed......................................
2025-04-03 12:16:14,381:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:14,381:INFO:Creating metrics dataframe
2025-04-03 12:16:14,384:INFO:Initializing Bayesian Ridge
2025-04-03 12:16:14,384:INFO:Total runtime is 0.048175124327341716 minutes
2025-04-03 12:16:14,384:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:14,384:INFO:Initializing create_model()
2025-04-03 12:16:14,385:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:14,385:INFO:Checking exceptions
2025-04-03 12:16:14,385:INFO:Importing libraries
2025-04-03 12:16:14,385:INFO:Copying training dataset
2025-04-03 12:16:14,390:INFO:Defining folds
2025-04-03 12:16:14,390:INFO:Declaring metric variables
2025-04-03 12:16:14,390:INFO:Importing untrained model
2025-04-03 12:16:14,390:INFO:Bayesian Ridge Imported successfully
2025-04-03 12:16:14,390:INFO:Starting cross validation
2025-04-03 12:16:14,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:14,671:INFO:Calculating mean and std
2025-04-03 12:16:14,672:INFO:Creating metrics dataframe
2025-04-03 12:16:14,673:INFO:Uploading results into container
2025-04-03 12:16:14,674:INFO:Uploading model into container now
2025-04-03 12:16:14,674:INFO:_master_model_container: 8
2025-04-03 12:16:14,674:INFO:_display_container: 2
2025-04-03 12:16:14,674:INFO:BayesianRidge()
2025-04-03 12:16:14,674:INFO:create_model() successfully completed......................................
2025-04-03 12:16:14,783:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:14,783:INFO:Creating metrics dataframe
2025-04-03 12:16:14,785:INFO:Initializing Passive Aggressive Regressor
2025-04-03 12:16:14,785:INFO:Total runtime is 0.0548477570215861 minutes
2025-04-03 12:16:14,786:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:14,786:INFO:Initializing create_model()
2025-04-03 12:16:14,786:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:14,786:INFO:Checking exceptions
2025-04-03 12:16:14,786:INFO:Importing libraries
2025-04-03 12:16:14,786:INFO:Copying training dataset
2025-04-03 12:16:14,790:INFO:Defining folds
2025-04-03 12:16:14,790:INFO:Declaring metric variables
2025-04-03 12:16:14,790:INFO:Importing untrained model
2025-04-03 12:16:14,791:INFO:Passive Aggressive Regressor Imported successfully
2025-04-03 12:16:14,792:INFO:Starting cross validation
2025-04-03 12:16:14,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:15,080:INFO:Calculating mean and std
2025-04-03 12:16:15,081:INFO:Creating metrics dataframe
2025-04-03 12:16:15,082:INFO:Uploading results into container
2025-04-03 12:16:15,083:INFO:Uploading model into container now
2025-04-03 12:16:15,083:INFO:_master_model_container: 9
2025-04-03 12:16:15,083:INFO:_display_container: 2
2025-04-03 12:16:15,083:INFO:PassiveAggressiveRegressor(random_state=8186)
2025-04-03 12:16:15,084:INFO:create_model() successfully completed......................................
2025-04-03 12:16:15,189:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:15,190:INFO:Creating metrics dataframe
2025-04-03 12:16:15,192:INFO:Initializing Huber Regressor
2025-04-03 12:16:15,192:INFO:Total runtime is 0.061644423007965084 minutes
2025-04-03 12:16:15,192:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:15,192:INFO:Initializing create_model()
2025-04-03 12:16:15,192:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:15,192:INFO:Checking exceptions
2025-04-03 12:16:15,192:INFO:Importing libraries
2025-04-03 12:16:15,192:INFO:Copying training dataset
2025-04-03 12:16:15,198:INFO:Defining folds
2025-04-03 12:16:15,198:INFO:Declaring metric variables
2025-04-03 12:16:15,199:INFO:Importing untrained model
2025-04-03 12:16:15,199:INFO:Huber Regressor Imported successfully
2025-04-03 12:16:15,199:INFO:Starting cross validation
2025-04-03 12:16:15,200:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:15,469:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-03 12:16:15,479:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-04-03 12:16:15,519:INFO:Calculating mean and std
2025-04-03 12:16:15,520:INFO:Creating metrics dataframe
2025-04-03 12:16:15,521:INFO:Uploading results into container
2025-04-03 12:16:15,521:INFO:Uploading model into container now
2025-04-03 12:16:15,521:INFO:_master_model_container: 10
2025-04-03 12:16:15,521:INFO:_display_container: 2
2025-04-03 12:16:15,522:INFO:HuberRegressor()
2025-04-03 12:16:15,522:INFO:create_model() successfully completed......................................
2025-04-03 12:16:15,627:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:15,627:INFO:Creating metrics dataframe
2025-04-03 12:16:15,630:INFO:Initializing K Neighbors Regressor
2025-04-03 12:16:15,630:INFO:Total runtime is 0.06894270181655883 minutes
2025-04-03 12:16:15,630:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:15,630:INFO:Initializing create_model()
2025-04-03 12:16:15,630:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:15,630:INFO:Checking exceptions
2025-04-03 12:16:15,631:INFO:Importing libraries
2025-04-03 12:16:15,631:INFO:Copying training dataset
2025-04-03 12:16:15,636:INFO:Defining folds
2025-04-03 12:16:15,636:INFO:Declaring metric variables
2025-04-03 12:16:15,636:INFO:Importing untrained model
2025-04-03 12:16:15,636:INFO:K Neighbors Regressor Imported successfully
2025-04-03 12:16:15,636:INFO:Starting cross validation
2025-04-03 12:16:15,639:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:15,961:INFO:Calculating mean and std
2025-04-03 12:16:15,961:INFO:Creating metrics dataframe
2025-04-03 12:16:15,963:INFO:Uploading results into container
2025-04-03 12:16:15,964:INFO:Uploading model into container now
2025-04-03 12:16:15,964:INFO:_master_model_container: 11
2025-04-03 12:16:15,964:INFO:_display_container: 2
2025-04-03 12:16:15,964:INFO:KNeighborsRegressor(n_jobs=-1)
2025-04-03 12:16:15,964:INFO:create_model() successfully completed......................................
2025-04-03 12:16:16,074:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:16,074:INFO:Creating metrics dataframe
2025-04-03 12:16:16,077:INFO:Initializing Decision Tree Regressor
2025-04-03 12:16:16,077:INFO:Total runtime is 0.07638645172119139 minutes
2025-04-03 12:16:16,077:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:16,077:INFO:Initializing create_model()
2025-04-03 12:16:16,077:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:16,077:INFO:Checking exceptions
2025-04-03 12:16:16,077:INFO:Importing libraries
2025-04-03 12:16:16,077:INFO:Copying training dataset
2025-04-03 12:16:16,081:INFO:Defining folds
2025-04-03 12:16:16,081:INFO:Declaring metric variables
2025-04-03 12:16:16,083:INFO:Importing untrained model
2025-04-03 12:16:16,083:INFO:Decision Tree Regressor Imported successfully
2025-04-03 12:16:16,083:INFO:Starting cross validation
2025-04-03 12:16:16,084:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:16,366:INFO:Calculating mean and std
2025-04-03 12:16:16,367:INFO:Creating metrics dataframe
2025-04-03 12:16:16,368:INFO:Uploading results into container
2025-04-03 12:16:16,369:INFO:Uploading model into container now
2025-04-03 12:16:16,369:INFO:_master_model_container: 12
2025-04-03 12:16:16,369:INFO:_display_container: 2
2025-04-03 12:16:16,369:INFO:DecisionTreeRegressor(random_state=8186)
2025-04-03 12:16:16,369:INFO:create_model() successfully completed......................................
2025-04-03 12:16:16,473:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:16,473:INFO:Creating metrics dataframe
2025-04-03 12:16:16,476:INFO:Initializing Random Forest Regressor
2025-04-03 12:16:16,476:INFO:Total runtime is 0.08302973508834838 minutes
2025-04-03 12:16:16,476:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:16,477:INFO:Initializing create_model()
2025-04-03 12:16:16,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:16,477:INFO:Checking exceptions
2025-04-03 12:16:16,477:INFO:Importing libraries
2025-04-03 12:16:16,477:INFO:Copying training dataset
2025-04-03 12:16:16,483:INFO:Defining folds
2025-04-03 12:16:16,483:INFO:Declaring metric variables
2025-04-03 12:16:16,484:INFO:Importing untrained model
2025-04-03 12:16:16,484:INFO:Random Forest Regressor Imported successfully
2025-04-03 12:16:16,484:INFO:Starting cross validation
2025-04-03 12:16:16,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:17,155:INFO:Calculating mean and std
2025-04-03 12:16:17,156:INFO:Creating metrics dataframe
2025-04-03 12:16:17,158:INFO:Uploading results into container
2025-04-03 12:16:17,158:INFO:Uploading model into container now
2025-04-03 12:16:17,158:INFO:_master_model_container: 13
2025-04-03 12:16:17,159:INFO:_display_container: 2
2025-04-03 12:16:17,159:INFO:RandomForestRegressor(n_jobs=-1, random_state=8186)
2025-04-03 12:16:17,159:INFO:create_model() successfully completed......................................
2025-04-03 12:16:17,268:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:17,269:INFO:Creating metrics dataframe
2025-04-03 12:16:17,271:INFO:Initializing Extra Trees Regressor
2025-04-03 12:16:17,271:INFO:Total runtime is 0.09628549416859944 minutes
2025-04-03 12:16:17,271:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:17,272:INFO:Initializing create_model()
2025-04-03 12:16:17,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:17,272:INFO:Checking exceptions
2025-04-03 12:16:17,272:INFO:Importing libraries
2025-04-03 12:16:17,272:INFO:Copying training dataset
2025-04-03 12:16:17,277:INFO:Defining folds
2025-04-03 12:16:17,277:INFO:Declaring metric variables
2025-04-03 12:16:17,278:INFO:Importing untrained model
2025-04-03 12:16:17,278:INFO:Extra Trees Regressor Imported successfully
2025-04-03 12:16:17,278:INFO:Starting cross validation
2025-04-03 12:16:17,280:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:17,868:INFO:Calculating mean and std
2025-04-03 12:16:17,869:INFO:Creating metrics dataframe
2025-04-03 12:16:17,870:INFO:Uploading results into container
2025-04-03 12:16:17,871:INFO:Uploading model into container now
2025-04-03 12:16:17,871:INFO:_master_model_container: 14
2025-04-03 12:16:17,871:INFO:_display_container: 2
2025-04-03 12:16:17,872:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=8186)
2025-04-03 12:16:17,872:INFO:create_model() successfully completed......................................
2025-04-03 12:16:17,980:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:17,980:INFO:Creating metrics dataframe
2025-04-03 12:16:17,982:INFO:Initializing AdaBoost Regressor
2025-04-03 12:16:17,982:INFO:Total runtime is 0.10814398527145386 minutes
2025-04-03 12:16:17,983:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:17,983:INFO:Initializing create_model()
2025-04-03 12:16:17,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:17,983:INFO:Checking exceptions
2025-04-03 12:16:17,983:INFO:Importing libraries
2025-04-03 12:16:17,983:INFO:Copying training dataset
2025-04-03 12:16:17,988:INFO:Defining folds
2025-04-03 12:16:17,988:INFO:Declaring metric variables
2025-04-03 12:16:17,988:INFO:Importing untrained model
2025-04-03 12:16:17,989:INFO:AdaBoost Regressor Imported successfully
2025-04-03 12:16:17,989:INFO:Starting cross validation
2025-04-03 12:16:17,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:18,464:INFO:Calculating mean and std
2025-04-03 12:16:18,465:INFO:Creating metrics dataframe
2025-04-03 12:16:18,467:INFO:Uploading results into container
2025-04-03 12:16:18,467:INFO:Uploading model into container now
2025-04-03 12:16:18,467:INFO:_master_model_container: 15
2025-04-03 12:16:18,468:INFO:_display_container: 2
2025-04-03 12:16:18,468:INFO:AdaBoostRegressor(random_state=8186)
2025-04-03 12:16:18,468:INFO:create_model() successfully completed......................................
2025-04-03 12:16:18,575:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:18,577:INFO:Creating metrics dataframe
2025-04-03 12:16:18,579:INFO:Initializing Gradient Boosting Regressor
2025-04-03 12:16:18,579:INFO:Total runtime is 0.11809070110321045 minutes
2025-04-03 12:16:18,579:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:18,579:INFO:Initializing create_model()
2025-04-03 12:16:18,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:18,579:INFO:Checking exceptions
2025-04-03 12:16:18,580:INFO:Importing libraries
2025-04-03 12:16:18,580:INFO:Copying training dataset
2025-04-03 12:16:18,584:INFO:Defining folds
2025-04-03 12:16:18,584:INFO:Declaring metric variables
2025-04-03 12:16:18,584:INFO:Importing untrained model
2025-04-03 12:16:18,584:INFO:Gradient Boosting Regressor Imported successfully
2025-04-03 12:16:18,584:INFO:Starting cross validation
2025-04-03 12:16:18,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:19,004:INFO:Calculating mean and std
2025-04-03 12:16:19,005:INFO:Creating metrics dataframe
2025-04-03 12:16:19,007:INFO:Uploading results into container
2025-04-03 12:16:19,007:INFO:Uploading model into container now
2025-04-03 12:16:19,008:INFO:_master_model_container: 16
2025-04-03 12:16:19,008:INFO:_display_container: 2
2025-04-03 12:16:19,008:INFO:GradientBoostingRegressor(random_state=8186)
2025-04-03 12:16:19,008:INFO:create_model() successfully completed......................................
2025-04-03 12:16:19,123:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:19,123:INFO:Creating metrics dataframe
2025-04-03 12:16:19,125:INFO:Initializing Light Gradient Boosting Machine
2025-04-03 12:16:19,126:INFO:Total runtime is 0.12720828851064045 minutes
2025-04-03 12:16:19,126:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:19,127:INFO:Initializing create_model()
2025-04-03 12:16:19,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:19,127:INFO:Checking exceptions
2025-04-03 12:16:19,127:INFO:Importing libraries
2025-04-03 12:16:19,127:INFO:Copying training dataset
2025-04-03 12:16:19,132:INFO:Defining folds
2025-04-03 12:16:19,132:INFO:Declaring metric variables
2025-04-03 12:16:19,133:INFO:Importing untrained model
2025-04-03 12:16:19,133:INFO:Light Gradient Boosting Machine Imported successfully
2025-04-03 12:16:19,133:INFO:Starting cross validation
2025-04-03 12:16:19,135:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:20,324:INFO:Calculating mean and std
2025-04-03 12:16:20,325:INFO:Creating metrics dataframe
2025-04-03 12:16:20,328:INFO:Uploading results into container
2025-04-03 12:16:20,328:INFO:Uploading model into container now
2025-04-03 12:16:20,329:INFO:_master_model_container: 17
2025-04-03 12:16:20,329:INFO:_display_container: 2
2025-04-03 12:16:20,329:INFO:LGBMRegressor(n_jobs=-1, random_state=8186)
2025-04-03 12:16:20,329:INFO:create_model() successfully completed......................................
2025-04-03 12:16:20,454:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:20,454:INFO:Creating metrics dataframe
2025-04-03 12:16:20,457:INFO:Initializing Dummy Regressor
2025-04-03 12:16:20,457:INFO:Total runtime is 0.1493841767311096 minutes
2025-04-03 12:16:20,457:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:20,458:INFO:Initializing create_model()
2025-04-03 12:16:20,458:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FFF8504C0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:20,458:INFO:Checking exceptions
2025-04-03 12:16:20,458:INFO:Importing libraries
2025-04-03 12:16:20,458:INFO:Copying training dataset
2025-04-03 12:16:20,461:INFO:Defining folds
2025-04-03 12:16:20,461:INFO:Declaring metric variables
2025-04-03 12:16:20,462:INFO:Importing untrained model
2025-04-03 12:16:20,462:INFO:Dummy Regressor Imported successfully
2025-04-03 12:16:20,462:INFO:Starting cross validation
2025-04-03 12:16:20,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:20,738:INFO:Calculating mean and std
2025-04-03 12:16:20,739:INFO:Creating metrics dataframe
2025-04-03 12:16:20,740:INFO:Uploading results into container
2025-04-03 12:16:20,741:INFO:Uploading model into container now
2025-04-03 12:16:20,741:INFO:_master_model_container: 18
2025-04-03 12:16:20,741:INFO:_display_container: 2
2025-04-03 12:16:20,741:INFO:DummyRegressor()
2025-04-03 12:16:20,741:INFO:create_model() successfully completed......................................
2025-04-03 12:16:20,852:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:20,853:INFO:Creating metrics dataframe
2025-04-03 12:16:20,856:WARNING:C:\Users\suvam\AppData\Local\Programs\Python\Python310\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2025-04-03 12:16:20,859:INFO:Initializing create_model()
2025-04-03 12:16:20,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=Ridge(random_state=8186), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:20,859:INFO:Checking exceptions
2025-04-03 12:16:20,860:INFO:Importing libraries
2025-04-03 12:16:20,860:INFO:Copying training dataset
2025-04-03 12:16:20,864:INFO:Defining folds
2025-04-03 12:16:20,864:INFO:Declaring metric variables
2025-04-03 12:16:20,864:INFO:Importing untrained model
2025-04-03 12:16:20,865:INFO:Declaring custom model
2025-04-03 12:16:20,865:INFO:Ridge Regression Imported successfully
2025-04-03 12:16:20,867:INFO:Cross validation set to False
2025-04-03 12:16:20,867:INFO:Fitting Model
2025-04-03 12:16:20,931:INFO:Ridge(random_state=8186)
2025-04-03 12:16:20,931:INFO:create_model() successfully completed......................................
2025-04-03 12:16:21,034:INFO:Initializing create_model()
2025-04-03 12:16:21,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=LinearRegression(n_jobs=-1), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:21,035:INFO:Checking exceptions
2025-04-03 12:16:21,035:INFO:Importing libraries
2025-04-03 12:16:21,035:INFO:Copying training dataset
2025-04-03 12:16:21,040:INFO:Defining folds
2025-04-03 12:16:21,040:INFO:Declaring metric variables
2025-04-03 12:16:21,040:INFO:Importing untrained model
2025-04-03 12:16:21,041:INFO:Declaring custom model
2025-04-03 12:16:21,041:INFO:Linear Regression Imported successfully
2025-04-03 12:16:21,042:INFO:Cross validation set to False
2025-04-03 12:16:21,042:INFO:Fitting Model
2025-04-03 12:16:21,106:INFO:LinearRegression(n_jobs=-1)
2025-04-03 12:16:21,106:INFO:create_model() successfully completed......................................
2025-04-03 12:16:21,215:INFO:Initializing create_model()
2025-04-03 12:16:21,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=Lasso(random_state=8186), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:21,215:INFO:Checking exceptions
2025-04-03 12:16:21,215:INFO:Importing libraries
2025-04-03 12:16:21,215:INFO:Copying training dataset
2025-04-03 12:16:21,220:INFO:Defining folds
2025-04-03 12:16:21,220:INFO:Declaring metric variables
2025-04-03 12:16:21,220:INFO:Importing untrained model
2025-04-03 12:16:21,220:INFO:Declaring custom model
2025-04-03 12:16:21,221:INFO:Lasso Regression Imported successfully
2025-04-03 12:16:21,222:INFO:Cross validation set to False
2025-04-03 12:16:21,222:INFO:Fitting Model
2025-04-03 12:16:21,284:INFO:Lasso(random_state=8186)
2025-04-03 12:16:21,284:INFO:create_model() successfully completed......................................
2025-04-03 12:16:21,386:INFO:Initializing create_model()
2025-04-03 12:16:21,386:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=Lars(random_state=8186), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:21,386:INFO:Checking exceptions
2025-04-03 12:16:21,387:INFO:Importing libraries
2025-04-03 12:16:21,387:INFO:Copying training dataset
2025-04-03 12:16:21,391:INFO:Defining folds
2025-04-03 12:16:21,391:INFO:Declaring metric variables
2025-04-03 12:16:21,391:INFO:Importing untrained model
2025-04-03 12:16:21,391:INFO:Declaring custom model
2025-04-03 12:16:21,391:INFO:Least Angle Regression Imported successfully
2025-04-03 12:16:21,393:INFO:Cross validation set to False
2025-04-03 12:16:21,393:INFO:Fitting Model
2025-04-03 12:16:21,456:INFO:Lars(random_state=8186)
2025-04-03 12:16:21,456:INFO:create_model() successfully completed......................................
2025-04-03 12:16:21,563:INFO:Initializing create_model()
2025-04-03 12:16:21,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=LassoLars(random_state=8186), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:21,563:INFO:Checking exceptions
2025-04-03 12:16:21,563:INFO:Importing libraries
2025-04-03 12:16:21,564:INFO:Copying training dataset
2025-04-03 12:16:21,568:INFO:Defining folds
2025-04-03 12:16:21,568:INFO:Declaring metric variables
2025-04-03 12:16:21,568:INFO:Importing untrained model
2025-04-03 12:16:21,568:INFO:Declaring custom model
2025-04-03 12:16:21,569:INFO:Lasso Least Angle Regression Imported successfully
2025-04-03 12:16:21,570:INFO:Cross validation set to False
2025-04-03 12:16:21,570:INFO:Fitting Model
2025-04-03 12:16:21,635:INFO:LassoLars(random_state=8186)
2025-04-03 12:16:21,635:INFO:create_model() successfully completed......................................
2025-04-03 12:16:21,751:INFO:_master_model_container: 18
2025-04-03 12:16:21,751:INFO:_display_container: 2
2025-04-03 12:16:21,753:INFO:[Ridge(random_state=8186), LinearRegression(n_jobs=-1), Lasso(random_state=8186), Lars(random_state=8186), LassoLars(random_state=8186)]
2025-04-03 12:16:21,753:INFO:compare_models() successfully completed......................................
2025-04-03 12:16:21,756:INFO:Initializing tune_model()
2025-04-03 12:16:21,756:INFO:tune_model(estimator=Ridge(random_state=8186), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>)
2025-04-03 12:16:21,756:INFO:Checking exceptions
2025-04-03 12:16:21,761:INFO:Copying training dataset
2025-04-03 12:16:21,764:INFO:Checking base model
2025-04-03 12:16:21,764:INFO:Base model : Ridge Regression
2025-04-03 12:16:21,765:INFO:Declaring metric variables
2025-04-03 12:16:21,765:INFO:Defining Hyperparameters
2025-04-03 12:16:21,951:INFO:Tuning with n_jobs=-1
2025-04-03 12:16:21,951:INFO:Initializing RandomizedSearchCV
2025-04-03 12:16:24,321:INFO:best_params: {'actual_estimator__fit_intercept': False, 'actual_estimator__alpha': 7.58}
2025-04-03 12:16:24,323:INFO:Hyperparameter search completed
2025-04-03 12:16:24,323:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:24,323:INFO:Initializing create_model()
2025-04-03 12:16:24,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=Ridge(random_state=8186), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000028FC4392CB0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'fit_intercept': False, 'alpha': 7.58})
2025-04-03 12:16:24,323:INFO:Checking exceptions
2025-04-03 12:16:24,323:INFO:Importing libraries
2025-04-03 12:16:24,323:INFO:Copying training dataset
2025-04-03 12:16:24,327:INFO:Defining folds
2025-04-03 12:16:24,327:INFO:Declaring metric variables
2025-04-03 12:16:24,328:INFO:Importing untrained model
2025-04-03 12:16:24,328:INFO:Declaring custom model
2025-04-03 12:16:24,328:INFO:Ridge Regression Imported successfully
2025-04-03 12:16:24,329:INFO:Starting cross validation
2025-04-03 12:16:24,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:24,616:INFO:Calculating mean and std
2025-04-03 12:16:24,617:INFO:Creating metrics dataframe
2025-04-03 12:16:24,618:INFO:Finalizing model
2025-04-03 12:16:24,683:INFO:Uploading results into container
2025-04-03 12:16:24,683:INFO:Uploading model into container now
2025-04-03 12:16:24,684:INFO:_master_model_container: 19
2025-04-03 12:16:24,684:INFO:_display_container: 3
2025-04-03 12:16:24,684:INFO:Ridge(alpha=7.58, fit_intercept=False, random_state=8186)
2025-04-03 12:16:24,684:INFO:create_model() successfully completed......................................
2025-04-03 12:16:24,787:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:24,787:INFO:choose_better activated
2025-04-03 12:16:24,787:INFO:SubProcess create_model() called ==================================
2025-04-03 12:16:24,788:INFO:Initializing create_model()
2025-04-03 12:16:24,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=Ridge(random_state=8186), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-04-03 12:16:24,788:INFO:Checking exceptions
2025-04-03 12:16:24,789:INFO:Importing libraries
2025-04-03 12:16:24,789:INFO:Copying training dataset
2025-04-03 12:16:24,792:INFO:Defining folds
2025-04-03 12:16:24,794:INFO:Declaring metric variables
2025-04-03 12:16:24,794:INFO:Importing untrained model
2025-04-03 12:16:24,794:INFO:Declaring custom model
2025-04-03 12:16:24,794:INFO:Ridge Regression Imported successfully
2025-04-03 12:16:24,794:INFO:Starting cross validation
2025-04-03 12:16:24,796:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-04-03 12:16:25,079:INFO:Calculating mean and std
2025-04-03 12:16:25,079:INFO:Creating metrics dataframe
2025-04-03 12:16:25,081:INFO:Finalizing model
2025-04-03 12:16:25,147:INFO:Uploading results into container
2025-04-03 12:16:25,148:INFO:Uploading model into container now
2025-04-03 12:16:25,148:INFO:_master_model_container: 20
2025-04-03 12:16:25,148:INFO:_display_container: 4
2025-04-03 12:16:25,148:INFO:Ridge(random_state=8186)
2025-04-03 12:16:25,148:INFO:create_model() successfully completed......................................
2025-04-03 12:16:25,249:INFO:SubProcess create_model() end ==================================
2025-04-03 12:16:25,250:INFO:Ridge(random_state=8186) result for R2 is 0.6577
2025-04-03 12:16:25,250:INFO:Ridge(alpha=7.58, fit_intercept=False, random_state=8186) result for R2 is 0.6605
2025-04-03 12:16:25,251:INFO:Ridge(alpha=7.58, fit_intercept=False, random_state=8186) is best model
2025-04-03 12:16:25,251:INFO:choose_better completed
2025-04-03 12:16:25,260:INFO:_master_model_container: 20
2025-04-03 12:16:25,260:INFO:_display_container: 3
2025-04-03 12:16:25,260:INFO:Ridge(alpha=7.58, fit_intercept=False, random_state=8186)
2025-04-03 12:16:25,260:INFO:tune_model() successfully completed......................................
2025-04-03 12:16:25,462:INFO:Initializing save_model()
2025-04-03 12:16:25,462:INFO:save_model(model=Ridge(alpha=7.58, fit_intercept=False, random_state=8186), model_name=best_regressor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2025-04-03 12:16:25,462:INFO:Adding model into prep_pipe
2025-04-03 12:16:25,473:INFO:best_regressor.pkl saved in current working directory
2025-04-03 12:16:25,566:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'furnishingstatus'],
                                    transformer=SimpleImput...
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 Ridge(alpha=7.58, fit_intercept=False, random_state=8186))])
2025-04-03 12:16:25,566:INFO:save_model() successfully completed......................................
2025-04-03 12:18:12,299:INFO:PyCaret ClusteringExperiment
2025-04-03 12:18:12,299:INFO:Logging name: cluster-default-name
2025-04-03 12:18:12,299:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-03 12:18:12,299:INFO:version 3.3.2
2025-04-03 12:18:12,300:INFO:Initializing setup()
2025-04-03 12:18:12,300:INFO:self.USI: 8483
2025-04-03 12:18:12,300:INFO:self._variable_keys: {'pipeline', 'data', 'n_jobs_param', 'logging_param', 'exp_name_log', 'X', 'seed', 'idx', 'USI', 'html_param', 'gpu_n_jobs_param', 'gpu_param', '_ml_usecase', 'exp_id', 'log_plots_param', '_available_plots', 'memory'}
2025-04-03 12:18:12,300:INFO:Checking environment
2025-04-03 12:18:12,300:INFO:python_version: 3.10.0
2025-04-03 12:18:12,300:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-03 12:18:12,300:INFO:machine: AMD64
2025-04-03 12:18:12,300:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-03 12:18:12,307:INFO:Memory: svmem(total=17037209600, available=3638890496, percent=78.6, used=13398319104, free=3638890496)
2025-04-03 12:18:12,307:INFO:Physical Core: 6
2025-04-03 12:18:12,307:INFO:Logical Core: 12
2025-04-03 12:18:12,307:INFO:Checking libraries
2025-04-03 12:18:12,307:INFO:System:
2025-04-03 12:18:12,307:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-03 12:18:12,307:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-04-03 12:18:12,307:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-03 12:18:12,307:INFO:PyCaret required dependencies:
2025-04-03 12:18:12,308:INFO:                 pip: 21.2.3
2025-04-03 12:18:12,308:INFO:          setuptools: 57.4.0
2025-04-03 12:18:12,308:INFO:             pycaret: 3.3.2
2025-04-03 12:18:12,308:INFO:             IPython: 8.29.0
2025-04-03 12:18:12,308:INFO:          ipywidgets: 8.1.5
2025-04-03 12:18:12,308:INFO:                tqdm: 4.67.0
2025-04-03 12:18:12,308:INFO:               numpy: 1.26.4
2025-04-03 12:18:12,308:INFO:              pandas: 2.1.4
2025-04-03 12:18:12,308:INFO:              jinja2: 3.1.4
2025-04-03 12:18:12,308:INFO:               scipy: 1.11.4
2025-04-03 12:18:12,308:INFO:              joblib: 1.3.2
2025-04-03 12:18:12,308:INFO:             sklearn: 1.4.2
2025-04-03 12:18:12,308:INFO:                pyod: 2.0.2
2025-04-03 12:18:12,308:INFO:            imblearn: 0.12.4
2025-04-03 12:18:12,308:INFO:   category_encoders: 2.6.4
2025-04-03 12:18:12,308:INFO:            lightgbm: 4.5.0
2025-04-03 12:18:12,308:INFO:               numba: 0.60.0
2025-04-03 12:18:12,308:INFO:            requests: 2.32.3
2025-04-03 12:18:12,309:INFO:          matplotlib: 3.7.5
2025-04-03 12:18:12,309:INFO:          scikitplot: 0.3.7
2025-04-03 12:18:12,309:INFO:         yellowbrick: 1.5
2025-04-03 12:18:12,309:INFO:              plotly: 5.24.1
2025-04-03 12:18:12,309:INFO:    plotly-resampler: Not installed
2025-04-03 12:18:12,309:INFO:             kaleido: 0.2.1
2025-04-03 12:18:12,309:INFO:           schemdraw: 0.15
2025-04-03 12:18:12,309:INFO:         statsmodels: 0.14.4
2025-04-03 12:18:12,309:INFO:              sktime: 0.26.0
2025-04-03 12:18:12,309:INFO:               tbats: 1.1.3
2025-04-03 12:18:12,309:INFO:            pmdarima: 2.0.4
2025-04-03 12:18:12,309:INFO:              psutil: 6.1.0
2025-04-03 12:18:12,309:INFO:          markupsafe: 3.0.2
2025-04-03 12:18:12,309:INFO:             pickle5: Not installed
2025-04-03 12:18:12,309:INFO:         cloudpickle: 3.1.0
2025-04-03 12:18:12,309:INFO:         deprecation: 2.1.0
2025-04-03 12:18:12,309:INFO:              xxhash: 3.5.0
2025-04-03 12:18:12,309:INFO:           wurlitzer: Not installed
2025-04-03 12:18:12,309:INFO:PyCaret optional dependencies:
2025-04-03 12:18:12,309:INFO:                shap: 0.47.0
2025-04-03 12:18:12,309:INFO:           interpret: Not installed
2025-04-03 12:18:12,309:INFO:                umap: Not installed
2025-04-03 12:18:12,309:INFO:     ydata_profiling: 4.12.0
2025-04-03 12:18:12,309:INFO:  explainerdashboard: Not installed
2025-04-03 12:18:12,309:INFO:             autoviz: Not installed
2025-04-03 12:18:12,309:INFO:           fairlearn: Not installed
2025-04-03 12:18:12,309:INFO:          deepchecks: Not installed
2025-04-03 12:18:12,309:INFO:             xgboost: Not installed
2025-04-03 12:18:12,309:INFO:            catboost: Not installed
2025-04-03 12:18:12,309:INFO:              kmodes: Not installed
2025-04-03 12:18:12,309:INFO:             mlxtend: Not installed
2025-04-03 12:18:12,309:INFO:       statsforecast: Not installed
2025-04-03 12:18:12,309:INFO:        tune_sklearn: Not installed
2025-04-03 12:18:12,309:INFO:                 ray: Not installed
2025-04-03 12:18:12,309:INFO:            hyperopt: Not installed
2025-04-03 12:18:12,309:INFO:              optuna: Not installed
2025-04-03 12:18:12,309:INFO:               skopt: Not installed
2025-04-03 12:18:12,309:INFO:              mlflow: Not installed
2025-04-03 12:18:12,309:INFO:              gradio: Not installed
2025-04-03 12:18:12,309:INFO:             fastapi: Not installed
2025-04-03 12:18:12,310:INFO:             uvicorn: Not installed
2025-04-03 12:18:12,310:INFO:              m2cgen: Not installed
2025-04-03 12:18:12,310:INFO:           evidently: Not installed
2025-04-03 12:18:12,310:INFO:               fugue: Not installed
2025-04-03 12:18:12,310:INFO:           streamlit: 1.40.0
2025-04-03 12:18:12,310:INFO:             prophet: Not installed
2025-04-03 12:18:12,310:INFO:None
2025-04-03 12:18:12,310:INFO:Set up data.
2025-04-03 12:18:12,313:INFO:Set up index.
2025-04-03 12:18:12,314:INFO:Assigning column types.
2025-04-03 12:18:12,316:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-03 12:18:12,316:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-03 12:18:12,316:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:18:12,317:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-03 12:18:12,317:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:18:12,317:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-03 12:18:12,317:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:18:12,317:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:18:12,318:INFO:Preparing preprocessing pipeline...
2025-04-03 12:18:12,318:INFO:Set up simple imputation.
2025-04-03 12:18:12,335:INFO:Finished creating preprocessing pipeline.
2025-04-03 12:18:12,338:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-04-03 12:18:12,339:INFO:Creating final display dataframe.
2025-04-03 12:18:12,359:INFO:Setup _display_container:                Description                 Value
0               Session id                  2048
1      Original data shape              (400, 5)
2   Transformed data shape              (400, 5)
3         Numeric features                     5
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                 CPU Jobs                    -1
9                  Use GPU                 False
10          Log Experiment                 False
11         Experiment Name  cluster-default-name
12                     USI                  8483
2025-04-03 12:18:12,363:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:18:12,364:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:18:12,364:INFO:setup() successfully completed in 0.07s...............
2025-04-03 12:18:12,364:INFO:Initializing create_model()
2025-04-03 12:18:12,364:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000028FC42C1420>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-04-03 12:18:12,364:INFO:Checking exceptions
2025-04-03 12:18:12,377:INFO:Importing untrained model
2025-04-03 12:18:12,377:INFO:K-Means Clustering Imported successfully
2025-04-03 12:18:12,379:INFO:Fitting Model
2025-04-03 12:18:12,631:INFO:KMeans(n_clusters=4, random_state=2048)
2025-04-03 12:18:12,631:INFO:create_models() successfully completed......................................
2025-04-03 12:18:12,632:INFO:Uploading results into container
2025-04-03 12:18:12,633:INFO:Uploading model into container now
2025-04-03 12:18:12,640:INFO:_master_model_container: 1
2025-04-03 12:18:12,640:INFO:_display_container: 2
2025-04-03 12:18:12,640:INFO:KMeans(n_clusters=4, random_state=2048)
2025-04-03 12:18:12,640:INFO:create_model() successfully completed......................................
2025-04-03 12:18:12,771:INFO:Initializing save_model()
2025-04-03 12:18:12,771:INFO:save_model(model=KMeans(n_clusters=4, random_state=2048), model_name=best_clustering, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.CLUSTERING, kwargs={})
2025-04-03 12:18:12,772:INFO:Adding model into prep_pipe
2025-04-03 12:18:12,776:INFO:best_clustering.pkl saved in current working directory
2025-04-03 12:18:12,780:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', KMeans(n_clusters=4, random_state=2048))])
2025-04-03 12:18:12,780:INFO:save_model() successfully completed......................................
2025-04-03 12:27:14,099:INFO:Initializing load_model()
2025-04-03 12:27:14,100:INFO:load_model(model_name=best_regressor, platform=None, authentication=None, verbose=True)
2025-04-03 12:27:14,201:INFO:Initializing predict_model()
2025-04-03 12:27:14,201:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x0000028FFB5C49A0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fu...
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model',
                 Ridge(alpha=7.58, fit_intercept=False, random_state=8186))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028F807BB0A0>)
2025-04-03 12:27:14,201:INFO:Checking exceptions
2025-04-03 12:27:14,201:INFO:Preloading libraries
2025-04-03 12:27:14,201:INFO:Set up data.
2025-04-03 12:27:14,206:INFO:Set up index.
2025-04-03 12:27:44,007:INFO:Initializing load_model()
2025-04-03 12:27:44,008:INFO:load_model(model_name=best_classifier, platform=None, authentication=None, verbose=True)
2025-04-03 12:27:44,051:INFO:Initializing predict_model()
2025-04-03 12:27:44,051:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000028FFB359F00>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(C=2.007, class_weight={}, max_iter=1000,
                                    random_state=8994))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x0000028F807BACB0>)
2025-04-03 12:27:44,051:INFO:Checking exceptions
2025-04-03 12:27:44,051:INFO:Preloading libraries
2025-04-03 12:27:44,053:INFO:Set up data.
2025-04-03 12:27:44,061:INFO:Set up index.
2025-04-03 12:29:02,505:INFO:PyCaret ClusteringExperiment
2025-04-03 12:29:02,505:INFO:Logging name: cluster-default-name
2025-04-03 12:29:02,505:INFO:ML Usecase: MLUsecase.CLUSTERING
2025-04-03 12:29:02,505:INFO:version 3.3.2
2025-04-03 12:29:02,505:INFO:Initializing setup()
2025-04-03 12:29:02,505:INFO:self.USI: 47be
2025-04-03 12:29:02,505:INFO:self._variable_keys: {'pipeline', 'data', 'n_jobs_param', 'logging_param', 'exp_name_log', 'X', 'seed', 'idx', 'USI', 'html_param', 'gpu_n_jobs_param', 'gpu_param', '_ml_usecase', 'exp_id', 'log_plots_param', '_available_plots', 'memory'}
2025-04-03 12:29:02,505:INFO:Checking environment
2025-04-03 12:29:02,505:INFO:python_version: 3.10.0
2025-04-03 12:29:02,506:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2025-04-03 12:29:02,506:INFO:machine: AMD64
2025-04-03 12:29:02,506:INFO:platform: Windows-10-10.0.26100-SP0
2025-04-03 12:29:02,511:INFO:Memory: svmem(total=17037209600, available=5219368960, percent=69.4, used=11817840640, free=5219368960)
2025-04-03 12:29:02,511:INFO:Physical Core: 6
2025-04-03 12:29:02,511:INFO:Logical Core: 12
2025-04-03 12:29:02,511:INFO:Checking libraries
2025-04-03 12:29:02,511:INFO:System:
2025-04-03 12:29:02,511:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2025-04-03 12:29:02,511:INFO:executable: C:\Users\suvam\AppData\Local\Programs\Python\Python310\python.exe
2025-04-03 12:29:02,511:INFO:   machine: Windows-10-10.0.26100-SP0
2025-04-03 12:29:02,511:INFO:PyCaret required dependencies:
2025-04-03 12:29:02,511:INFO:                 pip: 21.2.3
2025-04-03 12:29:02,511:INFO:          setuptools: 57.4.0
2025-04-03 12:29:02,511:INFO:             pycaret: 3.3.2
2025-04-03 12:29:02,511:INFO:             IPython: 8.29.0
2025-04-03 12:29:02,511:INFO:          ipywidgets: 8.1.5
2025-04-03 12:29:02,511:INFO:                tqdm: 4.67.0
2025-04-03 12:29:02,511:INFO:               numpy: 1.26.4
2025-04-03 12:29:02,511:INFO:              pandas: 2.1.4
2025-04-03 12:29:02,511:INFO:              jinja2: 3.1.4
2025-04-03 12:29:02,511:INFO:               scipy: 1.11.4
2025-04-03 12:29:02,511:INFO:              joblib: 1.3.2
2025-04-03 12:29:02,511:INFO:             sklearn: 1.4.2
2025-04-03 12:29:02,511:INFO:                pyod: 2.0.2
2025-04-03 12:29:02,511:INFO:            imblearn: 0.12.4
2025-04-03 12:29:02,511:INFO:   category_encoders: 2.6.4
2025-04-03 12:29:02,511:INFO:            lightgbm: 4.5.0
2025-04-03 12:29:02,511:INFO:               numba: 0.60.0
2025-04-03 12:29:02,511:INFO:            requests: 2.32.3
2025-04-03 12:29:02,511:INFO:          matplotlib: 3.7.5
2025-04-03 12:29:02,513:INFO:          scikitplot: 0.3.7
2025-04-03 12:29:02,513:INFO:         yellowbrick: 1.5
2025-04-03 12:29:02,513:INFO:              plotly: 5.24.1
2025-04-03 12:29:02,513:INFO:    plotly-resampler: Not installed
2025-04-03 12:29:02,513:INFO:             kaleido: 0.2.1
2025-04-03 12:29:02,513:INFO:           schemdraw: 0.15
2025-04-03 12:29:02,513:INFO:         statsmodels: 0.14.4
2025-04-03 12:29:02,513:INFO:              sktime: 0.26.0
2025-04-03 12:29:02,513:INFO:               tbats: 1.1.3
2025-04-03 12:29:02,513:INFO:            pmdarima: 2.0.4
2025-04-03 12:29:02,513:INFO:              psutil: 6.1.0
2025-04-03 12:29:02,513:INFO:          markupsafe: 3.0.2
2025-04-03 12:29:02,513:INFO:             pickle5: Not installed
2025-04-03 12:29:02,513:INFO:         cloudpickle: 3.1.0
2025-04-03 12:29:02,513:INFO:         deprecation: 2.1.0
2025-04-03 12:29:02,513:INFO:              xxhash: 3.5.0
2025-04-03 12:29:02,513:INFO:           wurlitzer: Not installed
2025-04-03 12:29:02,513:INFO:PyCaret optional dependencies:
2025-04-03 12:29:02,513:INFO:                shap: 0.47.0
2025-04-03 12:29:02,513:INFO:           interpret: Not installed
2025-04-03 12:29:02,513:INFO:                umap: Not installed
2025-04-03 12:29:02,513:INFO:     ydata_profiling: 4.12.0
2025-04-03 12:29:02,514:INFO:  explainerdashboard: Not installed
2025-04-03 12:29:02,514:INFO:             autoviz: Not installed
2025-04-03 12:29:02,514:INFO:           fairlearn: Not installed
2025-04-03 12:29:02,514:INFO:          deepchecks: Not installed
2025-04-03 12:29:02,514:INFO:             xgboost: Not installed
2025-04-03 12:29:02,514:INFO:            catboost: Not installed
2025-04-03 12:29:02,514:INFO:              kmodes: Not installed
2025-04-03 12:29:02,514:INFO:             mlxtend: Not installed
2025-04-03 12:29:02,514:INFO:       statsforecast: Not installed
2025-04-03 12:29:02,514:INFO:        tune_sklearn: Not installed
2025-04-03 12:29:02,514:INFO:                 ray: Not installed
2025-04-03 12:29:02,514:INFO:            hyperopt: Not installed
2025-04-03 12:29:02,514:INFO:              optuna: Not installed
2025-04-03 12:29:02,514:INFO:               skopt: Not installed
2025-04-03 12:29:02,514:INFO:              mlflow: Not installed
2025-04-03 12:29:02,514:INFO:              gradio: Not installed
2025-04-03 12:29:02,514:INFO:             fastapi: Not installed
2025-04-03 12:29:02,514:INFO:             uvicorn: Not installed
2025-04-03 12:29:02,514:INFO:              m2cgen: Not installed
2025-04-03 12:29:02,514:INFO:           evidently: Not installed
2025-04-03 12:29:02,514:INFO:               fugue: Not installed
2025-04-03 12:29:02,514:INFO:           streamlit: 1.40.0
2025-04-03 12:29:02,514:INFO:             prophet: Not installed
2025-04-03 12:29:02,514:INFO:None
2025-04-03 12:29:02,514:INFO:Set up data.
2025-04-03 12:29:02,517:INFO:Set up index.
2025-04-03 12:29:02,517:INFO:Assigning column types.
2025-04-03 12:29:02,518:INFO:Engine successfully changes for model 'kmeans' to 'sklearn'.
2025-04-03 12:29:02,518:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-03 12:29:02,519:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:29:02,519:INFO:Engine for model 'dbscan' has not been set explicitly, hence returning None.
2025-04-03 12:29:02,519:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:29:02,519:INFO:Engine successfully changes for model 'dbscan' to 'sklearn'.
2025-04-03 12:29:02,519:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:29:02,519:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:29:02,520:INFO:Preparing preprocessing pipeline...
2025-04-03 12:29:02,520:INFO:Set up simple imputation.
2025-04-03 12:29:02,538:INFO:Finished creating preprocessing pipeline.
2025-04-03 12:29:02,543:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-04-03 12:29:02,543:INFO:Creating final display dataframe.
2025-04-03 12:29:02,559:INFO:Setup _display_container:                Description                 Value
0               Session id                  1840
1      Original data shape              (400, 5)
2   Transformed data shape              (400, 5)
3         Numeric features                     5
4               Preprocess                  True
5          Imputation type                simple
6       Numeric imputation                  mean
7   Categorical imputation                  mode
8                 CPU Jobs                    -1
9                  Use GPU                 False
10          Log Experiment                 False
11         Experiment Name  cluster-default-name
12                     USI                  47be
2025-04-03 12:29:02,563:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:29:02,563:WARNING:
'kmodes' is a soft dependency and not included in the pycaret installation. Please run: `pip install kmodes` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-04-03 12:29:02,563:INFO:setup() successfully completed in 0.06s...............
2025-04-03 12:29:02,563:INFO:Initializing create_model()
2025-04-03 12:29:02,564:INFO:create_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000028FFF20DB10>, estimator=kmeans, num_clusters=4, fraction=0.05, ground_truth=None, round=4, fit_kwargs=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, raise_num_clusters=False, display=None, kwargs={})
2025-04-03 12:29:02,564:INFO:Checking exceptions
2025-04-03 12:29:02,576:INFO:Importing untrained model
2025-04-03 12:29:02,576:INFO:K-Means Clustering Imported successfully
2025-04-03 12:29:02,577:INFO:Fitting Model
2025-04-03 12:29:02,596:INFO:KMeans(n_clusters=4, random_state=1840)
2025-04-03 12:29:02,596:INFO:create_models() successfully completed......................................
2025-04-03 12:29:02,596:INFO:Uploading results into container
2025-04-03 12:29:02,597:INFO:Uploading model into container now
2025-04-03 12:29:02,603:INFO:_master_model_container: 1
2025-04-03 12:29:02,603:INFO:_display_container: 2
2025-04-03 12:29:02,603:INFO:KMeans(n_clusters=4, random_state=1840)
2025-04-03 12:29:02,603:INFO:create_model() successfully completed......................................
2025-04-03 12:29:02,704:INFO:Initializing save_model()
2025-04-03 12:29:02,705:INFO:save_model(model=KMeans(n_clusters=4, random_state=1840), model_name=best_clustering, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))]), verbose=True, use_case=MLUsecase.CLUSTERING, kwargs={})
2025-04-03 12:29:02,705:INFO:Adding model into prep_pipe
2025-04-03 12:29:02,707:INFO:best_clustering.pkl saved in current working directory
2025-04-03 12:29:02,711:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', KMeans(n_clusters=4, random_state=1840))])
2025-04-03 12:29:02,711:INFO:save_model() successfully completed......................................
2025-04-03 12:29:12,727:INFO:Initializing load_model()
2025-04-03 12:29:12,727:INFO:load_model(model_name=best_clustering, platform=None, authentication=None, verbose=True)
2025-04-03 12:29:12,735:INFO:Initializing predict_model()
2025-04-03 12:29:12,735:INFO:predict_model(self=<pycaret.clustering.oop.ClusteringExperiment object at 0x0000028FFF20DB10>, estimator=Pipeline(memory=FastMemory(location=C:\Users\suvam\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Customer_ID', 'Age',
                                             'Annual_Income', 'Spending_Score',
                                             'Purchase_Frequency'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('trained_model', KMeans(n_clusters=4, random_state=1840))]), ml_usecase=None)
2025-04-03 12:29:12,735:INFO:Set up data.
